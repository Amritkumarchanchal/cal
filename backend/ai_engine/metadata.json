{"Learn Machine Learning Like a GENIUS and Not Waste Time": [{"content": "so you want to learn machine learning and you somehow ended up here well I've got good news and bad news the bad news I'm not here to sell you some become an ml engineer in 3 months fantasy could it happen sure people also win the lottery the good news I've been exactly where you are about 8 years ago I thought I knew enough Basics to just apply for jobs and learn the rest while working spoiler alert I failed miserably but those failures taught me exactly what works and what doesn't and that's what I'm sharing today I've since taught all of this to hundreds of students in several countries so I think I have a good idea on what works and what doesn't hopefully I can save you months of frustration by showing you the smart way to learn machine learning learning data science was one of the best decisions I ever made and most of you can do it and you will learn some cool stuff on the way that even if you don't become a data scientist or machine learning engineer you will have learned programming how to build apps how to analyze and visualize data you will have strong statistics and research skills and be able to communicate data clearly many amazing job options will be open to you even if you don't become a data scientist but you will have to work hard but what should you work hard on and how do we even start that's what I'm here to tell you learning how to learn before we even touch machine learning let's talk about something crucial learning how to learn why because machine learning and AI like most things in Tech are constantly evolving and what matters isn't just what you know but how quickly you can adapt and learn new things a little secret I actually suck at at programming and algorithms but I am really good at learning new stuff here's why this matters specifically for machine learning technology changes fast new platforms and Frameworks drop constantly and new papers come out daily what's hot today might be obsolete tomorrow problem solving is everything machine learning isn't about memorizing algorithms it's about understanding data and patterns about breaking down complex problems and finding Creative Solutions confidence AKA don't get overwhelmed or scared of big problems people who know how to learn and problem solve don't get paralyzed when faced with a new big problem they develop a strategy for how to look at a new problem and break it down into manageable problems they have faced before they know how to look up Solutions and find tools necessary to solve new problems they adapt more quickly when Tech changes efficiency if you know how to learn you won't waste time on unnecessary things time is money learn what you actually need to get where you want to be there's no one size fits all solution for learning something it depends on your style of learning but also on your goals not everyone needs to learn everything so how do you learn how to learn this one you kind of have to figure out for yourself because what works for one person doesn't necessarily work for the next some people learn well with graphs and diagrams others with text others maybe with voice notes some people need to understand the theory before applying it others need to jump right in and use an algorithm before asking what it actually does in this video I will try to show you what worked for me while giving you resources that I believe will get you there as quickly as possible I will just mention a principle that has helped me a lot throughout my career the the Paro principle sometimes called 8020 principle it says that 80% of the results come from 20% of the effort constantly ask yourself why am I doing this is this actually getting me where I want to be or can I do something more useful with my time well the answer to this question isn't always the same for everyone I will try to now give you the 20% of the work that would have gotten me 80% of the way to becoming a data scientist adapt as needed but where do I start now let's build your machine Learning Foundation the right way here's your road map python while the next skill is at least as important I would start with learning python the main reason is that you will get a feeling of achievement fairly quickly and python is super simple why python python is the main language of data analytics data science and machine learning while also being a full-fledged programming language allowing you to write scripts build apps and websites and much more python will allow you to actually start writing real code within days without having to learn super complicated computer science Concepts like pointers memory allocation and garbage collection also with python you will be able to get a job as a programmer or data analyst or web developer even if you don't learn all the hard machine learning stuff I suggest you first install jupyter notebooks as they make learning much easier and jupyter notebooks are also a core tool for data analysts and data scientists all over the world then learn about these Core Concepts programming fundamentals basic syntax indentation rules comments and so on variables math if else Loops printing data types like strings ins floats booleans lists dictionaries functions classes and objects modules packages and importing do a pandas tutorial pandas is Python's primary data manipulation Library built for handling tabular data through data frame objects imagine it as Excel spreadsheets on steroids it will be your main tool for data analysis cleaning and transformation with powerful functions for merging reshaping and analyzing data the library strength lies in combining the power of numpy arrays with spreadsheet like functionality and SQL database like joints it also comes with built-in plotting functionality built on top of Python's powerful met plot lib libraries pandas is a true data analysis Powerhouse if you truly Master pandas you will excel at most data analysis positions in the world also because exploratory data analysis and data preparation are about 60 to 80% of a data scientist job it will also lay the foundation for that 8020 principle remember your First Data analysis project so before you get into any machine learning I would take the time here to work on an actual project to deepen your python pandas and data analysis knowledge as I mentioned in my previous videos real projects beat tutorials at developing a good data scientist find some data you want to analyze maybe from one of your old jobs or school maybe you can export some data from your favorite health tracker or ask some friends if they have some data they want analyzed or maybe download public data from the government the World Bank or a nonprofit any topic you're interested in it could be economics Sports politics video games the board games this last one was a passion of one of my former students work on importing the data into pandas clean up the data make the units uniform decide what to do about missing data and outliers plot the different variables look at correlations between variables and come up with some hypothesis about the data and test them by making more plots turn your results into a slideshow with nice graphs that tell a story that you can present to friends and family Pro tip Jupiter notebooks with data and plots can be turned directly into a slideshow this will also be the first project for your port portfolio which you can show when applying for jobs as a data analyst essential math for machine learning this might be the part that most of you fear the most but I think it is the most important part for anyone wanting to learn machine learning you should take this seriously you don't need to be a math genius or know about all of math to become good at machine learning but you need to really understand the Core Concepts from the areas I'm about to mention for more details on math for machine learning check out my video on the topic basic statistics and probability this for me is the most important Branch as a data analyst and data scientist now there are many online resources for statistics but I highly suggest taking the Con Academy statistics and probability course this course is completely free and is the one I took when I prepared for my first job as a data scientist the full course is probably around 50 hours of content so if you have prior math knowledge you probably won't spend more than 100 hours on this but it might take you longer that's around 2 3 weeks of full-time self-study more if much of this is completely new to you but please take the time to do this it will make everything that follows so much easier and save you much more than 100 hours of headaches later on ideally while you learn new Concepts here you go to your data set from the previous data analysis project phase and try to apply them there to deepen your intuition linear algebra fundamentals while also important linear algebra for machine learning is much more about learning some tools and rules this should be much quicker than learning probability and statistics Concepts the main thing you want to learn is how to operate with vectors and matrices and learn what the different operations mean this is more about mathem iCal tools and notations than Concepts I think learning this will take about a quarter to a third of the time it took you to learn the statistics Concepts so one or two weeks of studying should be enough for people with prior math knowledge I will also leave the link to the Khan Academy linear algebra course in the description calculus here again it's about learning some tools but also understanding what derivatives are conceptually and how they help in optimization problems you should really understand how functions and their derivatives work and know the basic rules of differentiation like the chain rule I would again calculate with one or two weeks if you have prior math knowledge I will also leave a con Academy Link in the description Pro tip you need working knowledge not a math PhD focus on intuition over proofs spend most your time on statistical concepts for linear algebra and calculus focus on learning the tools like Matrix operations and how to take the derivative of a function the core machine learning Concepts and algorithms now here's where many people mess up they jump straight to Deep learning but that's a mistake in my opinion you should spend most of your time on simple algorithms the reasons for that are manifold and discussed in my previous videos but basically many problems don't require complicated solution simple algorithms like linear regression are quicker to run they're more generalizable more interpretable and easier to learn from and communicate and more importantly these algorithms form the basis for the more complicated algorithms like neural networks so truly understanding them will help you understand the more complicated algorithms better too check out my video on machine learning algorithms but basically before getting into neural networks or even svm make sure you understand how linear regression and logistic regression work then look at decision trees and Ensemble algorithms like random forests and gradient boosting I learned most of these topics from the book an introduction to statistical learning the majority of you will prefer learning from videos so just watch the Youtube video series about this book by the authors themselves completely for free on YouTube I will leave a link in the description all the videos together are about 20 hours but since you will want to pause and take notes and read up on certain Concepts I think this will be another 100 hours or so of study time so that should be another two or more weeks of full-time self-study all these numbers are estimates as everyone learns at different speeds do a scikit learn tutorial scit learn is the number one machine learning library in the world for basic machine learning algorithms you can do a basic sklearn tutorial in a day or two and the good thing is that the simple and consistent syntax makes it such that once you know how to use the library for one algorithm you know how to use it for any algorithm as long as you know what algorithm is meant for what which you now know because you just learned it pyit learn also comes with great documentation and toy data sets to play around with I suggest you start using psyit learn while you are learning about the algorithms in the statistical learning course the genius move while you learn about the theory behind new algorithms for example going through the statistical learning course and starting with linear regression Implement and use the algorithm in the following three three ways implemented from scratch using basic python implemented using scikit learn using a toy data set then use both your own implementation and the syit learn toolkit to try out the algorithm on a real data set that you have prepared yourself now there's a common Pitfall that many beginners get stuck in tutorial hell it's where you essentially just keep following tutorials without striking out on your own and actually building something most learning comes from the trial and error of building an application so if you always follow a tutorial you get Stu at a basic level how do you not get stuck there do just one or two tutorials per area Max and then work on a real project your first machine learning project here you can either continue with your data analysis project from before or find a new more interesting data set for a machine learning project but don't forget to still use pandas to do an exploratory data analysis to prepare your data for modeling and form hypothesis about your data more often than not the goal of a machine learning project will be to predict some variable from other variables research the industry of your project a bit look at the data and make some hypothesis about what might influence your target variable either based on intuition about the industry or from looking at correlations and Scatter Plots of different variables design new features based on your knowledge of the problem then start modeling but start with simple algorithms like linear regression logistic regression and decision trees then move on to more complex algorithms like svm random forests or gradient boosting note how as complexity increases accuracy usually increases but interpretability decreases your goal is usually to find a sweet spot also don't forget over fitting as you increase in model complexity keep validation and test sets aside before starting to model and compare your models using the test set at the very end many times the more complex algorithms don't look as good anymore once you use the final test set it might be a good idea to work with data sets that have been published on sites like kaggle to then compare your Solutions and accuracies to other people's Solutions and get an idea of how well your models are in comparison to others but don't get frustrated a lot of people on kaggle are professionals with years of experience if you get anywhere close in accuracy you should be happy don't know what to work on you can start with a tutorial but instead of following it directly after building the core features add some features change some features swap out the data set and try to break your code and then fix it this is one of the best ways to learn while not getting stuck in tutorial hell collaborate and share your projects with others learning ML and isolation is the slowest way to learn instead find coding buddies to work on a project with present your work to friends and family or post it publicly on GitHub or in machine learning communities have someone more advanced than you give you feedback this will speed up your learning 10 times don't know anyone to work on a project with participate in a hackathon or write to people with similar interests on kaggle GitHub Discord Reddit LinkedIn Etc the connections you form this way will not only help you learn better but boost your career in unexpected ways check out my most recent video to learn more about the importance of networking and data science Advanced topics only now should you look at more advanced topics deep learning architectures cnns for computer vision RNN for sequential data or Transformers for NLP Advanced optimization techniques model deployment strategies and the latest research papers remember learn these by need not by fomo you don't need to know everything just learn these techniques if they are important to your project here some dos and don'ts don't don't get stuck in tutorial hell don't try to memorize everything don't learn in isolation don't chase every new trend don't copypaste code without understanding don't try to learn every new fancy tool or research paper instead build real projects focus on understanding share your progress join communities Master fundamentals first Implement from scratch learn by doing if you found this video helpful share it with someone who you think might also like it and get started on one of the tutorials in the description or on this very Channel also consider liking the video and subscri subcribing to be notified about similar content in the future thanks for watching"}], "5 Beginner AWS Cloud Projects To Get You Hired (2025)": [{"content": "hey everyone this is Lucy and in this video I'll be walking you through five beginner friendly AWS Cloud projects now as I've said on this channel over and over again the best way to build your Hands-On skills with AWS is by creating a project certifications are a great starting point but to really bridge that gap between your theoretical knowledge and what's required to Le a job in the cloud it's important for you to think about how you can use multiple AWS Services together to build a solution this solution could be a static website a mobile application or even a chat bot that can respond to simple queries the possibilities are endless but the problem is how do you get started should you read through hundreds of pages of documentation first or should you just jump straight into it and hope for the best well to be honest there's no one correct approach when starting a cloud project Some people prefer to follow a step-by-step tutorial While others might want the flexibility to build something without the exact instructions already provided to them my personal preference and what I recommend to beginners is to follow guided tutorials for your first few Cloud projects more importantly learn how to document them and speak about your projects during Cloud interviews and so over the next few months I'll be releasing a series of videos to help you build AWS Cloud projects at three different skill levels beginner intermediate and advanced if you want to stay updated make sure you subscribe to the channel and turn on notifications all right let's just dive straight into it the first beginner Cloud project is to build a daily task schedule application using party rock this platform allows you to create an application by simply describing what you want making it a great choice for beginners looking to build AI applications to get started visit party Rock's website and create an account select the build your own app option and this will open up an interface for you to create your own application now you might be wondering what can party rock actually be used for well as cheesy as it sounds the possibilities are endless you can create applications for your own personal use such as a to-do list or Resume Builder you could also create an application for your workplace such as a project management tool with Party Rock people have even built things like motivational quote generators and personality quizzes if you'd like to learn how to build a daily task schedule application I've included the full tutorial in the description below I've also created a guide book with the complete step-by-step instructions to all five projects in this video so feel free to check that out as well but yeah here are the overall steps you need to take if you'd like to build it out so start by entering a detailed prompt that describes the daily task schedule application you envision make sure you're descriptive enough so that partyy rock can understand exactly what you want once you submit your prompt the AI gets to work creating an application that fits your needs after the application is generated you'll be introduced to the customization process this gives you the option to add widgets like user input static text image generation and even a chatbot you can also change the layout of your application to match your brand or personal preferences once you finalize your application you can publish it and share it with others the estimated time for this project is around 15 to 20 minutes but of course it all depends on how complex you want your application to be be and how many features you'd like the cost for this project is $0 since party rock is offering all users a free trial to their service all right project number two is to build an image labels generator using Amazon recognition now this project is another fun one because we'll be processing images and labeling them for example if you have a photo of a cat amaz recognition will be able to identify what it is and label the image as a cat as mentioned I have the complete guide book for all five projects in the description below but here's the architectural diagram and the overall steps you'll need to take to build out the project so the Journey Begins with setting up an Amazon S3 bucket which will serve as the repository for the images you wish to analyze next you'll create an IM am roll and make sure Amazon recognition and S3 have access to each other after that you'll need to install the AWS C and write some code to use the detect labels option for images and finally use a python Library called map plot Li to visualize labels and add bounding boxes to items identified in the images this is the result of what one of your images could look like you could see that one use case of Amazon recognition could be in a smart surveillance system to recognize suspicious objects and activities on the road other potential use cases include identifying products in a store for inventory management analyzing customer behavior on retail stores and providing accessibility options to those who are visually impaired as you can probably tell Amazon recognition is a pretty useful service that can be applied in many Industries so I would recommend building a project to get some experience with it and to see it in action the project will take you about 20 minutes to build and Falls within the free tier now before we move on to the next project I'd like to share with you a helpful tool that will significantly help you on your journey of building AWS Cloud projects some of you might have heard of M before they're a platform that offers an innovation workspace for teams to collaborate well miror has recently released a really cool feature called AWS Cloud view AWS Cloud view allows you to instantly visualize your Cloud architecture by directly importing data from your aw account creating a clear view in just 20 seconds as you all know architectural diagrams are a very important part of documenting every cloud project so instead of manually creating your own diagrams you can create them with the help of miror here's how you can use mirror's edu as Cloud view first either link a cross account roll or upload a Json file containing data about your AWS resources next follow the instructions to select the relevant account and region you wish to visualize and finally sit back while they generate the diagram here's an example AWS diagram generated through Cloud view if you're looking to present your Cloud projects professionally or just want a faster way to create Cloud architectures AWS Cloud view in Miro is a complete Game Changer I'll leave a link to it in the description below moving on to the third project this one is to develop a text narrator using Amazon poly now Amazon poly is a service that turns text to speech allowing you to create an application that can talk now this is great when you don't feel like reading something and just want to listen to the audio version one example is is converting a blog post into an audio book here's the architectural diagram for the project and the steps you need to take so firstly find a piece of text that you'd like spoken out this could be anything from books and articles to newsletters and scripts next create an AWS Lambda function that acts as a bridge between your text and Amazon poly after that customize the voice in Amazon poly to match the tone and style of your content adjusting parameters like pitch and speed now even though this project may seem simple it does require a good understanding of AWS services and how to integrate them it also gives you a taste of how powerful text to speech capabilities can be in enhancing customer experience the estimated time to complete this project is 20 minutes and it also falls within the free tier the fourth Cloud project to help you get highed in 2024 is to build a language translation Bard this project uses three AWS Services AWS Lambda Amazon Lex and Amazon translate so for example if you want to translate a word or sentence into another language all you have to do is type into the chat bot and it will output the translation sounds straightforward enough right here's the architectural diagram and the steps you need to take firstly create a chatbot in Amazon Lex and Define clear user intents next specify utterances or phrases that users might say to interact with your Bot once that's done Define slots within the intents such as language or text to capture the specific information needed for the translation after that we're going to need a Lambda function that takes the slot data and perform a translation using Amazon trans translate and finally we'll integrate the Lambda function back into the Amazon Lex chatbot and deliver the translation smoothly to the user some potential use cases of an Amazon Lex translation bot include assisting businesses in communicating with International clients and helping Travelers communicate with locals from different languages you might be wondering why can't I use a translation app that has already been made well the answer is that businesses often require customized translation services especially when dealing with technical terms or industry specific language by using Amazon Lex you have the flexibility to tailor your Bot based on your specific needs overall building a language translation bot not only showcases your knowledge of using AWS services but is also a skill set for companies looking to build chatbots this project will take you about 1 to 2 hours to build and can be done for free through the aeds free tier the fifth and final project for today is to deploy a bucket list tracker application on AWS amplify this project once you build it out will help you keep a track of all the things you want to do in life you can enter bucket list items and delete them once they're complete now you can see that the architectural diagram for this project looks a bit more complex than the other ones and that's because we'll need multiple ads services to build this application the first step is to build your application with react focusing on userfriendly design and functionality that allows users to manage the bucket list items effectively next initialize a GitHub repo and connect your local development environment to GitHub after that use AWS amplifier to host your front end and Implement amplifier authentication to to add user authentication features like login and sign up once that's done develop the back end using AWS appsync and a graph Cur API for efficient data handling you can then integrate it with Dynamo DB for data storage finally deploy your application on AWS amplify test it out and make any necessary adjustments like all the other projects mentioned in this video this one Falls within the free tier however this final project will take you a bit longer to build around 1 and 1/2 to 2 hours and there you have it five AWS Cloud projects to help you get handson get hired and Advance your career if you found this video helpful please remember to give it a like and let me know in the comments which project was your favorite I'd also recommend checking out this video I made on how to document your AWS Cloud projects thanks so much for watching and I'll see you soon bye for now"}], "Justice: What's The Right Thing To Do? Episode 01 \"THE MORAL SIDE OF MURDER\"": [{"content": "Funding for this program is provided by: Additional funding provided by This is a course about Justice and we begin\nwith a story suppose you're the driver of a trolley car, and your trolley car is hurdling down\nthe track at sixty miles an hour and at the end of the track you notice\nfive workers working on the track you tried to stop but you can't your brakes don't work you feel desperate because you know that if you crash into these five workers they will all die let's assume you know that for sure and so you feel helpless until you notice that there is off to the right a side track at the end of that track there's one worker working on track you're steering wheel works so you can turn the trolley car if you want to onto this side track killing the one but sparing the five. Here's our first question what's the right thing to do? What would you do? Let's take a poll, how many would turn the trolley car onto the side track? How many wouldn't? How many would go straight ahead keep your hands up, those of you who'd go straight\nahead. A handful of people would, the vast majority\nwould turn let's hear first now we need to begin to investigate the reasons\nwhy you think it's the right thing to do. Let's begin with\nthose in the majority, who would turn to go onto side track? Why would you do it, what would be your reason?"}, {"content": "Who's willing to volunteer a reason? Go ahead, stand up. Because it can't be right to kill five people\nwhen you can only kill one person instead. it wouldn't be right to kill five if you could kill one person instead that's a good reason that's a good reason who else? does everybody agree with that reason? go ahead. Well I was thinking it was the same reason it was on 9/11 we regard the people who flew the plane who flew the plane into the Pennsylvania field as heroes because they chose to kill the people on the\nplane and not kill more people in big buildings. So the principle there was the same on 9/11 it's tragic circumstance, but better to kill one so that five can\nlive is that the reason most of you have, those\nof you who would turn, yes? Let's hear now from those in the minority those who wouldn't turn. Well I think that same type of mentality that\njustifies genocide and totalitarianism in order to save one type of race you\nwipe out the other. so what would you do in this case? You would to avoid the horrors of genocide you would crash into the five and kill them? Presumably yes."}, {"content": "okay who else?"}, {"content": "That's a brave answer, thank you. Let's consider another trolley car case and see whether those of you in the majority want to adhere to the principle, better that one should die so that five\nshould live. This time you're not the driver of the trolley\ncar, you're an onlooker standing on a bridge overlooking a trolley car track and down the track comes a trolley car at the end of the track are five workers the brakes don't work the trolley car is about to careen into the\nfive and kill them and now you're not the driver you really feel helpless until you notice standing next to you leaning over the bridge is it very fat man. And you could give him a shove he would fall over the bridge onto the track right in the way of the trolley car he would die but he would spare the five. Now, how many would push the fat man over the bridge? Raise your hand. How many wouldn't? Most people wouldn't. Here's the obvious question, what became of the principle better to save five lives even if it means\nsacrificing one, what became of the principal that almost everyone endorsed in the first case I need to hear from someone who was in the\nmajority in both cases is how do you explain the difference between\nthe two? The second one I guess involves an\nactive choice of  pushing a person and down which I guess that that person himself would otherwise not \nhave been involved in the situation at all and so to choose on his behalf I guess to  involve him in something that he otherwise would\nhave this escaped is I guess more than what you have in the first case where the three parties, the driver and the two sets of workers are already I guess in this situation. but the guy working, the one on the track\noff to the side he didn't choose to sacrifice his life any\nmore than the fat guy did, did he? That's true, but he was on the tracks. this guy was on the bridge. Go ahead, you can come back if you want. Alright, it's a hard question but you did well you did very well it's a\nhard question. who else can find a way of reconciling the reaction of the majority in these two cases? Yes? Well I guess in the first case where you have the one worker and the five it's a  choice between those two, and you have to  make a certain choice and people are going to die \nbecause of the trolley car  not necessarily because of your direct actions. The trolley car is a runway, thing and you need to make in a split second choice whereas pushing the fat man over is an actual\nact of murder on your part you have control over that whereas you may not have control over the trolley car. So I think that it's a slightly different situation."}, {"content": "Alright who has a reply? Is that, who has a reply to that? no that was good, who has a way who wants to reply? Is that a way out of this? I don't think that's a very good reason because\nyou choose either way you have to choose who dies\nbecause you either choose to turn and kill a person which is an act of conscious thought to turn, or you choose to push the fat man  over which is also an active conscious action so either way you're making a choice. Do you want to reply? Well I'm not really sure that that's the case, it just still\nseems kind of different, the act of actually pushing someone over onto the tracks and killing them, you are actually killing him yourself, you're pushing\nhim with your own hands you're pushing and  that's different than steering something that is going to\ncause death into another...you know it doesn't really sound right saying it now when I'm up here. No that's good, what's your name?"}, {"content": "Andrew. Andrew and let me ask you this question Andrew, suppose standing on the bridge next to the fat man I didn't have to push him, suppose he was standing over a trap door that I could open by turning\na steering wheel like that would you turn it? For some reason that still just seems more  more wrong. I mean maybe if you just accidentally like leaned into\nthis steering wheel or something like that or but,  or say that the car is  hurdling towards a switch that will drop the trap then I could agree with that. Fair enough, it still seems  wrong in a way that it doesn't seem wrong in the\nfirst case to turn, you say An in another way, I mean in the first situation you're\ninvolved directly with the situation in the second one you're an onlooker as well. So you have the choice of becoming involved\nor not by pushing the fat man. Let's forget for the moment about this case, that's good, but let's imagine a different case. This time\nyour doctor in an emergency room and six patients come to you they've been in a terrible trolley car wreck five of them sustained moderate injuries one\nis severely injured you could spend all day caring for the one severely injured victim, but in that time the five would die, or you could\nlook after the five, restore them to health, but during that time the one severely injured person would die. How many would save  the five now as the doctor? How many would save the one? Very few people, just a handful of people. Same reason I assume, one life versus five. Now consider another doctor case this time you're a transplant surgeon and you have five patients each in desperate\nneed of an organ transplant in order to survive on needs a heart one a lung, one a kidney,  one a liver and the fifth a pancreas. And you have no organ donors you are about to see you them die and then it occurs to you that in the next room there's a healthy guy who came in for a checkup. and he is you like that and he's taking a nap you could go in very quietly yank out the five organs, that person would\ndie but you can save the five. How many would do it? Anyone? How many? Put your hands up if you would do it. Anyone in the balcony? You would? Be careful don't lean over too much How many wouldn't? All right. What do you say, speak up in the balcony, you\nwho would yank out the organs, why? I'd actually like to explore slightly alternate possibility of just taking the one of the five he needs an organ who dies first and using their four healthy organs to save the other\nfour That's a pretty good idea. That's a great idea except for the fact that you just wrecked the philosophical point. Let's step back from these stories and these arguments to notice a couple of things about the way the arguments have began to unfold. Certain moral principles have already begun to emerge from the discussions we've had and let's consider what those moral principles look like the first moral principle that emerged from the \ndiscussion said that the right thing to do the moral thing to do depends on the consequences that will result from your action at the end of the day better that five should live even if one must die. That's an example of consequentialist moral reasoning. consequentialist moral reasoning locates morality\nin the consequences of an act. In the state of the  world that will result  from the thing you do but then we went a little further, we considered\nthose other cases and people weren't so sure  about consequentialist moral reasoning when people hesitated to push the fat man over the bridge or to yank out the organs of the innocent patient people gestured towards reasons having to do with the intrinsic quality of the act itself. Consequences be what they may. People were reluctant people thought it was just wrong categorically wrong to kill a person an innocent person even for the sake of saving five lives, at least these people thought that in the second version of each story we reconsidered so this points a second categorical way of thinking about moral reasoning categorical moral reasoning locates morality\nin certain absolute moral requirements in certain categorical duties and rights regardless of the consequences. We're going to explore in the days and weeks to come the contrast\nbetween consequentialist and categorical moral principles. The most influential example of consequential moral reasoning is utilitarianism,\na doctrine invented by Jeremy Bentham, the eighteenth century English\npolitical philosopher. The most important philosopher of categorical moral reasoning is the eighteenth century German philosopher\nEmmanuel Kant. So we will look at those two different modes of moral reasoning assess them and also consider others. If you look at the syllabus, you'll notice\nthat we read a number of great and famous books. Books by Aristotle John Locke Emanuel Kant, John Stuart Mill, and others. You'll notice too from the syllabus that\nwe don't only read these books, we also all take up contemporary political and legal controversies\nthat raise philosophical questions. We will debate equality and inequality, affirmative action, free speech versus hate speech, same sex marriage, military conscription, a range of practical questions, why not just to enliven these abstract and distant\nbooks but to make clear to bring out what's at stake\nin our everyday lives including our political lives, for philosophy. So we will read these books and we will debate these issues and we'll see how each informs and\nilluminates the other. This may sound appealing enough but here I have to issue a warning, and the warning is this to read these books in this way, as an exercise in self-knowledge, to read them in this way carry certain risks risks that are both personal and political, risks that every student of political philosophy have known. These risks spring from that fact that philosophy teaches us and unsettles us by confronting us with what we already know. There's an irony the difficulty of this course consists in the\nfact that it teaches what you already know. It works by taking what we know from familiar unquestioned settings, and making it strange. That's how those examples worked worked the hypotheticals with which we began with their\nmix of playfulness and sobriety. it's also how these philosophical books work. Philosophy  estranges us from the familiar not by supplying new information but by inviting and provoking a new way of seeing but, and here's the risk, once the familiar turns strange, it's never quite the same again. Self-knowledge is like lost innocence, however unsettling you find it, it can never be unthought or unknown what makes this enterprise difficult but also riveting, is that moral and political philosophy is a story and you don't know where this story will lead\nbut what you do know is that the story is about you. Those are the personal risks, now what of the political risks. one way of introducing of course like this would be to promise you that by reading these books and debating these issues you will become a better more responsible\ncitizen. You will examine the presuppositions of\npublic policy, you will hone your political judgment you'll become a more effective participant\nin public affairs but this would be a partial and misleading promise political philosophy for the most part hasn't\nworked that way. You have to allow for the possibility that political philosophy may make you a worse\ncitizen rather than a better one or at least a worse citizen before it makes you a better one and that's because philosophy is a distancing even debilitating activity And you see this going back to Socrates there's a dialogue, the Gorgias in which one of Socrates\u2019 friends Calicles tries to talk him out of philosophizing. calicles tells Socrates philosophy is a pretty toy if one indulges in it with moderation at\nthe right time of life but if one pursues it further than one should\nit is absolute ruin. Take my advice calicles says, abandon argument learn the accomplishments of active\nlife, take for your models not those people who spend\ntheir time on these petty quibbles, but those who have a good livelihood and reputation and many other blessings. So Calicles is really saying to Socrates quit philosophizing, get real go to business school and calicles did have a point he had a point because philosophy distances us from conventions from established assumptions and from settled beliefs. those are the risks, personal and political and in the face of these risks there is a\ncharacteristic evasion, the name of the evasion is skepticism. It's\nthe idea well it goes something like this we didn't resolve, once and for all, either the cases or the principles we were\narguing when we began and if Aristotle and Locke and Kant and Mill haven't solved these questions\nafter all of these years who are we to think that we here in Sanders Theatre over the\ncourse a semester can resolve them and so maybe it's just a matter of each person having his or her own principles\nand there's nothing more to be said about it no way of reasoning that's the evasion. The evasion of skepticism  to which I would offer the following reply: it's true these questions have been debated for a very\nlong time but the very fact that they have reoccurred and persisted may suggest that though they're impossible in one sense their unavoidable in another and the reason they're unavoidable the reason they're inescapable is that we live\nsome answer to these questions every day. So skepticism, just throwing up their hands\nand giving up on moral reflection, is no solution Emanuel Kant described very well the problem with skepticism\nwhen he wrote skepticism is a resting place for human reason  where it can reflect upon its dogmatic wanderings but it is no dwelling place for permanent settlement. Simply to acquiesce in skepticism, Kant wrote, can never suffice to overcome the restless\nof reason. I've tried to suggest through theses stories\nand these arguments some sense of the risks and temptations of the perils and the possibilities I would\nsimply conclude by saying that the aim of this course is to awaken the restlessness of reason and to see where it might lead thank you very much. Like, in a situation that desperate, you have to do what you have to do to survive. You have to do what you have to do you? You've gotta do What you  gotta do. pretty much,  If you've been going nineteen days without any food someone has to take the sacrifice, someone has to make the sacrifice  \nand people can survive. Alright that's good, what's your name?"}, {"content": "Marcus."}, {"content": "Marcus, what do you say to Marcus? Last time we started out last time with some stores with some moral dilemmas about trolley cars and about doctors and healthy patients vulnerable to being victims of organ transplantation we noticed two things about the arguments we had one had to do with the way we were arguing it began with our judgments in particular cases we tried to articulate the reasons or the\nprinciples lying behind our judgments and then confronted with a new case we found ourselves re-examining those principles revising each in the light of the other and we noticed the built-in pressure to try\nto bring into alignment our judgments about particular cases and the principles we would endorse on reflection we also noticed something about the substance\nof the arguments that emerged from the discussion. We noticed that sometimes we were tempted\nto locate the morality of an act in the consequences in the results, in the state of the world that\nit brought about. We called is consequentialist moral reason. But we also noticed that in some cases we weren't swayed only  by the results sometimes, many of us felt, that not just consequences but also the intrinsic\nquality or character of the act matters morally. Some people argued that there are certain things\nthat are just categorically wrong even if they bring about a good result even if they save five people at the cost of one life. So we contrasted consequentialist moral principles with categorical ones. Today and in the next few days we will begin to examine one of the\nmost influential versions of consequentialist moral theory and that's the philosophy of utilitarianism. Jeremy Bentham, the eighteenth century English political philosopher gave first the first clear systematic expression to the utilitarian moral theory. And Bentham's idea, his essential idea is a very simple one with a lot of  morally intuitive appeal. Bentham's idea is the following the right thing to do the just thing to do it's to maximize utility. What did he mean by utility? He meant by utility the balance of pleasure over pain, happiness over suffering. Here's how we arrived  at the principle of maximizing utility. He started out by observing that all of us all human beings are governed by two sovereign masters, pain and pleasure. We human beings like pleasure and dislike pain and so we should base morality whether we are thinking of what to do in our own lives or whether as legislators or citizens we are thinking about what the law should be, the right thing to do individually or collectively is to maximize, act in a way that maximizes the overall level of happiness. Bentham's utilitarianism is sometimes summed\nup with the slogan the greatest good for the greatest number. With this basic principle of utility on hand, let's begin to test it and to examine it by turning to another case another story but this time not a hypothetical story, a real-life story the case of the Queen versus Dudley and Stephens. This was a nineteenth-century British law case that's famous and much debated in law schools. Here's what happened in the case I'll summarize the story and then I want to hear how you would rule imagining that you are the jury. A newspaper account of the time described the background: A sadder story of disaster at sea was never told than that of the survivors of the yacht Mignonette. The ship foundered in the south Atlantic thirteen hundred miles from the cape there were four in the crew, Dudley was the captain Stephens was the first mate Brooks was a sailor, all men of excellent character, or so the newspaper account tells us. The fourth crew member was the cabin boy, Richard Parker seventeen years old. He was an orphan he had no family and he was on his first long voyage at sea. He went, the news account tells us, rather against the advice of his friends. He went in the hopefulness of youthful ambition thinking the journey would make a man of him. Sadly it was not to be, the facts of the case were not in dispute, a wave hit the ship and the Mignonette went down. The four crew members escaped to a lifeboat the only food they had were two cans of preserved turnips no fresh water for the first three days they ate nothing on the fourth day that opened one of the cans of\nturnips and ate it. The next day they caught a turtle together with the other can of turnips  the turtle enabled them to subsist for the next few days and then for eight days they had nothing no food no water. Imagine yourself in a situation like that what would you do? Here's what they did by now the cabin boy Parker is lying at the\nbottom of the lifeboat in a corner because he had drunk sea water against the advice of the others and he had become ill and he appeared to be dying so on the nineteenth day Dudley, the captain, suggested that they should all have a lottery. That they should all draw lots to see who would die to save the rest. Brooks refused he didn't like the lottery idea we don't know whether this was because he didn't want to take that chance\nor because he believed in categorical moral principles but in any case no lots were drawn. The next day there was still no ship in sight so a Dudley told Brooks to avert his gaze  and he motioned to Stephens that the boy Parker had better be killed. Dudley offered a prayer he told a the boy his time had come and he killed him with a pen knife stabbing him in the jugular vein. Brooks emerged from his conscientious objection\nto share in the gruesome bounty. For four days the three of them fed on the body and blood\nof the cabin boy. True story. And then they were rescued. Dudley describes their rescue in his diary with staggering euphemism, quote: \"on the twenty fourth day as we were having our breakfast a ship appeared at last.\" The three survivors were picked up by a German ship. They were taken back to Falmouth in England where they were arrested and tried Brooks turned state's witness Dudley and Stephens went to trial. They didn't\ndispute the facts they claimed they had acted out of necessity that was their defense they argued in effect better that one should die so that three could survive the prosecutor wasn't swayed by that argument he said murder is murder and so the case went to trial. Now imagine\nyou are the jury and just to simplify the discussion put aside the question of law, and let's assume that you as the jury are charged with deciding whether what they did was morally permissible or not. How many would vote not guilty, that what they did was morally\npermissible? And how many would vote guilty what they did was morally wrong? A pretty sizable majority."}, {"content": "Now let's see what people's reasons are, and let me\nbegin with those who are in the minority. Let's hear first from the defense of Dudley and Stephens. Why would you morally exonerate them? What are your reasons? I think it's I think it is morally reprehensible but I think that there's a distinction between\nwhat's morally reprehensible what makes someone legally accountable in other words the night as the judge said\nwhat's  always moral isn't necessarily against the law and while I don't think that\nnecessity justifies theft or murder any illegal act,  at some point your degree of necessity does\nin fact exonerate you form any guilt. ok. other defenders, other voices for the defense? Moral justifications for what they did? yes, thank you I just feel like  in a situation that desperate you have to do\nwhat you have to do to survive. You have to do what you have to do ya, you gotta do what you gotta do, pretty much. If you've been going nineteen days without any food you know someone just has to take the sacrifice\nhas to make sacrifices and people can survive and furthermore from that let's say they survived and then they become productive\nmembers of society who go home and then start like a million charity organizations and this and that and this and that,\nI mean they benefit everybody in the end so I mean I don't know what they did afterwards, I mean\nthey might have gone on and killed more people but whatever. what? what if they were going home and turned out to be assassins? What if they were going home and turned out to be assassins? You would want to know who they assassinated. That's true too, that's fair I would wanna know who they assassinated. alright that's good, what's your name?"}, {"content": "Marcus. We've heard a defense a couple voices for the defense now we need to hear from the prosecution most people think what they did was wrong, why? One of the first things that I was thinking was, oh well if they  \nhaven't been eating for a really long time,  maybe then they're mentally affected that could be used for the defense,  a possible argument that oh, that they weren't in a proper state of mind, they were making decisions that they otherwise wouldn't be making, and if that's an  \nappealing argument that you have to be in an altered mindset to do something\nlike that it suggests that people who find that argument convincing do you think that they're acting immorally. But I want to know what you think you're defending you k\n0:37:41.249,0:37:45.549\nyou voted to convict right? yeah\n I don't think that they acted in morally  appropriate way. And why not? What do you say,\nHere's Marcus he just defended them, he said, you heard what he said, yes I did yes that you've got to do what you've got to do in a\ncase like that. What do you say to Marcus? They didn't, that there is no situation that would allow human\nbeings to take  the idea of fate or the other people's\nlives into their own hands that we don't have that kind of power. Good, okay thanks you, and what's your name?"}, {"content": "Britt? okay. who else? What do you say? Stand up I'm wondering if Dudley and Stephens had asked for Richard Parker's  \nconsent in, you know, dying,  if that would would that exonerate them from an act of murder, and if so is that still morally\njustifiable? That's interesting, alright consent, now hang on, what's your name? Kathleen."}, {"content": "Kathleen says suppose so what would that scenario look like? so in the story Dudley is there, pen knife in hand, but instead of the prayer or before the prayer, he says, Parker, would you mind we're desperately hungry, as Marcus empathizes with we're desperately hungry you're not going to last long anyhow, you can be a martyr, would you be a martyr how about it Parker? Then, then then what do you think, would\nbe morally justified then? Suppose Parker in his semi-stupor  says okay  I don't think it'll be morally justifiable but I'm wondering. Even then, even then it wouldn't be? No You don't think that even with consent it would be morally justified. Are there people who think who want to take up Kathleen's  consent idea and who think that that would make it\nmorally justified? Raise your hand if it would if you think it would. That's very interesting Why would consent  make a moral difference? Why would it? Well I just think that if he was making his own original\nidea and it was his idea to start with then that would be the only situation in which I\nwould see it being appropriate in anyway\n \n0:40:25.940,0:40:28.359\nbecause that way you couldn't make the argument\nthat he was pressured you know it\u2019s three to one or whatever the ratio was, and I think that if he was making a decision to give his life\nthen he took on the agency to sacrifice himself which some \npeople might see as admirable and other people  might disagree with that decision. So if he came up with the idea that's the only kind of consent we could have\nconfidence in morally, then it would be okay otherwise it would be kind of coerced consent under the circumstances you think. Is there anyone who thinks that the even the consent of Parker would not justify their killing him? Who thinks that? Yes, tell us why, stand up I think that Parker would be killed with the hope that the other crew members\nwould be rescued so there's no definite reason that he should\nbe killed because you don't know  when they're going to get rescued so if you kill him you're killing him  \nin vain do you keep killing a crew member until you're rescued and then you're  \nleft with no one? because someone's going to die eventually? Well the moral logic of the situation seems to\nbe that. That they would keep on picking off the weakest maybe, one by\none, until they were rescued and in this case luckily when three at least were still alive. Now if if Parker did give his consent would it be all right do you think or not? No, it still wouldn't be right."}, {"content": "Tell us why wouldn't be all right. First of all, cannibalism, I believe is morally incorrect so you shouldn\u2019t be eating a human anyway. So cannibalism is morally objectionable outside so then even in the scenario of waiting until someone died still it would be objectionable. Yes, to me personally I feel like of it all depends on one's personal morals, like we can't just, like this is just my opinion of course other people are going to disagree. Well let's see, let's hear what their disagreements\nare and then we'll see if they have reasons that can persuade you or not. Let's try that Let's now is there someone who can explain, those of you who are tempted\nby consent can you explain why consent makes such a moral difference, what about the lottery idea does that count as consent. Remember at\nthe beginning Dudley proposed a lottery suppose that they had agreed to a lottery then how many would then say it was all right. Say there was a lottery, cabin boy lost, and the rest of the story unfolded. How\nmany people would say it's morally permissible? So the numbers are rising if we add a lottery,\nlet's hear from one of you for whom the lottery would make a moral difference why would it? I think the essential element, in my mind that makes it a crime is the idea that they decided at some point that\ntheir lives were more important than his, and that I mean that's kind of the basis for really\nany crime right? It's like my needs, my desire is a more important than yours\nand mine take precedent and if they had done a lottery were everyone\nconsented that someone should die and it's sort of like they're all sacrificing \nthemselves, to save the rest, Then it would be all right? A little grotesque but, But morally permissible? Yes."}, {"content": "what's your name?"}, {"content": "Matt. so, Matt for you what bothers you is not the cannibalism, but the lack of due process. I guess you could say that And can someone who agrees with Matt say a little bit more about why  a lottery would make it, in your view, morally permissible. The way I understood it originally was that that was the\nwhole issue is that the cabin boy was never consulted about whether or not it something was going\nto happen to him even though with the original lottery whether or not he would be a part of that\nit was just decided that he was the one that was going to die. Yes that's what happened in the actual case but if there were a lottery and they all agreed\nto the procedure you think that would be okay? Right, because everyone knows that there's gonna be\na death whereas you know the cabin boy didn't know that this discussion was even happening there was no you know forewarning for him to know that hey, I may be the one\nthat's dying. Okay, now suppose the everyone agrees to the lottery they have the lottery the cabin\nboy loses any changes his mind. You've already decided, it's like a verbal contract, you can't go back  \non that. You've decided the decision was made you know if you know you're dying for the \n reason for at others to live, you would, you know if the someone else had died you know that you would consume them, so But then he could say I know, but I lost. I just think that that's the whole moral issue is that there was\nno consulting of the cabin boy and that that's what makes it the most horrible is that he had no idea what was even\ngoing on, that if he had known what was going on it would be a bit more understandable. Alright, good, now I want to hear so there's some who think it's morally permissible but only about twenty percent, led by Marcus, then there are some who say the real problem here is the lack of consent whether the lack of consent to a lottery to\na fair procedure or Kathleen's idea, lack of consent at the moment of death and if we add consent then more people are willing to consider the sacrifice morally justified. I want to hear now finally from those of you who think even with consent even with a lottery even with a final  murmur of consent from Parker at the very last moment it would still be wrong and why would it be wrong that's what I want to hear. well the whole time I've been leaning towards the categorical moral reasoning and I think that there's a possibility I'd be okay with the\nidea of the lottery and then loser taking into their own hands to kill themselves so there wouldn't be an act of murder but\nI still think that even that way it's coerced and also I don't\nthink that there's any remorse like in Dudley's diary we're getting our breakfast it seems as though he's just sort of like, oh, you know that whole idea of not valuing someone else's life so that makes me feel like I have to take the categorical stance. You want to throw the  \nbook at him. when he lacks remorse or a sense of having done\nanything wrong. Right. Alright, good so are there any other defenders who who say it's just categorically wrong, with or without consent, yes  \nstand up. Why? I think undoubtedly the way our society is shaped, murder\nis murder murder is murder and every way our society looks down at it in the same  \nlight and I don't think it's any different in any case. Good now let \nme ask you a question, there were three lives at stake versus one, the one, that the cabin boy, he  had no family he had no dependents, these other three had families back home\nin England they had dependents they had wives and children think back to Bentham, Bentham says we have to consider the welfare, the utility, the happiness of everybody. We have to add it all up so it's not just numbers three against one it's also all of those people at home in fact the London newspaper at the time and popular opinion sympathized with them Dudley in Stephens and the paper said if they weren't motivated by affection and concern for their loved ones at\nhome and dependents, surely they wouldn't have done this. Yeah, and how is that any different from people on the corner trying to having the same desire to feed their family,\nI don't think it's any different. I think in any case if I'm murdering you to advance my status, that's murder and I think  \nthat we should look at all of that in the same light. Instead of criminalizing certain activities and making certain things seem more\nviolent and savage when in that same case it's all the same act and mentality  that goes into the murder, a necessity\nto feed their families. Suppose there weren't three, supposed there were thirty, three hundred, one life to save three hundred or in more time, three thousand or suppose the stakes were even bigger."}, {"content": "Suppose the stakes were even bigger I think it's still the same deal. Do you think Bentham was wrong to say the right thing\nto do is to add up the collected happiness, you think he's\nwrong about that? I don't think he is wrong, but I think murder is murder in any case. Well then Bentham has to be wrong if you're right he's wrong. okay then he's wrong. Alright thank you, well done. Alright, let's step back from this discussion and notice how many objections have we heard to what they did. we heard some defenses of what they did the defense has had to do with  necessity the dire circumstance and, implicitly at least, the idea that numbers matter and not only numbers matter but the wider effects matter their families back home, their dependents Parker was an orphan, no one would miss him. so if you add up if you tried to calculate the balance of happiness and suffering you might have a case for  saying what they did was the right thing then we heard at least three different types\nof objections, we heard an objection that's said what they did was categorically wrong, right here at the end categorically wrong. Murder is murder it's always wrong even if it increases the overall happiness of society the categorical objection. But we still need to investigate why murder is categorically wrong. Is it because even cabin boys have certain fundamental rights? And if that's the reason where do those rights come from if not from\nsome idea of the larger welfare or utility or happiness? Question number one. Others said a lottery would make a difference a fair procedure, Matt said. And some people were swayed by that. That's not a categorical objection exactly it's saying everybody has to be counted as an equal even though, at the end of the day one can be sacrificed for the general welfare. That leaves us with another question to investigate, Why does agreement to certain procedure,  even a fair procedure, justify whatever result flows from the operation of that procedure? Question number two. and question number three the basic idea of consent. Kathleen got us on to this. If the cabin boy had agreed himself and not under duress as was added then it would be all right to take his life \nto save the rest. Even more people signed on to that idea but that raises a third philosophical question what is the moral work that consent does? Why does an act of consent make such a moral difference that an act that would be wrong, taking a life,\nwithout consent is morally permissible with consent? To investigate those three questions we're going to have to read some philosophers and starting next time we're going to read Bentham, and John Stuart Mill, utilitarian philosophers. Don't miss the chance to interact online with other viewers\nof Justice join the conversation, take a pop quiz, watch lectures you've missed, and a lot more. Visit  \nwww.justiceharvard.org. It's the right thing to do. Funding for the program is provided by  Additional funding provided by"}], "Naomi Oreskes: \"The Scientist as Sentinel\"": [{"content": " Hey, hi. Hi. Hey. It's really nice of you to come tonight. My name is Melissa Franklin. I'm a physicist. You can clap now. I'm really excited about this talk tonight. I just want to say that I invited Professor Eskies to give this talk before the election. So obviously I'm brilliant. And I'm so happy that she's giving this talk tonight because it's so important, so incredibly important. This topic, the scientist, is sentinel is probably the most important thing for a lot of us right now. What do we do now? How do we make a contribution? So Naomi Eskies is kind of an interesting person. I've known her for just a little while because she arrived at Harvard just a few years ago as a professor in the history of science department. And in the Earth and Planetary Sciences department. And she's very cool. But most cool is that she got her degree from the School of Mines. I love School of Mines at the Imperial College in England, the place where there is now Brexit. And she left early and came back and went to Stanford University to do her PhD. But she didn't want to just do a normal PhD. She had to make it up herself because it's not in just one department, which I also like. So I just like her a lot in many ways. But maybe possibly other than the incredible work she does right now, which is so important to us, is her work with the Pope. Sorry, I know that sounds funny. But she wrote an introduction to the encyclical on climate change and inequality with Pope Francis. I've never really worked with the Pope. But I hear he's a great guy. And I wish he'd asked me, and even though I don't know anything about anything really, about climate change. Also, she's just incredibly prolific. She wrote a book called 2014 called The Collapse of Western Civilization, which was a positive thing. And she's also given really good TED talks, if you like that kind of thing. And she's just an incredible historian, but also she knows science. And she also wrote some books that I don't even know. The words about, like, do we believe in climate change?"}, {"content": "That's really important. So sorry, I think the thing that I'm looking forward to tonight is hearing from a really sane person who's very creative. And she's going to tell us what to do. She's going to tell us what to do. So please welcome her. Well, thank you for that great introduction. One of the things I've always struggled with as a historian and philosopher of science, who studies science and thinks about what scientists should do, is in my experience, most scientists do not want historians to tell them what to do. So I'm really, really happy that we've come to this moment. It's not turned on. I thought I'd turn it on. Okay, we've come to this moment where a physicist wants me to tell her what to do. That's pretty special."}, {"content": "I also thank you for that generous introduction. When I was studying at the Royal School of Mines, which is part of Imperial College London, and people would ask me where I went to school, and I would say go to the Royal School of Mines, and they would say, the Royal School of Mines? Are you studying philosophy? So yes, the Royal School of Mines, I studied mining geology. Also, when you said I'm very interesting, my mother is the kindest, sweetest person on earth, and never, ever, ever likes to say anything bad about anyone. But if you put on an article of clothing, the she thinks is a little not so flattering, she'll say, oh, that's interesting. So my family being interesting is not necessarily a compliment, but I will take it as a compliment here tonight. What I want to talk to you tonight about is work I've actually been doing for a number of years about this question of what the role of scientists should really be in relation to talking about contested public policy issues. I developed this specific talk for AAAAS that was here in Boston last month. I had the honor to do a keynote speech talk there. So I developed this talk as a talk about science for scientists. So in this talk, I'm going to use the word we when I refer to scientists. For those of you who aren't scientists, you can just say they, but the message I think is relevant for all of us in thinking through what our role needs to be in terms of thinking about contested issues of public policy. So some of you may have, and I'm going to come out from behind this podium because I don't like podiums. I don't like to be separated from my people. So some of you may have seen this that ran in the New Yorker a few weeks ago. Those smug pilots have lost touch with regular passengers like us. Who thinks I should fly the plane? Now of course we all laugh at that because to us it's obvious that the public ignores expertise and it's peril. And as people associated with a great university like Harvard, we have an expectation that our expertise should be respected and in many cases acted on. But as we've seen of late, many of our political leaders not only don't act on our expertise, but they actually rejected. And in some cases they actively misrepresented. And that creates a very difficult situation for us. What should we do when our work, our expertise, is being rejected, dispatched, and in some cases misrepresented? Should we speak up in public? Should we be speaking up in public on tricky, sensitive topics like evolution or the safety of vaccinations or in my case climate change? And if so, how? And what exactly does it mean to say that we should respect expertise? What are the boundaries of expertise? And if we as experts embrace a public role, what does that entail? So I want to start by talking about a scientist that I've studied in some detail, a man by the name of Roger Revelle. How many of you have heard of Revelle before? Oh a lot."}, {"content": "Wow, this is a great audience."}, {"content": "And not just the Earth Science professors. So Revelle, as many of you know, is a very famous chemical oceanographer. He was also one of the directors of the Scripps Institution of Oceanography in San Diego. And he was also the mentor to Al Gore. It's because of Roger Revelle that Al Gore first learned about climate change and began to think of it as a serious issue. In 1965, Revelle was serving as part of the President's Science Advisory Committee, a group that was writing a report on the state of the environment. And this report had an appendix that was co-author with four of his prominent geoscientific colleagues, including Dave Killing. And the title of this appendix was atmospheric CO2, the invisible pollutant. And in this appendix, Revelle and his colleagues warned that in due course, not tomorrow, not next year, but in due course, increased atmospheric carbon dioxide would likely alter the climate in serious and adverse ways. They wrote, throughout his worldwide industrial civilization, men is unwittingly conducting a vast geophysical experiment. By the year 2000, the increase in atmospheric CO2 will be close to 25%. This may be sufficient to produce measurable and perhaps market changes in climate. And as we all know today now, that prediction came true. So we can say that these leading scientists of a previous generation were acting as sentinels. They were calling attention to an issue that was not yet publicly recognized, in fact not even recognized by most of their scientific colleagues at this time. And they were pointing out that while the issue of visible pollution was getting a lot of attention in the media and in halls of power, particularly smog and Los Angeles, or the terrible London fogs that had killed people in the 1950s, there were other invisible pollutants that were also important. And carbon dioxide was probably the most important of these invisible pollutants. So they reached out to political leaders, in this case to the president of the United States, about their scientific research that implied a societal threat. Now, in our research and the Revell archives, we've never found any evidence that Revell worried that this might somehow not be an appropriate thing to do. On the contrary, in the context of growing public concern about air pollution in the 1960s, Revell considered to be obviously appropriate to alert political leaders to this other form of pollution that was not as obvious but could also have serious long term effects. And we also have seen from our research that most of the political leaders to whom he reached out did seem to be at least cautiously receptive to being made aware of this issue. And in current research that I'm doing here with two of my graduate students here at Harvard in the history of science department, Hannah Conway and Colleen Linear-Kristenson, we've identified a number of political leaders in the 1960s who took an interest in this issue and who thanked Revell and his colleagues for sending these materials to them. In some cases, followed up and asked for more information."}, {"content": "So those were, it was a very different time. Now, today though, many of us are reluctant to be sentinels. Many of us are worried that if we speak up in public beyond the confines of scientific publications or scientific meetings and conferences, that this will lead to us being viewed as advocates or activists, and that we will politicize our science and will lose credibility. So, I think that if you have heard this in last few weeks, maybe some of you have been involved in conversations with your students or your colleagues here at Harvard about whether we should participate in the March for Science and whether or not that threatens to politicize science in an undesirable way. So this is a question that colleagues and I have been looking at actually for a few years. Well, before the March on Science or March for Science or whatever March on Science, no. Guess it's a March for Science Donald Trump is marching on science. Well, before the current political situation, my colleagues and I have been interested in this question of how scientists think about their role in relation to political questions. So I've been for several years now part of a project that's coming wrapping up now called assessing assessments. My colleagues on this are Dale Jamison who just talked at the law school today about other work and Michael Oppenheimer and several other postdocs and graduate students. So in our work, this was one of the things that we asked scientists about. We asked them how do you think about the relationship between science and policy and how do you think about your role in relation to that question. And what we found was a very consistent pattern where the vast majority of scientists that we asked expressed a great deal of reluctance to take on any role other than simply presenting factual information in the context of scientific assessments. So not expressing opinions on policy and not even presenting those facts in other contexts outside of the assessment framework. And when we probe this and ask why many expressed the idea that there is or needs to be a bright line between science and the one hand and policy on the other. And that speaking up in public, even about the facts threatens to dull that line. And therefore scientists said, scientists said things like, well, you should do your work, but you should not go public. Some said using imperative, you must not go public. You must not cross the line. And when we said, well, why?"}, {"content": "They said, well, because if you do, you'll lose your credibility. The IPCC, the Intergovernmental Panel on Climate Change has addressed this issue explicitly through its rubric of being policy relevant, but not policy prescriptive. IPCC leaders acknowledge that their work is not pure science. That climate science is linked to major public policy issues. And that the IPCC exists because of its link to governance through the United Nations Framework Convention on Climate Change. But nevertheless, even though they acknowledge that the IPCC itself is a kind of hybrid organization, most climate scientists working within the IPCC still say that they should refrain from taking any kind of public policy. And they say, well, they should not be taking any kind of public role and stay removed from discussion of policy implications and considerations. And one of the most common refrains that we've heard both in the context of this research and more broadly is scientists saying that we should let the facts speak for themselves. The climate science colleague, James Hanson, has also written about this issue, and he's referred to this as redisense. He said that scientists in general are reluctant to speak up about what they know about climate change, so not just about the policy things, but even to speak up in public about the facts. And again, because they believe that we need to let the facts speak for themselves. Now, those of you who saw the poster for this talk saw that one of the pictures on it is this picture of Jim Hanson getting arrested, protesting at the White House over the lack of action on climate change. Many scientists who have we have spoken to have invoked Jim Hanson as proof. Now, Hanson has become a major figure not only because he speaks up about the evidence of climate change, which he does, but also because he's become an advocate for particular solutions. So he is an advocate for a carbon price established through a fee and dividend system. And in support of this work, he has been arrested several times. But I want to ask the question tonight, what exactly is Hanson proof of other than maybe that scientists are uncomfortable with his position? And it's not just climate science. This is an issue that affects scientists in many, many areas. So people who work in re-biology and conservation, people who study lead or other toxic in the environment, endocrine disrupting chemicals, neo-nicotonoid pesticides, and their potential impacts on pollinators, genetically modified crops, vaccine safety, the harms of sugar in the American diet, deaths and injury from gun violence, all of these are issues on which scientists do scientific work collect data factual information, but they have policy implications, policy implications that may be highly contested. So scientists in many fields face this sentinel problem. And I want to argue that scientists in the past have faced this problem too. That although this moment we're living in may feel unique, it certainly feels distinctive and troubling in our lifetimes, but it isn't actually a unique moment in terms of scientists facing this question of what their roles should be. So we could think of this problem as having a kind of spectrum of choices. At one end we might say, as many scientists do say, that we should just do our science and leave it to others to communicate it, to explain why it matters, and we're needed to propose remedies. And we could call this the pure science ideal. At the other end we could think about Jim Hanson, who does speak out, does get involved, does propose remedies, and in his case does even get arrested, we could call that the activist ideal. So what I want to do tonight is to argue for a middle ground. Now as a person who works on climate change, I adamantly reject the idea that the truth is always in the middle, because it's often not, but tonight I do want to suggest that there is a kind of middle ground that we might think about occupying. And then in any case thinking about the spectrum helps us think about where we want to be on that spectrum, because at the end of the day there isn't actually a right or wrong answer to this. These are judgments, but historical experience, historical evidence can help us make those judgments. Oh, thank you very much, and help us judge where we want to be in relation to this question. So my argument tonight has three parts. The first is to talk about historical precedent. To look at an example of scientists in the past who did step up and act as sentinels, not just on the fact of the problem, but also on policy solutions, and to argue that this precedent refutes our worry or our anxiety that taking a public position on an urgent issue undermines the credibility of our science, and then to argue to conclude that I do believe we need to speak because facts don't in fact speak for themselves. So what is the historical precedent? Well, some of you may already know, maybe you've heard me talk before, but it's obviously it's the precedent of nuclear weaponry. Many climate scientists feel that we are today in an existential crisis. Scientists in 1945 knew that they were. There was no question among physicists who worked on the Manhattan Project, who worked on nuclear weapons, that the potential for an arms race meant the potential to eliminate life on Earth as we knew it. And in this context, particularly as 1945 became 1948 and the Soviet Union exploded its first hydrogen bomb, and then the, sorry, it's atomic bomb, and then the United States developed a hydrogen bomb, and then the Soviet Union developed a hydrogen bomb, and pretty soon we were in an arms race. Many leading physicists felt that they had a moral obligation to speak out against nuclear proliferation. As many of you know, they had played an essential role in creating these weapons, and these weapons now threatened human safety and potentially even human survival. And therefore they felt it was actually rather obvious that they had an obligation to raise an alarm and suggest means to control this threat. So, drawing on the framework of scientific rationality, they argued that it was rational to be alarmed and irrational to be complacent. And therefore they did have an obligation. But one of the interesting things about this discussion that takes place in the late 40s and 50s is that many of these physicists argue that their obligation is not just to speak up on the technical aspects of nuclear weaponry, to explain how they worked and how they killed people and why they were so damaging, but also to address the problem of what to do about them, about how to control them. Because to them it was eminently clear that these things did need to be controlled. There was no real plausible argument that an unrestricted arms race would be a good thing for the world. The most famous example as many of you know is Niels Bohr, who spoke out actually even before the end of World War II, and predicted the arms race that would follow if there were not some kind of international dream in between the US and the Soviet Union. And also Albert Einstein, who in later years famously became an advocate for international peace and arms control. But it wasn't just Bohr and Einstein. Sometimes people have said to me, well Bohr could afford it, he was so famous or Einstein could afford to speak out. But it wasn't just these incredibly conspicuously famous figures. Actually a wide range of physicists, Hans Betta, Leo Zalard, James Frong, Philip Morrison, who taught for many years in MIT, and many, many others. There are dozens of physicists that we could name who became involved in a variety of different ways, large and small, to help alert the world to the threat of nuclear weapons and engage people in a conversation about arms control and disarmament. These men spoke to the moral imperative to control nuclear weapons, and they became advocates. The core of their argument is something that I've labeled epistemic proximity. And I think it's an important argument to understand because it's not just about a kind of moral obligation that arose from having built the weapons, but it also has specifically to do with their role as they understand it as experts. So the argument goes like this. not just that they helped build these weapons, but it's that as physicists, they had a uniquely vivid appreciation and understanding of the damage that these weapons could wreak. That they could explain things that other people really didn't and maybe even couldn't fully understand about what an arms race and a large-scale nuclear exchange would really mean. So people had seen the destruction of Hiroshima and Nagasaki. John Hersey had written about it very beautifully in his book Hiroshima, but many people said, well, yes, it's true, lots of people died, but how is that worse or different than the fire bombing in Dresden or the fire bombing of Tokyo? So for many people, it wasn't actually clear why these weapons were substantially worse. Now, this seems hard to conceptualize today and previously the slide said today, all the world leaders understand what a major nuclear explain would do. Okay, well, when you do contemporary history, you have to stand your toes. But clearly, in the late 40s and 50s, that was not the case. Some of you may know that President Harry Truman when confronted with the announcement of the Soviet atomic bomb and when he was asked, well, does this mean there will be an arms race, he said yes, and we will win it. Douglas MacArthur during the Korean conflict requested permission to use nuclear weapons. So it's not the case that people understood that using nuclear weapons would necessarily lead to some kind of terrible conflagration. So these scientists felt that the need to understand fully and viscerally what a large-scale nuclear exchange would mean that this need was severe and that they had to step up to that challenge and many of them did so in both public and private ways. So I think a comparable argument can be made about climate change today. I've given something like 300 public talks on climate change and I've spoken, I'm going to South Dakota tomorrow, so I now will have been to 47 or 50 states and I've talked in Idaho and North Dakota and Texas and Oklahoma and California. And one of the things that I feel I've learned is that many people, including many people who do not deny climate change or do not disparage climate science, still don't really quite get why this issue really matters. They don't quite understand just how serious uncontrolled climate change will be. One of my colleagues, quite famous and distinguished political scientists, said to me once over lunch, so tell me why I should be worried about polar bears. And this is part of why Eric Conway and I wrote the collapse of Western civilization because we were trying to think about, what could we do, what kind of story could we tell that would convey to people why climate change really matters and why this is not just a question of polar bears as much as I personally do love and worry about polar bears. Okay, so part two, I want to argue that this historical press and offers evidence that refutes our worry that taking a public position on an urgent issue will undermine our scientific credibility. And this argument is actually extremely short. The evidence simply doesn't support this hypothesis. If we think about Albert Einstein, I know of no evidence and maybe someone can come up with it but I know of no evidence that the theory of relativity or his work on the photoelectric effect ever lost credibility because of his advocacy of arms control. Now, there were anti-Semites in Germany who didn't like Einstein, but that was not because of his public advocacy. That was because of a whole set of other complicated issues. Hans Betta, as many of you know, won the Nobel Prize for his work on nuclear fusion fusion. No one ever suggested revoking that prize or that somehow that work was doubted or dubious because he was an arms control advocate. And Bohr is such an interesting character. Some of you know, many of Bohr's colleagues were dubious about the Copenhagen interpretation of quantum mechanics. Bohr wrote a lot of philosophical essays that lots of his colleagues thought were completely off the rails. But it wasn't, but not his arms control advocacy. Millions of schoolchildren learned about the Bohr model of the atom. If you took high school physics or college physics, you learned about the liquid drop model of fish and you learned about his crucial scientific contributions. And no one ever said that those contributions were undermined because he advocated arms control. Now what about Robert Oppenheimer? Some people say to me, well, what about Oppenheimer? Oppenheimer is a famous case of a scientist who got discredited. But what exactly happened to Oppenheimer? He lost his security clearance because of his opposition to the hydrogen bomb. And also because Edward Teller held a personal grudge against him. And he saw this as an opportunity to undermine him. So Oppenheimer lost political standing inside the US government. He lost his clearance. He lost his capacity to give advice to political leaders on certain delicate issues. But losing political standing with politicians is a very different thing than losing scientific credibility. And in fact, Oppenheimer became a hero in many circles. I mean, many of you have heard of Oppenheimer because of this, more than because of his science. So among many people, he gained credibility. So when we talk about credibility, we actually have to be more precise. We have to ask, are we talking about credibility with political leaders? Are we talking about credibility with the public? Are we talking about credibility with our own colleagues? Or what?"}, {"content": "These are different things. There's no evidence that Oppenheimer lost scientific credibility with any of his colleagues because of this work. So I want to argue that the fear of losing scientific credibility is exactly that. It's a fear. It's an anxiety. And there's actually very little evidence to support the worry. And you can call me naive, but I do think we should be making our decisions based on evidence. Even though I know that's a very controversial claim to make in the stage. And some of you may have seen that there's actually a study that just came out a couple weeks ago."}, {"content": "And I apologize I haven't had a time to make a slide of it. But a recent study that actually interviewed people of the public and posed to them some scenarios where scientists spoke out in public, made policy recommendations, actually showed that there's very little evidence to suggest that this causes you to lose credibility with the public either. So it's actually an interesting question. And it will be a question for another talk about, actually, why we are so worried about this issue when there's actually so little evidence to support it. But I haven't done that work to answer that question yet. OK, so part three, facts don't speak for themselves. Well, why do I say that? Why don't facts speak for themselves? Well, the simple answer. And when I started saying this 7, 8, 9, 10 years ago, this was considered controversial. Now it seems obvious. So that's good. I can make the talk shorter. We live in a world where many people are trying to silence facts. And as you know, as many of us now understand, these arguments are not actually about the facts. They're not just about the facts. In most cases, they're not even actually about the facts at all. Many of the arguments that are being used to undermine climate science, to be able to undermine evolution, to undermine vaccine safety. These are arguments about political beliefs, about economic interests, and about values. You cannot refute a claim about values with facts, or claim about facts with values. That's what philosophers would call a category mistake. We're conflating two different domains. If people are rejecting climate science because of values, then we have to think about what those values are, and why those values are perceived to be in conflict with our facts. And this was essentially the conclusion of the work I did with my colleague Eric Conway when we wrote the book Merchants of Doub."}, {"content": "When we started this project, we were frankly mystified. We had come across a story of some very famous scientists that we actually knew, one of whom had been the director of the script's institution of oceanography, where I was working at the time. And these prominent distinguished famous scientists had become climate change deniers. And there was no possibility that this was scientific illiteracy, because these were some of the most brilliant and successful scientists of the 20th century. It included Frederick Sites, who was the president of the US National Academy of Sciences. So the question we had was, why would these people reject the scientific work of their own colleagues? How do you make sense of that? And what we found overwhelmingly, not just are these men that we studied in our book, but in general that the rejection of climate scientific facts was not about scientific illiteracy or lack of scientific understanding. But actually, it was driven by an anxiety, by fear, by a worry, the worry that addressing climate change would lead to bigger government, higher taxes, and loss of personal freedom. And those concerns and the solutions that people were proposing for climate science were seen as clustering with conservative values. And that's why we've seen this enormous politicization of the issue because of conservatives believing that the implications of climate science threaten their values. It's this clash of values, then, that explains the polarization, and also some of the otherwise strange alliances that we see on this issue. The perception that addressing climate change, sorry, that addressing climate change will require big government or higher taxes, explains a good deal of the political polarization around the issue because opponents of big government are ideologically motivated to reject climate scientific events. And they've made common cause, then, with industries that reject the science because it threatens their profit. So the obvious part of this story, the economic mode of this economic self-interest aligns with a more subtle and complicated story about people seeing climate science as clashing with and threatening their values. So just to sum this up, I want to show you a short clip from the film that we were made of our movie. And this is just kind of merchants of doubt. And in that shell, it shows you who these people are and the sorts of arguments that they make to try to undermine scientific findings. Bill O'Keefe is Executive Vice President of the American Petroleum Institute. He's also a board member of the Global Climate Coalition, made up of oil and electric companies, automakers, and others. We believe it was the war on the oil. They had an off-hoyle agenda. Climate change was part of that. I think that it's unfortunate that the science is so distorted and mistated. And without it... The science is complicated. There are lots of different factors. So you really have to understand the whole picture. There is a natural variability that has nothing to do with me. Climate is changing naturally. Has to do with sunspots and has to do with the wobble of the earth. And so it's not too difficult to persuade some of the public that we really don't know for sure. So maybe that's way to wild. We need to have more proof. We need more data. The science isn't there to make that determination. There is no need for us to rush to this kind of judgment to respond. Others put out ads saying more pollution is going to be good for us. A doubling of the CO2 content to the atmosphere will produce a tremendous greening of planet Earth. CO2 is a benefit to plant life. It's increasing the bounty and the productivity of the planet, our ability to feed populations in this world. What you're seeing here from the coal industry is perfectly analogous to what the tobacco industry is to do. They refuse to change, refuse to shift. And they're trying to convince us that it's actually good for us, the way they used to say, luckies make you healthy. OK, so in that clip, you see sort of the basic, you see the merchants have doubt doing their thing. But in that clip, you're seeing people, mostly who represent the fossil fuel industry. So Lee Raymond from Exxon Mobil, Don Blankenship from Massey, Energy, Bill O'Kee from the American Petroleum Institute. But again, as I already mentioned, part of what we were trying to do in our work was to understand why would scientists, why would other people who don't have stock and exome mobile, why would they make common cause with this sort of work? And again, as I've already suggested, it's this confluence of money and ideology that explains the pattern that we saw. And this also helps to explain why climate change now is so much more prevalent in the United States than elsewhere. Because of our powerful commitment to individualism in the United States, and the historic American skepticism about the federal government going back to the founding of the Republican skepticism about centralized decision making. And if you think about it, think about the articles of confederation, think about the separation of powers. This country was rooted in an idea that investing too much power in centralized government would undermine the individual freedoms of the states and the people in them. We have a deeply rooted belief in the United States that the government that governs best governs least. And that's a belief that informs a huge amount of climate change denial. So climate skeptics, contrairions, deniers, whatever you want to call them, they play on these cultural norms, insisting that addressing climate change will lead to an expansion of the government and a constriction of our freedoms. And you've seen this kind of ideology on display in the last few weeks. And this resonates very strongly with many ordinary Americans, particularly in what we've come to call the red states. And therefore, people resist accepting the findings of climate science, and they're open to the suggestion that our findings are exaggerated or even perhaps a hoax. So I want to just give one example of how this works in sort of one scientist that we study that I think is a particularly illustrative example of how this ideological piece comes together with rejecting the findings of science. So one of the people that we studied was a physicist named Fred Singer, who some of you may be are familiar with. Singer was not a climate scientist. He was a physicist. In fact, he was the proverbial rocket scientist. He was the first director of the US whether satellite service and was involved in the early years of the US rocketry and space programs. But in addition to his scientific work, he was also involved in campaigns to challenge the scientific evidence of acid rain, of the ozone hole, of climate change, and also of the harms of tobacco. Fred Singer, in the early 1990s, worked with the Philip Morris tobacco company to attack the US Environmental Protection Agency over the issue of secondhand smoke. Now some of you know that we have known since the 1980s that secondhand smoke can cause cancer. The same chemicals that are in primary smoke also occur in the exiled smoke or in smoke that comes from a cigarette that's just burning. And if you breathe that smoke, you also can be subject to cancer and many of the other diseases that affect smoking, smokeers. This was first stated unequivocally in 1986 in a report of the US surgeon general in which the surgeon general declared that involuntary smoking, that was the term he used, is a cause of disease including lung cancer and healthy non-smokers, especially children. And based on this, as well as an independent review of over 6,000 peer-reviewed scientific papers, in the early 1990s, the EPA declared secondhand smoke to be a class A or proven carcinogen. In 1994, working with the tobacco industry, Fred Singer wrote a report attacking these scientific findings. And one of the reasons, this is a copy of out of the tobacco legacy documents of the cover page for this report. And I made this slide because Fred Singer is still alive and he accused me of being a liar. He has said in public that he never worked with the tobacco industry. So, yeah, there it is. Okay, so I love documents."}, {"content": "I love my job. So, Singer had been working as a consultant to Philip Morris and he was hooked up, I'm not sure exactly how, but he became, he started working with a lawyer named Kent Jeffries, a lawyer who was affiliated with the Kato Institute and the competitive enterprise institute. And some of you know these are things that promote free market solutions to social policy problems. The report was actually published by the Alexis de Toekeville Institute but funded by the tobacco institute, which was the so-called research arm of the tobacco industry. So, this report illustrates in a nutshell how this works. There's a kind of shell game where the tobacco industry would give money to the tobacco institute claiming that that was for research. Tobacco Institute would hire lawyers out of thing tanks like the Kato Institute. They would then work with a scientist who would give the thing scientific credibility and produce a report that would be issued by yet another thing tank. In this case, the Alexis de Toekeville Institute whose name would conjure up notions of freedom and democracy in America. Now, the interest of the tobacco industry in attacking the EPA is obvious. And I think the interest of these thing tanks in opposing regulation is nearly as obvious. But why would a physicist attack the scientific evidence of the harms of tobacco? Well, I would assume that singer was paid for this work but that's not the key part of the story in my view. The key part, I think, comes from his own words. So, in the introduction to this report, he explains why it's important to push back against the EPA. And he says, quote, if we do not carefully delineate the government's role in regulating dangers, there's essentially no limit to how much government can ultimately control our lives. And in our book and in our films, we document many, many examples of this argument. If we allow the government to regulate X, then soon it will also regulate Y and Z and we will lose our freedom. Acid rain today, the Bill of Rights tomorrow. This argument comes directly from the work of the Chicago economist Milton Friedman. And it's an argument that I call the capitalism and freedom argument. And indeed, we've seen this argument being resurrected in the last few months. It was used by Ronald Reagan in the 1990s to justify lower taxation, less government and to foster a marketplace deregulation. And that set of arguments has really been guiding conservative thinking in the United States since the Reagan administration. The two key texts are Milton Friedman's book by that name, capitalism and freedom, which was inspired and turned by the work of the Austrian neoliberal economist Friedrich von Haack. So if you're interested in this problem, these are the two books that you need to read to understand the intellectual framework that is guiding this whole argument. But if you go back to von Haack, his basic argument is he's making this argument towards the end of World War II, he's saying if we allow Western democracies to have national health insurance or other forms of intervention in the marketplace, we're going to be on the road to surf dumb. And it's only a matter of time."}, {"content": "It's a kind of inevitable creeping of government controlled into different aspects of life. So this is the common thread of science denial. And in fact, the common thread between climate change, acid rain, tobacco, and other things that otherwise might seem to be totally different issues, that scientists discover a problem, typically inadvertently, I mean, the scientists who were working on acid rain didn't set out to discover acid rain. They were studying forest ecology and watershed hydrology. But scientists discover a problem. And the solution to this problem appears to require some sort of government action, whether it's putting a price on carbon or banning CFCs or limiting sulfur emissions from coal-fired power plants. And so people who don't want that government action, either for economic reasons or philosophical ones, question the science and attack the scientists. Sociologists call this implacatory denial. You deny something because you don't like its implications. And it's a common pattern in human life. It's not restricted to climate change denial. But if you deny the evidence that your partner is having an affair, maybe that's OK. Life goes on. If you deny the evidence that the climate is changing, the consequences are pretty serious. So science has been politicized to bring this now back to our question. Science has been politicized as a means to undermine it by groups and individuals who do not like what they interpret to be the political implications of our scientific findings. So here's the crucial point, though. When scientists were attacked, when the scientists who worked on tobacco or acid rain or the ozone hole were attacked, it wasn't because they had crossed the line into policy. Most of the scientists who were attacked in these stories that we wrote about had actually not played any role in public policy at all. They had done what most of us think we're supposed to do. Do important work, publish and period your journals. Talk about. out of the meetings, but their scientific research had revealed or affirmed serious problems like deaths from tobacco use or the threat to life on Earth from ozone depletion. So these scientists did not become targets because they had spoken out. They became targets because of the importance and significance of their work. So I think that many of us in the scientific community have actually misinterpreted cause and effect. The causal arrow is the reverse of what most of us think. Now it is true that today there are some climate scientists like Mike Mann and like Jim Hanson who have spoken out, who have become public figures, but even these men, even Mike Mann and Jim Hanson, both of whom I know, they became public figures after they were attacked. They were scientists doing science. They got attacked and being attacked made them decide that they needed to stand up and be counted. So it may help to understand this also to know that there is actually a very long history in the United States of claiming that government intervention in the marketplace threatens our freedom. And this is from some new work I am doing now trying to understand the deeper roots of this argument, which it turns out go back to at least the 1920s. And one of the ironies of this is that these arguments have actually often been used to protect products, products, profits. And in some cases actually to restrict competition even when people are claiming to support a free market society. So I just thought this is such a very interesting advertisement that I found. And I thought I would ask you, what do you think this might be an ad for? And my postdoc is not allowed to answer, but anybody else? Yeah, Barbara wire, that is the usual answer. Sometimes people say hats. The answer is privately generated electricity. This was part of an ad campaign run in the early 1960s by a group of private sector electrical utilities who did not want the federal government to generate electricity at the Hoover Dam or other places in the United States. Now we can argue about the benefits of government electricity, but the point is to see that the argument is not being made, it's not about the merits of different ways of generating electricity. The argument is this fear mongering campaign that if we allow the government to generate electricity, pretty soon we'll be living behind barbed wire. So what does all of this tell us about facts and values? Well, we see that in all these stories, the facts and values are conflated and complicated in difficult ways that are difficult to sort out. But the key insight I think is to understand that these arguments are not about the scientific facts and because they're not about facts, they can't be refuted with facts. But they can be addressed with political or historical evidence or with other arguments about values. So for example, one thing we can do is to challenge the assertion that addressing climate change necessarily requires bigger government or higher taxes. And a good example of this is the history of acid rain. So some people in the audience here I know remember that acid rain, which was a very serious problem, was addressed in the 1990s through amendments to the Clean Air Act that created emissions trading, a market-based mechanism that was supported by both Democrats and Republicans and signed into law by Republican President George H.W. Bush. This law did not lead to the expansion of the federal government, it did not lead to higher taxes, nor did it lead to a loss of liberty of people living in the Midwest where acid rain was a problem. And in fact, the price of electricity in the American Midwest fell. The second thing I think that's important for us to think about is that I think we shouldn't be afraid to address values. For two reasons, first of all, because these are values, questions we have to address the values involved. If we just keep throwing more facts on people, it won't address the worry, the concern that they have. So if our fellow citizens in South Dakota, Ohio, or Oklahoma are worried about bigger government or worried about values, then we have to be able to talk about that. And I think that preventing disruptive climate change actually lines up with the fundamental values that many of our fellow Americans share. In fact, I think it lines up with more values that many of our fellow Americans share than simply the value of constraining big government. So think about it. The value of fairness, which includes protecting innocent people from getting hurt. We controlled secondhand smoke in part because there was so much overwhelming evidence that secondhand smoke hurt children. And that was one of the very powerful arguments that was made for the right of the EPA to regulate secondhand smoke in order to prevent hurt or harm to innocent people like non-smokers and children who were not choosing to smoke. Or the value of accountability that the people who made a problem have an obligation to address it. Or the value of being realistic, of accepting that market failures are reality, and sometimes there is the need for the government to nudge the market in the right direction. We saw that during the housing crisis we've seen it in the financial crisis. People know that markets don't always work the way we want them to. Or the value of technological leadership and hard work of rolling up our sleeves and getting the job done, something that Americans have always done and prided themselves in doing. And of course, most importantly is the argument that there are values that the market does not protect like the basic inherent dignity of all people. And this is the central argument that Pope Francis makes in the encyclical on climate change and inequality, that there is an inherent dignity to all humans, and that that is something that we all have a right to defend and protect. Freedom is important, but so are many other things. And in the long run, climate change deniers are not actually protecting our freedom. In fact, they're threatening it. And this I think is one of the most powerful arguments we can make. That while the climate change deniers say freedom, freedom, freedom, which they do, in reality, the shoe is on that other foot. So I want to just show you one other clip from the film where I'm speaking and addressing this issue. As sea level rises and hurricanes become more intense, people get killed. Their houses and communities get destroyed. But think about heat waves and droughts that ruin agricultural communities. All of these are problems that it will require government intervention to address. The great irony of the story to me is that people who don't like big government are going to get more of it. And we're going to see more money being spent on dealing with the aftermath of these disasters. There will be billions of dollars in real estate losses, but more than that, people die. That's why it matters. That's why this is meaningful for us and not just for polar bears or people in Bangladesh. That's why so many people in the scientific community now are really starting to talk in very worried tones. Because there's, I think, a growing sense in scientific community that we're running out of time to prevent a train ride. So obviously my argument is that we do need to speak up because we need to counter the disinformation, the misinformation, and the false value arguments that are being made by other people. But I want to end with one more thought which gets back to this idea of epistemic proximity. So if we go back to Roger Revelle in the 1960s, Revelle spoke up because he knew about something, the possibility of disruptive climate change that few other people were aware of. And like Born Einstein and Beta before them, Revelle and killing and their colleagues, we're speaking from their proximate expertise. Meaning about something that they understood by virtue of their expertise as scientists that other people did not understand. But they also respected the expertise of others to propose and formulate the solutions. And Revelle worked on climate change his whole life. He studied it from many different angles. But he always was very cautious about any response to a question about what the right policy solution was. And I think this points to an important distinction. And it's not the fact value distinction as people have normally understood it, but it is related to it. It's about the limits of expertise. It's about who really knows how to fly that plane. So there are many things which is natural scientists or social scientists depending on what our expertise is. There are many things which we're not experts about and not particularly qualified to speak about. So in the case of climate change, if you're a climate scientist, if you do work on the physical science of climate change, you're not particularly knowledgeable in most cases about the social and economic aspects of impacts or the details of policy. Earth scientists cannot say, oh sorry, Earth scientists can say that if we're to prevent dangerous anthropogenic interference in the climate system, which is what the UN Framework Convention commits us to, then we must do something to control greenhouse gases because greenhouse gases and deforestation are the causes of this problem. Just as CFCs were the causes of ozone depletion and second-hand smoke was the cause of lung cancer and otherwise healthy non-smokers. And that means preventing the continued dumping of CO2 into the atmosphere. That is a conclusion that falls directly from our science. We could call it a direct deductive consequence. And therefore I want to argue we should not hesitate to say things that fall out directly from our scientific knowledge and understanding. Indeed, I would argue that it is our responsibility to do so because we are the people who have that epistemic proximity, who understand the problem best. And in my model for this, then I said in the beginning I was going to put forward an idea of the responsible scientist and I think we have a model of someone who played that role in the United States and that's Sherry Rowling, who won the Nobel Prize in the mid-1990s for his work accurately predicting that chlorinated fluorocarbons would deplete stratospheric ozone. In the 1980s Rowling and his colleagues realized that unless we control CFCs, then destruction of stratospheric ozone would threaten the future of life on Earth. And because of that he began to speak publicly and like his nuclear physics colleagues beforehand he became an advocate for action to control these chemicals that were the cause of ozone depletion. So for him policy was a deductive consequence. Rowling felt that he couldn't do this because the need to control CFCs was a direct consequence of the scientific work. So we can think of the argument as going like this, CFCs destroyed ozone. stratospheric ozone protects life on Earth. So if we want to protect life on Earth, if we want life to continue, we must somehow control CFCs. Now, this didn't involve an implicit value premise, but that value premise was the value of life on Earth. And really, who was going to challenge that? I mean, that's a debate that I'd be happy to take on with any climate change denier. But here's the important point. His advocacy didn't undermine his scientific credibility. He did his key work in the 70s and early 80s and he became an advocate for action in the middle to later 80s and played a role actually in the development of the Montrel Protocol to control the substances that deplete stratospheric ozone. But in 1995, he was awarded the Nobel Prize in chemistry for this work along with Paul Krutzen and Mario Molina. I think that if anything, there's an argument to say that his advocacy actually cemented his scientific legacy that we know more about Sherry Rowling's scientific work today in part because of what he did as a public, as a responsible scientist. So is there a comparable position for climate scientists? Yes, absolutely. Greenhouse gases are causing climate change. Climate change is dangerous. As I say in the film, it threatens people's lives, it threatens our homes, our well-being, our prosperity, and it also threatens polar bears and many other species, coral reefs and others. So if we want to protect humans and other species from the damages of disruptive climate change, then we must dramatically reduce and eventually phase out greenhouse gas emissions. And this is a deductive consequence that follows logically from our scientific work. But, however, as natural scientists, we don't have the expertise to answer questions such as, which is better a carbon tax or emissions trading system. If we go for an emissions trading system, should it be revenue neutral? Sorry, if we go for carbon tax, should it be revenue neutral? And if so, should we do it through fee and dividend or through cutting tariffs and taxes elsewhere? And how useful are fee and tariffs in stimulating renewable energy production? Should we focus on grid integration or energy storage? And what about nuclear power? These are all matters of social science, law, policy, and politics."}, {"content": "It doesn't mean we can't have an opinion on these questions, of course, as citizens we can. And Jim Hansen has a right to be an advocate for the fee and dividend system if he wants to as a citizen. But I do think it's important for us to be clear about the limits of our own expertise because let's face it, we aren't the people, unless you have a pilot's license, we aren't the people to fly that plane. So I want to argue that we should be reticent about areas outside our expertise. We should respect the expertise of others who are expert in those domains, whether they're economists, psychologists, lawyers, or other natural scientists. And if we want to address these topics because we've concluded that they're essential to the solution, then we should forge collaborations with colleagues in those domains. Put another way, if we expect people to respect our expertise, then we also have to respect theirs. That seems like common sense. But we should not be reticent about talking about the things we know and understand, the things we know to be true. And we should not be reticent about calling out others who say things that we know to be untrue. Experience of the past several decades has shown that when it comes to facts about the natural world, there are many people prepared to speak against the facts for many diverse reasons. And therefore, someone has to speak for the facts. And that's someone, I think, is us."}, {"content": "Thank you very much. So, who's going to the science march? That was wonderful. If there are any questions, please ask them."}, {"content": "Yes. Just call on people. Yeah."}, {"content": "Oh. Oh, here we go."}, {"content": "Thank you. Is this on? Yes. Oh, boy. It's very on. So I'm a great admirer of your work. And I found your chain of logic persuasive this evening, but loses me at one point. You suggest, but never quite say, that if more climate scientists spoke out about climate change, it would make a difference. So to put it in question form, do you believe that in spite of evidence that Peter Froomehoff speaks out James McCarthy writes letters to the globe last week, Somerville, et cetera, et cetera. Any climate scientists are speaking out. It's not clear to me what difference that's making. Yeah, that's a fair question. Of course, with anything evolving, social change, these are very hard things to judge, what makes a difference, what moves the needle. But I think that if you think about it, I mean, you named four or five people and I could probably name four or five more. But there are something like 10,000 climate scientists in America. And when we think about the people who have spoken out, the same dozen names comes to mind all the time. And I've served on committees that give out prizes for climate science communication. And I can tell you that the lists of people that get nominated are distressingly small. So I think that actually the numbers of people who have really been involved making the effort are small compared to the pool of people who are potentially available to do the work. And I think it's very important to have a larger pool for a couple of reasons. One is that we know we do have good evidence from social science research about the so-called trusted messenger problem. People respond to messages in part based on who's telling it. And that makes it really important that it isn't just a couple of people. It isn't just Jim Hansen and Richard Somerville and Peter Fremhoff, much as I love all those people. No, I don't love Jim Hansen. No, just kidding. Not just I honor and respect all three of those men. We need more different people. And everyone talks about Catherine Haleho now because she's this famous evangelical Christian scientist. And it's absolutely fabulous what Catherine is doing. But I mean, she is so incredibly lonely. And she's not the only climate scientist in America who is a religious believer. So why are we always talking about Catherine Hale? I mean, where are the other Christian scientists, not Christian scientists, but scientists who are Christians? I mean, where are they, right? And we know we do have evidence from the evolution debate that it does make a difference. When students hear about, and the person doesn't even have to come to class, there was a great talk at Trippoliest just last month or whatever we were there. I don't know."}, {"content": "Time has stood still since Donald Trump got elected. But there was this great talk about an experiment that faculty at ASU have done where in class, in a biology class, they talk about scientists, evolutionary biologists who are also Christians like Ken Miller, Brown. And it doesn't, you don't need Ken to come to the class. Just talking about it, just having the students read something that he wrote about how he personally recognizes his religious faith with his scientific work. That makes a difference in how students receive the scientific information that they're getting. So we have evidence to say that it does make a difference. And so, and again, though, it's not just about writing a letter to the editor. I think the evidence also tells us that, no, I don't think writing more letters to the Boston Globe is the key thing right now. Oh, forgive me, but that is how I feel. But I think getting out, talking to people in communities, explaining to people how you became a climate scientist, what you've learned, and why it matters. Why it matters to people in the places they live. I think we do have evidence that that can make a difference. We also know that most people, when they vote, you know, they're not voting about, people didn't vote for Donald Trump because he said climate change was a hoax, right? And part of the problem is that people don't see climate change as a problem that affects them and their lives. So we need to do more to talk about what the relationship is between climate change and jobs and storms that do affect you or that affect your crops. And that's a message that I think has not been articulated nearly as fully as it needs to be. Yeah."}, {"content": "Oh, sorry, well, that's right. Okay, so it's alternate sides. I don't know who I'm talking to. Oh, hi. Yeah. I wonder if you could clarify something and just didn't focus quite for me."}, {"content": "And the most thing the last part of you talk. You said you distinguish science from the values and you said the people who are the deniers are really motivated by values. They associate their position with freedom and so on. Now are you saying that the scientists should get in a debate with them about values? You quickly outlined a few values like fairness and accountability and so on. But the scientists aren't expert about values necessarily. And besides which the deniers, it's not like they're... are leading with their values, they're denying the science. And that's something the scientists do know. So how much do you want the scientists to be talking about values and why? Yeah."}, {"content": "OK, that's a great question."}, {"content": "I think you're right, because this is tricky. So the point is, though, when climate change denires attack the science, and scientists then try to answer it with science, it doesn't work. Because first of all, now you're in a debate about the science. And that just, one of the claims of climate change denial is that the science is unsettling. There's a big debate. So if you participate in a debate, now they have won, because you've demonstrated that there's a debate. And we learned this again in the evolution situation, too. If an evolutionary biologist debates a creationist, the evolutionary biologist always loses. Because what the audience hears is, oh, there's a big debate. We don't really know. So the debate framework, when you're debating science, just doesn't work. So then the question is, well, what are some of the alternatives? And so what I'm trying to get at, and it is a little subtle, so maybe I didn't explain clearly, is to expose, to say, look, I understand that there's a value premise here, right? And I understand that you don't want to see the expansion of big government. So let's talk about how we could solve this with small government solutions. So it's a way of shifting the argument. And then I think a scientist can talk about values if they are your own values. Because we all have values. You don't have to be an expert on values to talk about your values. So one of the things I do sometimes is I do talk about accountability. And I say, look, most of us believe in accountability. So let's talk about who made this problem, and who's got the responsibility to fix it. Because one of the strategies that we've also seen being used is the idea that this is the fault of China or India, right? And so it's a way of saying, well, let's talk about the US contribution to climate change. We made this problem, but we also can fix it."}, {"content": "And we can fix it through technologically innovation. And then we can move the conversation into a discussion about grid integration and energy storage. And that moves the conversation where I want it. Because I don't want to be debating whether or not climate change is happening. I want to be debating how do we get better grid integration and energy storage. And then I've got the conversation where I want it to be. And then I can talk to my audience about all this cool stuff that's going on in the technological domain and all the jobs that have been created in green energy in this country, which it turns out almost nobody knows about. Here's a good question."}, {"content": "Again, my postdoc is not allowed to answer. But how many jobs do you think there are in coal in the United States? OK, most estimates say between 20 and 30,000. So this is a highly educated audience. And even you think it's much more than it is. Most people will tell you a million or 500,000, right? There are actually incredibly few jobs in coal mining in this country, despite all the fusing and rhetoric that we've been hearing about the one coal, right? How many jobs do we have now today, not in the future, but today in renewable energy? Anybody care to guess? 500,000? Do I? OK, this is a ridiculously educated audience."}, {"content": "This doesn't work as well. The correct answer, though, even in this wildly educated Harvard audience, 3.5 million. Yeah, who knows that?"}, {"content": "So that's the point. We want to be take, if people are worried about jobs, let's talk about jobs, because actually we have really good evidence on that job front. So does that kind of clarify it a bit?"}, {"content": "Good."}, {"content": "Thank you. Hi."}, {"content": "And I need to add something over here. I don't want this to get into a debate about religion, but I do have a point to make a question to ask. I'm actually from Texas. Don't worry, I'm on your side. And I'm a science advocate among my people. I just mentioned that. My family is chocked full of very religious people. My dad's a Southern Baptist minister. Most of the people in my family are in the ministry. And when I talk to them about this stuff, they don't deny the science. They deny that we'll be here long enough for it to matter. They keep telling me that don't worry, Jesus is coming. And so I wonder where the argument is, what the point we can make is, and if there's hope for even any progress with these kind of people. Yeah."}, {"content": "I don't think there's anything you can do, honestly. No, really."}, {"content": "I mean, I'm teaching science and religion in America, and one of the things that's so interesting about religious belief in America is how incredibly diverse it is. But if people are Millenarians who believe that Jesus is coming, that's all going in pretty soon anyway, I'm not really sure there's much of an argument you can make that would change those people's minds. So it might be better to just move on and work on, you know, I mean, Texas already has a feed and tariff for wind power. But to think about, you know, things you could do to support renewable energy that people might support for other reasons, like it's economically sensible, or some other issue that they might like. I don't know."}, {"content": "I'm sorry, what? I'm sorry. I know you're going to be a little bit more confused. Sorry. What was that?"}, {"content": "What? Do you think that the problem with religious belief is that we care to care to care to be back? We think that. Right. But if you think it's all about to end, right? I mean, if you really, and especially, no, but I mean, this does raise an important issue. I mean, one of the challenges that scientists often face is that things that for us are clearly evidence to support our theories are not necessarily evidence of that for other people. So if you have an eschatological philosophy, and you do believe that the world is about to end, then the intensification of hurricanes, you know, heating of the ocean, depth of coral reefs, things that for us are clearly evidence of climate disruption, for those people could be evidence that we're really getting close. So you can't really win that argument, right?"}, {"content": "And so you might just decide, you know, you need to move on, right? But the fact is, let's face it. I mean, political change doesn't come because everyone agrees on everything. Political change comes because enough people agree on enough things. And so I think that's where again, there are people who are evangelical Christians who might disagree with me on a whole heck of a lot of things, but still might be willing to support solar power because they could see the way in which it might empower their communities, right? Or they might see the way it could bring jobs to their communities. So yeah, yeah."}, {"content": "Oh, sorry, you're next. Okay, go ahead."}, {"content": "Hi. About a month ago, I went to Denver for three days of training with Al Gore's group, the Climate Reality Project. And as part of this free training, I've got an obligation to participate or be involved or organized 10 events during the year. Oh, gosh. As I was thinking about how to meet my obligations, one thing that occurred to me was to turn to my work. I work for a national company in healthcare. It's a billion dollar company. So I sent an email to the owner of the company and he said, oh, sure, let's talk about it. I had a conversation with him yesterday in which he said, well, you know, this is a really good thing, but I concerned about the political angle. Some of our customers and employees might not agree with the message. So as we talked over about half an hour, I was able to pull him around to thinking about this. This is a green initiative. We're doing something good. It's going to benefit people. So we take it out of the political angle. Well, today, Michael Mann gets into it with a Lamar Smith and with Judith Curry at the House Science Committee meetings and it's going to be in New York Times tomorrow and my boss is going to read that. So we've got this political environment going on that's making it difficult for people to take positions because they're afraid of the polarization. You're out there speaking. Catherine Heyho is. Michael Mann is. But where are the rest of the scientists? Well, I mean, that was the question we had earlier, right? And that is part of my argument is that I think that more people and more diverse people need to be involved in this issue. And the more different kinds of people are out there talking, the less this would look like, it would just be a particular political point of view. I mean, the hearing today was an interesting when I got approached by the committee last week. And this is theater, right? So we have to borrow from our colleagues in the theater department and think about how do you respond to a theatrical performance? And so when I'd recommend it, it was too late because they'd already invited Mike to come. And that's okay, Mike's great. But I said don't invite a scientist to respond, right? This is a charade, you know, I mean, it's ridiculous."}, {"content": "You can find three people say almost anything anywhere if you look hard enough. I think what you should do is just fill the chair with all the reports, you know, all the government reports, all the IPCC reports, just stack them and have a giant pile and say that's our response, right? You know, so, you know, we could begin to think creatively."}, {"content": "We don't have to just be pulled in all the time to these, you know, frameworks that we know are wrong and misleading. But we do get sucked into them and it's hard not to, right? It's hard not to think. I mean, it was an interesting moment for me when I realized the House Science Committee, well, the minority is calling me. And I'm telling them don't get a scientist to testify, you know, just bring in a pile of reports, right? And after I wrote, you know, I said that. I hung up the phone and thought, wow, that's an interesting moment, you know, right? So, but, I mean, we do have to be creative. We have to think differently about this, I think, than we have in the past. Okay, thank you. I'm actually related to what you just addressed. But so I'm a PhD student at this point without much public visibility or platform. And I'm just curious what you think are positive and productive venues for scientists to express their expertise to affect real change. Go to a local school, go talk in your church. I mean, we're all part of organizations and networks. And I think what you said about your job and your work is a really important insight. Sometimes we think we don't have access because we don't get invited to Congress so we don't get invited. But, you know, public opinion isn't really being made on the front page of the New York Times as much as the editors and New York Times would like to think that it is. Public opinion is being made by people talking to their friends and their neighbors and in their churches and in their synagogues and in their mosques and in their community groups. So there are opportunities to reach out to people all the time, but we sometimes don't see them because we take for granted what's around us. So I would say, you know, wherever you live, maybe the local library has a lecture series that you could volunteer to speak in. Or give me your phone number and I will tell them to invite you. And I mean, seriously, I get so many more invitations and I could possibly handle. And I'm always looking for other colleagues who I can suggest. So if you want to do talks, let me know. And I'll send, you know, I mean, obviously not everything I get invited to do, you know, they'll take a substitute, but some of those they will. But the point is they're all kinds of opportunities. And, you know, I was thinking about this the other day about being a Harvard professor and I'm going to South Dakota State tomorrow. You know, I think if most of us get invited to speak at Princeton or Chicago or Caltech, of course we go because we see the obvious value for our professional stature to do that. But I think that a lot of colleagues if they got invited to go to South Dakota State would just say no thanks, I'm busy, right? And my thinking about that is completely inverted now. I mean, I should say myself, 15 years ago, I would have probably thought that."}, {"content": "Now it's the other way around. I get invited to go to Princeton, I say, you guys don't need me, South Dakota State, they need me, right? So where I'm going to speak, what I'm accepting now is very different than even five years ago, because I'm really thinking in terms of places where outreach could make more of a difference. So I'm not doing any more teachers and teachers in Cambridge, I'm already told people that. Okay, so anyone's thinking about it, because I don't think this is where we need the action. And I think that all of us should be thinking about what are our points of connection to places where it could make a difference. And that, for a lot of us, means not on the Harvard campus, but it might be in our communities because lots of us live in places where, as I said, people might not be climate deniers, but they may not be very engaged in understanding why this issue is important. So let's just have two more questions, is that okay?"}, {"content": "Yeah, that'd be great, thank you. And then I'm sure, I know we would be happy to. Do what, go home and have a good night's sleep."}, {"content": "Yeah, yeah, yeah, okay. There are other contexts in which scientists are asked to make moral choices. A couple of years ago, Steven Hawking refused to attend a major conference in Israel because he was asked to observe the academic boycott there. Should scientists take a moral stand on very pressing issues of the day, if it's not directly related to their field of inquiry, even though it entails moral obligation in which some of their activities may come in contact with the circumstances that are resulting in various forms of repression in human suffering. Look, I mean, I can't tell other people what to do."}, {"content": "I think those kinds of issues are quite difficult and vexed and people have to decide for themselves. But in general, my view would be, would be no. I do think that as climate scientists or as toxicologists, or as marine biologists, or whatever our field is, that we have a particular role to play as experts. I mean, that's why I use the cartoon about applying the plane. And that's what I'm really most interested in. Now, of course, as human beings, we're going to be making choices all the time about what we think are more or more, or we might make choices about our own safety. I mean, speaking of Texas, I've been to Texas more than once. But I do have reservations now about going back. Now that Texas and universities are allowing students to carry guns on campus. I mean, I find that very problematic and actually potentially a threat to my own personal safety. So I think that we might make choices. We might decide, in particular, situations that we might not go somewhere because it offends our personal sensibilities or because we think it threatens our safety. Or we might just feel that we just need to take a stand. But at the same time, there's always that question of who you're hurting, right? Because when I went to Houston, I guess it was a year or two ago, it was right around the time that the legislature was debating that thing about carrying guns on campus. And I actually almost didn't go. And of course, my colleagues there said the obvious thing, which is if you don't come, you'll hurt us, right? We want to hear you. We, our students need to hear you. So what good does it do if you don't come, right? So there's always that question about who are you impacting through your actions. So I think when you get out and when you talk to people and when you try to be, to listen and be empathetic and understand people's questions and answer them honestly and take people's questions seriously, that's almost always a good thing to do. When you say, I can't go here because of X or Y, I think that's much more complicated, much more fraught. I think that's a good thing."}, {"content": "All right, let's start. I'll turn it on. I can speak through the stuff. I know it's on the screen for you. No, I won't be able to go up. Listen to that now."}, {"content": "Okay, my name's Andrew Bergman. I'm a PhD student here in applied physics and a member of a new group called the Environmental Data and Governance Initiative. And this question is something I'm experiencing, but I'll frame it in terms of the conversation about climate change. I think that sometimes what I notice, and it's sort of related to this question, but more explicitly about expertise within a very specific field. Even when you say someone is a climate scientist, that is a lot of different types of scientists working on a totally disparate set of issues. And sometimes when you go testify in Congress, you're talking about the general science of climate. But the specificity with which people like Oppenheimer and others really understood the nuclear physics they were working on, doesn't necessarily apply in the same sort of general way to climate scientists. And I support scientists who have sort of peripheral or solid understanding advocating. But when we want the specific sort of expertise driven, sort of as you said, like somebody who really is an expert has a very different platform which they can stand and speak, should we as a scientific community be more discerning and actually say like, when you decide to speak out as an expert, be clear about the specificity of your expertise. And don't show up to schools or Congress and say you're an expert just because you have a degree in physics. I mean, I don't think when my friends ask me, tell me about climate science, I say I really don't know. I'm trusting other scientists. And that's the reality."}, {"content": "This is a really important point."}, {"content": "Thank you for raising it. So one of the reasons why I've been thinking about this whole issue of approximate expertise is because it's actually essential if we're going to be able to refute merchants of doubt type claims, right? Because one of the ways that the whole doubt-mongering strategy works is to recruit scientists to be part of this, right? And that was a key strategy that the tobacco industry invented, which was to find scientists to come and speak. Now, in many cases, those people were actually scientists of some kind. They had some kind of scientific training, but they weren't oncologists. They weren't public health officials. They weren't physicians. And Fred Singer, who I talked about, is a classic case in point. I mean, the man was a very intelligent, very highly educated person, but he knew nothing about cancer or bronchitis or emphysema or epidemiology or any of the disciplines that could have been potentially relevant to that case. And that's the key point about what you're saying. So when it comes to climate science, there are many disciplines that are relevant. And there are many angles from which you might enter into the topic with legitimate strong expertise. Just as with tobacco, you could have been a physician. You could have been an epidemiologist. You could have been an oncologist. Many different expertise could have been relevant there. And Singer had none of them. So that should have been a red flag. It should have been a red flag to his colleagues. It should have been a red flag to the media. But it's not, in part, because we don't discern. And that is why I think it's so important that we are discerning and that we also exercise a certain amount of restraint. Right? And I work hard, really hard on this, because I get asked about all kinds of things. And you know, I have, I mean, just the other day, I got asked this question. I went and talked to the EPS graduate students and someone wanted to talk about immigration. And the first thing I said is, I, I, I, I, you know, no, I'm like, I feel like I know a lot of things and immigration isn't one of them. I don't feel like, you know, and I just said, let's talk about other things, right? So being able to say, it's not my area. I really don't know. If I answer that question, I just be giving you my personal opinion. I think that's really important."}, {"content": "Now that said, though, there is one other nuance to add to this. Expertise is not absolute, it's relative. So depending on the context, it might be that even though you're a physicist, you might actually be pretty knowledgeable about evolutionary biology. Maybe you've even read the origin of species. And if somebody asked you a question about it, you might be able to say, well, look, I'm not an evolutionary biologist, but I do know certain things. Or something I sometimes say when I'm asked, I'm not an economist, you know, but some of my best friends are economists. But my economist, my economics colleagues, say that carbon pricing is one of the most effective things we could do to level playing field and pay the true cost, not the price, but the cost of carbon. So you can invoke the authority of other experts that you know or that you've read. And then that invites your audience to say, okay, so if we want to learn more about this, you know, next year we invite an economist to come and speak to you. And you can even give them the names. You could say, well, I am friends with Nick Stern and here's what Nick says about it, right? And that's, I think, legitimate because you've talked to the person you've played attention to their arguments. One time years ago, when I was talking to a group of grad students, a student, and I forget, she was studying choral reefs. It was something to do with marine biology. And she said that she was in a choral group, a singing group, in which one of the other people in the group had asked her about climate change. And it was some element of climate change that was quite far away from what she worked on. And she said she felt really awkward because she felt like she wasn't an expert. But I said to her, you know, that's true. You're not an expert on, you know, tropospheric warming. But in that group, you are the local expert. And people are turning to you because they know that you're getting a PhD. This was at UC Davis. They know you're at Davis. They know Davis is a good school. And by asking you, they're actually saying that they trust you. They want to know what you know about this. And in that situation, I think it is reasonable to say, well, it's not my specialty, but here's what I know. And I think that, so expertise is contextual and relative. And it's about, in a way, it's just about being thoughtful about where your limits of expertise are and being honest about that. And when it goes too far to say, okay, I really can't answer that. I'm sorry. So, and on that note, I can't answer that. On that note. Thank you. Thank you. Thank you."}], "Naomi Oreskes: Why we should trust scientists": [{"content": "Every day we face issues like climate change or the safety of vaccines where we have to answer questions whose answers rely heavily on scientific information. Scientists tell us that the world is warming. Scientists tell us that vaccines are safe. But how do we know if they are right? Why should be believe the science? The fact is, many of us actually\ndon't believe the science. Public opinion polls consistently show that significant proportions of the American people don't believe the climate is\nwarming due to human activities, don't think that there is\nevolution by natural selection, and aren't persuaded by the safety of vaccines. So why should we believe the science? Well, scientists don't like talking about \nscience as a matter of belief. In fact, they would contrast science with faith, and they would say belief is the domain of faith. And faith is a separate thing\napart and distinct from science. Indeed they would say religion is based on faith or maybe the calculus of Pascal's wager. Blaise Pascal was a 17th-century mathematician who tried to bring scientific\nreasoning to the question of whether or not he should believe in God, and his wager went like this: Well, if God doesn't exist but I decide to believe in him nothing much is really lost. Maybe a few hours on Sunday."}, {"content": "(Laughter) But if he does exist and I don't believe in him, then I'm in deep trouble. And so Pascal said, we'd better believe in God. Or as one of my college professors said, \"He clutched for the handrail of faith.\" He made that leap of faith leaving science and rationalism behind. Now the fact is though, for most of us, most scientific claims are a leap of faith. We can't really judge scientific\nclaims for ourselves in most cases. And indeed this is actually\ntrue for most scientists as well outside of their own specialties. So if you think about it, a geologist can't tell you whether a vaccine is safe. Most chemists are not experts in evolutionary theory. A physicist cannot tell you, despite the claims of some of them, whether or not tobacco causes cancer. So, if even scientists themselves have to make a leap of faith outside their own fields, then why do they accept the\nclaims of other scientists? Why do they believe each other's claims? And should we believe those claims? So what I'd like to argue is yes, we should, but not for the reason that most of us think. Most of us were taught in school\nthat the reason we should believe in science is because of the scientific method. We were taught that scientists follow a method and that this method guarantees the truth of their claims. The method that most of us were taught in school, we can call it the textbook method, is the hypothetical deductive method. According to the standard\nmodel, the textbook model, scientists develop hypotheses, they deduce the consequences of those hypotheses, and then they go out into the world and they say, \"Okay, well are those consequences true?\" Can we observe them taking\nplace in the natural world? And if they are true, then the scientists say, \"Great, we know the hypothesis is correct.\" So there are many famous examples in the history of science of scientists doing exactly this. One of the most famous examples comes from the work of Albert Einstein. When Einstein developed the\ntheory of general relativity, one of the consequences of his theory was that space-time wasn't just an empty void but that it actually had a fabric. And that that fabric was bent in the presence of massive objects like the sun. So if this theory were true then it meant that light as it passed the sun should actually be bent around it. That was a pretty startling prediction and it took a few years before scientists were able to test it but they did test it in 1919, and lo and behold it turned out to be true. Starlight actually does bend\nas it travels around the sun. This was a huge confirmation of the theory."}, {"content": "It was considered proof of the truth of this radical new idea, and it was written up in many newspapers around the globe. Now, sometimes this theory or this model is referred to as the deductive-nomological model, mainly because academics like \nto make things complicated. But also because in the ideal case, it's about laws. So nomological means having to do with laws. And in the ideal case, the hypothesis isn't just an idea: ideally, it is a law of nature. Why does it matter that it is a law of nature? Because if it is a law, it can't be broken. If it's a law then it will always be true in all times and all places no matter what the circumstances are. And all of you know of at least\none example of a famous law: Einstein's famous equation, E=MC2, which tells us what the relationship is between energy and mass. And that relationship is true no matter what."}, {"content": "Now, it turns out, though, that there \nare several problems with this model. The main problem is that it's wrong."}, {"content": "It's just not true. (Laughter) And I'm going to talk about\nthree reasons why it's wrong. So the first reason is a logical reason."}, {"content": "It's the problem of the fallacy\nof affirming the consequent. So that's another fancy, academic way of saying that false theories can make true predictions. So just because the prediction comes true doesn't actually logically\nprove that the theory is correct. And I have a good example of that too, \nagain from the history of science. This is a picture of the Ptolemaic universe with the Earth at the center of the universe and the sun and the planets going around it. The Ptolemaic model was believed by many very smart people for many centuries. Well, why? Well the answer is because it made \nlots of predictions that came true. The Ptolemaic system enabled astronomers to make accurate predictions\nof the motions of the planet, in fact more accurate predictions at first than the Copernican theory\nwhich we now would say is true. So that's one problem with the textbook model."}, {"content": "A second problem is a practical problem, and it's the problem of auxiliary hypotheses. Auxiliary hypotheses are assumptions that scientists are making that they may or may not even\nbe aware that they're making. So an important example of this comes from the Copernican model, which ultimately replaced the Ptolemaic system. So when Nicolaus Copernicus said, actually the Earth is not the center of the universe, the sun is the center of the solar system, the Earth moves around the sun. Scientists said, well okay, Nicolaus, if that's true we ought to be able to detect the motion of the Earth around the sun. And so this slide here illustrates a concept known as stellar parallax. And astronomers said, if the Earth is moving and we look at a prominent star, let's say, Sirius -- well I know I'm in Manhattan\nso you guys can't see the stars, but imagine you're out in the country, \nimagine you chose that rural life \u2014 and we look at a star in December, we see that star against the backdrop of distant stars. If we now make the same observation six months later when the Earth has moved to this position in June, we look at that same star and we \nsee it against a different backdrop. That difference, that angular\ndifference, is the stellar parallax. So this is a prediction that the Copernican model makes. Astronomers looked for the stellar parallax and they found nothing, nothing at all. And many people argued that this proved \nthat the Copernican model was false. So what happened? Well, in hindsight we can say \nthat astronomers were making two auxiliary hypotheses, both of which we would now say were incorrect. The first was an assumption \nabout the size of the Earth's orbit. Astronomers were assuming \nthat the Earth's orbit was large relative to the distance to the stars. Today we would draw the picture more like this, this comes from NASA, and you see the Earth's orbit is actually quite small. In fact, it's actually much\nsmaller even than shown here. The stellar parallax therefore, is very small and actually very hard to detect. And that leads to the second reason why the prediction didn't work, because scientists were also assuming that the telescopes they had were sensitive enough to detect the parallax. And that turned out not to be true. It wasn't until the 19th century that scientists were able to detect the stellar parallax. So, there's a third problem as well. The third problem is simply a factual problem, that a lot of science doesn't fit the textbook model. A lot of science isn't deductive at all, it's actually inductive. And by that we mean that scientists don't necessarily start with theories and hypotheses, often they just start with observations of stuff going on in the world. And the most famous example\nof that is one of the most famous scientists who ever lived, Charles Darwin. When Darwin went out as a young \nman on the voyage of the Beagle, he didn't have a hypothesis, he didn't have a theory. He just knew that he wanted\nto have a career as a scientist and he started to collect data. Mainly he knew that he hated medicine because the sight of blood made him sick so he had to have an alternative career path. So he started collecting data. And he collected many things, \nincluding his famous finches. When he collected these finches,\nhe threw them in a bag and he had no idea what they meant. Many years later back in London, Darwin looked at his data again and began to develop an explanation, and that explanation was the\ntheory of natural selection. Besides inductive science, scientists also often participate in modeling. One of the things scientists want to do in life is to explain the causes of things. And how do we do that? Well, one way you can do it is to build a model that tests an idea. So this is a picture of Henry Cadell, who was a Scottish geologist in the 19th century."}, {"content": "You can tell he's Scottish because he's wearing a deerstalker cap and Wellington boots. (Laughter) And Cadell wanted to answer the question, how are mountains formed? And one of the things he had observed is that if you look at mountains\nlike the Appalachians, you often find that the rocks in them are folded, and they're folded in a particular way, which suggested to him that they were actually being\ncompressed from the side. And this idea would later play a major role in discussions of continental drift. So he built this model, this crazy contraption with levers and wood, and here's his wheelbarrow, buckets, a big sledgehammer. I don't know why he's got the Wellington boots. Maybe it's going to rain. And he created this physical model in order to demonstrate that you could, in fact, create patterns in rocks, or at least, in this case, in mud, that looked a lot like mountains if you compressed them from the side. So it was an argument about\nthe cause of mountains. Nowadays, most scientists prefer to work inside, so they don't build physical models so much as to make computer simulations. But a computer simulation is a kind of a model. It's a model that's made with mathematics, and like the physical models of the 19th century, it's very important for thinking about causes. So one of the big questions\nto do with climate change, we have tremendous amounts of evidence that the Earth is warming up. This slide here, the black line shows the measurements that scientists have taken for the last 150 years showing that the Earth's temperature has steadily increased, and you can see in particular\nthat in the last 50 years there's been this dramatic increase of nearly one degree centigrade, or almost two degrees Fahrenheit. So what, though, is driving that change? How can we know what's causing the observed warming? Well, scientists can model it using a computer simulation. So this diagram illustrates a computer simulation that has looked at all the different factors that we know can influence the Earth's climate, so sulfate particles from air pollution, volcanic dust from volcanic eruptions, changes in solar radiation, and, of course, greenhouse gases. And they asked the question, what set of variables put into a model will reproduce what we actually see in real life? So here is the real life in black. Here's the model in this light gray, and the answer is a model that includes, it's the answer E on that SAT, all of the above. The only way you can reproduce the observed temperature measurements is with all of these things put together, including greenhouse gases, and in particular you can see that the increase in greenhouse gases tracks this very dramatic increase in temperature over the last 50 years. And so this is why climate scientists say it's not just that we know that\nclimate change is happening, we know that greenhouse gases are a major part of the reason why. So now because there all these different things that scientists do, the philosopher Paul Feyerabend famously said, \"The only principle in science that doesn't inhibit progress is: anything goes.\" Now this quotation has often\nbeen taken out of context, because Feyerabend was not actually saying that in science anything goes. What he was saying was, actually the full quotation is, \"If you press me to say what is the method of science, I would have to say: anything goes.\" What he was trying to say is that scientists do a lot of different things. Scientists are creative. But then this pushes the question back: If scientists don't use a single method, then how do they decide what's right and what's wrong? And who judges? And the answer is, scientists judge, and they judge by judging evidence. Scientists collect evidence in many different ways, but however they collect it, they have to subject it to scrutiny. And this led the sociologist Robert Merton to focus on this question of how scientists scrutinize data and evidence, and he said they do it in a way he called \"organized skepticism.\" And by that he meant it's organized because they do it collectively, they do it as a group, and skepticism, because they do it from a position of distrust. That is to say, the burden of proof is on the person with a novel claim. And in this sense, science\nis intrinsically conservative. It's quite hard to persuade the scientific community to say, \"Yes, we know something, this is true.\" So despite the popularity of the concept of paradigm shifts, what we find is that actually, really major changes in scientific thinking are relatively rare in the history of science. So finally that brings us to one more idea: If scientists judge evidence collectively, this has led historians to focus on the question of consensus, and to say that at the end of the day, what science is, what scientific knowledge is, is the consensus of the scientific experts who through this process of organized scrutiny, collective scrutiny, have judged the evidence and come to a conclusion about it, either yea or nay. So we can think of scientific knowledge as a consensus of experts. We can also think of science as being a kind of a jury, except it's a very special kind of jury. It's not a jury of your peers, it's a jury of geeks. It's a jury of men and women with Ph.D.s, and unlike a conventional jury, which has only two choices, guilty or not guilty, the scientific jury actually has a number of choices. Scientists can say yes, something's true. Scientists can say no, it's false. Or, they can say, well it might be true but we need to work more\nand collect more evidence. Or, they can say it might be true, but we don't know how to answer the question and we're going to put it aside and maybe we'll come back to it later. That's what scientists call \"intractable.\" But this leads us to one final problem: If science is what scientists say it is, then isn't that just an appeal to authority? And weren't we all taught in school that the appeal to authority is a logical fallacy? Well, here's the paradox of modern science, the paradox of the conclusion I think historians and philosophers and sociologists have come to, that actually science is the appeal to authority, but it's not the authority of the individual, no matter how smart that individual is, like Plato or Socrates or Einstein. It's the authority of the collective community. You can think of it is a kind of wisdom of the crowd, but a very special kind of crowd. Science does appeal to authority, but it's not based on any individual, no matter how smart that individual may be. It's based on the collective wisdom, the collective knowledge, the collective work, of all of the scientists who have worked on a particular problem. Scientists have a kind of culture of collective distrust, this \"show me\" culture, illustrated by this nice woman here showing her colleagues her evidence. Of course, these people don't\nreally look like scientists, because they're much too happy. (Laughter) Okay, so that brings me to my final point."}, {"content": "Most of us get up in the morning. Most of us trust our cars. Well, see, now I'm thinking, I'm in Manhattan, this is a bad analogy, but most Americans who don't live in Manhattan get up in the morning and get in their cars and turn on that ignition, and their cars work, and they work incredibly well. The modern automobile hardly ever breaks down. So why is that? Why do cars work so well? It's not because of the genius of Henry Ford or Karl Benz or even Elon Musk. It's because the modern automobile is the product of more than 100 years of work by hundreds and thousands and tens of thousands of people. The modern automobile is the product of the collected work and wisdom and experience of every man and woman who has ever worked on a car, and the reliability of the technology is the result of that accumulated effort. We benefit not just from the genius of Benz and Ford and Musk but from the collective intelligence and hard work of all of the people who have worked on the modern car. And the same is true of science, only science is even older. Our basis for trust in science is actually the same as our basis in trust in technology, and the same as our basis for trust in anything, namely, experience. But it shouldn't be blind trust any more than we would have blind trust in anything. Our trust in science, like science itself, should be based on evidence, and that means that scientists have to become better communicators. They have to explain to us not just what they know but how they know it, and it means that we have\nto become better listeners. Thank you very much."}, {"content": "(Applause)"}], "1. Introduction and Supply & Demand": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER: This is 14.01. I'm John Gruber, and\nthis is microeconomics. Today, I want to\ncover three things. I want to talk about\nthe course details. I want to talk about\nwhat is microeconomics. And then I'll start the\nsubstance of the course by talking about\nsupply and demand. Couple of the points about\nthe course-- the course will have a distinct sort\nof policy angle to it. I sort of do economic policy,\ngovernment policy is my thing. So I think it's what\nmakes economics exciting and it sort of offers, I\nthink, an interesting angle to understand why we're\nlearning what we're learning. I think sometimes\nin an intro class, it's sort of hard to\nunderstand why the heck you're doing things. However, that's just\nsort of a slight flavor. If you're really more\ninterested in this, I teach a whole\ncourse called 1441. I'm not teaching it\nthis year, but it will be taught by a visitor\nin the spring, Kristin Butcher from Wellesley."}, {"content": "And I'll be teaching next year. That dives much more\ninto these policy issues. So I'm going to use government\npolicy as sort of an organizing theme, but it won't be the\ndominant theme of the class. Finally, three points\nabout my teaching style. I don't write\neverything on the board. We're not in high\nschool anymore. You're actually responsible for\nwhat I say, not what I write. Partly that's because my\nhandwriting is brutal, as you can tell already. So what that means is,\nplease, please do not be afraid to ask me what the\nhell I just wrote on the board. There's no shame in that. Don't just lean to your\nneighbors, and say, what the hell did he\njust write in the board. Ask, me, because if\nyou can't read it, I'm sure someone else can't\nread it, so feel free to ask. And in general, please\nfeel free to engage with questions in this class. The other point of my teaching\nstyle is I talk way too fast. And the longer I go-- there's\na mathematical function, which is the longer I\ngo without interruption, the faster I speak,\nuntil I just spin off. So basically, please\nask questions. If anything is not\nclear, or you just want to ask questions\nabout some related tangent or whatever, please\nfeel free to do so. You might think, how would\nthat work in a class this big? There's always way too\nfew questions, even a class this big. So never be afraid that it\nwill slow me down or whatever. Ask me questions. We have plenty of\ntime on the class. And you'll be doing\nyour classmates a favor, because it'll slow me down. Finally, last point, I\nhave this terrible tendency to use the term \"guys\"\nin a gender neutral way. So this class, I\nlike to see, looks like it's a fairly\nhealthy representation both males and females. When I say \"guys,\"\nI don't mean men. I mean people. I mean people. So women, don't\ntake it personally. \"Guys\" means economic agent. It means people. It doesn't mean men. Just the way-- just\na bad tendency. It drives my wife crazy,\nbut I've decided better to just apologize up front\nthan try to fix it throughout, which is impossible. So let's talk about\nwhat is microeconomics. So fundamentally,\nmicroeconomics-- how people took AP high school Econ? How many people--\nfor how many people was it taught really well? That's about right. That's why I did my high\nschool online class."}, {"content": "That's the answer\nI wanted to hear. So tell your friends\nstill in high school who are taking high school\nEcon, if your high school teacher isn't great,\ntell them to go on EdX and take the class. And help out your friends\nstill in high school. So what is microeconomics? Microeconomics is\nthe study of how individuals and\nfirms make decisions in a world of scarcity. Scarcity is what\ndrives microeconomics. Basically, what\nmicroeconomics is is a series of constrained\noptimization exercises, where economic agents, be\nthey firms or individuals, try to make themselves\nas well off as possible given their constraints. Yeah. AUDIENCE: Will this\ncover irrationality? JONATHAN GRUBER: I will,\nbut not as much as I should. Essentially, we\nhave another course in the department called 1413,\nBehavioral Economics, which gets into that much more. I will sprinkle it\nthroughout, but not as much as I actually\nbelieve in it. In other words, the way\nwe think about economics is it's best to sort\nof get the basics down before you start worrying\nabout the deviations. Find it's better\nto climb the tree before you start going\nout in the branches. So basically, what this\ncourse is then about is it's about trade-offs. It's about given that\nyou're constrained, how do you trade off things\nto make yourself as well off as possible? And behind this notion of\ntrade-offs is going to be-- I'll say about 100 times this\nis the most important thing in the course, so\njust ignore that. But this is one of the\nmost important things. I'll say \"one of the\nmost important\" things in the course, is the\nnotion of opportunity cost. Opportunity cost is a\nvery important concept that we teach, sort of the\nfirst concept we teach, which is that every\naction or every inaction has a cost in that you\ncould've been doing something else instead. So if you buy a shirt, you\ncould have bought pants. If you stayed at\nhome and watched TV, you could have been out working. Everything you do has\na next best alternative you could have done instead. And that is called the\n\"opportunity cost.\" And that's a critical\nconcept in economics, and that is why,\nin some sense, we are referred to casually\nas the \"dismal science.\" Economics is referred to\nas the dismal science. First of all, I'm flattered\nwe're considered a science. But it's called the\n\"dismal science\" because our whole point\nis that nothing is free. There is always a trade-off."}, {"content": "There's always an\nopportunity cost. Anything you do, you could be\ndoing something else instead. And your constrained\noptimization means you're going to\nhave to pass up one thing to do another. Now, some may call it\n\"dismal,\" but as a former MIT undergraduate, I call it \"fun.\" And this is why I think\nMIT is the perfect place to be teaching economics,\nbecause MIT engineering is all about constrained\noptimization. That's what engineering is. And economics is\njust the engine. It's just the principles\nyou learn in engineering applied in different contexts. So if we think about the\n2.007 contests-- that still exist with the robots, 2.007? Yeah, the 2.007 contests,\nthose, as you know, are contests where you're given\na limited set of materials. And you have to build a\nrobot that does some task, like pushing ping-pong balls off\na table or something like that. That's just constraint\noptimization. It's got nothing to\ndo with economics, but it's constrained\noptimization. So just think of microeconomics\nas like engineering, but actually interesting. So think of microeconomics\nas engineering, but instead of\nbuilding something to push a ping-pong ball\noff tables, you actually build people's lives,\nand businesses, and understand the decisions\nthat drive our economy. So same principles\nyou could think of for your engineering classes,\nbut applied to people's lives. And that's why, in fact, modern\neconomics was born in this room, this room or 26.100 by\nPaul Samuelson in the 1940s and '50s, who wrote the\nfundamental textbook that gave birth to modern economics. Because he was here and\napplied the kind of engineering principles of MIT\nto actually develop the field of modern economics. What we'll learn today\nwas developed at MIT, so it's a great place\nto be learning it. Now, with that as background--\nany questions about that, about what is microeconomics? With that as\nbackground, let's turn to our first model we'll talk\nabout this semester, which is the supply and demand model. Supply and demand--\nnow, the way we're going to proceed in this course\nis going to drive you crazy, because we're going to\nproceed by teaching, as the very first\nquestion pointed out, by teaching very\nsimplified models. We're going to essentially--\nwhat is a model? A model is technically\na description between any two or more economic\nvariables or any two or more variables. But unlike the models used\nin all your other classes, these aren't laws, by and\nlarge, they're models. So we don't have a relation\nbetween energy and mass which you can write down. It's a law and you're done."}, {"content": "We have models which are\nnever 100% true, but always pretty true, \"pretty\"\nbeing somewhere between 10% and 95% true. So basically, the idea\nis to make a trade-off. We want to write\ndown in our models a set of simplifying\nassumptions that allow us, with a relatively\nsmall set of steps, to capture relatively\nbroad phenomena. So it's essentially a trade-off. On the one hand,\nwe'd like a model that captures as well as\npossible the phenomena in the real world, like\nE equals Mc squared. But we want to do so in the\nmost tractable possible way so that we can teach it\nfrom first principles, and don't need an arrow to teach\nevery single insight we have. So basically in\neconomics, we tend to resolve that by erring\non the side of tractability. That is why I can teach\nyou the entire field of microeconomics--\nwhich is really sort of-- macro is kind of\na fun application. Micro is really economics. I can teach you the entire\nfield of microeconomics in the semester,\nbecause I'm going to make a whole huge set\nof simplifying assumptions to make things tractable. But the key thing\nis that you will be amazed at what these\nmodels will be able to do. With a fairly simple\nset of models, we will be able to offer\ninsights and explain a whole huge variety\nof phenomena, never perfectly, but\nalways pretty well, generally pretty well. And so that is\nessentially the trade-off we're going to try\nto do this semester. So the line I like\nis the statistician George Box said that all models\nare wrong, but some are useful. Now obviously, it doesn't apply\nto models in the hard sciences, but in the social\nsciences, that's true. And basically, I'm\ngoing to write down a set of models like that. Now, with every model I write\ndown, I'm going to try-- my goal is to have you\nunderstand it at three levels. The first and most\nimportant level is the intuitive\nlevel, the level which you sort of understand. I call it \"passing\nthe Mom Test.\" You can go home and explain\nit to your mom at Thanksgiving or at the end of semester. No offense to dads, just\ncalled it \"the Mom Test.\" So basically, that's\nthe intuitive level. You really understand it in a\nway that you could explain it."}, {"content": "The second is graphical. We were going to do--\nmost of our models here were developed in a\ngraphical framework using x/y graphs that really in\neconomics, we think delivers a lot of shorthand power. And the third is mathematical. The mathematical is probably\nthe least important, but it's the easiest\nto test you on."}, {"content": "So we're going to need to know\nthings mathematically as well. So let's start by considering\nthe supply and demand model by using\nthe famous example brought up by Adam Smith. Adam Smith is sort of considered\nthe father of economics. If Paul Samuelson is the\nfather of modern economics, Adam Smith is the\nfather of all economics. His 1776 book, The\nWealth of Nations did an incredible job\nof actually laying out the entire core of\nthe economics field-- no math, just words,\nbut he just nailed it. And one of his most\nfamous examples was the water diamond paradox. He said, think about\nwater and diamonds. He said, start with water. Nothing is more important\nfor life than water. It's the building\nblock of all of life. Even when we look for\nlife on other planets, we always start by\nlooking for water. Now think of diamonds, one\nof the more frivolous things you can buy, certainly\nirrelevant to leading a successful or happy or\nproductive life, or any life. Yet for most of us,\nwater's free and diamonds are super expensive. How can this be,\nAdam Smith asked. Well, the answer he posed is\nthat what I first described was just demand. That is, we demand\nlots of water. We demand fewer diamonds. But we have to match that\nwith the concept of supply. And the supply of water\nis almost infinite, while the supply of diamonds--\nmaybe not naturally, maybe it's through decisions\nof various businesses-- but it's somewhat limited. So basically what\nhe developed is what we call the \"supply\nand demand scissors\"-- that you can't just think of\nsupply or demand in isolation. You have to put\nthem together if you want to explain the real world\nphenomena we see, like the fact that water is cheap and\ndiamonds are expensive. So let's just about an example. So there's one graph\nthat was handed out in the back, which\nis, let's talk about the market for roses. So in the market for roses,\nwe have a demand curve and a supply curve. So what we have here-- this\nis the kind of x/y graph we're going to look at all\nthroughout the semester. On the x-axis is the\nquantity of roses. On the y-axis is\nthe price of roses. The blue, downward-sloping\nline is the demand curve. Now, what I'm going to do here,\nI'm just giving you a overview. We are going, over the next\nfive or six lectures, dive into where this demand\ncurve comes from. We'll go to first principles\nand build it back up. But for now, what\nwe know of a demand curve is it simply\nrepresents the relationship between the price of a good\nand how much people want it. Therefore, we assume\nit is downward sloping. At higher prices, people\nwant less of the good. And we'll derive where\nthat comes from shortly, starting next lecture. But for now, I think\nit's pretty intuitive that if the price\nof roses is higher, people want fewer of them. And that's why it's\ndownward sloping. Basically, as the\nprice of roses goes up, people want fewer roses. The yellow curve is\nthe supply curve. Now, after we've derived\nthe demand curve, we'll then go and\nspend about 12 lectures deriving the supply curve. That's a bit harder. But once again, we'll\nstart from first principles and build it up. For now, you just need to\nknow that's how much firms are willing to supply,\ngiven the price. So basically, as\nthe price goes up, firms want to\nproduce more roses. The higher price means\nyou make more money, so you want to\nproduce more of them. This is slightly less\nintuitive than demand, but we'll derive it and\nexplain how it can be. But for now, just go\nwith the basic intuition that if you're making\nsomething, and you can sell it in the market for\na higher price, you're going to want\nto make more of it. And that leads to the\nupward sloping supply curve. Where the points meet is\nthe market equilibrium. Where supply and demand meets\nis the market equilibrium. And that is the point where\nboth consumers and producers are happy to make a transaction. Consumers are happy because\non their demand curve is the $3 and 600 roses. That is, they are willing\nto buy 600 roses at $3. Producers are happy,\nbecause on their supply curve is the same point. They are willing to\nsupply 600 roses at $3. That is the one point\nwhere consumers are happy and producers are happy. Therefore, it's\nthe equilibrium-- highly non-technical, but\nthat's the basic intuition. The point at which they're\nboth willing to make that transaction, the\npoint at which they're both satisfied with\nthat transaction, is the equilibrium, which\nin this case is $3 per rose and 600 roses. Now, this raises\nlots of questions. Where did the curves come from? How does equilibrium\nget achieved? Why the heck do we give roses? These are a bunch of questions."}, {"content": "We will come to\nall these questions over the next set of lectures. But the basic thing\nis to understand this intuition of Adam Smith's\nsupply and demand model. Questions about that? Now, this model also raises\nanother important distinction that we'll focus\non this semester and is easy to get mixed up. So I want you to, if\nyou're ever unclear, I want you to ask me about it. And that's the distinction\nbetween positive versus normative analyses--\npositive versus normative. Positive analysis is the\nstudy of the way things are, while normative\nanalyses is the study of the way things should be. A positive analysis is the\nstudy of the way things are, while normative\nanalysis is the study of the way things should be. Let me give you a great\nexample, which is eBay auctions."}, {"content": "Auctions are a terrific example. They're like the\ntextbook example of a competitive market. You can see it in your head-- demand comes as a bunch of\npeople going on and bidding. People who want\nit more bid more, so you actually\nget a demand curve. The higher the price, the fewer\npeople you're getting to bid. Supply is how many units\nof it are for sale on eBay. You bid until those two meet. And then you have a\nmarket equilibrium at that bidded price. Now, one example\nof an eBay auction that got a lot of attention\na number of years ago, early in the days\nof eBay, was someone offered their\nkidney for auction. They said, look,\nI got two kidneys."}, {"content": "You only need one to live. There are people out\nthere who need a kidney. I'm putting my kidney\non eBay for auction. And what happened,\nbidding went nuts. It started at $25,000. It climbed to $5 million before\nthe auction was shut down, and eBay decided\nthey wouldn't allow you to sell your body on\neBay, bodily parts on eBay. So this raises two questions. The first is the\npositive question, why did the price go so high? So what's the answer to that? What's the answer to\nthe positive question? AUDIENCE: Somebody\nwanted a kidney. JONATHAN GRUBER: Good\nanswer, but let's raise hands and give answers. That's part of it."}, {"content": "Yeah. AUDIENCE: Low\nsupply, high demand. JONATHAN GRUBER: Low\nsupply, high demand. Demand is incredibly high,\nbecause I'd die without it. Supply is low, because\nlike not a lot of us are willing to\nsell their kidneys on eBay So low supply, high\ndemand led to a high price-- Adam Smith at work. That's the positive analysis. But then there's the\nnormative question, which is, should you be allowed to\nsell your kidneys on eBay? That's the normative question."}, {"content": "The positive question is,\nwhat happens if you do? The normative question\nis, should you? Now, the standard\neconomics answer to start would be, of course you should. We're in a world where\nthousands of people die every year because there's\na waiting list for a kidney transplant. and these are people who would\nhappily pay a lot of money to stay alive, I presume. Meanwhile, there's\nhundreds of millions of people walking around with\ntwo kidneys who only need one. And many of these\npeople are poor. And lives could be changed\nby being paid $1 million for their kidney, and might be\nhappy to take the risk that one kidney will be fine, as\nit is for most everyone for most of their\nlife, in return for having a life-changing\npayment from a stranger. So economists say, look-- here's a transaction that\nmakes both parties better off. The person who gets the\nkidney gets to stay alive, and they are willing to\npay a huge amount for that. The person who sells the\nkidney in most probability is fine, because\nalmost all of us can make it through life\nfine with one kidney, and create a life-changing\namount of money that could allow them to pursue\ntheir dreams in various ways. So that's the standard\nargument, would be, yeah, you should be able to\nsell your kidneys on eBay. So the question is, why not?"}, {"content": "Why would we want to\nstop this transaction? What are the\ncounter-arguments to that?"}, {"content": "Let's raise our hands."}, {"content": "Yeah. AUDIENCE: Potentially, I\nthink maybe the issue is because on eBay, there's\nno way to regulate it or you don't necessarily know. People could be like selling\nfake kidneys, per se. JONATHAN GRUBER: Right. So the first type\nof problem comes out of the category we\ncall \"market failures.\" Market failures are reasons\nwhy the market doesn't work in the wonderful\nway economists like to think it should. So for example,\nthis answer puts up there could be the\nproblem of fraud. People might not be\nable to tell if they're getting a legit kidney or not. There could be the example\nof imperfect information. Do you know what the\nodds are that you can spend the rest of your\nlife with only one kidney? I don't either. We ought to know that before\nwe start selling our kidneys. There could be\nimperfect information."}, {"content": "This is one type of problem,\nwhich is the market, maybe the market may fail. Yeah. AUDIENCE: Well, the\ncurrent system also holds people who are poor\nand have a failed kidney-- and which are people who would\nbe completely screwed otherwise in the [INAUDIBLE] system. JONATHAN GRUBER:\nA second problem is what we call\n\"equity\" or \"fairness.\" Equity or fairness, which is\nwe would end up with a world where only rich people\nwould get kidneys. Currently, there's a bunch of\nvoluntary donors and people who are in accidents who\nhave kidneys left over. And those go to people\non the basis of where they are on a waiting list. It's actually a\nprioritized waiting list. It's kind of a cool-- one of my colleagues, Nikhil\nAgarwal, if you think about-- I'll talk a lot this semester\nabout the imperialistic view of economics, all the\ncool things we can study. So he actually uses\neconomic models to study the optimal way to\nallocate organs to individuals. now it's just done\nbased on a waiting list, but it may be that someone\nfurther down the waiting list needs it more than someone\nhigher up the waiting list because they're more\ncritical or whatever. So there's various\noptimal ways to allocate. But certainly, the\noptimal way to allocate wouldn't be the rich\nguy gets it first. That would be unlikely to be\nwhat society would necessarily want. So there's an equity\nconcern with that. What else?"}, {"content": "What other-- yeah. AUDIENCE: In that\nsituation, since you know you can make money\noff of selling kidneys, and you take advantage\nof people, it's very bad, the black market for kidneys. JONATHAN GRUBER: Right, so\nthere's sort of a third-- it's related to\nfraud, but there's sort of a third\nclass of failures that gets into the question\nabout behavioral economics that was raised earlier, which\nwe could just call behavioral-- it's called\n\"behavioral economics,\" for want of a better term,\nwhich is essentially, people don't always\nmake decisions in the perfectly rational,\nlogical way we will model them as doing so this semester. People make mistakes. That's a word we hate\nusing in economics. We hate saying \"mistakes.\" Ooh, boo, mistakes--\nnobody makes mistakes. We're all perfectly\neconomic beings. But we know that's not true. Increasingly over the\npast several decades, economists have started\nincorporating insights from psychology into our\nmodels, to not just say people make mistakes,\nthat their lackadaisical, but to rigorously model the\nnature of those mistakes and understand how\nmistakes can actually happen due to various cognitive\nbiases and other things. In this world, you can imagine\npeople could make mistakes. They could not really\nsit down and quite understand what\nthey're doing, and they could have sold their\nkidney when it's really not in their own long-term interest. Yeah. AUDIENCE: Would\nanother example be if there's a family that\nis in extreme poverty, even though they\nonly have one kidney, they might sell the other\none, just to get more money for the family, per se? JONATHAN GRUBER: Well, in\nsome sense that would be, once again-- if we took this factor out,\nif the market works well with its behavioral\neffects, we'd say, you know, that's their decision. If they otherwise they\nstarve, who are you to say? But once you choose\nthis, say, wait a second, maybe they're not evaluating\nthe trade-offs correctly. Even if there's no fraud, even\nif there's perfect information, they may not know how to process\nthat information correctly. But that is not\nstandard economics."}, {"content": "That's not what we'll spend a\nlot of time on in the semester, but it's obviously realistic. So those are a bunch of good\ncomments, great comments. And yeah. AUDIENCE: Also, in\ninelastic demand, such that people\nalways need kidneys-- JONATHAN GRUBER: That won't\nturn out to be a problem. That doesn't turn\nout to be a problem. We'll come back--\nthat's a great comeback that we talk about the\nshape of demand curves. We want to return to that\nquestion in a few lectures, but that doesn't\nactually cause a problem. It's just that's more of\na positive thing about why the price is so high, but it's\nnot a normative issue about whether you should\nallow it or not. So basically,\nthese are exactly-- to me, honestly, I spend\nmy life thinking a lot about these things. I think these are really\ninteresting issues. But you can't get to\nthe normative issues without the positive analysis. You do the positive\nanalysis to understand the economic framework\nbefore you start jumping to drawing conclusions. That's no fun. We all want to jump\nto draw conclusions, saying this should happen,\nthis shouldn't happen. You can't do that."}, {"content": "We have to be disciplined. We have to start with the\nfundamental economic framework. And basically, the bottom line-- I said I'll teach this\ncourse with a policy bent, but you have to recognize\nthat economics at its core is a right-wing science. Economics at its\ncore is all about how the market knows best, and that\nbasically governments only mess things up. That's sort of the\nbasic, a lot of what we'll learn this semester. As the semester\ngoes on, we'll talk about what's wrong\nwith that view and how governments\ncan improve things. Indeed, I teach a whole\ncourse about the proper role of government the economy. But the standard of economics\nis, \"the market knows best.\" And that leads us to the last\nthing I want to talk about, which is basically, how freely\nshould an economy function? Let's step back to\nthe giant picture. Let's step back from\na market for roses to the entire economy. How freely should a market,\nshould an economy function? We have what's known as\na \"capitalistic economy.\" In a capitalistic economy,\nfirms and individuals decide what to\nproduce and consume, maybe subject to some rules of\nthe road set by the government. There's some minimum\nrules of the road to try to avoid fraud\nor misinformation, but otherwise, we\nlet the dice roll. Firms let consumers\ndecide sort of what to do. Now, this has led to\ntremendous growth. America was not\na wealthy nation, was not a very wealthy\nnation 100 years ago, or 150 years ago. Led to tremendous\ngrowth, where we are now the most powerful, still the\nmost powerful and wealthiest nation the world, largely driven\nby the capitalistic nature of our economy. On the other hand,\nwe are a nation with tremendous inequality. We are by far the most unequal\nmajor nation in the world. The top 1% of Americans has a\nmuch higher share of our income than in any other large\ncountry in the world, any other large developed\ncountry in the world. The bottom 99% has less of\nour income corresponding with anywhere else. So it's led to major inequality. And it's led to other problems. It turns out that the\ngovernment can't appropriately set the rules of the road to\navoid things like fraud, as we saw with Enron, if you\nremember back to that, or a lot of what happened\nin the financial meltdown. It turns out it's\nhard to get people perfect information, et cetera. So we've seen the problems. We've grown very\nwealthy as a nation. We've introduced a whole set of\nproblems through this system. Now, the other extreme is what's\ncalled the \"command economy.\" Rather than a\ncapitalist economy, it's what's called\na \"command economy.\" In this case, the government\nmakes all the production and consumption decisions. The government doesn't just\nset the rules of the road, the government owns the road. The government says, we're\ngoing to use this many cars this year. And people can get\nthem in some way. It could be a lottery,\ncould be waiting in line. How do we decide how\nto allocate them? We're not going to let\nthe market allocate them. We, the government,\nwill allocate them. We'll allocate how many get\nproduced and who gets them. And this was the model\nof the Soviet Union that I grew up with. This was the pre-1989\nSoviet Union. The government decided how many\nshirts, cars, TVs, everything. It's sort of bizarre\nto think that literally everything the government\ndecided how much to produce. And by and large, the government\ndecided who got it partly through corruption-- that\nis, the party members, party leaders got it first-- and often just through waiting\nin line for the remaining application. Now in theory,\nthis ensured equity by making sure that\neverybody had shot at things. In practice, it didn't\nwork well at all and actually was\nwhat dragged down the collapse of the\nold Soviet economy, was that the command\nmodel simply doesn't work. Partly there's just too many\nopportunities for corruption. When the government\ncontrols everything, that means there's no checks\nand balances on the opportunity for enormous corruption. The capitalist economy puts\nsome natural checks and balances on that. And partly because it\nturns out that it's hard to control human nature. And Adam Smith had it right. Adam Smith talks about\nthe \"invisible hand\" of the capitalist economy. The invisible hand is\nbasically the notion that the capitalist\neconomy will manage to distribute things roughly in\nproportion to what people want. And that's where\nfolks want to be."}, {"content": "Folks who want a\ncertain kind of car are going to want to\nget to that kind of car, and if the government\nhas it wrong, they're going to get upset. And it's going to lead to\na less functional economy. So basically, Adam\nSmith's view is that-- the invisible hand view is that\nconsumers and firms serving their own best interest will\ndo what is best for society. So the fundamental core\nof the capitalistic view is that consumers and firms\nserving their own best interest will do what ends up\nbeing best for society. And that's essentially\nthe model we'll learn to start in this course. Yeah. AUDIENCE: In that\ndefinition, are we defining the best for\nsociety as in everybody has the most money? Or everyone has the best health\nor the best standard of living? What is the best [INAUDIBLE]? JONATHAN GRUBER: Great question."}, {"content": "We're going to spend a lot\nof the semester talking about that. For now, we're going to\ndefine \"best for society\" as the most stuff gets\nproduced and consumed. That's how we're\ngoing to find it-- obviously raises a set\nof issues about what about pollution, what\nabout health, et cetera. We're going to come to those,\nbut for the first two-thirds of the course \"best\nfor society\" means what we're going to call\n\"maximum surplus,\" which is the most stuff gets\nproduced that people value. So that's how we're\ngoing to do it. And in his view, the\ninvisible hand does that. And by and large, it's a very\nhelpful framework to turn to. However, at least it\ncan lead to outcomes that are not very fair. So the way we're going\nto proceed in this course is we're going to start\nby talking about how Adam Smith's magic works. How does the magic happen? How does individuals\nand firms acting in their own self-interest,\nwithout caring about anybody else, end up yielding\nthe largest possible productive economy? How does that happen?"}, {"content": "And we're going to\ntalk about that. We'll start with\ndemand, which is how do consumers\ndecide what they want given their resources. We'll talk about the principle\nof utility maximization, the idea that I have\na utility function that I can mathematically\nwrite down what I want. I'll have a budget constraint,\nwhich is the resources I have, and those two\nconstrain optimization. We'll say given what I want\nand the resource I have, what decisions do I make? Boom, we get the demand curve. Then we'll turn to supply, and\nwe'll talk about how do firms decide what to produce. That's much more\ncomplicated, because firms have to decide\nwhat inputs to use and what outputs to produce. And we'll talk about\nhow firms can operate in very different markets. There is a competitive market\nthat Adam Smith envisioned, but that doesn't always work. Sometimes we get\nmonopoly markets, where one firm dominates. And you can actually\nhave outcomes which aren't the best\npossible outcome, even with the invisible hand. So we'll talk about\ndifferent kinds of markets. Then we'll put it together\nto get market equilibrium, and talk about\nSmith's principles. And then from there, we'll\ntalk about how it breaks down in reality, different\nchange in reality, how there are various\nmarket failures that can get in the way, why we\nhave to care about equity and what implications that has,\nabout behavioral economics, about a set of other factors. So that's basically how we're\ngoing to proceed this semester. As I said, the\nlectures are important, but the recitations are as well. Once we're sort of\nin steady state, the recitations will be about\nhalf new material and half working through problems\nto help you prepare for that next problem set. So the way the problem\nsets are going to work is the problem set\nthat's assigned will cover material that's\ntaught up to that date. So for example, problem\nset one is going to be assigned next Friday. That will cover everything\nyou've learned up through next Wednesday. Therefore, in section\non next Friday, we'll do a practice problem\nwhich you should understand because it'll cover things\nthat were taught in class, and help prepare you\nfor the problems. And we'll do that every week. That's about half the section. The other half of the\nsection will be new material. This Friday, the section on\nFriday is all new material. What we do on Friday is\ncover the mathematics. I don't like doing math. I always get it wrong. So I leave math for the TAs,\nwho are smarter than I am. So this Friday, we'll be doing\nthe mathematics of supply and demand, and how you\ntake the intuition here and the simple\ngraphics, and actually turn it into mathematical\nrepresentations, which is what you need for the problem sets. That's this Friday. Then we'll come back\non Monday and start talking about what's\nunderneath the demand curve. All right, any other questions? I'll see you on Monday."}], "1. Course Introduction and Newtonian Mechanics": [{"content": "Professor Ramamurti\nShankar: This is a first part of the year-long course\nintroducing you to all the major ideas in physics,\nstarting from Galileo and Newton right up to the big\nrevolutions of the last century, which was on relativity and\nquantum mechanics. The target audience for this\ncourse is really very broad. In fact, I've always been\nsurprised at how broad the representation is. I don't know what your major is; I don't know what you are going\nto do later so I picked the topics that all of us in physics\nfind fascinating. Some may or may not be useful,\nbut you just don't know. Some of you are probably going\nto be doctors and you don't know why I'm going to do special\nrelativity or quantum mechanics, but you don't know when it will\ncome in handy. If you're a doctor and you've\ngot a patient who's running away from you at the speed of light,\nyou'll know what to do. Or, if you're a pediatrician\nwith a really small patient who will not sit still,\nit's because the laws of quantum mechanics don't allow an\nobject to have a definite position and momentum. So these are all things you just don't know when they will\ncome in handy, and I teach them because these\nare the things that turn me on and got me going into physics\nand whether or not you go into physics,\nyou should certainly learn about the biggest and most\ninteresting revolutions right up to present day physics. All right. So that's what the subject\nmatter's going to be, and I'm going to tell you a\nlittle bit about how the course is organized. First thing is, this year it's going to be\ntaped. You can see some people in the\nback with cameras as part of an experimental pilot program\nfunded by the Hewlett Foundation and at some point they will\ndecide what they will do with these lectures. Most probably they'll post them somewhere so people elsewhere\ncan have the benefit of what you have sitting in the classroom. So I've been told that from now on we just ignore the camera and\ndo business as usual. Nothing's going to be changed. I tried to negotiate a laugh track so that if the jokes don't\nwork we can superimpose some laughter. I was told \"no.\" I just got to deal with it as\nit happens. So it's going to be--it's like\none of the reality shows where things are going to be as they\nare and hopefully after a while we'll learn to act and behave\nnormally and not worry about its presence. Then, coming to the rest of the details of the course. By the way, there are more details on the website that I\nposted, that was given to me by the university,\nif you want to know more about what all this is about. The course organization is fairly simple. We're going to meet Monday and Wednesday in this room,\n11:30-12:45. I will give you some problems\nto do on Wednesday and I'll post them on the website. You guys should get used to going to the class' website. I'm really, really dependent on that now. I finally learned how to use it. I will use that to post\ninformation, maybe once in a while send e-mail to the whole\nclass. If you want to get those\ne-mails, you got to sign up for the course because I push a\nbutton and it goes to anybody who's signed up there. The homework will be given on Wednesday and it's due before\nclass the following Wednesday. Let me introduce you to our\nhead TA, Mara Daniel, who's recently Mara Baraban. So Mara's going to be the\nperson who will see you after class and she will take the\nproblem sets that you have submitted before class and\nshe'll give you the graded ones after class. Okay? That will be sorted up,\nit'll be up there. So you should drop the homework\nbefore you come into class, rather than furiously work on\nit during class, and the solutions will be\nposted the same afternoon. So there is not much point in\ngiving homework that's late. But once in a while,\nyou know, you will come up with a reason that I just cannot\nargue with. You got married,\nyou're getting a transplant, whatever it is. That's fine. You got a transplant,\nI want to see the old body part. You got married, I want to see your spouse. If something happened to a grandparent, I'm counting. Up to four I don't get suspicious. Go five, six, seven, eight,\nI will have to look into the family tree."}, {"content": "But, you know, any reasonable excuse will be\nentertained. Relative importance given to\nthese different things, there's 20% for your homework,\n30% for the Midterm, which will be sometime in\nOctober, and 50% for the Final. That'll be the weighted average. But I have another plan called the \"Amnesty Plan\" in which I\nalso compare just your final grade,\nwhat you did on the Final exam, and whichever is higher of the\ntwo is what I will take to determine your overall course\ngrade. This is something I used to\nannounce near the end but then some people felt that it's not\nfair not to know this from the beginning. So, I'm telling you from the beginning, but don't dream and\nthink that somehow the Final's going to be so much different\nfrom your regular day-to-day performance,\nbut to give you some reason to live after the Midterm. So, you feel there is hope. I can change everything\novernight; it does happen. I put that in for a reason because sometimes some of you\nhave not taken a physics course and you don't know how to do\nwell in physics and slowly you catch on and by the time it's\nFinal exam you crack the code; you know how to do well. As far as I'm concerned, that's just fine. If at the end of the semester you take a three-hour exam in a\nclosed environment and you answer everything,\nI don't care what you did in your homework or your Midterm. That's not relevant."}, {"content": "So that's how the grading will\nbe done. We have Mara's group of TAs. She is the head TA and she's the one you should write to\nwhenever you have a problem. Then we also have two faculty\nmembers. One is a Postdoctoral Fellow,\nMark Caprio. So he will have a discussion\nsection on Tuesdays between 1:00-2:00 in Sloane Lab. And Steve Furlanetto--I don't know if Steve is here or not. There's Steve, our new Assistant Professor. He will have his section on Tuesday night in Dunham Lab,\nin Room 220. Tuesday night is the night when\nyou people realize homework is due on Wednesday. So we know that, so he will be there to comfort\nyou and give you whatever help you need. All right. My own office hours I've not\ndetermined yet. I will have to find out when it\nis good for you. You know, I live and work out\nof Sloane Lab up on the hill and it was easy to have office hours\nbefore or after class but now you have to make a special trip. So, just give me a little bit of time to find out maybe by\nsoliciting e-mail responses from you what would be a good time\nfor my office hours. But for any procedural things,\nlike, you know, this problem set was not graded\nproperly, and so on, there's no point\ne-mailing me because I'm going to send it to Mara anyway. So directly deal with the powers that be. Okay, finally I want to give you some tips on how to do well\nin this course and what attitude you should have. First, I advise that you should come to the lectures. It's not self-serving; it's not so much for my benefit. I think there is something useful about hearing the subject\npresented once orally. Secondly, the book,\nyou can see, one of you had a book here,\nit's about 1,100 pages and when I learned physics it was,\nlike 300 pages. Now, I look around this room,\nI don't see anybody whose head is three times bigger than mine,\nso I know that you cannot digest everything the books\nhave. So I have to take out what I\nthink is the really essential part and cover them in the\nlecture. So, you come to class to find\nout what's in and what's not in. If you don't do that,\nthere's a danger you will learn something you don't have to,\nand we don't want that. Okay, so that's why you come to\nclass. Second thing,\nmost important thing for doing well in physics,\nis to do the homework. The 20% given to the homework\nis not a real measure of how important it is. Homework is when you really figure out how much you know and\ndon't know. If you watch me do the thing on\nthe blackboard, it looks very reasonable."}, {"content": "It looks like you can do it but the only way you're going to\nfind out is when you actually deal with the problem. That's the only time you're going to find out. So, I ask you to do the problems as and when they're\nposted. So if I post it on Wednesday to\ncover the material for that week, then you should attempt it\nas quickly as possible because I'm going to assume you have\ndone the problems when you come for the next few lectures. And in doing the homework, it is perfectly okay to work in\ngroups. You don't have to do it by\nyourself. That's not how physics is done. I am now writing a paper with two other people. They are my experimental colleagues who write papers with\n400 other people, maybe even 1,000 other people. When they do the big collider experiments in Geneva or\nFermilab, collaborations can run into hundreds. So, it's perfectly okay to be part of a collaboration,\nbut you've got to make sure that you're pulling your weight. You've got to make sure that if you explain to others how to do\nthis problem, then somebody else contributes\nto something else, but you know what everybody\ncontributed in the end. So the game is not just to\nsomehow or other get the solution to the problem set but\nto fully understand how it's done,\nand the TAs will be there to help you. Every day there's going to be a TA in the undergraduate lounge. I would urge you to use that. That's a beautiful new lounge\nthat the Provost's Office allowed us to build for\nphysicists and chemists, or whoever happens to be in the\nbuilding. If you go there on the third\nfloor of Sloane, you may run into other people\nlike you who are trying to work on problems. You may run into upper-class students, students who are more\nadvanced, you will run into your TA. So that's a good climate. There are coffee machines and\nthere are lounge sofas and everything else. There are computers, there are printers,\nso it's a good lounge, and I think if you go there one\nday a week to do your problem sets,\nmore often that's a good meeting place,\nI recommend that. The final piece of advice,\nthis is very important so please pay attention to this,\nwhich is, I ask you not to talk to your neighbors during\nlecture. Now, this looks like a very\ninnocuous thing, but you will find out,\nit is the only thing that really gets my back up. Most of the time I don't really care. I'm really liberal, but this disturbs me because I\nam looking at you, I'm trying to see from your\nreaction how much of my lecture you are following,\nand then it's very distracting when people are talking. So please don't do that. If you talk,\nI am going to assume you are talking about me. If you laugh, I'm going to assume you are\nlaughing at me. That's not really what I think,\nbut that's how disturbing it is when people talk,\nand very nice students who do not realize this often disrupt\nmy line of thinking. So I ask you to keep that to a\nminimum. Once in a while you'll have to\ntalk to your neighbor and say, \"Can you please pass me my\npacemaker that fell down?\" That's fine. Then you go back to your business."}, {"content": "But don't do too much of that. Finally, there is this ancient\nissue about sleeping in class. Now, my view is,\nit's just fine, okay. I know you guys need the rest and interestingly,\nthe best sleepers are in the first couple of rows. I haven't met you guys. It's not personal. I have found some people really have to come to the first and\nsecond row because they claim that if they don't hear me they\ncannot really go to sleep. Now, that was true in Sloane\nbut I think Luce has got very good acoustics so you can\nstretch out in the back. But my only criterion is if you\ntalk in your sleep, now that's not allowed because\ntalking is not allowed. Next, if you're going to sleep,\nI ask you to sit between two non-sleepers because sometimes\nwhat happens, the whole row will topple over. We don't want the domino effect. Now, it's going to be captured\non tape and that's going to be really bad for my reputation,\nso spread yourself around other people. All right. So that's it in terms of class,\nyou know, logistics and everything. I'm going to start going into the physics proper. I will try to finish every lecture on time,\nbut sometimes if I'm in the middle of a sentence or the\nmiddle of a derivation, I may have to go over by a\ncouple of minutes; there's no need to shuffle your\nfeet and move stuff around. I know what time it is. I also want to get out like you guys, but let me finish\nsomething. Other days I may finish a few\nminutes before time. That's because the ideas of\nphysics don't fall into 75-minute segments and sometimes\nthey spill over a little bit. Also, I'm used to teaching this\ncourse three times a week and now it's suddenly twice a week,\nand so things that fell into nice 50-minute units are now\nbeing snipped up different ways so it's pretty difficult. So, even for me, some of it will be new and the\ntiming may not be just right. I should tell you first of all\nthat in this class, the taping is not going to\naffect you because the camera is going to be behind your head. I mentioned to you in the website that this is not the big\nopportunity you've been looking for to be a star. Only the back of your head will be seen. In some cases, the back of the head could be\nmore expressive than the front, in which case this is your\nopportunity and I wish you luck. But otherwise,\njust don't worry about it because you will be only heard."}, {"content": "You may not even be heard. So, I've been asked that if a\nquestion is not very clear, I should repeat it so that\npeople listening to it later will know what the question was. Let me make one thing very\nclear. That is, I'm not in favor of\nyour talking to each other because you're distracting. Your stopping me at any time is just fine. I welcome that because I've seen this subject for God knows\nhow many years. The only thing that makes it\ndifferent for me is the questions that you people have. You can stop me any time and you should not feel somehow you\nare stopping the progress of the class. There is no fixed syllabus. We can move things around and\nit's far more exciting for me to answer your questions than to\nhave a monologue."}, {"content": "So, don't worry about that. So stop me anytime you don't follow something,\nand don't assume that you're not following something because\nthere's something wrong with your level of comprehension. Quite often, you guys come up with questions\nthat never cross my mind, so it's very interesting."}, {"content": "And things we've been repeating year after year after year,\nbecause they sound so reasonable,\nsuddenly sound unreasonable when some of you point out some\naspect of it that you didn't follow. So, it could be very interesting for all of us to\nhave issues to discuss in class, and quite often some questions\nare very common and your classmates will be grateful to\nyou that you brought it up. Otherwise, you know,\nTAs get ten e-mails, all with the same question. Okay."}, {"content": "So I'm going to start now. Anybody have any questions about class? The format? The Midterm? The exams? All right."}, {"content": "Yes? Student:\nYou said there's going to be two hours to be announced. How do we wait for [inaudible] Professor Ramamurti\nShankar: Oh, you mean my office hours? Student: No. I thought there was an\n[inaudible] Professor Ramamurti\nShankar: No, the discussion sections are\nTuesday afternoon from 1:00-2:00,\nand Tuesday night from 8:00-10:00, and the website has\ngot all the details on when and where. Yes? Student:\nSo the lab times will still be [inaudible]\nProfessor Ramamurti Shankar: Yeah. There are many, many lab times and you have to\ngo to the website for the lab. And, by the way,\nthat reminds me. I've got here lots of flyers\ngiven to me by the director of the laboratories which will tell\nyou which lab is the right lab for you,\nand they're offered many times a week. Yes? Student:\nAs far as knowing the material, just from your class,\nhow important is taking a lab concurrent with this class? Professor Ramamurti Shankar: I think it's a good\nidea to take the lab, particularly in this particular\nclass because I don't have any demonstrations. They're all in the other building. So, this will remind you that physics is, after all,\nan experimental science and you will be able to see where all\nthe laws of physics come from. So, if you're going to take it,\nyou should take it at the same time. Yes? Student:\nCould you please talk about when you expect [inaudible]\nProfessor Ramamurti Shankar: Ah,\nvery good. This is a calculus-based class\nand I expect everyone to know at least the rudiments of\ndifferential calculus. What's a function,\nwhat's a derivative, what's a second derivative,\nhow to take derivatives of elementary functions,\nhow to do elementary integrals. Sometime later,\nI will deal with functions of more than one variable,\nwhich I will briefly introduce to you,\nbecause that may not be a prerequisite but certainly\nsomething you will learn and you may use on and off. But there are different ways of doing physics. Mine is to demonstrate over and over how little mathematics you\nneed to get the job done. There are others who like to\nshow you how much mathematics you could somehow insinuate into\nthe process, okay. There are different ways of\nplaying the game, and some of us find great pride\nin finding the most simple way to understand something. That's certainly my trademark; that's how I do my research\nalso. So, if you feel there's not\nenough math used, I guarantee you that I\ncertainly know enough eventually to snow the whole class,\nbut that's not the point. I will use it in moderation and\nuse it to the best effect possible rather than use it\nbecause it is there. Okay. So I don't know your mathematical background,\nbut the textbook has an appendix, which is a reasonable\nmeasure of how much math you should know. You've got to know your trigonometry,\nyou've got to know what's a sine and what's a cosine. You cannot say, \"I will look it up.\"\nYour birthday and social security number is what you look\nup. Trigonometry functions you know\nall the time. Okay."}, {"content": "I will ask you, and you do."}, {"content": "All right. And of course, there's trigonometric\nidentities you know from high school. Pages and pages of them, so no one expects you to know\nall those identities, but there are a few popular\nones we will use. All right."}, {"content": "Anything else?"}, {"content": "Yes? Student: This may be a bit early,\nbut when will we be having our Midterm? Professor Ramamurti Shankar: Yeah. Midterm will be sometime around 20th of October. I have to find out exactly the right time. We have 24 lectures for this class and the first 12 roughly\nwill be part of the Midterm, but after the 12th lecture I\nmay wait a week so that you have time to do the problems and get\nthe solutions. Then I will give you the\nMidterm. Yes? Student: If wanting one of the two lab\ncourses, which one do you recommend? Professor Ramamurti Shankar: Yeah,\nthis tells you in detail. This flyer answers exactly that. Okay, there was one more question from somebody?"}, {"content": "Yes? Student:\nA few people I've talked to have recommended that we start\ntaking the lab second semester instead of first. Would that be advisable or should we take both\nconcurrently? Professor Ramamurti\nShankar: I don't have a strong view. I think you should take the lab sometime but I don't know how\nmany semesters that you have to take. But I would say the advice of your predecessors is very\nimportant. If they tell you this is what\nworks, that's better than what somebody like me can tell you. Also, you should talk to Stephen Irons,\nwho is the director of the labs. He has seen every possible situation."}, {"content": "He will give you good advice. Let's start now."}, {"content": "Okay. So we are going to be studying\nin the beginning what's called Newtonian mechanics. It's pretty remarkable that the whole edifice is set up by just\none person \u2013 Newton -- and he sent us on the road to\nunderstanding all the natural phenomena until the year\n18-hundred-and-something when Maxwell invented the laws of\nelectromagnetism and wrote down the famous Maxwell equations. Except for electromagnetism, the basics of mechanics,\nwhich is the motion of billiard balls and trucks and marbles and\nwhatnot, was set up by Newton. So that's what we are going to\nfocus on, and you will find out that the laws of physics for\nthis entire semester certainly can be written on one of those\nblackboards or even half of those blackboards. And the purpose of this course is to show you over and over and\nover again that starting with those one or two laws,\nyou can deduce everything, and I would encourage you to\nthink the same way. In fact, I would encourage you\nto think the way physicists do, even if you don't plan to be a\nphysicist, because that's the easiest way\nto do this subject, and that is to follow the\nreasoning behind everything I give you. And my purpose will be not to say something as a postulate,\nbut to show you where everything comes from,\nand it's best for you if you try to follow the logic. That way, you don't have to store too many things in your\nhead. In the early days when there\nare four or five formulas, you could memorize all of them\nand you can try each one of them until something works,\nbut after a couple of weeks you will have a hundred formulas and\nyou cannot memorize all of them. You cannot resort to trial and\nerror. So you have to know the logic. So the logical way is not just the way the physicists do it,\nit's the easier way to do it. If there is another way that it\nwill work for non-physicists, I won't hesitate to teach it to\nyou that way if that turns out to be the best way. So try to follow the logic of everything. Okay. So, Newtonian mechanics is our\nfirst topic. So, Newtonian mechanics has two\nparts. All of physics is a two-part\nprogram. The plan, every time,\nis to predict the future given the present. That's what we always do. When we do that right,\nwe are satisfied. So the question is,\n\"What do you mean by \u2018predict the future?'\"\nWhat do you mean by the future? What do you mean by the present? By \"present,\" we mean--we will pick some part of the universe\nwe want to study and we will ask,\n\"What information do I need to know for that system at the\ninitial time, like,\nright now, in order to be able to predict the future?\"\nSo, for example, if you were trying to study the\nmotion of some object, here is one example. [throws a piece of candy for someone to catch]\nProfessor Ramamurti Shankar: See,\nthat's an example of Newtonian mechanics."}, {"content": "I'll give you one more demonstration. Let's see who can catch this one. [throws another piece] Professor Ramamurti\nShankar: That's a good example. So, that was Newtonian mechanics at work,\nbecause what did I do? I released a piece of candy,\nthrew it from my hand, and the initial conditions have\nto do with where did I release it and with what velocity. That's what he sees with his eyes. Then that's all you really need to know. Then he knows it's going to go up, it's going to curve,\nfollow some kind of parabola, then his hands go there to\nreceive it. That is verification of a\nprediction. His prediction was,\nthe candy's going to land here, then he put his hand there. He also knew where the candy was going to land,\nbut he couldn't get his hand there in time. But we can always make predictions. But this is a good example of what you need to know. What is it you have to know about this object that was\nthrown, I claim, is the initial location of the\nobject and the initial velocity. The fact that it was blue or\nred is not relevant, and if I threw a gorilla at him\nit doesn't matter what the color of the gorilla is,\nwhat mood it is in. These are things we don't deal\nwith in physics. There is a tall building,\na standard physics problem. An object falls off a tall\nbuilding. Object could be a person. So we don't ask why is this guy ending it all today? We don't know, and we cannot deal with that. So we don't answer everything. We just want to know when he's\ngoing to hit the pavement, and with what speed. So we ask very limited questions, which is why we brag\nabout how accurately we can predict the future. So, we only ask limited goals and we are really successful in\nsatisfying them. So, we are basically dealing\nwith inanimate objects. So the product of Newtonian\nmechanics of predicting the future given the present,\nhas got two parts, and one is called kinematics\nand the other is called dynamics. So, kinematics is a complete description of the present. It's a list of what you have to know about a system right now. For example, if you're talking about the\nchalk--if I throw the chalk, you will have to know where it\nis and how fast it's moving. Dynamics then tells you why the\nobject goes up, why the object goes down and\nwhy is it pulled down and so on. That's dynamics. The reason it comes down is gravity is pulling it. In kinematics, you don't ask the reason behind\nanything. You simply want to describe\nthings the way they are and then dynamics tells you how they\nchanged and why they changed. So, I'm going to illustrate the\nidea of kinematics by taking the simplest possible example. That's going to be the way I'm going to do everything in this\ncourse. I'm going to start with the\nsimplest example and slowly add on bells and whistles and make\nit more and more complicated. So, some of you might say,\n\"Well, I've seen this before,\" so maybe there is nothing new\nhere."}, {"content": "That may well be. I don't know how much you've seen, but quite often the way\nyou learned physics earlier on in high school is probably\ndifferent from the way professional physicists think\nabout it. The sense of values we have,\nthe things that we get excited about are different,\nand the problems may be more difficult. But I want to start in every example, in every situation that\nI explain to you, with the simplest example,\nand slowly add on things. So, what we are going to study\nnow is a non-living object and we're going to pick it to be a\nmathematical point. So the object is a mathematical\npoint. It has no size. If you rotate it, you won't know. It's not like a potato."}, {"content": "You take a potato,\nyou turn it around, it looks different. So, it's not enough to say the potato is here. You've got to say which way the nose is pointing and so on. So, we don't want to deal with that now. That comes later when we study what we call \"rigid bodies\". Right now, we want to study an entity which has no spatial\nextent. So just a dot,\nand the dot can move around all over space. So we're going to simplify that too. We're going to take an entity that lives along the x\naxis. [draws a line with integrals]\nIt moves along a line. So you can imagine a bead with\na wire going through it and the bead can only slide back and\nforth. So, this is about the simplest\nthing. I cannot reduce the number of\ndimensions. One is the lowest dimension. I cannot make the object simpler than being just a\nmathematical point. Then, you've got to say,\n\"What do I have to know about this object at the initial time? What constitutes the present, or what constitutes maximal\ninformation about the present?\" So what we do is we pick an\norigin, call it zero, we put some markers there to\nmeasure distance, and we say this guy is sitting\nat 1,2, 3,4, 5. He is sitting at x = 5. Now, of course, we've got to have units and the\nunits for lengths are going to be meters. The unit for time will be a second, and time will be\nmeasured in seconds. Then we'll come to other units. Right now, in kinematics, this is all you need. Now, there are some tricky problems in the book. Sometimes they give you the speed in miles per hour,\nkilometers per year, pounds per square foot,\nwhatever it is. You've got to learn to\ntransform them, but I won't do them."}, {"content": "I think that's pretty elementary stuff. But sometimes I might not write the units but I've earned the\nright to do that and you guys haven't so you'll have to keep\ntrack of your units. Everything's got to be in the\nright units. If you don't have the units,\nthen if you say the answer is 19, then we don't know what it\nmeans. Okay."}, {"content": "So here's an object. At a given instant,\nit's got a location. So what we would like to do is\nto describe what the object does by drawing a graph of time\nversus space and the graph would be something like this. You've got to learn how to read this graph. I'm assuming everyone knows how to read it. [draws a graph of x versus t]\nThis doesn't mean the object is bobbing up and down. I hope you realize that. Even though the graph is going\nup and down, the object is moving from left to right. So, for example, when it does this,\nit's crossed the origin and is going to the left of the origin. Now, at the left of the origin, it turns around and starts\ncoming to the origin and going to the right. That is x versus t. So, in the language of calculus, x is a function\nof time and this is a particular function. This function doesn't have a name. There are other functions which have a name. For example, this is x = t,\nx = t^(2), you're going to have x = sin\nt and cos t and log t. So some functions have a name, some functions don't have a\nname. What a particle tries to do\ngenerally is some crazy thing which doesn't have a name,\nbut it's a function x (t). So you should know when you look at a graph like this what\nit's doing. So, the two most elementary\nideas you learn are what is the average velocity of an object,\nas then ordered by the symbol v-bar. So, the average is found by taking two instants in time,\nsay t_1 and later t_2,\nand you find out where it was at t_2 minus\nwhere it was at t_1 and divide\nby the time. So, the average velocity may\nnot tell you the whole story. For example,\nif you started here and you did all this and you came back here,\nthe average velocity would be zero, because you start and end\nat the same value of x, you get something;\n0 over time will still be 0. So you cannot tell from the\naverage everything that happened because another way to get the\nsame 0 is to just not move at all. So the average is what it is. It's an average,\nit doesn't give you enough detail. So it's useful to have the average velocity. It's useful to have the average acceleration,\nwhich you can find by taking similar differences of\nvelocities. But before you even do that,\nI want to define for you an important concept,\nwhich is the velocity at a given time, v (t). So this is the central idea of calculus, right? I am hoping that if you learned your calculus,\nyou learned about derivatives and so on by looking at x\nversus t. So, I will remind you,\nagain, this is not a course in calculus. I don't have to do it in any detail. I will draw the famous picture of some particle moving and it's\nhere at t of some value of x. A little later, which is t + \u0394t. So \u0394t is going to stand always for a small finite\nintegral of time; infinitesimal interval of time\nnot yet 0. So, during that time,\nthe particle has gone from here to there, that is x +\n\u0394x, and the average velocity in that interval is\n\u0394 x/ \u0394t. Graphically,\nthis guy is \u0394 x and this guy is \u0394t,\nand \u0394x over \u0394t is a ratio. So in calculus,\nwhat you want to do is to get the notion of the velocity right\nnow. We all have an intuitive notion\nof velocity right now. When you're driving in your\ncar, there's a needle and the needle says 60;\nthat's your velocity at this instant. It's very interesting because velocity seems to require two\ndifferent times to define it -- the initial time and the final\ntime. And yet, you want to talk about\nthe velocity right now. That is the whole triumph of\ncalculus is to know that by looking at the position now,\nthe position slightly later and taking the ratio and bringing\nlater as close as possible to right now,\nwe define a quantity that we can say is the velocity at this\ninstant. So v of t,\nv(t) is the limit, \u0394t goes to 0 of\n\u0394x over \u0394t and we use the symbol dx/dt\nfor velocity. So technically,\nif you ask what does the velocity stand for--Let me draw\na general situation. If a particle goes from here to\nhere, \u0394x over \u0394t, I don't know how\nwell you can see it in this figure here,\nis the slope of a straight line connecting these two points,\nand as the points come closer and closer,\nthe straight line would become tangent to the curve. So the velocity at any part of the curve is tangent to the\ncurve at that point. The tangent of,\nthis angle, this \u03b8, is then \u0394x over \u0394t. Okay, once you can take one derivative,\nyou can take any number of derivatives and the derivative\nof the velocity is called the acceleration,\nand we write it as the second derivative of position. So I'm hoping you guys are comfortable with the notion of\ntaking one or two or any number of derivatives. Interestingly, the first two derivatives have\na name. The first one is velocity,\nthe second one is acceleration. The third derivative,\nunfortunately, was never given a name,\nand I don't know why. I think the main reason is that\nthere are no equations that involve the third derivative\nexplicitly. F = ma. The a is this fellow here, and nothing else is given\nan independent name. Of course, you can take a\nfunction and take derivatives any number of times. So you are supposed to know, for example,\nif x(t) is t^(n), you're supposed to know\ndx/dt is nt^(n-1). Then you're supposed to know\nderivatives of simple functions like sines and cosines. So if you don't know that then, of course, you have to work\nharder than other people. If you know that,\nthat may be enough for quite some time. Okay, so what I've said so far\nis, a particle moving in time from point to point can be\nrepresented by a graph, x versus t. At any point on the graph you can take the derivative,\nwhich will be tangent to the curve at each point,\nand its numerical value will be what you can call the\ninstantaneous velocity of that point and you can take the\nderivative over the derivative and call it the acceleration. So, we are going to specialize to a very limited class of\nproblems in the rest of this class. A limited class of problems is one in which the acceleration is\njust a constant. Now, that is not the most\ngeneral thing, but I'm sure you guys have some\nidea of why we are interested in that. Does anybody know why so much time is spent on that? Yes? Student:\n[inaudible] Professor Ramamurti\nShankar: Pardon me?"}, {"content": "Student:\n[inaudible] Professor Ramamurti\nShankar: Right. The most famous example is that\nwhen things fall near the surface of the Earth,\nthey all have the same acceleration,\nand the acceleration that's constant is called g,\nand that's 9.8 meters/second^(2). So that's a very typical problem. When you're falling to the surface of the Earth,\nyou are describing a problem of constant acceleration. That's why there's a lot of emphasis on sharpening your\nteeth by doing this class of problems. So, the question we are going to ask is the following,\n\"If I tell you that a particle has a constant acceleration\na, can you tell me what the\nposition x is?\" Normally, I will give you a\nfunction and tell you to take any number of derivatives. That's very easy. This is the backwards problem. You're only given the particle has acceleration a,\nand you are asked to find out what is x? In other words, your job is to guess a function\nwhose second derivative is a,\nand this is called integration, which is the opposite of\ndifferentiation, and integration is just\nguessing. Integration is not an\nalgorithmic process like differentiation. If I give you a function, you know how to take the\nderivative. Change the independent\nvariable, find the change in the function, take the ratio and\nthat's the derivative. The opposite is being asked\nhere."}, {"content": "I tell you something about the\nsecond derivative of a function and ask you what is the\nfunction. The way we do that is we guess,\nand the guessing has been going on for 300 years,\nso we sort of know how to guess. So, let me think aloud and ask how I will guess in this\nproblem. I would say,\nokay, this guy wants me to find a function which reduces to the\nnumber a when I take two derivatives,\nand I know somewhere here, this result,\nwhich says that when I take a derivative,\nI lose a power of t. In the end, I don't want any\npowers of t. It's very clear I've got to\nstart with a function that looks like t^(2). This way when I take two derivatives, there will be no\nt left. Well, unfortunately,\nwe know this is not the right answer, because if you take the\nfirst derivative, I get 2t. If I take the second derivative I get 2, but I want to get\na and not 2. Then it's very clear the way\nyou patch it up is you multiply it by this constant and now\nwe're all set. This function will have the\nright second derivative. So, this certainly describes a\nparticle whose acceleration is a. The a is not dependent on time. But the question is, is this the most general\nanswer, or is it just one answer, and I think you all know\nthat this is not the most general answer. It is one answer. But I can add to this some\nnumber, like 96, that'll still have the property\nthat if you take two derivatives,\nyou're going to get the same acceleration. So 96 now is a typical constant, so I'm going to give\nthe name c to that constant. Everyone knows from calculus that if you're trying to find a\nfunction about which you know only the derivative,\nyou can always add a constant to one person's answer without\nchanging anything. But I think here,\nyou know you can do more, right? You can add something else to the answer without invalidating\nit, and that is anything with one power of t in it, because if you take one\nderivative it'll survive, but if you take two\nderivatives, it'll get wiped out. Now, it's not obvious but it is true that you cannot add to this\nanymore. The basic idea in solving these\nequations and integrating is you find one answer,\nso then when you take enough derivatives, the function does\nwhat it's supposed to do. But then having found one\nanswer, you can add to it anything that gets killed by the\nact of taking derivatives. If you're taking only one\nderivative you can add a constant. If you're taking two derivatives you can add a\nconstant and something linear in t.. If you knew only the third derivative of the function,\nyou can have something quadratic in t without\nchanging the outcome. So, this is the most general\nposition for a particle of constant acceleration,\na. Now, you must remember that this\ndescribes a particle going side to side. I can also describe a particle going up and down. If I do that, I would like to call the\ncoordinate y, then I will write the same\nthing. You've got to realize that in\ncalculus, the symbols that you call x and y are\ncompletely arbitrary. If you know the second\nderivative of y to be a, then the answer looks\nlike this. If you knew the second\nderivative of x, the answer looks like that. Now, we have to ask what are these numbers,\nb and c. So let me go back now to this\nexpression, x(t) = at^(2)/ 2 + c +\nbt. It is true mathematically,\nyou can add two numbers, but you've got to ask yourself,\n\"What am I doing as a physicist when I add these two numbers?\"\nWhat am I supposed to do with a and b? I mean, with the b and c?"}, {"content": "What value should I pick? The answer is that simply\nknowing the particle has an acceleration is not enough to\ntell you where the particle will be. For example, let's take the case where the\nparticle is falling under gravity. Then you guys know, you just told me,\nacceleration is -9.8, my g is -9.8. We call it \"minus\" because it's accelerating down and up was\ntaken to be the positive direction. In that case, y(t) will be\n-1/2gt^(2) + c + bt. So, the point is,\nevery object falling under gravity is given by the same\nformula, but there are many, many objects that can have many\nhistories, all falling under gravity, and what's different\nfrom one object and the other object is,\nwhen was it dropped, from what height,\nand with what initial speed. That's what these numbers are\ngoing to tell us and we can verify that as follows. If you want to know what the number c is,\nyou say, let's put time t = 0. In fact,\nlet me go back to this equation here. You'll put time t = 0, x(0) doesn't\nhave this term, doesn't have this term,\nand it is c. So I realize that the constant,\nc, is the initial location of the object,\nand it's very common to denote that by x_0. So\nthe meaning of the constant c is where was the object at the\ninitial time? It could've been anywhere. Simply knowing the acceleration is not enough to tell you where\nit was at the initial time. You get to pick where it was at\nthe initial time. Then, to find the meaning of\nb, we take one derivative of this, dx/dt,\nthat's velocity as a function of time, and if you took the\nderivative of this guy, you will find as at + b. That's the velocity of the object. Then, you can then understand that v(0) is what\nb is, which we write as v_0. Okay,\nso the final answer is that x(t) looks like\nx_0 + v_0 t + 1/2 at^(2). Okay. So what I'm saying here is we are specializing to a limited\nclass of motion where the particle has a definite\nacceleration, a. Then, in every situation where the body has an acceleration\na, the location has to have this form,\nwhere this number (x_0) is where\nit was initially, this (v_0 )\nwas the initial velocity of the object. So, when I threw that thing up and you caught it,\nwhat you are doing mentally was immediately figuring out where\nit started and at what speed. That was your initial data. Then in your mind, without realizing it,\nyou found the trajectory at all future times. Now, there is one other celebrated formula that goes\nwith this. I'm going to find that,\nthen I'll give you an example. Now, I'm fully aware that this\nis not the flashiest example in physics, but I'm not worried\nabout that right now. You'll see enough things that\nwill confound you, but right now I want to\ndemonstrate a simple paradigm of what it means to know the\npresent and what it means to say this is what the future behavior\nwill be. We want to do that in the\nsimplest context, then we can make the example\nmore and more complicated, but the phenomenon will be the\nsame."}, {"content": "So, what we have found out so\nfar, I'm purposely going from x to y because I\nwant you to know that the unknown variable can be called\nan x or can be called a y. It doesn't matter, as long as the second\nderivative is a; that's the answer. Now there's a second formula one derives from this."}, {"content": "You guys probably know that too from your days at the daycare,\nbut I want to derive the formula and put it up,\nthen we'll see how to use it. Second formula tries to relate\nthe final velocity of some time, t, to the initial\nvelocity and the distance traveled with no reference to\ntime. So the trick is to eliminate\ntime from this equation. So let's see how we can\neliminate time. You know that if you took a\nderivative of this, you will find v(t) is\nv_0 + at. What that means is,\nif you know the velocity of the given time and you know the\ninitial velocity, you know what time it is. The time, in fact, is v - v_0\nover a. If I don't show you any\nargument for v, it means v at time\nt and the subscript of 0 means t is zero. So what this says is, you can measure time by having\nyour own clock. A clock tells you what time it\nis, but you can also say what time it is by seeing how fast\nthe particle is moving because you know it started with some\nspeed. It's gaining speed at some rate\na. So, if the speed was so and so\nnow, then the time had to be this. So time can be indirectly inferred from these quantities. Then you take that formula here (t) and you put it here,\n(y(t)) to see a times t,\nyou put this expression. So what will you get? We'll get an expression in which there is no t;\nt has been banished in favor of v. So, I'm not going to waste your time by asking what happens if\nyou put it in. I will just tell you want\nhappens. What happens is,\nyou will find that v^(2) = v_o^(2) + 2a times\n(y- y_0). [Note: The Professor said x\nwhen he meant y] How many people have seen this\nthing before?"}, {"content": "Okay."}, {"content": "That's a lot. Look, I know you've seen this. At the moment, I have to go through some of\nthe more standard material before we go to the more\nnon-standard material. If this part's very easy for\nyou, there's not much I can do right now. So let me draw a box. Drawing a box to you guys means\nimportant. These are the two important\nthings."}, {"content": "Remember, I want you to\nunderstand one thing. How much of this should you\nmemorize? Suppose you've never seen this\nin high school. How much are you supposed to\nmemorize? I would say,\nkeep that to a minimum, because what the first formula\ntells you should be so intuitive that you don't have to cram\nthis. We are talking about particles\nof constant acceleration. That means, when I take two\nderivatives, I want to get a, then you should know\nenough calculus to know it has to be something like\nat^(2), and half comes from taking two\nderivatives. The other two you know are\nstuff you can add, and you know where you're\nadding those things, because the particle has a head\nstart. It's got an initial position. Even at = 0, and it has an initial velocity,\nso even without any acceleration,\nit will be moving from y^(0) to y^(0) + vt. The acceleration gives you an extra stuff, quadratic in time. Once you've got that, one derivative will give you\nthe velocity, then in a crunch you can\neliminate t and put it into this formula. But most people end up memorizing these two because you\nuse it so many times. It eventually sticks in you but\nyou shouldn't try to memorize everything. So, we are now going to do one standard problem where we will\nconvince ourselves we can apply this formulae and predict the\nfuture given the present. So the problem I want to\ndo--there are many things you could do but I just picked one,\nand this is the one with round numbers so I can do it without a\ncalculator. Here's the problem. There is this building and it's going to be 15 meters high,\nand I'm going to throw something and it's going to go\nup and come down. It's something I throw up has\nan initial speed of 10 meters per second. So we have to ask now,\nnow that my claim is, you can ask me any question you\nwant about this particle and I can answer you. You can ask me where it will be nine seconds from now,\neight seconds from now, how fast will it be moving. I can answer anything at all. But what I needed to do this\nproblem was to find these two unknowns."}, {"content": "So, you've got to get used to the notion of what will be given\nin general and what is tailor-made to the occasion. So, we know in this example the initial height should be 15\nmeters and the initial velocity should be 10,\nand for acceleration, I'm going to use -g and\nto keep life simple, I'm going to call it -10. As you know, the correct answer is 9.8,\nbut we don't want to use the calculator now so we'll call it\n-10. Consequently,\nfor this object the position y, at any time t\nis known to be 15 + 10t - 5t^(2). That is the full\nstory of this object. Of course, you've got to be a\nlittle careful when you use it. For example,\nlet's put t equal to 10,000 years. What are you going to get? When t is equal to\n10,000 years or 10000 seconds, you're going to find y\nis some huge negative number. You know, that's not right,\nwhat's wrong with that reasoning? Student: [inaudible]\nProfessor Ramamurti Shankar: So you cannot use\nthe formula once it hits the ground because once it hits the\nground, the fundamental premise that\na was a constant of -9.8 or -10 is wrong. So that's another thing to remember. Once you get a formula, you've got to always remember\nthe terms under which the formula was derived."}, {"content": "If you blindly use it beyond its validity,\nyou will get results which don't make any sense. Conversely, if you get an answer and it doesn't seem to\nmake sense, then you've got to go back and ask,\nam I violating some of the assumptions, and here you will\nfind the assumption that the particle had that acceleration\na is true as long it's freely falling under gravity but\nnot when you hit the ground. Now, if you dug a hole here\nuntil there, and of course it may work until that happens,\nokay. But you've got them every time. This is so obvious in this problem, but when you see more\ncomplicated formula, you may not know all the\nassumptions that went into the derivation and quite often you\nwill be using it when you shouldn't. All right. See, this you agree,\nis a complete solution to this miniature, tiny,\nMickey-Mouse problem. You give me the time and I'll\ntell you where it is. If you want to know how fast\nit's moving at a given time, if you want to know the\nvelocity, I just take the derivative of\nthis answer, which is 10 - 10t. So let me pick a couple of trivial questions one can ask."}, {"content": "One can ask the following question. How high does it go? How high will it rise? To what height will it rise? So, we know it's going to go up\nand turn around and come down. We're trying to see how high\nthat is. So, that is a tricky problem to\nbegin with because if you take this formula here,\nit tells you y if you know t,\nbut no, we're not saying that. We don't know the time and we\ndon't know how high it's rising so you can ask,\n\"How am I supposed to deal with this problem?\"\nThen you put something else that you know in your mind,\nwhich is that the highest point is the point when it's neither\ngoing up nor coming down. If it's going up,\nthat's not the highest point. If it's coming down,\nthat's not the highest point. So at the highest point it\ncannot go up and it cannot go down. That's the point where velocity is 0. If you do that, let's call the particular time\nt*, then 10t* - 10 = 0, or t*\nis 1 second. So we know that it'll go up for\none second then it will turn around and come back. Now, we are done because now we can ask how high does it go,\nand you go back to your, and y (1) is 15 + 10 -\n5, which is what? Twenty meters. By the way, you will find that I make quite a lot of mistakes\non the blackboard. You're going to find out,\nyou know, one of these years when you start teaching that\nwhen you get really close to a blackboard, you just cannot\nthink. There's definitely some inverse\ncorrelation between your level of thinking and the proximity to\nthe blackboard. So if you find me making a\nmistake, you've got to stop me. Why do you stop me? For two reasons. First of all,\nI'm very pleased when this happens, because I'm pretty\nconfident that I can do this under duress,\nbut I may not do it right every time. But if my students can catch me making a mistake,\nit means they are following it and they are not hesitating to\ntell me. Secondly, as we go to the more\nadvanced part of the course, we'll take a result from this\npart of the blackboard, stick it into the second part\nand keep manipulating, so if I screwed up in the\nbeginning and you guys keep quiet,\nwe'll have to do the whole thing again. I would ask you when you follow this thing to do it actively."}, {"content": "Try to be one step ahead of me. For example,\nif I'm struck by lightning, can you do anything? Can you guess what I'm going to say next? Do you have any idea where this is going?"}, {"content": "You should have a clue. If I die and you stop,\nthat's not a good sign, okay. You've got to keep going a little further because you\nshould follow the logic. So, for example,\nyou know, I'm going to calculate next when it hits the\nground. You should have some idea of\nhow I'll do it. But this is not a spectator\nsport. If you just watch me,\nyou're going to learn nothing. It's like watching the U.S. Open and thinking you're some kind of a player. You will have to shed the tears and you've got to bang your head\non the wall and go through your own private struggle. I cannot do that for you. I cannot even make it look hard\nbecause I have memorized this problem from childhood,\nso there is no way I can make this look difficult. That's your job."}, {"content": "All right. So, we know this point at one second is 20 meters,\nso let's just ask one other question and we'll stop. One other question may be, \"When does it hit the ground\nand at what speed?\" -- a typical physics question. So when does it hit the ground? Well, I think you must know now\nhow to formulate that question. \"When does it hit the ground\"\nis \"When is y = 0\"? By the way, I didn't tell you this but I think you know that I\npicked my origin to be here and measured y positively to\nbe upwards and I called that 15 meters. You can call that your origin. If you call that your origin,\nyour y_0 will be 0, but ground will be called\n-15. So, in the end,\nthe physics is the same but the numbers describing it can be\ndifferent. We have to interpret the data\ndifferently. But the standard origin for\neverybody is the foot of the building. You can pick your origin here, some crazy spot. It doesn't matter. But some origins are more equal\nthan others because there is some natural landmark there. Here, the foot of the building is what I call the origin. So, in that notation, I want to ask,\nwhen is y = 0? I ask when y = 0,\nthen I say 0 = 15 + 10t - 5t^(2). Or I'm canceling the 5 everywhere and changing the sign\nhere I get t^(2) - 2t - 3 = 0. That's when it hits the ground. So let's find out what the time\nis. So t is then 2 + or -\nor + 12 over 2, which is 2 + or - 4 over\n2, which is -1 or 3. Okay, so you get two answers\nwhen it hits the ground. So it's clear that we should\npick 3. But you can ask,\n\"Why is it giving me a second solution?\"\nAnybody have an idea why? Student:\nBecause there was an entire parabola [inaudible]\nProfessor Ramamurti Shankar: That's correct. So her answer was, if it was a full parabola,\nthen we know it would've been at the ground before I set my\nclock to 0. First of all,\nnegative time should not bother anybody;\nt = 0 is when I set the clock, I measured time forward,\nbut yesterday would be t = -1 day,\nright? So we don't have any trouble\nwith negative times. So the point is,\nthis equation, it does not know about the\nbuilding. Doesn't know the whole song and\ndance that you went to a building and you threw up a rock\nor anything. What does the mathematics know? It knows that this particle happened to have a height of 15,\na time 0, and a velocity of 10, a time 0, and it is falling\nunder gravity with an acceleration of -10. That's all it knows. If that's all it knows,\nthen in that scenario there is no building or anything else;\nit continues a trajectory both forward in time and backward in\ntime, and it says that whatever seconds,\none second before you set your clock to 0, it would've been on\nthe ground. What it means is if you'd\nrelease a rock at that location one second before with a certain\nspeed that we can calculate, it would've ended up here with\nprecisely the position and velocity it had at the beginning\nof our experiment. So sometimes the extra solution\nis very interesting and you should always listen to the\nmathematics when you get extra solutions. In fact, when a very famous physicist, Paul Dirac,\nwas looking for the energy of a particle in relativistic quantum\nmechanics, he found the energy of a\nparticle is connected to its momentum, this p is what\nwe call momentum, and its mass by this relation. It's a particle of mass m and momentum p\nhas this energy so you solve for the energy, you get two answers. Now, your temptation is to keep\nthe first answer because you know energy is not going to be\nnegative. Particle's moving,\nit's got some energy and that's it. But the mathematicians told Dirac, \"You cannot ignore the\nnegative energy solution because it tells you there's a second\nsolution and you cannot throw them out,\"\nand it turns out the second solution, with negative energy,\nwas when the theory is telling you,\nhey, there are particles and there are anti-particles,\nand the negative energy when properly interpreted will\ndescribe anti-particles. So the equations are very smart. The way the physics works is you will find some laws of\nmotion in mathematical form, you put in the initial\nconditions of whatever, you solve the equations,\nand the answer that comes, you have no choice. You have to accept the answer, but there are new answers\nbesides the one you were looking for. You've got to think about what they mean, and that's one of the\nbest things about physics because here's a person who is\nnot looking for anti-particles. He was trying to describe\nelectrons, but the theory said there are two roots in the\nquadratic equation and the second root is mathematically as\ninteresting as the first one. It has to be part of a theory,\nand then trying to adjust it so it can be incorporated,\nyou discover anti-particles. So always amazing to us how we\ngo into the problem, our eye or mind can see one\nclass of solutions, but the math will tell you\nsometimes there are new solutions and you've got to\nrespect it and understand and interpret the unwanted\nsolutions, and this is a simple example\nwhere you can follow what the meaning of the second solution\nis. It means that to the problem\nyou pose, there's more than the answers that you could imagine. Here it meant particle that was released from the ground\nearlier. There it meant something much\nmore interesting, mainly anti-particles\naccompanying particles. They are going to accompany\nparticles surely as every quadratic equation has two\nsolutions. All right, so now in this\nproblem, we can do something slightly different,\nand let's use this expression here,\nand I will do that, then I'll stop for today. If you were asking questions, like, how high does it go,\nbut you don't ask when does it go to the highest point,\nthen you don't have to go through the whole process of\nfinding the time at which it turned around. I don't know where that is, that disappeared on the\nblackboard, then putting the time equal to 1 second into this\nformula. If the question of time is not\nexplicitly brought up, then you should know that you\nhave to use this formula. So how do we get it here? Well, we say at the top of the loop, when it goes up and comes\ndown the velocity is 0. Therefore, you say 0^(2)\n= initial velocity^(2) + 2 times -g,\nthat's my acceleration, times y - y_0. If you solve for that, you find y - y_0 =\nv_0^(2) over 2g,\nand if you put in the v_0 I gave you,\nwhich was what, 10? That's 100 over 20, which is 5 meters. So y = y_0 + 5 meters, and that was the height\nto which it rises. I think we got it somewhere\nelse. We found the maximum height to\nbe 20 meters. Another thing you can do is you\ncan find the speed here. If you want to find the speed\nthere, you put the equation v^(2) = v_0^(2)\n+ 2 times -g (y - y_0). What is y - y_0? The final y is 0, the initial y is\n15. You solve for that equation and you will find the\nfinal velocity. So, if time is not involved,\nyou can do it that way. I want to derive the last\nresult in another way, then I will stop,\nand that's pretty interesting because it tells you the use and\nabuse of calculus. So I'm going to find for you\nthis result using calculus in a different way. So, from the calculus we know dv/dt = a. Now, multiply both sides by v. Now you have to know from\nelementary calculus that v times dv/dt is\nreally d by dt of v^(2) over 2. Now, I hope you guys know that much calculus,\nthat when you take a derivative of a function of a function,\nnamely v^(2) over 2 is a function of v,\nand v itself is a function of t,\nthen the rule for taking the derivative is first take the\nv derivative of this object,\nthen take the d by dt of t,\nwhich is this one. On the right-hand side,\nI'm going to write as a dx/dt. This much is standard. I'm going to do something which\nsomehow we are told never, ever to do, which is to just\ncancel the dts. You all know that when you do\ndy/dx, you're not supposed to cancel\nthat d. That's actually correct. You don't want to cancel the d in the derivative. But this happens to be completely legitimate,\nso I'm going to assume it's true and I'll maybe take a\nsecond and explain why it's legitimate. What this really means is in a given time, \u0394t,\nthe change in this quantity is a times the change in\nthis quantity. Therefore, you can multiply\nboth sides by the \u0394t, but the only thing you should\nunderstand is \u0394t, as long as it's small and\nfinite, will lead to some small infinite errors in the formula,\nbecause the formula is really the limit in which \u0394x\nand \u0394t both go to 0. So what you have to do is\nmultiply both sides by \u0394t, but remember it's\ngot to be in the end made to be vanishingly small. As long as we understand that, we can do this cancellation and\nthis says on the left-hand side the change in the quantity\nv^(2) over 2 is a times the change in the quantity\nx. So add up all the changes or what you mean by\nintegral. Same thing. Add up all the changes. The change in v^(2) over\n2 will be the final v^(2) over 2 - the initial\nv^(2) over 2 and the other side will be a\ntimes change in x; x - x^(0) and that's the\nformula I wrote for you: v^(2) is\nv_0^(2) + 2a (x - x^(0)). So,\nthe point is whenever you have derivatives with something over\ndt, do not hesitate to cancel the dts and think\nof them as \u0394v^(2) over 2 is equal to a times\n\u0394 of x. This will be actually true as long as both\nquantities are vanishingly small. They will become more and more true as \u0394x and\n\u0394v^(2) become vanishingly small,\nin the limit in which they are approaching 0,\nthe two will be, in fact, equal. If \u0394x is a finite amount, like 1 second,\nthis will not be true because in the starting equation,\n\u0394x and \u0394t and \u0394v^(2) were all assumed\nto be infinitesimal. So don't hesitate to do\nmanipulations of this type, and I will do them quite often. So you've got to understand when it's okay and when it's not\nokay. What this means is,\nin a time \u0394t, this quantity changes by some\namount, and in the same time,\n\u0394t, that quantity changes by some amount,\nthen keeping the \u0394t equal to some number we may\nequate the changes of the two quantities,\nprovided it is understood that \u0394v^(2) over 2 is a\nchange in v^(2) over 2 in the same time in which the\nparticle moved a distance, \u0394x. Adding the differences, we eliminate time and we get\nthis final result."}, {"content": "All right. So if you go to your website today, you will find I've\nassigned some problems and you should try to do them. They apply to this chapter. Then next week we'll do more\ncomplicated problems that involve motion in higher\ndimensions, how to go to two dimensions or three dimensions. "}], "Giving you guys a chance....": [{"content": "you guys know what this is It's a nose Swizzle check this [Applause] out sorry it was in the background it distracted me book review I can't clap cuz it will sound horrible at last book review will return last year I uploaded a video I bet you didn't watch it so I'm giving you a second chance I want to help you guys out it's was talking about habits how to take bad habits and replace them with good ones I know this seems like some sort of U productivity idity 2025 Sigma bigma I was trying to be go beyond that and use ideas from philosophy to incorporate these ideas and for me it really worked I picked up drawing I've been sketching every day since but that's just one of many things that I I think at least I've learned from reading reading is something that I enjoyed as a kid something I had also abandoned kind of like drawing actually something I enjoyed as a kid but then I picked it up again and realized just how much I loved it and uh it was the best thing I've ever done for myself by far reading completely changed my whole perspective in life I think it's just something incredibly valuable that I think everyone should experience and that's why I've announced book review 2025 cuz I want you guys to have the same Journey or if not Inspire to go on your own all these books that we're going to read I've already read but I will re read them with you I don't want to blame having a kid but I have not read nearly as much as I used to this past couple years and I want to get back into it as well so I can't make any excuses therefore you can't make any excuses now I haven't really figured out how I'm going to do this but I realize the best way to make anyone do anything is through shame therefore we will have have a shame list for anyone that fails book review 2025 and also everyone that do complete book review 2025 will get a sense of ah beyond the infinite wisdom also a sense of ah now let's get into the books the book list in January we're going to start off we're going to work our way this way we're going to start off super simple baby level T teing this is ancient Chinese wisdom it's only 100 pages but you could very easily finish it in a in one day but we're not supposed to do that we're going to take our time with it hey you can do whatever you want who cares it's hard to hold a book and a microphone the reason I H picked this book is because it's a really good soft start if for Rusty readers out there I think it's very simple it breaks down ancient wisdom in a nice simple way I kept seeing simple as you see I I've labored things in this because I think there are some passages that are just brilliant and that I keep coming back to that's sort of a theme throughout all these books that I've picked is it's books that really resonated with me I've learned stuff from them that I've Incorporated in my life and that I like to revisit and rethink about and remind myself and I think u t teing is just a great start of that and if you want to do a head start maybe let's say you finished this and you're like okay I want to move on obviously you can do that sorry to interrupt I actually wanted to review a book really quickly it's one that speaks highly to my heart and my Soul it's the book of the best vpn's on the planet starting n VPN only have you guys heard about this have you heard about nordvpn this book draws heavily for my own personal life the other day for example I was downloading legal Minecraft mods and oh I felt like I was being watched I don't know why so I launched nordvpn and my internet activity go po FBI agent go where'd he go and I could continue downloading my legal Minecraft mods safe and sound knowing that nor VPN has a strict no log's policy my internet business is my internet business as it should be another example from this great book that correlates with my personal life is when I was watching legal Minecraft anime online and all of a sudden not alloud in your region be nearly fainted was crying luckily I can always save the day with nordvpn Bing bam boom connect to anywhere in the world get rid of any region blocks the internet is open and free as it should be thank you nor VPN not just for being an amazing service but for being an amazing sponsor to this channel for so [Music] long this is what be does now he there's nothing to do with ad he thinks hello and by is blowing a kiss I just realized I did the same if you use my link in the description you get four bonus month and a huge discount the best offer you can get on nor VPN and if you're not convinced try it out for 30 days money back guaranteed I promise you will like it give it a shot I've been using it for how many years now like I know they're paying me but I'm actually paying to use it myself I'm happy to sponsor products that I actually use myself so thank you nordvpn check out nordvpn.com PewDiePie the link is the description let's continue with the book reviews the second book is in in the Buddhist words I've talked about this book so much because it's an incredible book we S I hate using the word Awakening for lack of better one that's all I'm going to use because it really was an Awakening experience for me to read this book I never examined myself in in such a way and it's funny the book seems almost aware of this itself where most of us throughout our lives go through our days and it maybe in our entire existence for many existences as Buddhism believes where we're drawn to Sensational Pleasures we're drawn to all these distractions without fully examining our lives and and our purpose and what we're doing and when you read it you get that understanding and you look at yourself obviously first you look at yourself but then you look at the whole world and you realize you want everyone to sort of stop and go no wait let's what are we doing here let's rethink this uh what is our purpose come on to me there's just something so tragic about living your life without examining it it taught me so much about Sensational pleasure especially I'm Mr dopamine okay I'm sure a lot of people can relate to this but there's almost this romanticized idea of of a sad man at a bar hunched over with a drink like there's something cool about it smoking a cigar these things are not cool that's sad all of that is sad and not a sad in that wow so sad kind of way just bad don't romanticize these things you know what I mean being drawn these Sensational Pleasures you can Free Yourself completely from them I'm speaking way more about this than I thought I would but here we are you just binding yourself to different things that you don't need and by uprooting these uh issues they will you'll completely be free from them I used to think about drinking alcohol every single day now it has zero control over me there's so much in Buddhism that ties into what we're going to go into later as well but moving on January February March March you can pick whatever you want I I think every third month I will let you guys decide I think the point of reading is not just to blindly follow what someone laid in front of you it's about finding your own Curiosities okay you read this huh I'm interested in maybe expanding on this or do reading something different maybe I hated it and this is not for me that's part of the your own Discovery I will announce which books I will read but I see them sort of outside of the list they might be maybe too advanced for some of you sounds so demeaning like you you dummies I'm going to read maybe I'll do uh uh meditations of first Philosophy by Renee Descartes I never read Renee there's a couple philosophers that I just never touched and I want to I I just feel like I should read them so that's what I pick for March moving on with the book list January February March April I don't know the months unless I count them in order another book I've talked about so much we're going to read epic Titus discourses and selected writings if you for some reason haven't read this with the amount of yapping I've done about this book you got to do it now I think if I had to pick one book out of all of these one book to rule the moral I would pick the inidian literally means handbook it is the handbook of stoicism it is the simplest way to ever explain stoicism people mostly associate stoicism with Marcus aurelus or maybe senica and aurelus obviously is an incredible story I think his life is more interesting and obviously he talks about stoicism which is amazing and he lived sism which is amazing but uh just take the inidian it puts it so beautifully and so simply and I think everyone can benefit from these ideas they are similar to Buddhism in the sense of it's in a way of avoiding suffering I've been very fortunate and and privileged I there hasn't been much times where I even feel like I need stoicism but reading stoicism it almost feels like I I put on this armor like I'm ready for anything whatever life is going to give me I'll be ready for it and that's how stoicism changes your perspective instead of fearing Misfortune you you sort of look at it as this gives me a chance to show show my virtue and and what I've learned I remember there was a book I read about American soldier that crashed his plane over Vietnam during the war and he had started sism and as he was shut down and falling in his parachute he he thought to himself this is my chance to practice what I've learned from stoicism because he knew how they would torture soldiers and uh they did okay I'm going to have to speed up cuz be is going to na soon next up we have hey play to The Republic oh oh if you think I've yed a lot about epic tittis I've actually realized I Y way more about play The Republic I I love I made a 40-minute video talking about this book I love it so much I think it is also really good introduction to philosophy because it covers so so many areas the whole premise of the book is uh Socrates is discussing with Glon they're trying to find the definition of justice since it's something that they're trying to discover together it makes you feel part of this philosophical discussion like you're transported into this uh the same room as as the greatest mind of all time and you get to experience and join this discussion what other medium could do that but literature it's just so incredible I feel so fortunate to even be reading this book it examines the human soul but then goes into a macro level and they try and examine okay so to answer this question we need to examine what is the ideal way of running a society yeah it goes into all these amazing and interesting ideas some are a little bit weird actually now I think about it I feel like I shouldn't say I enjoy this book too much big disclaimer I do not agree with every single idea that this author has a necessary 2019 disclosure everyone and then in the end it ties it all together in this beautiful like depiction of the afterlife and and rebirth kind of like Buddhism as well and what sort of Life they want to live and it answers that question in the end and I just think about it all the time I absolutely love it it's an an amazing book I'm just so excited for you for you guys defitely H anyway third month free I'm going to read I'm going to read content critique of pure reason I feel like I have to recount I tried a while ago I think I got a third in and uh I stopped for whatever reason it is extremely dense literature like uh I do not necessarily recommend casual readers to pick this one up I uh read a bit about Kant and I find him to be more interesting than his work he was just Mega autistic he's basically Sheldon Cooper which makes for a lot of interesting and sort of silly things about his life he had the famous philosopher walk every day at the exact same time but he refused to speak to anyone so if anyone tried to he would Resort he didn't want his lips to open cuz that would constitute us talking so he would resort to making noises with his mouth like mhm it's just I don't know it's funny to me I obviously know some ideas around him and his moral principles are quite famous I'm curious to read if his reasoning can sort of bring me over or not I don't know interjecting I done a little bit more research about the books that I picked cuz obviously I haven't read them and I think it might be a little difficult to do K in just a month so I was thinking okay maybe I'll do two much and or maybe I'll I was trying to think the best way to do it but then I thought you know what I'm just going to try my best if I fail that's okay I can I can pick it up at some other time or or keep going so I'm just saying this if you're deciding to read the same book which I don't encourage to be honest but if you are to be honest I I want you guys to pick your own interest uh but yeah just wanted to explain my reasoning right so next up guess what another book I've talked about a ton Aristotle nikan ethics that sounds so Advanced but it's really simple do not be turned turned off from this it is talking about happiness how to be happy what what does it mean to be a good person uh the Greek had this word for happiness which is a beautiful word called udonia and it sort of translates vaguely to flourishing as an individual and this is something I think about a lot and I can sort of make sense out of it I used this book a lot my previous video that I talked about last year about the ideas of habit cuz the Greeks understood habit and how it can lead to good virtues while bad habit obviously leads to bad virtues and but it's not just about becoming this imulation I almost Ed the tough word there but I I gave up amalgamation sort of this new Millennial idea of how you should be the more you achieve the more you show people that you're doing that is not the answer if anything that just leads to another attachment but Aristotle talk about the golden mean and this sort of balance instead of your life I'm looking forward to refresh my ideas on it I think it's just incredibly incredibly useful and valuable for people to read next is more for me you don't have to read this I I'll say you have to read a classic uh I think so many people don't want to read classic literature but that is just a huge mistake I can never say it right donkey shot the cter mon the crystal Moby Dick actually I don't I wasn't huge M day I read cash 22 recently too which is another classic I just think that was hilarious I love it actually but a classic literature maybe seems a bit dull but they are classic for a reason every time I read one it's just an amazing experience and my favorite I I don't know if it even counts as a classic but my favorite is The Iliad I love the ilad so much I've had such a weird experience with it because uh when I was a kid I think around 11 or 12 I was so into the Troy War history I don't know why I think I read it about it somewhere like a Comic version and I wanted to know everything there was about it how tall were the walls and I wanted to remember all the years and then you find out about things that you know may or may not have happened you know with the Achilles fighting Hector and all these things I just thought it was so cool I couldn't believe not everyone was talking about it and I thought it was the coolest thing ever it was basically my Marvel of the time you know I was like the gods are helping all in all these battles that's the coolest thing ever and then finally in my 30s I read the actual Iliad and I thought the gods are helping in the war that's the coolest thing ever I I I absolutely love it most people know the Iliad or associate The Iliad with the troyan horse everyone knows about it but surprisingly it isn't in The Iliad and the Iliad ends completely differently and to me the ending of Iliad was so beautiful it really struck me deeply I remember when I read it and I think most Classics do they really just hit you differently I don't know how to explain it yeah I just thought it was so incredible and I I love reading it and I want to reread it so uh that's why I picked it but I just encouraged maybe picking a a classic that you're interested in it will be worth it so next month it's free you can read whatever you want I will read Arthur schopenhauer I think actually you can read it as well it sort of makes sense to read before nche I will read the world as will and representation I think I've already read it but I think I definitely need a refresher chaen was the first as far as I understand the Western uh Buddhist he wanted to escape suffering and N which will read later really looked up to shophow but also critiqued him heavily and I want to sort of better understand schopenhauer and why cuz I I don't remember much I don't even have the copy here I left it in UK so I look forward to read open hour and then we have October I know like I'm the one who made the least so obviously I'm going to like all the books but I'm like this is so sick I love this all right so next up we're going to go into n thus so spoke sarra I talked about this book in the video I made last year a little bit there are these ideas of Will To Power the Uber MCH uh you you heard God is dead this is all in this book sarra n is such a interesting character he is the most misunderstood philosopher by far and even amongst people that have a better idea of n everyone seems to disagree as well but I I understand I understand n okay I got it I don't all these books that we read by the way so far not all of them but most of the philosophers n has up he hat he hated everyone he had this hit hit list of philosophers and he would attack them all the time it's kind of funny but I also saw it as a you know you criticize things that you like in a sense as much as I love sism and we will understand sism once we got to nche he did criticize stoicism and I think his criticism is actually fair you know nche is famously misunderstood as the poster boy for nihilism when in reality as you probably know now is he fought for the opposite he thought about this life his life affirming philosophy to me I think is so important I don't remember if s sistra had that much of that idea in it actually I think it's more in the gay science I know it's a hilarious title of a book I still think sister if I had to pick one each it's it's a really good one to start on well I don't know it's a really good one to pick apparently I don't know if it's true I think it is he was high on opioids when he wrote it so it is vastly different from other books I read from him but that also makes it very fun I think it's really fun to read and I can't wait for you guys to experience it as well like all of these books next up we have we're going to finish with sidara by Heron has maybe it doesn't make sense to end on this maybe it does make sense to end on this I think I'll know once I read reread it it is the the story of Buddha there are different depictions of Buddha amongst Buddhism but the more modern version as far as I understand is that he was a person that lived went through difficulties and suffering just as we did but then overcame it and became enlightened and became the Buddha and that is the story of suhara so I think it's a beautiful beautiful book that I would highly recommend to anyone it really surprised me caught me out of nowhere I had this horrible version of it from Amazon doesn't even have a proper spine uh if anyone have a better version if you want to give it to me I would love it and then finally you're free December I'm going to read phenomenology of Spirit by hego cuz I never read hego and I feel like I should he just have such a boring face I just assume he is equally boring I think any of these FL K looks boring yeah I'll say it if he has a dumb face probably his ideas are dumb too it's like I learned nothing from all this that is the 2025 book review imagine if you all you have to do is spend let's say the average of these book are 300 Pages they are probably a little bit more but probably more or less if you read 20 Pages a day for 30 days 2 minutes per page probably less maybe you know instead of going on your phone the first thing in the morning or um before bed replace that with the reading and it will have no change in your productivity or what you're doing but it will just vastly improve your life and I guarantee it rep a bad habit with a good one let's do it I'm so excited for you guys I'm so excited for me this is going to be great that's it hug come here"}], "3. Budget Constraints and Constrained Choice": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER:\nToday, we're going to continue our discussion\nof consumer choice. And we're going to\ntalk now about what happens when we take that\nunconstrained choice we talked about on Monday and\nimpose budget constraints. We'll talk about what\nbudget constraints are. We'll then come to talking\nabout how consumers make constrained choices. And then we'll end with\nan example of food stamps. So let's start by talking\nabout budget constraints. And we'll start by talking\nabout their construction, the construction of\nbudget constraints. So, basically, last\ntime, we talked about the fundamental\naxiom of consumer choice that more is better. So what stops people from\njust bingeing on everything? It's their budget constraint. It's their limited resources. Now, for most of\nthis course, we're going to make a simplifying\nassumption that your budget-- that is what you spend-- equals your income. That is what you earn, OK? That is there won't be any\nsavings or borrowing, OK? Now that is a\nsimplifying assumption. And, indeed, we'll\nspend a couple lectures at the end of the semester\ntalking about what happens when people can save or borrow. That said, this is not\na terrible description of most Americans. The median American household\nhas $400 in the bank. So this is not kind of\na terrible description of the way most people live\ntheir lives in America, which is what they\nearn each week is what they spend each week. So that's what we'll do. It also might not be sort\nof a terrible description of your life. I presume, in college, you're\nnot doing a lot of savings. You maybe do a little\nborrowing, but not a lot of savings or borrowing. So what we're going\nto do is we're going to assume that's\ntrue for you as well. We're going to assume your\nparents have given you some amount of money to spend. We'll call it Y. Your income\nY is the amount of money your parents have given\nyou to spend for say the semester or the month. And, once again, let's say\nall you spend your money on is pizza and cookies, OK? That's all you want to\nspend your money on. We write the budget\nconstraint as saying that your resources,\nyour income Y, can be spent on either\npizza or cookies. And the constraint is\nthat you could spend it-- that budget has to be divided\nbetween pizza, where there's the price per slice of pizza\ntimes the number of slice of pizza, or cookies. We have the price per cookie\ntimes the number of cookies. So p sub p is the price\nper slice of pizza. p sub c is the price per cookie. P is the number of pizzas, and\nC is the number of cookies. That's your budget constraint. You can essentially\ndevote your income to some combination\nof pizza and cookies, but you have to consider\nhow much they actually cost in doing that. I find this easier\nto see graphically."}, {"content": "So let's turn to figure 3-1. Figure 3-1 shows a\nbudget constraint. So how does the budget\nconstraint look? Well, the x-axis is\nyour income divided by the price of cookies. That is, if you decide to devote\nall your income to cookies, then how many\ncookies can you have? Y over pc. If your income is $100,\nand cookies are $10-- that means you're going\nto Insomnia Cookies-- then you can only have\n10 cookies, et cetera. Likewise, the\ny-intercept is the income divided by the price of pizza. That's how many\npizzas you can have. The budget constraint\nrepresents-- the budget constraint, the\nslope of the budget constraint, is the price ratio, the\nnegative of the price ratio because it's a downward-sloping\nline, pc over pp. That is every extra\ncookie that you buy, holding your\nincome constant, lowers the amount of pizza\nyou can have by p sub p, OK? So let's consider an example. Suppose that Y is $96,\nthat the price of pizza-- it's an expensive\npizza place-- is $12, and the price of a\ncookie is $6, OK? $12 for pizza, this is like\ndowntown San Francisco or New York. $96 income, $12 for a slice\nof pizza, $6 for a cookie, OK? I'm sorry. Y is-- I wanted to\nmake Y 72, my bad. So Y is 72. Your income is $72, OK? And you can spend it\non pizza and cookies, and those are the prices. Now what that means is,\nif you wanted just pizza, you could get six pizzas. If you wanted just cookies,\nyou can get 12 cookies. And, generally,\nthe rate at which you can trade off pizza for\ncookies is minus 1/2, OK? That is every additional\ncookie would require giving up half a slice of pizza, OK? Every additional cookie requires\ngiving half a slice of pizza. That's why the slope\nwould be negative 1/2, OK? So, basically, we're going to\ncall the slope of the budget constraint-- the slope, we are going\nto call the Marginal Rate of Transformation, the MRT. Last time, we did the MRS, the\nMarginal Rate of Substitution. Now we're going to have\nMRT, the marginal rate of transformation, which is\nequal to minus pc over pp. Or the slope of the\nbudget constraint, OK? That is the marginal\nrate of transformation. Now this class is not alchemy. We are not literally\ntransforming pizza into cookies. That would be kind of cool,\nbut we're not doing that. That's somewhere\nelse at MIT, OK? But it's effectively\ndoing the same thing. What we're doing is, given that\nwe have a fixed amount of money and given that we're\ngoing to spend it all, the more you spend on pizza,\nthe less you spend on cookies. So you're effectively\ntransforming pizza into cookies and vice\nversa because you're going to spend all your money. You've got to spend\nit on something. So, the more you spend on one,\nthe less you get of another. So, through the\nbudget constraint, we are effectively transforming\none good to the other. By having more of one, we're\ngetting less of the other. So that's the sense\nin which we call it the marginal rate\nof transportation-- of transformation. So, basically, this comes\nback to the key concept we talked about in the very\nfirst lecture, opportunity cost. The opportunity cost of a\nslice of pizza is two cookies. Remember, opportunity\ncost is the value of the next best\nalternative, OK? The opportunity cost is\nthe next best alternative. Well, here you only have\ntwo alternatives, pizza and cookies. So the opportunity cost of a\nslice of pizza is two cookies. And that's the sense\nin which you're transforming pizza into cookies\nor cookies into pizza, OK? Now this seems kind of\nabstract, but let's actually think of an organization\nwhich has taken this principle to heart to develop the\nbest method of weight loss in America, which is Weight\nWatchers, OK, Weight Watchers. Now it turns out that\ndieting is super hard and basically doesn't work, OK? There's a large\nliterature, which says that people go\non diets all the time. Then they stop them, and\nthey gain the weight back. OK, dieting is incredibly hard\nand basically doesn't work, OK? But a much more\nsuccessful approach has been established\nby Weight Watchers. It's not the only\napproach, but it's been proven much\nmore successful, OK? And, essentially, what\ndoes Weight Watchers do? They set up a budget constraint\nand ask you to follow it. So, for example,\nthey essentially assign point values to every\ngood you might consume. You go on the website,\nand everything in the world you might want\nto eat has a point value. They then ask, well, what\nweight are you today? What's your age and gender? That stuff matters\nfor weight loss. And what weight do\nyou want achieve? And they say, if you\nwant to achieve a weight loss of x over y\ndays, then you've got to limit\nyourself to z points. So, essentially, your\ngoal is to lose weight. So we're going to give\nyou the budget constraint. We're not going to\ntell you what to eat. That's why it's\nbetter than dieting because, once again,\nAdam Smith was right. People like to have choices."}, {"content": "They like to let\nchoice drive things. But we are going to\ntell you a total budget. So, for example, vegetables\nare like zero points. Snickers bars are like\nsix points, et cetera. They have various\npoint systems, OK? So, for example, suppose your\nbudget is 30 points, which would be pretty typical, OK? Suppose you go to\nMcDonald's for lunch, and you get a number one. The number one at\nMcDonald's is a Big Mac, which has 14 points, fries,\nwhich have 10 points, and a Coke, which\nhas six points. That's 30 points, and\nit's only lunch, OK? You've blown your whole\nbudget for the day on lunch. Now you could just get\ndepressed and say screw it. I'll just be fat. But, clearly, looking\naround the room, you guys have not\nmade that choice. Or you could look at\nthe budget constraint and say, well, what\nelse can I get. Well, it turns out you can\nget a 10-piece nugget, which is 12 points, apple\nslices, which is one point, and a Diet Coke,\nwhich is zero points, for a total of only 13 points. Now you have 13 points and\nplenty of room for dinner. Now, to be honest,\nanyone who tells you that second lunch is as good as\nthat first lunch is a liar, OK? I'd much rather a Big Mac and\nfries and a Coke than nuggets and apple slice and Diet Coke. Give me a break."}, {"content": "But I'd also much\nrather have dinner, OK? So, basically, this lets\nyou make the trade-off by imposing a budget\nconstraint, by setting relative prices across goods. The points are like utils. They're not meaningful."}, {"content": "They're only\nmeaningful relatively. It lets you set relative\nprices across goods and then it lets\nyou, essentially, optimize across those various-- across those various goods. So budget constraints,\nessentially, by setting up this marginal\nrate of transformation, can help with a lot of\nkind of decisions in life. OK, questions about that? OK, now what happens if we\nshock the budget constraint? So we talked about\nconstructing them. What about shocking\nthe budget constraint? We're going to do a lot\nin this class of what we call comparative statics,\nwhich is, essentially, making changes in\none thing or another and seeing what it\ndoes to the system. So let's talk about shocking\nthe budget constraint. Let's start first with\na change in prices. Suppose the price of pizza\ngoes from $12 up to $18. This is a really good\nslice of pizza, OK? Well, what happens to\nthe budget constraint? Let's look at figure 3-2. Figure 3-2 shows what happens. You have your original\nbudget constraint BC1. The equation of that line is\n12P plus 6C equals 72, OK? The price of pizza and the\nnumber of slices of pizza plus the price of cookies\ntimes the number of cookies equals 72. Now the price of\npizza has gone up. What that's done is that has\npivoted inward your budget constraint to BC2. It has flattened the\nbudget constraint because the slope,\nremember, is the ratio of the price of cookies to\nthe price of pizza, right? That's a ratio."}, {"content": "Well, that ratio\nhas just fallen. It used to be a 1/2. Now it's a 1/3. Negative 1/2-- well,\nit used to be a half. Now it's a 1/3. So the slope has fallen from\nnegative 1/2 to negative 1/3. So what's happened is you can\nstill have as many cookies as you had before. The y-intercept has\nnot changed, but you can have fewer slices of pizza. That's why it's a pivot\nbecause one price has not changed, only the other price. So it's a pivot inward. The other thing\nhere, you'll notice we have all these funny\ndots and stuff, OK? That represents\nwhat has happened to what we call your opportunity\nset, your opportunity set, which is an\nimportant concept, OK? Your opportunity set is the\nset of choices available to you given your income\nand market prices, the set of choices available\nto you given your income and market prices. So your opportunity\nset initially was the black dots\nplus the red dots. Now your opportunity\nset has shrunk. Your opportunity set is\nnow just the black dots. Given your income,\nyou can now get less stuff, same amount of\ncookies, but less pizza. And you are worse off. Your opportunity set has shrunk. Your opportunity set-- even\nthough your parents are still sending you the same check, you\nare worse off because you can now buy less pizza with it, OK? So that's what happens\nto the opportunity set when a price changes. And, likewise, you\nshould show to yourself the same thing will happen when\nthe price of cookies change. In that case, you'll\nget an increase in the steepness of the\nbudget constraint, OK? But your opportunity\nset will still-- your opportunity set\nwill still shrink, OK? Now what about-- yeah? AUDIENCE: Don't we not\ncare about all the dots below the line, though,\nbecause we're assuming we're spending all the money? JONATHAN GRUBER: Well,\nthat's a good point, and we're going to\ncome back to that. We haven't-- we assume they're\nspending all their money, but it's just a way\nof representing. You could think of the line\nbeing lower as the same thing. We care about-- we just\ncare about the area because it represents the\nset, but you're right. You could just focus\non the line and say the line is everywhere lower. So they're worse off. That's another\nway to look at it. But we like to think\nabout as a set. It comes in handy later\nfor various reasons, OK? But that's a good question."}, {"content": "Now let's ask about\na second thing. What if your income goes up? What if prices are\nback to 12 and 6, but your parents decide\nto send you more money? Suppose your parents--\nor send you less money. It turns out you haven't\nbeen paying enough attention in 14.01. You're parents are mad. They're monitoring you. That's why we have\nthe camera here. This goes directly to\nall your parents, OK?"}, {"content": "I'm sort of joking. And so let's say parents cut\nyour allowance to $60, OK? Well, what does that do? That's in figure 3-3. OK, in figure 3-3, the\nold budget constraint was that you get\npizzas and cookies at a price of $6 and $12,\nand you could get them until you spend $72. Now you can only get\nthem until you spend $60. Now what we see is not a pivot\nin the budget constraint, but an inward shift in\nthe budget constraint, because the relative\nprice of pizza and cookies has not changed. Therefore, the slope\nhasn't changed. OK, the slope is\ndictated solely-- you don't do anything\nto control the slope. The market controls\nthe slope, OK? But you and your family\ncontrol the level, and the level has shrunk. So you're pivoting inwards, OK? And, once again,\nnow, instead of being able to buy say 12\ncookies and six pizzas, now you can only buy say\n10 cookies and five pizzas. That's the most you can get, OK? So, once again, your opportunity\nset has been restricted, but in a different kind of way\nthrough this pivot inward, OK? So that's how we\nsort of manipulate these budget constraints. And we're going to come\nback to that next lecture. That'll be important."}, {"content": "Yeah? AUDIENCE: So, in looking\nat the differences, can like an increase\nin the price of pizza or like a decrease\nin your budget-- is it more showing that\nlike the change in slopes doesn't really\naffect you if you're like say buying more\ncookies than pizza? But like, in terms of if\nyour budget as a whole decreases, then it\naffects you overall. JONATHAN GRUBER: That's\na great question, and we're going to actually\nanswer that question next lecture very explicitly. So hold on to that\nquestion, and we'll talk about we're going\nto compare explicitly why income changes\ndiffer from price changes and what are the\nunderlying mechanisms. Yeah? AUDIENCE: How do you\ndetermine your marginal rate of transformation? How do determine your--\nlike say it wasn't just pizza and cookies. Like say it was more products. How would you\ndetermine that value? JONATHAN GRUBER:\nGreat, great question."}, {"content": "So, as I said, we\nalways are going to start with simplifying\nassumptions to make life easy. There's no reason\nthat this couldn't be written in three dimensions. And you'd have\nrelative marginal rates of transformation, rates at\nwhich you're willing to trade off various things. So you could just extend\nthe math in all dimensions. It wouldn't add any\nrichness, and it'd just make your head spin. But the basic-- so\nall the basic ideas can come across with\ntwo goods, but it'd be the same mechanics\nwith more goods, OK? You essentially, when we get to\nthe constrained optimization, you'll essentially have\nmore first-order conditions in your constrained\noptimization. That's the way to\nthink about it."}, {"content": "OK, so let's-- actually,\nthat's a great segue. Let's turn to the\nsecond part, which is how we use budget\nconstraints and the utility function we learned about\nlast time to actually describe how consumers make choices. So we're going to take utility. Remember, I said\nlast time consumers are going to maximize their\nutility subject to a budget constraint. Well, now we've taught\nyou about utility. We've taught you about\nbudget constraints. Let's put them together, OK? How to consume-- how do\nconsumers put them together? Well, graphically, the\nrepresentation of preferences was our indifference curves. That represented\npeople's indifference with further out\nindifference curves made people happy, right? That was last time. So, essentially, what we're\ngoing to ask graphically is what is the\nhighest indifference curve you can achieve\ngiven your budget, right? We know you want to be that\nhighest indifference curve possible by more is better. So we're simply\ngoing to ask what is the highest\nindifference curve you can reach given your budget, OK? So let's consider the same\nutility from last time. Utility is square\nroot of P times C, OK? And let's consider the same\nbudget we wrote down up here-- $72 income, $12 price of\npizza, $6 price of cookies. And now let's ask where\ncan you go with that."}, {"content": "So let's turn to figure\n3-4 and do it graphically."}, {"content": "We'll do it mathematically\nin a minute, OK? So, in figure 3-4, you\nhave our budget constraint, which runs from 6\npizzas to 12 cookies. That's the original\nbudget constraint. And you have a series\nof indifference curves. And these indifference\ncurves, I1, I2, I3, I4, they all come directly\nfrom this utility function. So, simply, I've solved\nthis utility function. I'll talk about the\nmath in a little bit, and you'll do more math\nin section on Friday, OK? But, essentially,\nyou can solve-- we'll show you--\nyou'll drive on Friday how you take this\nutility function and literally can draw the\nindifference curves from it, OK? But, for now, take my word\nthat these indifference curves represent this utility function. And what we see is that\npoint D is the furthest out indifference curve you\ncan achieve while still meeting your budget, while still\nmeeting your budget constraint. And, therefore, we say that\nthe optimum, graphically, is the tangency between\nyour indifference curve and your budget constraint is\nthe optimal constrained bundle. You see how we brought-- last time, we talked about\nfurther out indifference curves make you happier. Today, we talked about\nthe fact that you're limited by your budget. So we have the furthest\nindifference curve you can get to is going\nto be, definitionally, at the tangent of the\nindifference curve and the budget constraint. And, once again,\nthat gives you-- we realize we don't want\nto measure utils, but, just for mathematical, for\nmathematical purpose, that gives utility at the tangency\nof square root of 18, OK? At that point, you are choosing\nsix cookies and three pizzas. That is the choice\nyou are making. That is the best off you\ncan get given your budget. And, to see this, let's\ntalk about some other points and why they're not better, OK?"}, {"content": "Let's talk about point A. Why isn't point A better? Why isn't it better\nto have two-- maybe you just-- maybe you\nlike cookies a lot and don't like--\nor like pizza a lot and don't like\ncookies that much. How can we say that point\nD is better than point A? Yeah? AUDIENCE: Because point D is\non a higher indifference curve. JONATHAN GRUBER: It's on a\nhigher indifference curve. So point D dominates\npoint A because it's a higher indifference curve. Well, fine. Same person, by that logic,\nwhy not choose point E? AUDIENCE: It's above the budget."}, {"content": "JONATHAN GRUBER: Yeah,\nyou can't afford it. So the bottom line is\nyou can see graphically why the tangency is\nthe best you're going-- is the best you're going to do. OK, likewise, point C\nyou wouldn't choose. Point C has the same slope. It has the same\nslope as point D. In other words, the slope\nis minus 1/2 at point C. You've drew a line tangent\nto point C. The slope will be minus 1/2, just\nlike it is at point D, but you wouldn't be\nspending all your money. So you wouldn't choose\nthat point either. Yeah? AUDIENCE: What if you have\njust three indifference curves so there is none\nthat hit the tangent? Do you just go for one that's\nlike the most tangent I guess? JONATHAN GRUBER: We're going\nto come to-- we're going to-- well, first of all,\nwe're not going to have discrete indifference. We could have lines, and\nthe lines could end up-- you could end up lying along. You could end up lying along a\nbudget constraint for example. Or you could have-- you could even have\nutility functions, which just touch a\nbudget constraint at one extreme or another. And we'll talk\nabout those cases. Yeah? AUDIENCE: So [INAUDIBLE]\nutility function go through lines and the\nbudget constraint, right? JONATHAN GRUBER: Yeah. AUDIENCE: Isn't this just\nLagrange [INAUDIBLE]?? JONATHAN GRUBER: Well,\nlet's come to the math then. OK, let's come to the\nmathematical derivation. So that's the graphic. So let's come to the math, OK?"}, {"content": "Now, always a bit\nof a tightrope act when I'm doing math up here on\nthe board, so bear with me, OK? But the key thing is the math\nof constraint optimization is all about the\nmarginal decision. Remember, it's hard to say\nhow many cookies you want. It's easier to say should\nI have the next cookie, OK? It's about constraint\noptimization. And what we want to ask is we\nessentially want to compare how do you feel about trading\noff pizzas versus cookies versus what will the market let\nyou do in sort of trading off pizzas versus cookies. That is the optimum\nis going to occur when we set your marginal\nrate of substitution, which, remember, we defined\nas minus MUc over MUp, equal-- I'm going to get rid of this-- equal to your marginal\nrate of transformation, which we defined as\nminus pc over pp. And this is the fundamental\nequation of consumer choice. If you understand\nthis equation, you can solve virtually\nevery consumer choice problem I'll give you, OK? That basically, at the optimum,\nthe ratio of marginal utilities equals the ratio prices. That is the rate at which\nyou want to trade off pizza for cookies is the rate\nat which the market will allow you to trade off\npizza for cookies, OK? Basically, it's saying\nthe ratio of the benefits. Think of this as the benefits\nand this as the costs. Think of the MRS\nas the benefits. It's what you want. MRT is the costs. It's where you're constrained. You want to set the\nratio of the benefits equal to the ratio\nof the costs, OK? Now I find it actually easier\nto think of it this way. If you just rearrange terms,\nyou can write it as MUc over pc equals MUp over p sub p. I like this way of writing\nit because I call this the bang for the buck equation. What this is saying, your\nmarginal happiness per dollar should be equal. This is sort of the happiness\nper dollar spent on cookies. This is the happiness per\ndollar spent on pizza. And you want those to be equal. You want the bang\nfor the-- you want to put your next\ndollar where it's going to make you happiest, OK? And so, basically, think of\nthat as your bang for your buck. So, for example, suppose\nyou were in a position where the MRS was\ngreater than the MRT. You're in a position where the\nmarginal utility of cookies-- and I'm getting\nrid the negatives. There's negative on both sides. So I'm just going to get\nrid of the negatives, OK? The marginal utility of cookies\nover the marginal utility of pizza was greater\nthan the price of cookies over the price of pizza, OK? That is the slope of\nthe indifference curve was greater than the slope\nof the budget constraint. This is the slope of\nthe indifference curve. OK, this is slope of\nthe indifference curve. This is the slope of\nthe budget constraint. In absolute value, the slope\nof the indifference curve is greater in absolute value\nthan the slope of the budget constraint, OK? That would be true at points\nlike point A, point A where you intersect-- where you basically intersect\nfrom above the budget constraint by the\nindifference curve. So a point like point\nA has a steeper slope of the indifference curve than\ndoes the budget constraint. What that says is\nintuitively-- and, once again, I want you to understand\nthe intuition-- the rate at which you\nare willing to give up, the rate at which you\nare willing to give up cookies for pizzas-- I'm sorry. Let me say it-- let me say it a better way. The marginal benefit to\nyou of another cookie relative to another\npizza is higher than what the market will charge\nyou to turn pizza into cookies. Let me say it again. The marginal benefit to you of\nanother cookie, which is this-- this is how much more\nyou want the next cookie relative to how much more\nyou want the next pizza-- is greater than\nwhat the market is going to charge you to trade\nin your pizza for cookies. Therefore, you should trade\nin your pizza for cookies, OK? So let's say this\nmathematically. At a point like A,\npoint A, OK, you have your marginal\nutility for pizza is the derivative of the\nutility function with respect to the number of\nslices of pizza. It's the marginal utility. It's derivative of\nthe utility function. So it's dU dp, which is equal\nto 0.5 times C over square root of P times C, OK? And, at point A,\nat point A, we had two cookies and five pizzas. At point A, P was five. C was two. OK, that's true of point A. So we can evaluate the\nmarginal utility dU dp, which equals 0.5 times C\nover square root of P times C. So that's 1 over the\nsquare root of 10. That's the marginal utility\nof the next slice of pizza. The next slice of\npizza makes you 1 over square root of 10 happy. Once again, that\nnumber is meaningless. So we only care\nabout it in ratios. So we need the ratio. So let's do the marginal\nutility of cookies. That's dU dC, which\nis 0.5 times P over square root of P\ntimes C, which is 2.5 over the square root of 10, OK? So the marginal utility of pizza\nis 1 over square root of 10. Marginal utility of cookies is\n2.5 over the square root of 10. Therefore, your marginal rate\nof substitution is minus 2.5. Remember, marginal rate of\nsubstitution is MUc over MUp. So your marginal rate of\nsubstitution is minus 2.5. What does that mean? Can anyone tell me\nwhat that means? Your marginal rate of\nsubstitution is 2.5. What does that mean?"}, {"content": "That is a meaningful concept. Utils are not, but that is. Yeah, say it loudly\nso we can hear. AUDIENCE: You're\nwilling to trade-- you're willing to trade\ntwo pizzas for one cookie. JONATHAN GRUBER: You're\nwilling to trade. Exactly, you're willing to\ngive up 2.5 slices of pizza for one cookie. That's what that number means. And that is a meaningful number. That's not an ordinal. That's cardinal."}, {"content": "We can use that. You are willing to give\nup 2.5 slices of pizza to get one cookie. What is the market\nasking you to give up? How much pizza do you have\nto give up to get one cookie? Half a slice. You are happy to give up\n2 and 1/2 slices of pizza to get a cookie,\nbut the market is saying we'll let you\nhave a cookie for half a slice of pizza. So what should you do? AUDIENCE: Trade. JONATHAN GRUBER: Eat less pizza. Eat more cookies. That will unambiguously\nmake you happier. And that's why you should move\nfrom point A towards point D. OK, that's the intuition, OK? You basically want to\ntrade pizza for cookies until these things are equal. Indeed, I'd like you to go home\nand do the same math starting at point B. If you do the\nsame math starting at point B, you'll find the MRS\nis much below 1/2. That is, at that point,\nyou are happy to give up tons of cookies to get pizza\nbecause, jeez, you've got 10 cookies and one slice of pizza. You'd give up tons of\ncookies to get pizza. But the market says you\nonly have to give up two cookies to get pizza. So you'll happily do it, and\nyou move back towards point D. And that's sort of in a bundle\nsort of the intuition and math and graphics of how we do\nconstrained optimization. OK, that is hard\nand very important."}, {"content": "Questions about that? Don't hesitate to ask."}, {"content": "OK, that is hard\nand very important. If you understand\nthis, you're sort of done with consumer theory, OK? This is sort of the core of what\nconsumer theory is all about. It's all about\nthis balancing act. The whole course\nis fundamentally all about one equation,\nwhich is marginal benefits equals marginal costs, OK? Everything we do is going\nto be about weighing the marginal benefit\nof an activity against its marginal costs. If we take the next\nstep, what's the benefit? And what's the cost? Well, here the marginal\nbenefit is the MRS. The marginal cost is the MRT. We want to set them equal."}, {"content": "And this sort of example\nI hope explained why, OK? So that is how we think\nabout constrained choice. Now I want apply it. I want to apply it by looking at\nthe example of food stamps, OK? Now food stamps are not actually\ncalled food stamps anymore. When I was a kid, they\nwere called food stamps. It's basically a program\nthe government has that provides money\nfor individuals to buy food if\nthey're low income. Essentially, we have in the US\nwhat's called the poverty line. And I'll talk a lot more about\nthis at the end of the class, but the poverty\nline is essentially a measure of what's a\nminimum level of resources you need to live in America. The poverty line for an\nindividual is about $14,000. OK, for a family of\nfour, it's about $28,000. How you feel about\nthat number obviously is going depend on\nwhere you're from. If you're from Boston,\nyou'll say that's insane. If you're from some rural\npart of the country, you think, yeah, that's\npoor, but manageable. OK, we'll talk later\nabout the poverty line, what's good and bad about it. But, in any case, if you're\nbelow the poverty line in America, roughly speaking,\nyou get help with buying food. And that comes through a\nprogram we now call SNAP. It used to be\ncalled food stamps. I've got to update my notes. Supplemental Nutrition--\nI don't know. I know the N is for nutrition. OK, so, basically, what\nthe SNAP program does is it gives you a debit card. If you qualify on income\ngrounds, you get a debit card, and that debit card can be used\nto buy food and food only, OK? So you essentially get a\ndebit card from the government that you can use to buy\nfood if you're poor enough. And they give you sort of\na fixed amount every month, and that amount can be\nused to purchase food. So here's the question. Why go through this rigmarole? Why not just give people cash? This fancy thing, if we want\nto give poor people money, why don't you just\ngive them money? And we're going to-- I don't want the answer yet, OK? What I want to do is\nshow you graphically how we think about\nthe trade-off, and then we'll\ncome to the answer. So hold your thoughts. So let's actually graph how\nwe think about food stamps. Let's go to figure 3-5A. And let's start with\na cash transfer. So here's the setup. Imagine people start\nwith an income of $5,000. That's super poor, OK? $5,000 is their whole family\nincome for the year, OK? And let's say all they can\nspend it on is food or shelter. Remember, as this gentleman\npointed out, in life, there's more than two goods,\nbut it makes it a lot easier to have two goods. So imagine this case. Your two goods are\nfood and shelter. And, actually, quite\nfrankly, if you're that poor, that probably is\nthe only two goods you have to-- you can worry\nabout at that level of income. OK, it's food and shelter. So you $5,000 to devote\nto food and shelter. So you have some\noriginal budget line, which is labeled\nthere original budget line, that runs from 5,000\nin food to 5,000 in shelter. And then you can have some of\nin between, some along the way, OK? Now let's say we give\nsomeone $500 in cash. Obviously, this graph\nis not to scale, OK? It looks like you're doubling\nhis income, but it's only $500. This just sort of makes it\neasier, a not to scale graph. Let's say we give someone-- we\nsay to them, look, you're poor. We're going to give\nyou $500 in cash. Well, now all we've done\nis shift out your budget constraint from 5,000 to 5,500. OK, we've shifted out\nyour budget constraint from 5,000 to 5,500. What does that do\nto your choices?"}, {"content": "Well, consider two\ndifferent types of people. Person y, OK, they used to\nbe on indifference curve I0. They used to spend almost\nall their income on food and not a lot on shelter."}, {"content": "They were probably homeless, OK? So they spent all\ntheir money on food and were basically homeless. Now what do they do? Well, they spend a little\nmore on food and a lot more on shelter. Maybe now they get--\nyou know, $400 still doesn't buy you much shelter. They spend a little more, OK? Maybe, a night a week,\nthey can get shelter, OK? So, basically,\nthat's what they do. That's their constrained\noptimization. We're not saying\nit's right or wrong. This is not normative economics. It's positive. The positive thing is, given\ntheir utility function, they move from point y1 to y2. Now imagine someone\nlike individual x."}, {"content": "They're different. Their tastes are such that\nthey don't need to eat. They just want to have shelter. So they're up at\npoint x1 initially. And you give them\nthat $500, and they spend just a little bit more of\nit on food and even more of it on shelter. They just love\ntheir shelter, OK? And they're just super-- they're super Weight Watchers. They don't eat, OK? So, basically, they\nmove from x1 to x2. Once again, not\nnormative right or wrong, it's just these are\nfeasible choices people could make given the opportunity\nset with which they're faced. And that's what happens when\nyou give them the $500 in cash. Questions about what I did\nhere on this graph alone? Yeah? AUDIENCE: Like, even\nif like you gave them money specifically for\nfood, couldn't they then just reallocate\ntheir other money? JONATHAN GRUBER: OK,\nthat's a good point."}, {"content": "We'll come back to that. That's time out if\nyou're not a sports fan. OK, so we will\ncome back to that. And, in fact-- OK, but do people\nunderstand what the cash transfer is, how it works? OK, now let's go to SNAP. And let's say, with SNAP,\ninstead of giving them $500, we'll give them the debit card. Instead of handing\nthem a $500 check, we give them a debit\ncard with $500 on it that can only be used on food. How does this affect\ntheir budget constraint? Now we see where budget\nconstraints start to get interesting and fun\nand the kind of challenges you're going to face in this\ncourse in drawing budget constraints. The original budget\nconstraint continues to be the original budget line\nrunning from 5,000 to 5,000. The new budget constraint\nis this kinked line that runs from 5,000 on\nthe y-axis to the point x2 at 5,000 on the y-axis. So it starts at 5,000 on\nthe y-axis, 0 on the x-axis. There's a flat line that goes\nto 5,000 on the y-axis, 500 on the x-axis. And then it slopes down\nparallel to the original budget constraint to 5,500. Can someone explain to me\nwhy that's the new budget constraint? Yeah? AUDIENCE: You can't\nspend a negative amount. So you can't spend\nlike negative amounts of your non-food-stamp\nmoney on food. JONATHAN GRUBER:\nExactly, you have-- we are forcing you to\nspend at least $500. Compared to cash, where you can\ndo whatever the hell you want, we are forcing you to spend\n$500 of your money on food. Coming to the\nquestion back there, it doesn't have to be a\nspecifically labeled 500. It can be any 500. But we're forcing you to\nspend at least $500 on food. Well, what does that\ndo to your choices? Well, for person y,\nit makes no difference whether they get cash or\nwhether they get food stamps. Now the person, light blue\nshirt, turquoise shirt, asked that question. Why does it make no difference? Yeah? Why does it--\nwhatever, greenish, I don't know, yeah, you. Why does it make no\ndifference for person y if I give him food\nstamps or cash? AUDIENCE: He's already spending\na lot of his money on food. So any money he gets he can\njust reallocate differently so he can spend\nsome of the money he would have used\non food on shelter. JONATHAN GRUBER: Exactly, he can\njust reallocate his money, OK? That's exactly right. So, for person y,\nthere's no difference. Look, they're already\nspending, what, $4,900 on food. You give him a thing\nlabeled $500 for food. It's not going to\naffect their life. They'll just take 500. They'll just spend-- they'll\njust treat it as $500 more in cash. They're indifferent. So nothing affects them. But what about person x? Well, person x, remember,\nthe dashed portion of this budget constraint is\nfrom the old cash example. And the dotted\nindifference curve is what they would\nhave chosen with cash. Remember, person\nx with cash would have chosen to still spend\nless than $500 on food. Even when you gave\nthem $500, they still only spent $300 on food. So we are forcing them to not\nbe on their preferred budget constraint. Rather, we're forcing\nthem down to point x2, which is they'll spend the\nminimum they can on food, but the minimum is $500, OK? We are forcing them\ndown to point x2. Now why do I say forcing them? Why do I know for sure they\nare being forced, that they're less happy at x2 than they would\nhave been when they gave them the cash? How do I know that for sure?"}, {"content": "Yeah? AUDIENCE: They're at a\nlower indifference curve. JONATHAN GRUBER: Exactly. Think of it this way. The fundamental-- one\nof the important things is people always get\nto the point that makes them happiest, OK? We call it the robustness\nof economic equilibria. People get to the point\nthat makes them happiest. They want-- they\nalways before had the choice of spending $500 on\nfood, and they chose not to. Therefore, if you force\nthem to spend $500 on food, they must be less happy, OK? Think of it that way. They always could have\nspent $500 on food. They didn't. Therefore, in\nforcing them, you're making them less happy, OK? So they are worse off, OK? They are forced to spend. They'd rather spend\nsome of that money and find a nicer place to live,\nbut we're not letting them. We're making them buy food, OK? Do people-- I don't want-- I just want to know if people\nunderstand the graphics here and the conclusions I drew. OK, now why?"}, {"content": "Why are we doing this? Why would you-- they're\nbetter off with cash. Why would we force\nthem to have food? Yeah? AUDIENCE: Say\nbecause what makes-- what puts people on the\nhighest indifference is just what makes them\nhappiest, but not necessarily what makes them like\nlive the longest or like have the best\nhealth So, perhaps, like if you never spend money\non food, and then you die, that would be really bad. JONATHAN GRUBER: OK, but,\nbasically, what you're saying is you know better than the guy. Let me-- I'm not accusing you."}, {"content": "I'm just saying, look,\nif people knew best, maybe they'd like to just like\nhave a nice house and die, OK? If people knew\nbest, then there'd be no reason to do this."}, {"content": "The reason to do this is because\nwe think they don't know best. So, for example, let's change\nthe label on the y-axis, just a small change. Let's cross out shelter\nand write cocaine."}, {"content": "[LAUGHTER] OK? Well, in that case, maybe\nwe don't feel so bad about forcing the guy to buy\nfood instead of cocaine, OK? In other words, this a\nprogram which might make sense if we are paternalistic. Now we're getting into normative\neconomics, paternalistic. If we think that people\nwon't necessarily make the right decisions\nfor themselves, then it may be worth\nactually making them worse off because\nthey're not worse off. Their perceived\nbenefits are worse, but they don't know\nwhat they're doing, OK? Now you can see why-- I hope you can\nsort of immediately see why this concept makes\neconomists a little nervous because why do we know what they\nwant better than they do, OK? So it makes people a\nlittle bit nervous, economists a little\nbit nervous, and a lot of people a little bit nervous\nto say, gee, maybe they're just happier doing cocaine. And how do we know that\nthat's the wrong way for them to spend their resources?"}, {"content": "Yeah? AUDIENCE: Well,\nlike can't you look at it from the perspective of\nlike this is taxpayer money, right? So then aren't you\nalso just factoring in how the taxpayer wants to\nspend their money and then their indifference curve\nand all their information? JONATHAN GRUBER: That's\na very good point. Now but there's sort\nof two points there. First of all, if the taxpayers'\ngoal is to help poor people, then why shouldn't you make them\nas happy as possible, right? If tax-- why am I giving\nmoney to this poor guy? Because I'm sad his poor. But, what you're saying, I'm\nnot actually that sad he's poor. I'm sad he's not eating. If you're really\njust sad he's poor, then you should give him money. If what you're\nsad about is, gee, I don't like how he's living-- I don't like his-- I'm sad he can't have better\nfood to eat, sad at the place he lives. Then you're starting to\nimpose your preferences, but let's be important."}, {"content": "That's imposing\nyour preferences."}, {"content": "Yeah? AUDIENCE: I feel like the\nindifference curve only goes for happiness or\nlike contentedness, but, really, the point\nof SNAP isn't really with contentedness or\nhappiness, but rather like what would be to a\nmore sustainable life. JONATHAN GRUBER: Well, that's a\nrelated point of the taxpayer. If the taxpayer\ncares about, look, we want a healthy\npopulace that's going to live a long time and\nbe productive and pay taxes, then that would be\na reason to do this. But, once again, I\nwant to emphasize, OK, this is paternalism. If you really just care\nwhat makes people happiest, you should give them cash, OK? So that raises\ntwo questions, OK?"}, {"content": "First of all, first\nquestion-- yeah? AUDIENCE: So how about\nlike negative [INAUDIBLE].. Because, for example, if\nwe pump a lot of money-- if we allow people to\nspend a lot on shelter, that's not really\ngoing to help people. It would just make the real\nestate developers rich. And say the amount\nof shelter is kind of fixed, but like the amount of\nfood that eaten [INAUDIBLE].. So, if we let people\nspend more money on food-- JONATHAN GRUBER: Yeah,\nyeah, so, basically, that's a great question. And, in general,\nwe're going to-- I'm going to answer a\nlot of those questions with the same cheat\nthis semester, which is we're going to assume\nthe markets are perfectly functioning. So there's no-- you're imposing\nsort of a market failure. If there's no market-- once\nthere's market failures, all bets are off. But, with no market\nfailure and no paternalism, you'd want to give them cash. So this raises an\nimportant question. Do food stamps actually\nincrease food purchases? First of all, there's two\nreasons why they might not."}, {"content": "Reason one is everybody\ncould be like y."}, {"content": "x is sort of a\nsilly case, right? You're going to die if\nyou eat that little. And food stamps\naren't that much. They're maybe like\n$3,000 a year. Everybody is going\nspend $3,000 on food. So the first issue is the first\nreason why food stamps may not matter is that, in\nfact, everybody is spending at least that amount. Everybody is like y,\nand nobody is like x. What's another reason\nwhy it might not matter? What's a way people could\nget around food stamps? Yeah? AUDIENCE: Buy food with\nfood stamps and sell it. JONATHAN GRUBER: Yeah,\nthey could set up a black market where they,\nessentially, say, look, I only want $2,000 of food. The government is\nmaking it worth $3,000. I'll buy my extra\n$1,000 of food, and I'll sell it to\npeople who do want it. And I'll end up still\neating $2,000 worth of food. So we actually want to know do\nfood stamps actually increase food consumption in practice. Are they making a difference? Well, actually, we've run\nan experiment on this, OK? We're going to talk\nin this class a lot about empirical\nresults in economics. This class is mostly going\nto be a theoretical class. That is we'll talk\nabout models and ideas. But we're also--\nsince, basically, I'm an empirical\neconomist, we're going to talk about empirical\neconomics, which is results and testing the\ntheories we develop. Empirical economics,\nhere's a great example of empirical economics is we\nset up a theoretical model. You always want to\nstart with the theory, but the theory sometimes\nhas predictions, which are uncertain. Here we have an uncertain\nprediction from theory about whether food stamps will\naffect food purchases or not. So let's test it. And the way we test\nit is we actually have run food stamps cash out\nexperiments where we literally take guys on food stamps\nand give them cash instead and watch what happens to their\nconsumption before and after. It's a real randomized trial. We literally flip a coin. Heads, you keep\nyour food stamps. Tails, we replace\nthose food stamps with an equal amount of cash. Then we watch what happens. What happens is that people\nspend about 15% less on food when you give them cash\ninstead of food stamps. That is food stamps is forcing\npeople to spend about 15% more on food than\nthey would like to unconstrained by the cash. Yeah?"}, {"content": "AUDIENCE: Yeah, this gets\nyou into the behavior of [INAUDIBLE]. I remember reading an\nexperiment like, if you have the price of gas go down,\nthe actual like amount of money spent on gas is constant. And this might\ntranslate to food stamps because like food stamps\nare like explicitly on food. JONATHAN GRUBER: Yeah, you\nknow, that's a great question. And that's you're asking about\nricher theory, richer theory. And I'm telling you that\nI'm going to give you the empirical evidence. So, whatever the theory\nis, the empirical evidence tells you what happens. And there's different\nexplanations for why. So the empirical evidence is\nthat, basically, the price of our paternalism is 15%, OK? We are making people,\neffectively, 15% worse off. We're making them spend 15%\nmore food than they want to. So is it worth it? Well, actually, the\nevidence is starting to pour in that it might not\nbe worth it because there's starting to be a lot of\nexperiments where we're giving people just cash,\nespecially in developing countries. In developing\ncountries, the answer seems to be just\ngiving people cash makes them better\noff, that actually, especially in\ndeveloping countries, people use the cash\nin productive ways. So, for example, they have a\nseries of evaluation programs where they've given people cash,\nmostly in developing countries, in Africa in particular,\nsome in the US. And they find that people\nspend relatively little of that on drugs and\nalcohol, but they actually tend to spend it productively. And, in fact, they found,\nin developing countries, this often provides valuable\nresources for individuals to start businesses. So they ran experiment Uganda\nwhere a nonprofit company randomly offered\na group of women $150, which is huge\nrelative to their income. That's 50% to 100% of annual\nincome in Uganda, $150. And what they found was, after\ntwo months-- after 18 months, these women had used that\nmoney to start businesses. And that actually\nraised their earnings. That actually effectively\ndoubled their earnings. From that one\ninjection of cash, it led them to actually double\ntheir annual earnings, OK? So that leads one to\nthink that maybe we should stop being paternalistic\nand just give cash. Unfortunately, if you're a\nreader of policy websites like I am, the best one\nof which is vox.com-- it's a great website-- they had an article just\nthe other day pointing out how they actually followed\nthese women up nine years later. And, nine years later, the\neffect had totally gone away. So the story isn't quite\nnecessarily positive, but it's not negative. They're not worse\noff, but it looks like, at least what\nin the short run made them better off, well,\nthat effect fades over time. But the bottom line\nis, at this point, I think the evidence\nis sort of probably in favor of being\nless paternalistic and just giving\npeople cash, but that runs into a lot of difficulties\nin terms of our concerns about how people will spend it. So let me stop there. We will come back\non Monday, and we'll talk about how we actually go\nfrom this stuff to the demand curves we started\nthe class with."}], "Stanford CS229 I Machine Learning I Building Large Language Models (LLMs)": [{"content": "so let's get started uh so I'll be talking about building llms today um so I think a lot of you have heard of llms before uh but just as a quick recap uh llms standing for large language models are basically all the chat Bots uh that you've been hearing about recently so uh Chad GPT from open ey Claud from entropic Gemini and and lman other type of models like this and today we'll be talking about how do they actually work so it's going to be an overview because it's only one lecture and it's hard to compress everything but hopefully I'll touch a little bit about all the components that are needed to train uh some of these llms uh also if you have questions please interrupt me and ask uh if you have a question most likely other people in the room or on Zoom have other have the same question so please ask um great so what matters when training llms um so there a few key components that matter uh one is the architecture so as you probably all know LMS are newal networks and when you think about new networks you have to think about what architecture you're using and another component which is really important uh is the training loss and the training algorithm um so how you actually train these models then it's data so uh what do you train these models on um the evaluation which is how do you know whether you're actually making progress towards the goal of of uh llms and then the system component so that is like how do you actually make these models run on uh Modern Hardware which is really important because these models are really large um so now more than ever system is actually really an important topic um for llms so those five components um You probably all know that llms and if you don't know LMS are all based on Transformers or at least some version of Transformers uh I'm actually not going to talk about the AR lecture today uh one because I gave a SE lecture on um Transformers a few weeks ago and two because you can find so much information online on uh Transformers but I think you can it's there's much less information about the other four topics so I really want to talk about those um another thing to say is that most of Academia actually focuses on architecture and training algorithm and losses um as academics and I've done that for a lot big part of my career is simply we like thinking that this is uh like we make new architectures new models and it it seems like it's very important but in reality honestly what matters in practice is mostly the three other topics so data evaluation and systems uh which is what of most of Industry actually focuses on um so that's also one of the reason why I don't want to talk too much about the architecture uh because really the rest is super important um great so overview of the lecture I'll be talking about pre-training so pre-training uh you probably heard that word this is the general word this is kind of the classical language modeling uh Paradigm uh where you basically train your language model to essentially model all of internet and then there's a post training which is a more recent Paradigm which is taking these large language models and making them essentially AI assistants um so this is more of a recent Trend since Chad GPT uh so if you ever heard of gpt3 or gpt2 that's really pre-training land uh if you heard of chat GPT which you probably have this is really posttraining land uh so I'll be talking about both but I'll start with pre-training and uh specifically I'll talk about what is the task of pre-training llms and what is the laws that people actually use so language modeling this is a quick recap uh language models at a high level are simply models of probability distribution over sequences of tokens or of words so it's basically some uh model of P of X1 to XL where X1 is basically word one and Excel is the last one in the sequence or in the sentence um so very concretely if you have a sentence like the mouse ate the cheese what the language model gives you is simply a probability of this sentence being uttered by a human or being found on on online uh so if you have another sentence like the the mouse at cheese uh here there's grammatical mistakes so the model should know that this uh should have some syntactic knowledge so it should know that this has less likelihood of appearing online uh if you have another sentence like the cheese ate the mouse uh then the model should hopefully know about the fact that usually cheese don't eat Mouse um so there's some semantic knowledge and this is less likely than the first sentence so this is basically at a high level what language models are um one word that you probably have been hearing a lot in the news are generative models uh so this is just something that can generate models that can generate sentences or can generate some data uh the reason why we say language models are generative models is that once you have a model of a distribution you can simply sample from this model and now we can generate data uh so you can generate sentences uh using a language model so the type of models that uh people are all currently using are what we call Auto regressive language models and the key idea of autor regressive language models is that you take this distribution over words and you basically decompose it into the into the distribution of the first word multiply the by the distribution of or the likelihood of the distribution of the second word given the first word uh multiply by P of the third word given the first two words um so there's no approximation here this is just the chain rule of probability which you hopefully all know about uh really no approximation this is just one way of modeling a distribution uh so slightly more concisely you can write it as a product of U of PS of the next word given everything which happened in the past so of the context and uh so this this is what we call Auto regressive language models again this is really not the only way of modeling distribution this is just one way uh it has some benefits and some downsides one downside of autoaggressive language models is that when you actually sample from this autoaggressive language model you basically have a for Loop which generates the next word then conditions on that next word and then regenerate an other word so basically if you have a longer sentence that you want to generate you it takes more time to generate it uh so there are some downsides of this current Paradigm but that's what we currently have so I'm going to talk about this one uh great so Auto regressive language models at a high level um what the task of autoregressive language model is is simply predicting the next word as I just said so if you have a sentence like she likely prefers uh one potential next word might be dogs and the the way we do it is that we first tokenize so you take these words or subwords you tokenize them um and then you give an IDE for each token so here you have 1 2 three uh then you pass it through this black box as I already said we're not going to talk about the architecture you just pass it pass it through a model and you then get a distribution a probability distribution over the next word over the next token and then you sample uh from this distribution you get a new token and then you DET tokenize so you get a new ID you then DET toonize and that's how you basically sample from a language model uh one thing which is important to not is that the last two TS uh two steps are actually only need needed during inference uh when you do training you just need to predict uh the most likely token and you can just compare to the real token which happen in practice and then you basically change the weights of your model to increase the probability of generating that token um great so autoaggressive neural language models so to be slightly more specific still without talking about the architecture uh the first thing we do is that we have all of these oh sorry yes on the previous slide when you're predicting the probability of the next tokens does this mean that your final like output VOR has to be the same dimensionality as the number of tokens that you have yes how do you deal with like if you have more to like if you're adding more tokens to your cor something yeah so we're going to talk about tokenization actually later uh so you will get some sense of this you basically can deal with adding new tokens I am I'm kind of exaggerating there are methods for doing it but essentially people don't do it um so it's really important to think about how you tokenize your text and that's why we'll talk about that later but it's a very good point to notice that you basically the vocabulary size so the number of tokens that you have is essentially the output of your uh language model so it's actually pretty pretty large okay so autoaggressive new language models first thing you do is that you take every word or every token you embed them so you get a um some Vector representation for each of these tokens um you pass them through some ual Network as we said it's a Transformer then you get a representation for all the word in all the words in the context so it's basically representation of the entire sentence uh you pass it through a linear layer as you just said to basically map it to the number so that the output the number of outputs is the number of tokens uh you then pass it through some soft Max and you basically get uh probity distribution over the next words given every word in the context and the law that you use is basically it's essentially a task of classifying the next token so it's a very simple kind of machine learning task so you use the cross entry P loss where you basically you look at the actual Target that happened which is a target distribution which is a one hot encoding which here in this in this case says I saw uh the real word that happened is cat so that's a one hot um distribution over cat and here this is the actual uh do you see my mouse oh yeah this is the distribtion that you generated and basically you do cross entropy which really just increases the probability of generating cat and decreases all the the probility of generating all the other tokens one thing to notice is that as you all know again uh this is just equivalent to maximizing the text log like the text log likelihood because you can just rewrite the the max over the probability of um this autoregressive language moding task as just being this minimum over I just added the log here and minus which is just the minimum of the loss which is the cross enty loss so basically minimizing the loss is the same thing as maximizing the likelihood of your text any question questions okay tokenizer um so this is one thing that people usually don't talk that much about tokenizers are extremely important uh so it's really important that you kind of understand at least uh what they do at a high level so why do we need token in the first place uh first it's more General than words so one simple thing that you might think is oh we're just going to take every word that we will have you just say every word is a new is a token in its own um but then what happens is if there's a typo in your word then you might not have any token associated with this this word with a typo and then you don't know how to actually pass this word with a typo into a large language model so what do you do next and also even if you think about words words is a very like words are fine with like Latin based languages uh but if you think about a language like taii you won't have a simple way of tokenizing by spaces because there are no spaces between words um so really uh tokens are much more General Than Words first thing second thing that you might think is that you might tokenize every sentence character by character you might say a is one token b is another token uh that would actually work and probably very well the issue is that then your sequence becomes super long and as you probably remember from the lecture on on Transformers uh the complexity uh grows quadratically with the length of sequences so you really don't want to have a super long sequence um so tokenizers basically try to deal with those two problems and give common subsequences a certain token and usually how you should be think about is around uh an average every token is around three four letters um and there are many algorithm for tokenization I'll just talk about one of them to give you a high level which is what we call bite P en coding which is actually pretty common one of the two most common tokenizers and the way that you train a tokenizer is that first you start with a very large Corpus of text and here I'm really not talking about training a large language model yet this is purely for the tokenization step uh so this is my large Corpus of text with these five words um then you associate every character in this Corpus of text a different token uh so here I just split up every character with a different token uh and I just color coded all of those tokens and then what you do is that you go through your text and every time you see pairs of tokens that are very common the most common pair of token you just merge them so here you see three times the the the tokens T and O next to each other so you're just going to say this is a new token and then you continue you repeat that so now you have to talk which happens three times to with an E that happens sorry two times and an token which happens twice and then ex which also happen twice so this is that if you were to train a tokenizer on this Corpus of text which is very small that's how you would uh finish with a token with a pre like a trained tokenizer uh in reality you do it on on much larger corpuses of text um and this is the real tokenizer of uh actually I think this is gpt3 or chat GPT uh and here you see how it would actually separate these words so basically you see the same thing as what we gave in the previous example token becomes its own token so tokenizer is actually split up into two tokens token and iser um so yeah that's all about tokenizers any questions on that yeah how do you deal with spes and how do you deal with yeah so actually there's a a step before tokenizers which is what we call pre- tokenizers which is exactly what you just said uh so this is mostly in theory there's no reason to deal with spaces and punctuation separately you could just say every space gets its own token every um uh punctuation get its own token and you can just do all the merging the problem is that so there's an efficiency question actually training these tokenizes takes a long time uh so you better off because you have to consider every pair of token so what you end up doing is saying if there's a space this is very like pre- tokenizes are very English specific you say if there's a space we're not going to start looking at the the token that came before and the token that came afterwards so you're not merging in between spaces but this is just like a optimiz like a computation optimization you could theoretically just deal with it um the same way as you deal with any other character and yeah when you merge tokens do you delete the tokens that you merged away or do you keep the the smaller tokens that merge um you actually keep the smaller tokens I mean in reality it doesn't matter much because um usually on large Corpus of text you will have actually everything uh but you usually keep the small ones and the reason why you want to do that is because if in case there's as we said before you have some um some grammatical mistakes so some typos you still want to be able to represent these words by character um so yeah yes are the tokens unique so I mean say in this case T Ken is there only one occurrence or could do you need to leave multiple occurr so they could have take on different meanings or something oh oh I see what you say no no it's every token has its own uh unique ID um so a usual this is a great question for example if you think about a bank which could be bank for like money or bank like water um it will have the same token but the model will learn the Transformer will learn that based on the words that are around it it should associate that I'm saying I'm being very high wavy here but associate that with the with a with a representation that is either more like the bank money side or the Bank water side um but that's a Transformer that does that it's not a tokenizer yes yeah so you mentioned during tokenization keep the smaller tokens you started with right like if you start with a t you keep the T and then you build your tokenizer to the that you can now in token so let's say maybe you didn't train on token but like in your data you are trying to encode token so how does the tokenizer know to encode it with token or a great question you basically when you so when you tokenize so that's after training of the tokenizer when you actually apply the tokenizer you basically always choose the largest uh token that you can apply uh so if you can do token you will never do T you will always do token um but there's actually so people don't usually talk that much about tokenizers but uh there's a lot of of computational benefits uh or computational tricks that you can do for making these things faster uh so I really don't think we and honestly I think a lot of people think that we should just get away from tokenizers um and just kind of tokenize character by character or bites by bites uh but as I said right now there's this issue of like length uh but maybe one day like in five or 10 years we will have different architectures that don't scale quadratically with the length of the sequence and uh maybe we'll um yeah move away from tokenizes so can you share with us the drawback why do people want to move away from the tokenizer oh um yeah so think one good example is uh math if you think about math actually numbers right now are not tokenized so for example 327 might have its own token which means that models when they see numbers they don't see them the same way as we do and this is very annoying because what I mean the reason why we can kind of generalize with math is because we can deal with every every letter separately and we can then do composition where you know that basically if you add stuff it's just the same thing as adding every one separately plus like whatever the unit that you add so they can do that um so then you have to do like special tokenization and like one of the big changes that GPT 4 did uh is changing the way that they tokenize uh code so for example uh if you have code you know you have like often in Python these four spaces at the beginning those were dealt with uh kind of strangely before um and as a result like the model couldn't really understand uh how to deal with code uh so so toiz actually a lot um okay so I'll move on right now but we can come back later on token Isis great so we talked about the task the L the tokenizer let's talk a little bit about evaluation uh so the way that LMS are usually evaluated is what we call is using what we call perplexity um at a high level it's basically just your validation loss uh the slight difference with perplexity is that we use something that is slightly more interpretable which is that we use the average per token loss and then you expon entiate it and the reason why you exponentiate it is because you want I mean the loss has a log inside and you like one humans are actually pretty bad at thinking in log space but two logs depend on the base of the log uh while when you exponentiate you basically have everything in the uh kind of the vocabulary size uh unit um and the average proten is just so that your your complexity is independent of the length of your sequence um so perplexity is just two to the power uh average of the loss of the sequence um so perplexity is between one and the length of the vocabulary of your tokenizer uh one it's simply well if you predict perfectly the thing which uh every word then every word will have basically product of ones uh so the best perplexity you can have is one if you really have no idea you basically predict with one divided by uh size of vocabulary um and then you do simple math and you basically get perplexity of size of vocabulary uh so the intuition of perplexity is that basically the number of tokens that your model is kind of hesitating between uh so if you if your model is perfect it doesn't hesitate it know exactly the word if it really has no idea then it hesitates between uh all of the vocabulary uh so perplexity really improved that's perplexity on a standard data set between 2017 and 2023 it it went from kind of 70 tokens to less than 10 tokens over these five six years so that means that the models were previously as dating between 70 words every time it was generating a word and now it's as dating between like less than 10 words so that's much better perplexity is actually not used anymore in academic benchmarking mostly because it depends on the tokenizers that you use uh it depends on the actual data that people are evaluating on but it's still very important for development of llms so when you when you actually train your own llm people will still really look at the perplexity uh one common other way and now more common in Academia of evaluating these llms is just by taking all the classical NLP benchmarks and I'll give you a few examples later and just kind of aggregating everything um so collect as many automatically evaluatable benchmarks and just evaluate across all of them um so one such if uh or actually two such uh benchmarks of what we call uh Helm which is from Stanford and another one is the hugging face open LM leader board which are the probably two two most common ones right now um so just to give you an idea in Helm there are all of these type of tasks which are mostly things that can be easily evaluated uh like question answering so think about many different question answering uh tasks um and the benefit with question answering is that you usually know what is the real answer um so you can the way that you evaluate these models and I'll give you a concrete example in one second um is that you can just look at How likely the language model is to generate the real answer compared to some other answers and that's essentially at a high level how you evaluate these models um so to give you a specific example mlu is probably the most common um academic Benchmark for llms uh and this is just a collection of many question and answers in all of those domains for example College medicine College physics astronomy and these type of topics and the questions are things like so this in astronomy what is true for type 1 a supernova then you give uh four different potential answers and you just ask the model which one is more likely so there are many different ways of doing it either you can look at the likelihood of generating all these answers uh or you can ask the model which one is the most likely uh so there are different ways that you can promp the model but at a high level you know which one is correct and there are three other mistakes um yes kind creating is like unconstrained text as the output yeah how do you evaluate a model if it give something that's you know semantically completely identical but is not the exact token list that expect yeah so that's a great question I'll talk more about that later here in this case we don't do unconstrained so the way you would evaluate MML is basically either you you ask the first question and then you look at the likelihood of the model generating a the likelihood of the model generating b c and d and you look at which one is the most likely or you can as the model out of ABC d which one is the most likely and you look at whe the to the most likely next token is A B C or D so uh you can strain the model to say it can only answer these four things you say you constraint the model you mean you constraint The Prompt or do you mean of its whole probability distribution outputs you only comparing the outputs like you're only comparing the a so uh in the second case I gave you you would do exactly the I actually you would do both you would prompt the model saying ABC or D plus you would constrain to only uh look at these two these four tokens in the first case you don't even need to generate anything so in the first case you literally just look given that it's a language model it can give a distribution over sentences you just look at what is the likelihood of generating all of these words what is the likelihood of generating the second choice and you just look at whether the most likely sentence is actually the real answer so you don't actually sample from it you really just use P of x one to excel does that make sense uh that being said evaluation of open-ended questions is something we're going to talk about later and is actually really important and really challenging yes earlier you mentioned that um like um metrics like flexity are not are not like usually used because it depends on like how you do your terization some design choices I was wondering if you could speak more to that oh um yeah so think about perplexity I told you perplexity is between one and vocabulary size so now imagine that Chad GPT uses a tokenizer that has like 10,000 tokens but Gemini from Google uses a tokenizer that had 100,000 uh potential tokens then actually the Gemini one will will have like the upper bound of the the perplexity that you can get is actually worse for Gemini than for Chad GPT does that make sense so that's just an idea it's actually a little bit more complicated than that but that's just like one uh first or the bit of you can see that the tokenizer actually matters um great okay so evaluation challenges there are many I'll just talk about two really briefly uh one as I told you there are two ways of doing evaluation for these mlu actually there are many more than two but I give you two examples um and it happens that for a long time even though that was a very classical Benchmark that everyone used uh actually different uh different companies and different um different uh uh different organization were actually using different ways of evaluating mlu and as a result you could you get completely different results for example Lama 65b uh which was the first model of meta in the Lama series uh had on Helm 63.7 accuracy but on this other um Benchmark had like 48.8 um so really the way that you evaluate and this is not even talking about prompting this is really just kind of the the way that you evaluate the uh the models prompting is another issue so really there are a lot of inconsistencies it's not as easy as it looks uh first thing yeah sorry how can we make sure that all these models AR trained on The Benchmark okay second thing this is a great question uh chain test contamination uh this is something which I would say is really important in Academia in uh given that the talk is mostly about training large language models uh for companies it's maybe not that important CU they know what they trained on uh for us we have no idea so for us it's a real problem uh so there are many different ways of trying to test whether uh the test set sorry whether the test set was actually in the training Set uh one kind of cute trick um that people uh in in the lab on T lab have found is that what you can do is that given that most of the data set online are not randomized you can just look at and in that language models what they do is just predict the next word um you can just look at the entire test Set uh what if you generate all the examples in order versus all the examples in a different order and if it's more likely to generate a thing in order given that there's no real order there then it means that probably was in a training set does that make sense um so there are many that's like one of them there are many other ways of doing it train test contamination again not that important for development really important for academic benchmarking great so there are many other challenges but uh I'll move on for now great data um so data is another really big topic um at a high level people just say oh you basically train large language models on all of Internet what does that even mean um so or people sometimes say all of clean internet which is even less defined um so internet is very dirty and really not representative of what we want in practice if I download a random website right now you would be shocked at what is in there it's definitely not your Wikipedia um so I'll go really briefly on like what people do um I can answer some questions but I mean data is on its own is a huge topic uh basically first what you do is download all of Internet what that means is that you use uh web crowlers that will go on every web page on Internet or every web page that is um on Google uh and that is around 250 billion pages right now um and that's around one petabyte of of data so this is actually a common common C is one web crowler so people will usually write their own web crowlers what they do is that they use standard web crowlers and we common crawl is one of them uh that basically every month adds all the new websites that were added on uh internet that are found by by Google and they put it in a big uh basically a big data set um so that's on common call you have around 250 billion pages right now so 1 E6 gigabytes of data once you have this uh so this is a random web page like literally random uh from this common craw and what you see is that one it really doesn't look at type of things that you would usually see but actually so this is an HTML page uh it's hard to see but if you look through you will see some content for example here here uh tesing world is your ultimate source for the system X high performance server and then you have three dots so you don't even the sentence is not even finished that's how a random internet looks like uh so of course it's not that useful if you just train a like large language model to generate things like this so what are some of the steps that are needed first one you extract the text from the HTML so that's what I just try to do by looking at uh basically the correct text uh there are a lot of challenges by through this for example extracting math is actually very complicated but pretty important for training large language models um or for example boiler plates a lot of your forums will have the same type of headers the same type of Footers uh you don't want to repeat all of this in your data um then you will filter undesirable content uh so not safe for work harmful content pii uh so usually every company has basically a a black list of websites that they don't want to train the models on that Black List is very long and you basically say if it comes from there we don't train on this there are other ways of doing these things is that you can train a small model for classifying what is pii removing these things um it's hard every Point here that I'm going to show you is like a hard amount of work uh but I'm going to go go quickly through it so filter undesirable content second or fourth is the dup D duplication as I said um you might have things like headers and Footers in forums that are always the same you want to remove that another thing that you might have is a lot of URLs that are different but actually show the same website um and you might also have a lot of like U um paragraphs that come from like common books that are basically duplicated a thousand times or 10,000 times on internet so you have to duplicate also very challenging uh because you have to do that at scale once you do duplication you will do some heuristic filtering you will try to remove low quality documents uh the way you do that are things like rules-based um filtering for example if you see that there are some outlier tokens if the distribution of tokens in the website is very different than the usual distribution of tokens then it's probably some outlier if you see that the length of the words in this website is super long there's something strange going on on that website if you see that the the website has only three words maybe is it worth training on it maybe not if it has like 10 million words maybe there's something also wrong going on that page um so a lot of rules like this yes why we filter out undesirable content from our dat set instead of kind of putting it in is like a supervised loss right like can we not just say like you know here's this like hate speech website let's actively try to Let's actively penalize the for generating we'll do exactly that but not at this step that's where the posttraining will come from uh pre-training um the idea is just to say I want to model kind of how humans speak essentially um and I want to remove all these like headers photos and and menus and things like this but it's a very good uh like idea that you just had and that's exactly what we'll do later Next Step modelbased filtering so once you filtered a lot of data what you will do uh that's actually a very cute trick uh you will take all of Wikipedia and you will look at all the links that are linked through Wikipedia p because probably if something is referenced by Wikipedia it's probably some high quality website and you will train a classifier to predict whether something comes from whether a document comes from one of these references uh from Wikipedia or whether it's from the random web and you will try to basically say I want more of the things that come from Wikipedia references does that make sense so yeah so you will train a a machine learning uh model usually also very simp simple models because you need to do that really at scale I mean just think about the 250 billion Pages uh next one you will try to classify your data into different different um domains you will say okay this is entertainment this is books this is code this is like these type of domains and then you will try to either um up or down weight some of the domains uh for example you might say uh you might see that actually if you train more on code then actually your model becomes bettered on reasoning so that's something that people usually say in a very handwavy way if you train your model more code actually it helps reasoning so you want to upweight the coding uh distribution because that helps for General language modeling skills uh books is usually also another one that people usually um upweight entertainment they usually downweight uh so things like this of course you want to do it so people used to do it maybe uh kind of theistically now there's entire pipelines that we'll talk about of how to do these things uh slightly more um automatically and then at the end of training uh usually train um after training on all of this data that we saw usually train on very high quality data at the end of of training your large language model where you decrease your learning rate uh and that basically means that you're kind of overfitting your model on a very high quality data so usually what you do there is like Wikipedia you basically overfit on Wikipedia yeah and you overfit on like human uh data that was collected um the other things like continual pre-training for getting longer context I'm I'm going to skip over all of these things uh but I just to give you a sense of how hard it is when people just say oh I'm going to train on internet that's a lot of work um and really we haven't figured it out yet so collecting World data is a huge part of practical large language model uh some might say it's actually the key yes about data so basic question so usually when you start with like the terabyte of data after I go through all that steps the typical amount of data you have in and then like how how large a team does it typically think to go through all the steps you talk about so how is the question how large is the data after you filter yeah after you filter and then to go through all the step how large a team do you need to go through like the the other fation sttion uh how slow is it or how like how how many people would you need to be able to do this uh okay that's a great question I'm going to somewhat answer about the data uh how large is the data set uh at the end of this slide uh for number of people that work on it um that's a good question I'm actually not quite sure but I would say yeah I actually don't quite no but I would say it's probably even bigger than the number of people that work on kind of the two tuning of the pre-training of the model uh so the data is bigger than kind of the modeling aspect um yeah I I don't think I have a good sense I would say probably in Lama's team which have like 70 years people I would say maybe 15 work on data uh I yeah all these things you don't need that many people you need a lot of computer so because for data you need a lot of CPUs um so yeah and I'll answer the second question at the end of this slide so as I just kind of alluded to really we haven't solved data at all for pre-training so there's a lot of research that that has to be done first how do you process these things super efficiently uh second how do you balance kind of like all of these different domains uh can you do synthetic data generation that's actually a big one right now uh and because we don't have uh we'll talk about that later we don't have enough data on the internet um can you use multimodal data instead of just text data and how does that improve even your text performance um there's a lot of seccy because really this is the key of most of the pre-train pre-trained large language models so for competitive Dynamics uh usually these these um these companies don't talk about how they do the data collection and also there's a copyright liability issue they definitely don't want to tell you that they've trained on books even though they did um because if not you can uh sue them uh common academic benchmarks uh so that will kind of answer what you asked um it started so those are the smaller ones it's the names are not that important but it started from around 150 billion tokens which around uh 800 GB of data now it's around 15 trillion of to 15 trillion tokens which is also uh the size of the models that are right now the best models are probably trained on that amount of data so 15 trillion tokens uh which is probably I guess two order of manage bigger than that so 80 uh E3 gab so that would be around 100 to thousand times uh filtering of the common crawl if I'm not mistaken um so yeah one very one very uh famous one is the pile so this is academic Benchmark of the pile and we can just look at what distribution of data they have it's things like um archive PBM Central uh which is all the the biology stuff uh here it's Wikipedia you see stack exchange um some GitHub and some books and things like this um again this is on the smaller side so this is if we look at here this is on 280b so in reality it's like 100 times bigger so you cannot have that much of GitHub and and of Wikipedia um in terms of close Source models just to give you an idea uh Lama 2 um it was trained on 20 two trillion tokens lamb 3 15 trillion tokens which is currently the best model that we know on how much it was trained on which is the same thing as this the the the best academic or the biggest academic Benchmark which is 15 trillion tokens GPD 4 we don't really know but it's probably in the same water of magnitude or it's probably around that actually it's probably around 13 um from leaks if the leaks are true um great so scaling laws um any other questions on Data before you go to scaling laws sorry I know I'm giving you a lot of information but uh there's a lot into training at large language models great scaling laws so so the idea is that what people saw um around 2020 or at least from a long time but they've been able to kind of theoretically show it or impurely show it since 2020 is that the more data you train your models on and the larger the models the better the performance this is actually pretty different than what you've seen in this class in this class we teach you about overfitting overfitting doesn't happen with large language models uh larger models better performance um it's something that really took a long time for the community who took this type of class to realize um but for the exam overfitting exists so okay the idea of scaling laws is that if given that you know that more data and larger models will always give you better performance can we predict how much better your performance will be if you increase the amount of data and the size of your model and surprisingly it works uh so here you see three plots from a very famous paper called scaling loss from openi um here you see on the x-axis compute so how much did you train like how much compute did you did you spend for training and here you see test loss so this is essentially I mean it's not perplexity but it's your validation loss um so it's a log of the perplexity and if you put these two on uh log scale uh then you see that uh the the performance or like the this the sorry the the scaling law is linear uh that means that if you increase your compute by a certain amount you can you can say by how much your test loss will actually decrease same thing with data and same thing for parameters if you increase the data set size your loss will will decrease by an amount that is somewhat predictable if you increase the number of parameters it will decre the loss will decrease by amount which is somewhat predictable this is really amazing um very surprising I mean it looks in nocuous when you look at these type of plots but that's crazy because it means that you can predict uh how well we're going to perform in 2 3 years depending on how much compute we will add assuming that these things will hold there's nothing theoretical about it um yes two things one what is the loss that they're using here is this perplexity or so it's it's you know I said perplexity was like two to the power of the LW so this is the the the power of the perplexity and then the second thing is when you like increase the number of parameters or you increase the total data set size going dat times doesn't that just inherently increase your compute like do all this work to just specific no this is a great question so the compute here is actually a factor of two things the data and the parameter what I'm showing here is that you can um well actually we're going to talk about that in details but basically if you increase the number of parameters you should increase the number of data that you have um so you actually don't go multiple times through the same data set no one does EPO in a lar at least not yet uh because we have still kind of enough data um so yeah this is all the same Trend which is increase compute decrease loss yes have we seen the numbers for the last two years or is it still holding it is still holding I I don't have like good numbers to show you uh but it is still holding surprisingly yes is there no evidence like empirical evidence that you plateau expected PL no empirical evidence of plateauing anytime soon um why we don't know um will it happen probably I mean it doesn't need to because it's actually in log scale so it's not like as if it had to go it had to Plateau like mathematically it could continue decreasing like this I mean most people think that it will probably Plateau at some point we don't know when um okay so that's I'll talk more about scaling laws now so why are scaling laws really cool imagine that I give you um you're very fortunate I gave you 10,000 gpus for this month what model will you train how do you even go about answering that question and I mean this is a a hypothetical but that's exactly what these companies are faced with uh the old pipeline um which was basically you tune High parameters on the big models so let's say I have 30 days I will train 30 models for one day each I will pick the best one uh and that will be the final model that I will use in production um that means that the model that I actually used was only trained for one day the new pipeline is that you first find a scaling recipe so you find something that tells you for example oh like one common thing is that if you increase the size of your model you should decrease your learning rate so you find a scaling recipe such that you know if I increase the the the the size of my model here's what I should do with some high parameters then you tune your high parameter on smaller models of different sizes let's say I will say for 3 Days of my 30 days I will train many different models and I would do highper parameter tuning on these small models each of different sizes then I will fit a scaling law and try to extrapolate from these smaller models which one will be the best if I if I train it for much longer or sorry if I train it for a larger model and then I will train the final huge model for 27 days instead of just one day um so the new pipeline is not train things or do high prity tuning on the real scale of the model that you're going to use in practice but do things on smaller ones at different scales try to predict how well they will perform once you make them bigger I will give I will give you a very concrete example right now uh let's say Transformers versus lstms let's say you you have these 10,000 gpus you will not sure which one you should be using should I be using Transformer based model or LCM based model what I will do is I will train Transformers at different skills so here you see different parameters on the x-axis Y axis is my test loss I will then train different different lstms at different scales once I have these points I will see oh it kind of fits a scaling law I will fit my scaling law and then I will be able to predict oh if I had 10 times more compute here's how well I would perform for the LM it's actually slightly less linear for the lstm but like you could probably try to predict where you would end up and clearly from this plot you would see that Transformers are better um one thing to notice when you read these type of scaling laws is that are two things that are important uh one is really your scaling rate uh which is kind of the uh the slope of the the slope of the scaling law the other thing is your um your intercept like you could start worse but actually become better over time it just happens that lstms are worse for both uh but I could show you another one where things you can predict that actually after a certain scale you're better off using that type of model than others uh so that's why scaling laws are actually really useful any questions on that yeah so these are all kind of very how how sensitive are these to like small differences in the architecture like one one like Transformer architecture versus another Transformer architecture you basically have to like fit your own curve and make basically say like oh scaling law has tell me there should be some like logarithmic function let me extrapolate that for my own yeah so uh usually for example if you're an academic and you want to now at least that's like pretty recent and you want to propose a new like activation uh that's exactly what you will do you will fit a scaling law show another scaling law with the standard like I don't know G and you will say that it's better in reality once you start thinking about it in scaling loss terms you really realize that actually all the architecture differences that we can make like the small minor ones all they do is maybe change a little bit the The Intercept but really that doesn't matter uh cuz just train it for 10 hours longer or like wait for the next uh for the next Compu gpus and these things are really secondary which is exactly why I was telling you originally people spend too much time on the architecture and losses um in reality these things don't matter as much data though if you use good data you will have much better scaling loss than if use bad data so that really matters uh another really cool thing you can do with scaling laws is that you can ask yourself uh how to optimally allocate training resources should I train larger models because we saw that it's better when you train larger models but we saw that it's also better when you use more data so which one should I do should I just train on more data a smaller model or should I train a larger model on less data um so chinchilla is a very famous paper that first showed this uh the way they did it I want to give you a little bit of a sense of what these plots are uh here you see training loss again on the x-axis you see parameter parameter differences uh sorry parameter size uh number of parameters so the size of the model and here all these curves are what we call isof flops which is that all the models on this curve H have been trained with the same amount of compute um the way that you do that is that you train you change sorry you vary the number of tokens that we trained on and the size of the models but you vary in such a way that the total compute is constant okay so all these curves that you see with different colors have different amount of computers that were trained on then you take the best one for each of those curves once you have the best one for each of those curves um you can ask you can plot um how much flops it was and which curve were you on and how much parameters did you actually use for training that specific point you put that on the on the log log uh scale again and now you fit a scaling law again so now I have something which tells me if I want to train a model of 10^ 23 flops here's exactly the number of parameters that I should be using 100 100b and you can do the same thing with flops and tokens so now you can predict if if I tell you exactly I have one month of compute what size of model should I be training F your scaling law and I tell you um of course that all looks beautiful in reality like there's like there's a lot of like small things of like should you be counting like embedding parameters like there's there's a lot of complexities but if you do things well these things actually do hold um so the optimal number of parameters that that chinchilla Pap have found is to use 20 tokens for every parameter that you train uh so if you add one more parameter you should add you should train your thing on your model on 20 more tokens so one caveat here is that this is optimal training resources so that is telling me if you have 10^ 23 FL or if you have like 100 I don't know how much that is100 million or 10 no that's much less actually let's say I have $5 million to to train my best model that gets the lowest loss how how what would I train on in reality these companies need to think about inference also if you have a smaller model they will spend less over time um so actually if you consider the inference cost you have other papers that Tred to show that um it's around 150 uh parameters per sorry tokens per parameters because you prefer having a smaller model cuz over time you're going to you're going to actually um spend less money on inference of these models so 150 to one that's around what the best models are trained on right now at least the ones that are that are used um in practice for in production great any question on chin great oh sorry in practice how expensive is inference for these models rela to train actually very expensive uh I will not talk about inference because that would be another entire lecture but just think about Chad GPT where they have I don't know how much it is now like 600 million people that used it um like that's a lot um yeah so it's actually very expensive there's a lot of optimization you can do for in though um and that's an entire other lecture so I'm going to skip that uh this time but it's very interesting okay tuning um as I said there are many things that you can uh answer with scaling laws I just try to give you two examples uh but really there are many things what data do you use what mixture what data mixing waiting you use data mixtures that's what we talked about before uh what architecture you use whether you should make your models uh wider or deeper um should you be paying for more gpus or actually collecting more data um all these things are things you can try to answer with scaling laws one thing I want to say is the bit lesson if you ever heard of Richard sudden a very famous blog post in 2019 um what he realized uh which I think not enough people realize I didn't definitely did not realize at that time um is that once you see these type of scaling laws you know that the more compute you have the better models you will get so with skill you will get better model and you also know by Mo law or these type of variant of Mo law that you will always have better compute then the only thing that matters is just to have architectures that can leverage computation so what matters is basically systems data and less so the architecture like the small architecture differences like your your your activation and things like this uh so I think that's like one of the reasons why most of research focuses on um some things that for industry matters less and I was one of those researchers for a large part of my my career um so don't spend time over complicating do the simple things do it well seal them that's really what openi taught us with um with chat gpg and with all the gpts before okay I want to give you some backup the envelope computation so I might be off by a few factors here but I just want to give you a sense of how costly it is to train some of these models I'll give as an example Lama 3 400b which is currently the best open source model that you can get uh it was trained on 15.6 tokens it has 45 billion parameters so just now that you know what is like this uh optimal tokens per parameter that's around 40 so that's a little bit more than chinchilla but less than this like inference uh optimal um model so they went for training optimality uh flops for this model so one simple uh way to compute flops is six uh times the number of parameters times the number of data you train on uh so if you do the simple calculation here it's 3.8 e25 flops the reason why this is important is that if you follow the little bit the news there's an executive order from Biden that basically says that once you have uh 1 e26 parameters uh sorry flops uh then you have special scrutiny on your models so they went 2x less than that so they really went right below this to not have special scrutiny so 38 uh I might be off by a little bit but it's definitely under the 1 26 oh um so paramet p is parameters n is data number of tokens this is a uh this is just an approximation we yeah okay uh compute and we know that they trained on 16,000 h100s um and we know the throughput but they they said it too uh so if you do the computation it takes around 70 days um or 26 million GPU hours at least that's with my uh back of the envelope computation they actually said that they use 30 million instead of 26 million GPU hours um so maybe they had like some uh some challenges I don't really know but if you follow the simple computation it's around 70 days um cost uh I mean this it's hard to to approximate but I'm just going to say it's kind of the rent like what if I were to rent h100s that many h100s for that many days how much will I pay uh h100 a lower bound on the on the renting uh cost of h100 is around 2 hours uh $2 per hour so if you multiply this by 26 million uh hours uh you get 52 million uh dollars so they probably pay less than that but not actually much less because all these um all these services that actually rent gpus they don't make that much money so it's it's probably slightly less but not that much less um now salary I said 50 employees 500k per year say yeah it's probably the right ballpark 25 million uh so if you put all together around 75 million um dollars for training uh this Slammer model I'm probably off by like 10 million but but that's kind of right uh bpk carbon emitted um a lot of people might ask like also the cost is not the only thing that is important so I did the computation um it's around 4 uh 4,000 um tons of CO2 equivalent that is actually only 2,000 return tickets from JFK to uh London so right now uh carbon emitted is actually not uh I mean it's huge but it's not like um meaningful yeah yet I think in maybe GPT 6 gpt7 once you multiply this by 100 that might become a real issue right now it's still not uh I think um an issue in the grand scheme of things next model the way you should be thinking about these models is that every new generation the number of flops essentially uh multiplies 10x or at least that's what they try uh if they have enough energy and if they can buy enough gpus uh great any question on these back of the envelope math no okay so now we talked about pre-training I wanted to also chat about systems because now we know computer is really important so there's a question of how do you optimize the how do you optimize your computer I will leave that for the end because I'm not sure how much time we will have I think it's important but hopefully I I'll be able to to talk about it later it's slightly different than what we've been talking about right now so I'll move on to post training for now so the task of post training ER the reason why we need to do Post training is as I told you before um it's to make AI assistants so language modeling is not uh really the thing that you want when you have an AI assistant uh for example if you ask to gbd3 which is a purely language Model A pure language model not a um not an aligned one if you ask a question like explain the moon landing to a six-year-old the completion that you would get is something like explain the theory of gravity to a six-year-old because what it learned is that on on on internet if you have one question you usually have maybe another bullet point of other similar questions you don't usually have question and then answer later uh this is not what you want from an AI assistant so how do we uh do this alignment which is this post training and making these models assistance um so the goal of this alignment is to basically get LMS follow the instructions that are given um by users and and maybe some designers kind of desires um so think about moderation you don't want the model like open ey definitely doesn't want the model to say stuff that is very toxic um so here you see on the left hand side uh that when you ask a question it actually provides a a real answer so it's not like uh before the llm and on the right hand side you see that it would if you ask to write a tweet describing how a certain part of the population are evil it will say that it cannot do that um so that's kind of this alignment uh the background here is that uh basically the data that you want for training some of these models um is like we know what we want which is just asking humans this is a question this is the answer that you want uh but the thing is that it's very expensive to collect that data and it's hard to find it online uh in contrast pre-training data is not what you want but there's a lot of it um so what what we will do a the main idea is simply take a pre-train large language model pre-train all of internet and then you just fine tune so you just change a little bit of weights on the type of data that you actually want and hopefully given it you already pre-train it on all of Internet it basically learns or knows how to speak in English and and knows a standard um language syntax uh then you can really find tune in with very little data okay sft so supervis fine tuning is really exactly what I just said which is the idea of fine-tuning the large language model on uh basically the desired answers that are collected from humans um so why is it called supervis fine tuning because you basically want to do language modeling on the real ansers so language modeling is this like next word prediction and and that's the fine-tuning part and then you want to do it on desired answers given by humans so that's why we call it supervis so how do we collect this data well we I just said it you just ask humans uh to to tell you this is the this is a question this is the answer that you uh you would want from some of these models so this is an example um sorry I can't read very well on my computer but uh my kid uh needs to do a science um no let's read this one can you write a short introduction about the relevance of the term monopsony and then it says monopsony refers to a market structure blah blah blah and that's a human that wrote that um so actually this is open Assistant which was a a way to collect um uh data online by humans so this type of supervised fine tuning or alignment is really the key of Chad GPT this is what made uh the big jump from gpt3 which was mostly something that was known by AI researchers to Chad GPT which became known by basically everyone um so the problem with uh human data is that it's uh very slow to collect and very expensive um so one possible simple idea is to use llms to scale data collection uh so that's exactly what we did with alpaca uh one year ago what we did is that we asked uh humans or we use a data set of human uh question answers so there were 175 uh question answers here and we asked the best mod at the time so text3 to basically generate many more of these question and answers so all we did is like this is what humans would write now write similar answers and similar questions and we collected 52,000 LM generated question answers and then what we did is simply we took Lama 7B which was the best pre-train model at the time and we just fine- tuned this with supervised fine tuning as I told you and that's how we got um the Alpac s7b model uh and this is the type of data that we collected so things like what does algorithm mean an algorithm is a step by a stepbystep uh set of instruction used to solve a problem or achieve a goal blah blah blah blah so the data is not actually it's actually pretty good given it was LM generated by LMS from essentially two generations ago um so that really started at least for us kind of as an academic replication of chat GPT uh now it really there's a big field of like synthetic data generation of how to use llms to basically make development of llms faster um and by basically by decreasing the amount of of human hours that you need quantity of data so we talked about what type of data and how we collect it um one thing which is surprising with sft is that you don't need that much data uh so what this paper showed this is called Lima is that if you have if you scale the amount of data that use from uh supervised fine training from 2,000 to 32,000 it really doesn't help much so here scaling laws definitely don't help um so the the intuition here is that all you learn um is is you learn how to format your desired answers another way of saying it is that your pre-trained models they essentially model the distribution of every user on internet one that might write bullet points another one that might answer qu answer question with an answer so all you tell your model is like wait you should actually be optimizing more for this type of user than another one so you're not actually teaching it and you're not teaching anything through this um sft uh so supervis fine tuning all you do is you tell the model to kind of optimize for one type of user that it saw already in a pre-train data set so the knowledge is already in the pre-train llm uh and you basically just specialize to one type of user great any question on sft yes so I know it's a big issue with synthetic data where uh if you keep generating data from the same distribution eventually you're not learning a new distribution you're essentially playing with it it just bootstrapping that yeah surely you can't scale that forever right you can't keep going on and generating from the same distribution you hope to learn something new yeah uh so are there it's an active area of research but any thoughts that you have around how people are maybe thinking around this and uh better ways to bootstrap or to give up on this idea and and realize that the chart shows you don't need that many so just get humans to generate 2,000 really good uh yeah so that's a very good question uh so for the data stuff so I'm saying it's not that important for sft but there will be another thing we'll talk about right after where actually data does matter my intuition based on not that much empirical results is that you can still get um even though you use your LMS if you use purely LM generated text and you do that for like three four generations of llms I agree with you that probably you won't improve much but for me what is important is how do you use like human in the loop with llms not purely LMS not purely uh humans but maybe what you can do is just have the model generate some new text and just uh humans write a few Edits edits are much faster than writing the entire text and I think that if you have that type of collaboration then from like kind of an information theoretical point of view you still get additional information but you still much faster than if you use humans and I think that as a field we'll probably move towards these type of things uh which is um really just finding the examples that are important and and asking humans it's kind of active learning just asking humans exactly when uh you need to to get inputs yes do we train with like the same loss function the same like General training algorithm for the supervis tuning bit as we do for the for the pre-training right because like the examples you showed I think the the important thing of the good examples is they're like supera accurate there's these more complex still just like chain same so that's why here I yeah I didn't maybe didn't emphasize enough this is just language modeling fine tun the LM with language model on the desired answers so this is literally the same loss um it will be different in two seconds but the first step of sft is literally the same loss where you just say Okay I want to actually specialize on that type of data so there's even a question of like what is pre-training what is post-training because in reality it's just like a different data that you use the reason why we usually call it post training is that the way we collect that data is very different great great questions uh yes maybe it's the same question but why would these 2,000 examples have such an overweighted influence you tun so that's why we uh also that's another reason why we call it post training is that we use different type of hyper parameters so you know I told you basically at the end of pre training you essentially end up with a learning rate of zero and here you're going to increase your learning rate so like 1 eus 5 one E Yeah and and so um the weight that you give to them is actually different um okay uh Second Step or second part of this post training um is what we call reinforcement learning from Human feedback or rhf uh some of you might have heard of that um the idea is that sft has a problem namely that uh you do behavioral cloning which means that you just try to clone what the humans would say and that had that has many issues one of them is that you're bound by human abilities so if um like humans actually humans won't generate the things that they think is actually the best thing to generate so if you ask me to write a book I mean I can definitely enjoy a book I can probably say one book is better than another but I'm definitely not going to be as good as writing the book that I want to read uh so you're going to be bound by the human ability to generate things even though the humans might be better at distinguishing between things that's one issue issue number two uh I find that actually pretty interesting is that it might if you ever heard of the word hallucination so this is llms generating F like false information hallucination might these people have um hypothesized that that can come from the supervised fine tuning even if you do supervised fine tuning on data that is correct and the reason why that is is that if uh given I told you that basically sftt is with very little data and it's with data that doesn't the model doesn't learn anything new so what if the human gives an answer that the model didn't know was true from the model perspective you the human basically is telling the the model uh generate this thing that seems plausible but actually have no idea if it's true or not um so just to give you a very concrete example if we go back to this uh monopsony example can you write blah blah blah about monopsony uh imagine that a human uh wrote a reference on this type of book um and that book might exist that might be a correct reference but what if the llm never saw this reference during pre-training then it doesn't know that it's a correct reference so really what you tell the model is to generate or make up some plausibly sounding reference um rather than actually tell the real reference that it saw during pre-training uh so hallucination might be um uh a re like might be caused by this sft that's problem number two does that all make sense great problem number three price generating the ideal answers is very pricey and that comes back to your question um of like humans writing answer is actually pretty expensive um so that's where rhf comes in the idea is that instead of cloning the behaviors of humans we're going to maximize human preference um and the way we're going to do that so the pipeline is that for a certain for every instruction you're going to ask a model to generate two answers um and usually use a pretty good model so you usually don't use an LM here you use a sft uh fine tune you use a fine tuned llm already to give like pretty good answers and then you ask labelers which of these two answers was better so select the preferred one and then with different type of algorithms we're going to talk about the algorithms um you just fine-tune the model to generate more of the green thing than the red thing so more of the good stuff uh so now the question is how and we're going to talk about that right now so there are two ways that we're going to talk about and two that are mainly used in the community um the first one is simply the idea of of using reinforcement learning so hopefully you all know what reinforcement learning is now um so when you think about using reinforcement learning one important question is like what is the reward that we're optimizing uh so in this case there are really two options that I could think about the first one you could just say I'm going to compare the output generated by some baseline the output generated by my model U and I'm just going to ask the human to say which one is better and I'm going to use this as a reward so if I'm better than the Baseline this is a plus one if not it's a minus one one uh so now it's binary reward the problem with binary reward is that it's very sparse and you don't get much information out of it uh like maybe your answer was slightly better maybe it was like way better and you don't really know from this um how much better it was so option two is that you can train what we call a reward model which is simply a classifier uh so you use machine learning to to classify how much better uh two outputs are from the preference from the perspective of the human um so this is a little bit meta but what you basically do is that you train uh you take um a reward model R which is a uh just a large also a large um a large classifier and you basically ask this reward model you give it the input and the actual output that you have one of the two outputs uh and you just um exponentiate that so that's the soft Max law that you all know about and now you divide by um the the exponential reward uh on the first example sorry on the first output and this is on the second output and you basically train so the reason why you do that is that you train your your model you train this reward model to be able to classify um how much better one output is to another one so another uh slightly less convoluted way of saying it is that your reward model will output some reward that will be used as the logits of your soft Max so now if you have high logic in your softmax it means that you highly likely this um output is better uh so that's what we call Bradley ter model yes is this reward model going over the entire output or is it going um so this takes the entire uh yeah this takes the entire output at once so it takes all the input and all the output and it gives one number yes would human be sorry with the reward model where would a human be like oh I see okay sorry maybe I wasn't clear um you train this reward model to fit this green and and red preference from humans so basically you train a classifier to say whether the humans prefer red or green uh but instead of using the binary reward which is what the human would tell you you basically use the logits of the soft Max and the thing with the logits is that that logits are continuous so now you know that if your reward model said it has high logits then in some ways the human highly prefer this answer to some other answer great um so as I just said continuous information so it's better so that's what people uh use in practice or at least used to use in practice I'll tell you about uh the other algorithm later uh so what you do at the end is that you basically try to just use reinforcement learning that you know about now we know we have reward what you sample through is the generation from your large language model um and then you just use some regularization term so the reason why you do this regularization term is for avoiding what we call over optimization so this reward model might not be really represent like might not perfectly model human preferences so you don't want to maximize this thing to essentially Infinity um and you do it using uh po which is a common uh reinforcement learning algorithm um one thing to note here because it will be important for later is that when we use maximum likelihood um sorry now the large language models are actually a policy for your reinforcement learning it's not maximizing maximum likelihood anymore which means that you're not modeling any distribution anymore and the reason why this is important is that models that went through this type of Po actually don't give you likelihoods of text that are meaningful cuz what you optimize them to do is B basically just optimized for generating the most likely thing not optimize for modeling like all the answers that humans might say another way of saying that is that there's nothing that incentivizes here the model to not give a like a um a single possible generation nothing here says it's good if you have some distribution with some entropy um okay if you haven't followed it's not that important but just good to knowe great so PO is exact what chat GPT did originally so here's the on the blog post or what they have is step one do supervise fine training which now you all know about step two train a reward model on human preferences step three do po multiple steps which is where you see this this blue arrow so you continue you train the model once with po you collect new data you continue uh and that's why and that's exactly what Chad GPT did uh that was a big breakthrough between gpt3 and Chad GPT one thing to note is that uh P has many challenges reinforcement learning is something that's super nice theoretically in practice anyone who ever worked with reinforcement learning knows it's such a mess uh there's a lot of things like roll outs out of Loops clipping so many complications um so it's messy this is the idealized PO used for LM settings so that's already much more complicated than this expectation we saw before and in practice it's actually much more complicated so we have one implementation of it that we had to do and I'm not going to go through it but basically you have like so much stuff that you have to think about when you implement that type of of uh po algorithm so you have clipping everywhere you have a lot of complexities and things are not well documented all this to say um that we're going to there was a new method that was proposed uh also from Sanford one year ago called DPO which is essentially a simplification of Po um and the way uh what they did or the idea that they have is that instead of using reinforcement learning you can just maximize the probability of generating the stuff that you like and minimizing the probability of the stuff that you don't like uh so if you think about the human preference the red and green maximize uh green minimize red um so the loss is actually this one uh where what you see this is simply um some log of the model so this is the likelihood of a model generating the things that the human preferred given the the inputs um and what you try to do is basically maximize uh the likelihood of generating the things that you like minimize the likelihood of the things that you don't like um all the rest of the terms here it's not too important it's actually really not that complicated to understand but at a high level it's really just maximizing the things you like minimizing the the rest um and one thing to note uh which I was going to say just here is that actually all the rest is chosen such that um the global Minima of of Po and a global Minima of like this DPO under some assumptions are essentially equivalent so this is the right thing to do mathematically I'm not going to go through the derivations but that's the right thing to do uh it's pretty different with Po in the sense that now and with P what you had to do is collect the human preferences then train a uh reward model with maximum likelihood then use reinforcement learning now all you do is basically maximum likelihood much simpler yes I mean yeah so it seems like this is a much simpler and B like what you just intuitively do if this why did they start with this reward model like what what led them doing that I think it's a great question uh I don't really know what I can tell you is that at open ey the people who did the um uh who did basically this PP uh sorry who did Chad GPT initially are the ones who actually wrote Po and I think they were just like there are a lot of reinforcement learning people and I think that for them it was very intuitive um so there's also some additional like potential benefits for example I don't want to yeah for example if you use the reward model uh the cool thing here with reinforcement learning is that you can use unlabeled data with the reward model so here you can only use the label data for doing DPO um for PP for po you first train your reward model and then you can use unlabeled data uh where the reward model will basically label this unlabeled data so there there's additional kind of potential uh there could be potential improvements in practice it happens at down and on and I think just that a lot of people in this team were reinforcement learning experts including uh the main author of Po John hman um so much simpler in poo and is basically performs as well uh so now this is the standard uh thing that people use at least in the open source Community I believe it's actually the standard also in in Industry so that's called DPO gains um so those are all the papers on the left here this is on a summarization task you see all I want to show you is that basically the pre-train models uh were okay and they improve with scale if you do supervised fine tuning you improve them a little bit more if you do po or something with all HF with human feedback you get performance that are as often times depending on a benchmark even better than uh humans so this is the human uh reference summaries same thing this is on a uh on a paper that we have Alpaca Farm where we see uh the evaluation here is not too important but basically you see pre-train model you jump to sft and then you jump to PPO and popo have the exact same performance so basically all HF helps that's kind of the conclusion and DPO is simple uh data uh the way that you collect that type of data um first idea is just use humans as we already talked about uh guidelines are very complicated for what humans should be labeling and and it's really not that easy and actually if you ever do some of the labeling you will see that it's extremely complicated like if I zoom in to this uh here I have a question tell tell me about self-driving cars and you read both self-driving cars are vehicles that are capable of detecting their surroundings blah blah blah self-driving cars are cars that are equipped with sensors blah blah blah to navigate without the need for a driver I mean both seem okay like which one is better it's actually hard to say at a glance um and as a result uh the problem with humans is that you will start optimizing a lot of like high level features for example the second one is longer I can guarantee you that most humans will choose second one even though I mean maybe the first one is better I don't know I haven't read it carefully so challenges with humans first slow and expensive uh second as I just mentioned it's hard to focus on things that matter like correctness and people uh usually look at things that don't matter as much like the form like length uh and as a result so what I show here is that uh when you do lhf the more you do of lhf the longer the output of the of the models become so if you've ever been annoyed at chat GPT answering you super long sentences this is because of all rhf um annotator distribution shift uh like the distribution of annotators that you use matters a lot and you have to think like what is what is even the humans that we want to represent in these models uh now the question is like crowdsourcing ethics uh like usually these basically a lot of the the labeling that is done um like the people who do them are not paid well and they have to go through a lot of toxic data uh because you basically want the model to avoid saying the toxic data um so crowdsourcing ethics too so many challenges with human data um so what we did also last year is again the same thing as alpaca just the idea of like oh well they're challenges with humans maybe we can just replace them with llms uh so what we did is simply replace um oh I see that I'm just realizing that the slides are not sented anyways uh you replace a human preference with LM preferences uh so here on this uh figure you see on the xaxis the price that we paid uh for collecting human data it's around $300 for 1,000 examples and this is on mechanical turkers which are usually like cheaper than than maybe some of the other um companies that you could go through and on the Y AIS it's basically the agreement with uh other humans with the mode of other humans and what you see is that actually as I told you before labeling is really complicated humans agree with themselves only around 66% of the time on a binary Tas and it's not that the humans are not good here because uh we were five main authors on this paper we tried to label this data ourselves and we only had like say 67 or 68% accuracy even though we talk like we talk for like 3 hours of how we should be doing labeling really it's complicated it's not an easy task um and here I just showed many different models and um basically you see that models are much cheaper and they can actually get higher agreement with the mode of humans than human humans themselves and the reason why is because humans have a lot of varant models have no varant so they might be a little bit more biased but have less virence uh so it works surprisingly well and now it's kind of the standard in open uh Source Community I think even in Industry a lot of people use both humans and llms for improving uh the colle collection of allf data um and this is like this is the paper from last year but honestly now it's more like that llms would be around this agreement and this cost so around I would say 50x cheaper than humans and better agreement with human than humans themselves okay so that gets us to evaluation of post training um that goes back to your initial question at the beginning of the lecture how do you evaluate something like chpt uh the answers that chpt could give are basically unbounded and it's not that there one right answer there are many answers that are just as good um so there are many challenges one you can't use validation loss because one method might use po the other one might use DPO validation loss is not comparable second you can't use Cal uh sorry perplexity that's the thing I told you before these models uh are not calibrated they don't give distributions they they just optimize for one thing so you can't use perplexity for actually evaluating uh these type of models once they're aligned sorry one Z lined third uh there's a large diversity of questions that human might ask to these models generation open QA like some question answering some summarization and all of these things so there's so many things you have to cover um then the tasks are really open-ended so it's very hard to automate so that's what you were alluding to before so the idea uh is that instead of trying to come up with really easily automated uh benchmarks uh it's just we're going to ask questions that that users actually ask to these models in practice and we're just going to ask annotators to say between these two models which one is better like what's the what's the better output so basically do exact same thing as um basically the data from rhf but you use it now for evaluation yes I'm not sure I understand what you mean by like can't use perplexity and not calibrated right like LM is still doing like next token prediction so I can't so think about um the optim solution after doing PO is basically one model that gives you uh essentially a Delta um like basically says that there's only one sentence that is that could be generated for that question so now if you use it on something that is slightly semantically differently different it would actually give a likelihood of zero for that answer so in reality it's not that extreme because as you say it's still a distribution but I just shows you that there's a there's a fundamental issue with perplexity once these models are not llms anymore they were not trained at least with P they were not trained to to do maximum likelihood anymore they were trained to be policies okay um so probably the most common or like the most um yeah the most common Benchmark or the most trusted one is what we call Chad uh sorry chatbot Arena uh which is basically go on internet have random users on the internet blindly talk with two chat Bots just ask many questions see the two answers and rate which one is better and and you do that over hundred of thousands of users and then you get uh the actual preferences and you get rankings of models uh so you can go right now on chatbot Arena and actually interact with these models um one potential issue just to highlight is that while people who want to do these type of things are usually more like Tech driven um or like techsavvy uh so a lot of the questions that you will ask are more like Tech stuff discussing software errors inquiries about AI tools and all these things um so another issue is cost and speed if you really want to use something like this for development process um it will be too costly because you would need to basically pay a lot of humans to do that so one simple idea is again as we said many times just use LM instead of humans uh you probably know the drill at this point uh steps for every instruction generate outputs by some baseline and the model that you want to evaluate um so here you imagine that I I'm comparing an answer from Chad GPT and from I'm just asking a model uh another model uh which one is better and I just basically average that out uh yeah I asked gp4 which one is better I average that out over my entire distribution over my entire Benchmark or data set and that gives me a RN rate so RN probability for one model compared to another one and now you can rank models uh and this is the Alpa eval uh leaderboard so the benefits of this is that actually we show we get 98% correlation with Chad B Arena so very high correlation with humans um so this is yeah comparison with correlation with other benchmarks and it takes less than three minutes and less than $10 to run so it's pretty cheap um there are downsides though uh one of them is purus correlation um so as we already saw before LMS prefer this is one SP correlation not many I'll just talk about one LMS prefer longer outputs actually humans also prefer longer outputs but the problem or the issue once you use llms is that once there bias you will continue optimizing that humans at some point I can guarantee you if I ask a simple question and you give me five pages of answers I'll be like no I don't like that answer but LMS if they have this bius and they were trained for that they will continue preferring longer outputs so uh here we see um the the preference just showing that like humans and models prefer longer outputs um and here is another view of the initial apaka eval data uh Benchmark where when we asked um when we we rank gp4 when we look at the Run rate of gp4 versus actually uh gp4 itself if we com if we use the standard GPT 4 it gets 50% kind of by definition because we're comparing GPT 4 versus gp4 but if we ask a gbd4 to be slightly more verose so we just say in the prompt be Vos in your answers then it gets a r rate of 64.4% so really there's a huge variance and if we ask it to be concise it gets 20% so there's a huge variance depending on um whether you ask it to be concise of that's very annoying um so one possible solution which is what we did is uh just use some regression analysis I'm not going to go into details but basically use Cal inference tools to control for length and right now uh actually length matters much less so if you ask it to be veros we still get some gains but much less great so that's all about post training and now for the next eight minutes I might talk about systems or just answer questions yes can you um go back to your post training in terms of post training how did we tune those parameters using the small body of fine-tuning data and have such big effect on the model you mentioned earlier that there's a different set of hyperparameters are we changing just some of the weights the later weights or all the weights what's actually happening yeah uh yeah I I kind of skimmed through all of this you change all the weights actually um industry would change all the weights in open source land you might have heard of Laura which is going to change basically only some of the weights or it actually to be more specific it's going to add some differences to the output of every of every layer but but in Industry you're going to just fine tune all the weights um and also to say something else about the data actually the SL St all HF you usually going to collect uh a lot more data than with sft so if fft is like 5,000 10,000 maybe 50,000 with rhf I think you're going to be more around like the 1 million uh order of magnitude it's still much less than pre-training though yeah because pre-training is 15 trillion tokens I mean this is like that's not even a drop and yet you influence the weight a lot so because you do it I mean you have to think that how you do it is you use um I mean as I said the learning rate that you're going to use is going to be different but also you only do that so just imagine if I train even if I train on one sentence but over and over again all at some point my model will only that sentence even if uh it was just one sentence instead of the 15 trillion tokens so if you use a large enough learning rate and for enough time you will basically overfit that sentence so the the the key thing to to remember is that um the data is not I it's not as if you mix some posttraining data and some pre-training data you do pre-training and then you just start fine-tuning only on the post trining so another way maybe another perspective is that the post the pre-training is just the initialization of your model and once you view it that way that this is just initialization of Weights then there's nothing special like you don't need to remember that you train a lot of data before the only thing that matters is that you had an initialization and now I actually train a model so maybe think about it that way like there's a there's a mark of property in some way just like you had your weights this is my initialization now I'm training that one does that kind of answer your question kind of but you said something just now about it's almost the equivalence of just rerunning the find tuning data many times is it actually is that what actually happens in order to give so much more preference um you might I actually don't know right now how they do it in Industry when we did alpaca we had to do three box so you did run it three times to it um but I mean even the number of times that you run it through it's actually not important the only thing like the only thing is the is kind of the effective learning rate that what matters um so yeah great so I think I have five minutes [Music] right okay I might try to give a high level Overview at least from one of the systems trick systems as we said uh for everyone Bott neck is a sorry compute is the huge bottleneck uh one question you might ask is why not buy more gpus uh gpus are expensive but also are scarce even if you have $10 million right now you cannot buy the best gpus um there's oh yeah there's also some physical limitations when you have when you have multiple gpus you have to communicate between them that takes time um so just buying more gpus is not that easy um so it's really important to think about how do you allocate resources and how do you optimize your pipeline so system 101 on gpus I'm sorry I'm going slightly faster I hope for that some of you at least can follow uh gpus are basically optimized for throughput CPUs are optimized uh for latency so gpus the way you have to think about it is that there's one Comm there's one command that is run on many many Calles at the same time on different type of data um so this is how you see a GPU you see there are many different CES we call them streaming multiprocessors which is very different than the usual CPU architecture so just think High throughput paralyzation for gpus uh gpus are optimized for fast matrix multiplication so every time you will do uh you will do something on GPU if you can do it with a a matrix multiplication it's going to be 10 times faster than with anything else uh that is a little bit annoying because it means that we're kind of uh bottlenecked to doing anything with Matrix multiplications um another thing to note with gpus is that compute has been improving faster than memory and communication so right now gpus usually are hard to keep uh like the data that you send that send to gpus is actually hard to keep up with the processess so most of your gpus are actually going to be idle if you just run normal code if you don't optimize your code so communication and this will continue over time another thing to know about gpus is that there's a memory hierarchy this is the same thing actually with CPUs but basically the closer you are to your cuse the less memory there is but the faster things run if you're further more memory slower um okay I'm going to skip that okay actually I'm going to say it I told you about this uh the fact of communication uh the metric that people usually look at is model flop utilization so what is the theoretical maximum that GPU could run at no more flops that you could use per second divide sorry the number of OB observed through put divided by this theoretical um maximum and in general if you reach 50% you're very happy like Facebook I looked at Lama was at 45 or something like this so that that means that data doesn't come fast enough even for these big companies so one simple trick and that might be the only one I'm going to tell you about is low Precision one simple idea is that well if I'm going to put my floats in lower Precision then there's going to be fewer bits that I have to send to my gpus if there's fewer bits it's faster communication lower memory consumption things are going to go faster uh and for deep learning it just happens that de decimal is not that important uh so so when you do matrix multiplication when you do like for example SGD there's already so much noise that if you update something by 0.01 or 0.015 who cares uh so basically instead of using uh 32 bits per float which is um what people used to use or 64 for example which is what you would use in other domains you use 16 bits uh for matrix multiplication so for every float you use 16 bits um and for training you have this type of like uh what we call aut atic mix Precision which is that uh some of the things are in 32 bits others are in 60 bit in 16 bits um generally the way you should be thinking about it is that your weights are stored of your model are stored in 32 bits um but just before the computation you put everything in 16 16 bits like this you do computation super fast and at the end you update your weights in 32 Bits And the reason why you do all the updates in 32 bits it's just think that if your learning rate for example is very small you still want to be able to like make a difference in your weights uh so all the computation is done in 16 bits but the weights are actually stored in 32 bits so that's like the standard way that people are doing it um okay I'll actually talk just about this and then I'll skip all the rest operator Fusion because I think this is actually pretty cool as I just said communication is very slow and actually every time you use a pie torch line it basically moves variable to Global memory of your GPU so when you have something like this x do cosine uh equal X1 and then you do X1 do cosine what is happening behind the scenes is that you take the X which is data you ship it to your um to your actual processes of your gpus you apply the coign you ship it back to the main memory of your GPU and then you see the next sign you ship it back to the computer to the GPU processor you apply another cosign and you ship it back again um so another way to see that is that you go from your Dam which is your Global memory in your GPU and you ship it to compute you ship it back for every line This is a naive way of doing it this seems very wasteful um so the idea simple idea of operative Fusion is just communicate do all the computation ship it back once and this is exactly what fuse kernels are um so if you ever want to make your comp your computations in pytorch much faster just apply torch. compile on your model this is going to make your model around two times faster and what it does is simply that it rewrites your code uh your P like your py torch code basically in C++ in Cuda uh to to do the communication only once then do all the operations then uh ship it back okay I'm not going to have time to talk about tiling tiling is important paration paration is important um and mixture of experts mixture of experts is important Outlook there are many things we haven't T talked about we haven't talked about architectures we definitely haven't talked about inference um there are many other things that are important with LMS what is the UI that you use I mean arguably chat jpt the big novelty was just have a simple UI to use it multimodality what are all the misuses you could have uh the fact that there might not be enough data on the internet to train all these models legality of data collection so many other things if you are interested in all these topics uh I would suggest three classes cs224n is probably the one that touches the least on uh LMS uh but it gives some background and historical context um of all the LMS and gives kind of some adjacent material CS 324 I think it's called Uh I think it's just called large language models uh more in-depth reading and lectures on everything I talked about CS 336 which is large language model from scratch you actually build your own llm uh it's an amazing class also given by my two supervisors very heavy workload so be careful and um great"}], "15. Input Markets I\u2014Labor Market": [{"content": "[SQUEAKING]\n[RUSTLING] [CLICKING] JONATHAN GRUBER:\nAll right, let's get started today with our\nlecture on factor markets. So when we talked\nabout producer theory, we talked about input\nprices, that firms had prices for their\nwages and their capital. And we just sort of\nposed those as given. I just sort of gave\nyou values for the wage and the renter rate of capital. But we never really talked about\nwhere those prices come from. Given that they may be\nthe most important prices in our whole economy,\nit's probably worth spending a little time\non talking about where do w and r actually come from. And that's we'll do for\nthe next three lectures, is talk about factor markets,\ntalk about the markets that give us the price\nof labor and capital. We're going to start\nby talking about factor demand, the general demand\nfor labor and capital. And then we'll move on to\ntalk about factor supply, where does supply come from. We'll then develop\nthe equilibrium, and that will tell us where\nwages and the interest rate come from. So that's sort of the\nmap of where we're going, is we're basically\ngoing to develop the markets that give us the\nwage rate and the interest rate. So let's start with factor\ndemand, factor demand. And let's start, and\nwe're going to start with the cleanest case. We're going to assume that\nfactor markets are perfectly competitive. So unless I say\notherwise, we're assuming the market for\nworkers, or the market for machines, or capital,\nis perfectly competitive. OK, we'll come back and bend\nthat a little bit later. So what that means is that\nthere's basically many sellers and buyers, OK? So any worker is\nbasically competing with lots of workers for jobs. Any firm is competing\nwith lots of firms to hire the workers, OK? And we're also going-- we're going to assume a\nperfectly competitive input market, that is lots\nof firms and workers competing to match\nwith each other. We're also going to assume a\nperfectly competitive output market, that is, we're going\nto examine this for the case not of a monopoly firm but of\na perfectly competitive firm. So just think of this, you have\na perfectly competitive firm competing with lots of other\nfirms to hire workers, OK? So let's start by talking\nabout short run labor demand in this context. Let's talk about short\nrun labor demand. Now, in the short\nrun, capital is fixed. So our decision is just, do\nwe add another worker or not, or another hour of labor or not. Like I said, the units\ndon't really matter here, but let's take in\nterms of workers. Do we add another worker or not? Well, as with everything\nelse in this course, we want to consider the marginal\nbenefits and the marginal costs of that decision. The marginal benefit\nof an extra worker is that one extra unit of\nlabor raises productivity by the marginal\nproduct of labor, OK? One more unit of labor\nraises our output by the marginal\nproduct of labor, OK? But that's not the only\npart of the benefit, because we don't actually\ncare as a firm about units of output. We care about revenues. So the benefit of a worker is\nnot just the how many units it produces, but the\nvalue of those units. And what is the value of\nthe next unit produced? It's the marginal revenue. So the value of the\nnext unit of labor is what we call the marginal\nrevenue product, MRP sub L. The marginal\nrevenue product is the marginal product of\nlabor times marginal revenue. That's the benefit of\nanother unit of labor. It's not just what they\nmake, but what it's worth. It's not just what they make,\nbut what it's worth, OK? So that's the marginal benefit. The value of another\nunit of labor is it makes marginal revenue\nproduct amount more stuff, and you sell that at\nthe marginal revenue. That's the marginal benefit. What's the marginal cost\nof another unit of labor? So this is the marginal benefit\nof another unit of labor. What's the marginal cost? Well, the marginal cost\nof labor is just the wage. So we simply set this\nequal to the wage. We set the marginal\nrevenue product of labor equal to the wage, and that\ngives us our optimization condition for the\noptimal amount of labor the firms want to demand-- is to set the marginal\nrevenue product of labor equal to the wage. Marginal benefits of hiring\nanother unit of labor equals the marginal cost of\nhiring of the unit of labor. Now to go further,\nremember, I said this is a perfectly\ncompetitive output market. So what is the marginal revenue\nin a perfectly competitive output market? What's the marginal revenue\nof a firm producing-- yeah. Price. So I can write this\nmore to say that I want to set the marginal product\nof labor times the price equal to the wage, OK? So basically, what\nwe're saying here-- think about it-- is hire workers\nuntil the cost of the next unit of labor is the same as\nwhat that unit will actually produce for you, OK? The next unit of\nlabor costs you w. It produces for you MPL times p. So you want to hire workers\nuntil that condition is met, OK? So think about that, and figure\n15-1 sort of shows this, OK? We have a supply of labor. In 15-1, that's\nhorizontal, because we're assuming competitive\nmarket for workers, OK? We're assuming a\ncompetitive market for workers, that is a\nperfectly competitive market. So if I try to pay workers one\npenny more than other firms, every worker in the world\nwill want to work for me. If I pay workers one penny\nless than other firms, no workers will\nwant to work for me. That's what a perfectly\ncompetitive labor market means, that literally, I am\na price taker in the input market. I don't get to set the wage, OK? I don't get to set the wage. The wage is given to\nme by the labor market. So just like a perfectly\ncompetitive firm doesn't get to set the\nprice of their product-- it's given to them by\nthe competitive market. A perfectly competitive\nfirm in the input market doesn't get to set\nthe wage they pay. It's given them through\nthe kind of process that delivered us our prices\non the output side, OK? So we get a horizontal\nlabor supply curve. And then we have this downward\nsloping labor demand curve. Why is it downward sloping? Someone raise their\nhand and tell me. Why is the labor demand\ncurve downward sloping? Yeah. AUDIENCE: Marginal product\nof labor is diminishing. JONATHAN GRUBER: Exactly. The diminishing marginal\nproduct of labor means you have a\ndownward sloping marginal benefit of labor. Each additional-- remember,\nholding capital fixed is only one shovel. So each additional\nworker add less and less to digging that hole, OK? So marginal product\nis diminishing. Since p is a constant,\nthat doesn't really affect the slope. I mean, it affects the slope. It doesn't really\naffect the sign. Doesn't affect the sign. It's diminishing because the\nmarginal product of labor is diminishing. So the equilibrium is\nwhere they intersect. So the bottom line-- this\nis complicated and new-- the bottom line intuition\nis to think about, as I decide whether to hire\none more hour of work-- you've got a firm. You've got to decide,\ndo I want the worker to work one more hour? You do the tradeoff\nof, what am I going to pay them for an\nhour versus what are they going to get me for an hour. What they're going to get\nme is their marginal product times the price, OK? Now, that-- So in other words, the wage is\nnot just the marginal product. It's imagining if two workers\nwere equally productive. With one more hour of work,\nthey each make three more units. But let's say, in one case, a\nunit is a computer chip, OK? In another case, a\nunit is a potato chip. We clearly would not want to\npay the same wage to someone who produces three more computer\nchips to someone who produces three more potato chips. We'd want to pay a\nlot more to the person to do more computer chips. Why? Not because computers\nare inherently valuable. In fact, potato chips\nare much more delicious than computer chips. Because they sell\nfor a higher price. So therefore, you'd\nwant to pay more to the worker who produces more\nunits of a more valuable good. So let's think about\na sports example, OK?"}, {"content": "And I realize we're all\nabout baseball today, as we should be. Go, Red Sox. But let's focus on\nbasketball for a minute, OK? Now, imagine you're a owner of\na team in the NBA, the National Basketball\nAssociation, and you're trying to decide how much\nyou pay one of your players. So basically, in that\ncase, your goal is to-- your goal is wins. That's the goal. That's the profit you're trying\nto maximize, is your wins. Let's say you're probably\ntrying to maximize your revenues from\nads and stuff, but assume that's\nproportional to wins. OK, assume that\nbasically, the more you win, the more money you make. So let's say the thing you're\ntrying to maximize is wins, OK? So your labor demand,\nthe marginal product you care about, is the\ncontribution of the next player to your win total. That's what you care about. The marginal product of labor is\nhow much does that next player add to my win total, OK? So for example, LeBron James,\nthe best player in basketball, arguably the best\nplayer in history-- we could have that-- we could\nhave the LeBron versus Michael debate some other time, OK? LeBron James makes $31\nmillion, and that's because his marginal\nproduct is enormous. He adds a huge amount\nof wins to any team, OK? We'll see with the-- we'll run the\nexperiment to watch how the Cleveland Cavaliers\ntank this year once LeBron has left, OK? Now, other players\ndon't make as much. Let's compare LeBron\nJames to Nate Robinson. You guys might not\nknow Nate Robinson is. He's one of the shortest players\nin the history of the NBA at a paltry 5'9\", which sounds\npretty tall to you and I, but it's tiny for the NBA. He was a very exciting player. It's kind of fun to\nwatch this little guy run among these giants. But he was just OK. He wasn't a great player. He was a fine player. He made about $2 million a\nyear by the end of his career. So basically, you have\nLeBron making 31 million and Nate Robinson\nmaking two million, and that's sort of related\nto their marginal product. So LeBron adds a lot\nmore to your wins. Now, what happened\nis Nate Robinson quit basketball in\nthe US, and went to play basketball in Israel. In Israel, they love basketball. They have a league. And he went to Israel,\nand he was dominant. He was the best player in\nIsrael, because they don't-- it's not as good as the US, OK? So his marginal\nproduct went way up. Nate Robinson went\nfrom being someone that had a small marginal\nproduct to maybe the highest marginal product in the\nleague, and his wage went down from two million to 500,000. So this is a situation where\nsomeone's marginal product went way up and their wage went down. Why?"}, {"content": "Yeah. AUDIENCE: Because people\naren't paying as much to watch basketball. JONATHAN GRUBER: Right, because\nthe marginal product went up, but the price went way down, OK? And what we care\nabout is the wage equals to marginal\nproduct times the price. So you have a situation where a\nplayer got better but got paid less because they got better. He moved from making computer\nchips to making potato chips, OK? He moved from a\nmarket where he was earning a valuable commodity\nto one where he was earning one that was much less. So basically, it's a\nsituation-- that example shows why you have\nto care about both the quantity of the additional\nworker and the value of what they're producing, OK? Any questions about that?"}, {"content": "Yeah. AUDIENCE: When we talk about\nperfectly competitive input market, are we saying that\nlike all of the workers-- like a single hour of work\nregardless of who you get it from is equal, right? JONATHAN GRUBER: No, no. A single hour of\nwork is paid equally. It's not equal. Marginal product varies. We're talking about the market."}, {"content": "Let's think about a\nperfectly competitive-- I probably went\ntoo fast with this. Let's say a perfectly\ncompetitive output market is where the firms sell\nthe goods into a market where people have\nperfect information and can shop across\nall firms easily. A perfectly competitive\ninput market is where firms hire workers\nin a situation workers have perfect information\nand compare across all firms equally. So basically, the point\nis, think about a perfectly competitive output market. People are in a market where\nlots of people are shopping, and all the options\nare in front of them. A perfectly competitive labor\nmarket where you as a worker have lots of firms\nyou can work for, and they're all clearly\nin front of you, and they all offer a\nwage, and you can see it. AUDIENCE: OK, but\nwe're not saying that the firms have perfect\ninformation across all the laborers, and [INAUDIBLE]. Are we saying if we have the-- JONATHAN GRUBER:\nWhat we're saying is-- we're not saying the\nfirms have perfect information about the laborers. The firms essentially-- let\nme think of the best way describe this. So once again, the firms are--\nfrom the firm's perspective, they do have\nperfect information. No, the wages\naren't-- yes, right, the workers aren't the same. They have different\nmarginal products. The firms know you're better\nthan you or vice versa. But from the firm's\nperspective-- from the workers'\nperspective, is just like, think of the\nworkers as the consumers in a perfect competitive\noutput market. For a perfectly\ncompetitive output market, the consumers can easily\nshop across all the firms they might buy from. In a perfectly\ncompetitive input market, workers can easily\nshop among all firms they might work for, OK? That's a good question."}, {"content": "Other questions? OK, now let's think\nabout the long run. This is the short run. Let's think for a minute\nabout long run labor demand. Think for a second about\nlong run labor demand. Well, what's different? The only thing that's\ndifferent is in the long run, capital can adjust as well. The only thing\ndifferent about the long run-- all the intuition,\neverything's the same. It's just that capital\ncan adjust as well. And what this means\nis that long run labor demand is more elastic than\nshort run labor demand, OK? So we could see this\nin figure 15-2, OK? So the figure shows two\ndifferent short run labor demand curves at two\ndifferent levels of capital. So the short run labor\ndemand when k bar equals 32 is that lower one. The short run labor demand\nwhen k bar equals 108 is the higher one. And what this says\nis, in the short run, you've got these two\nlabor demand curves. In the long run, you\ncould optimize capital. You can pick a point\non either curve, depending on which level\nof capital you choose. And by definition,\nthat allows you be more elastic at choosing your labor. You're more flexible\nbecause you can optimize not just over workers,\nbut over machines as well. It's the same\nintuition we developed before talking about short\nrun and long run costs, that the long run cost\ncurve was a lower envelope than the short run cost curve. Same thing here. This applies that\nthe long run labor demand is more elastic, because\nI basically am more flexible. I not only can choose\na longer curve, I can choose which curve I use. And by definition, that\nmeans that the long run is more elastic, OK? Just a small sort\nof side point there. Now, the last thing I\nwant to talk about here is capital demand. We talked about short run\nand long run labor demand. Let's talk about capital demand. It basically is the same thing. Capital demand is the\nexact same intuition. You want to get machines\nuntil the marginal product of capital, marginal\nproduct of the next machine, times the price you get for your\ngood equals the interest rate. It's the same condition. So we want to hire workers\nso the marginal product of the labor times the price of\nour good equals the wage rate. We want to invest\nin more machines until the margin\nproduct of capital of the next machine times\nthe price for our goods is equal to the interest rate. So it's exact same logic. Here's the marginal cost. The next unit of\ncapital-- remember, we talked about the intuition. You're always renting things. So thinking about\nrenting a machine, the next machine\ncosts are to rent. Do you want to rent it?"}, {"content": "Well, it depends."}, {"content": "What will it produce, and what\ncan you sell that stuff for? So you rent the next machine\nif the marginal product of capital, if the\ngoods it produces, times what you sell\nthose goods for, you want to do that until that\nequals the interest rate, OK? Questions about that?"}, {"content": "Yeah. AUDIENCE: [INAUDIBLE]\nmachine that you buy and own? JONATHAN GRUBER: Yes. We're going to talk about that\na lot starting next lecture."}, {"content": "Right now, I think I'll\njust put this down here. We'll come back to\nit, but I'm going to focus on labor\nfor this lecture, OK? So let's focus on labor, and\nlet's-- so I just put that down, and we'll back to\ncapital, but focus on labor for a minute, and make sure to\nunderstand where labor demand comes from. Now let's talk about where\ndoes labor supply come from. We talked about,\nat the firm level, labor supply is\nperfectly elastic. So go back to figure 15-1. That was a firm level curve, OK? That was a firm level curve. That's a perfectly elastic\nlabor supply to a firm, but that doesn't\nmean labor supply to the market's\nperfectly elastic. So now we want to derive\nmarket labor supply. So I'll call this\nderiving market labor supply, deriving market\nlabor supply, OK? Now, this is basically\nthe question of, how do we model how hard\npeople want to work? This is, once\nagain, getting where the economics is exciting, OK? You sort of knew that economics\nwas involved in how much Ford charged for a car,\nbut you might not have thought so much\nabout that economics was involved in deciding how\nhard you work, but it is. And we're going to use the\nsame tools of consumer choice. Indeed, I used to teach this\nas an application of consumer choice, and now I teach it here,\nbecause it's the same tools of consumer choice. But now, consumers, instead of\nchoosing good A versus good B, are going to choose how hard\nthey're going to work, OK? So basically, like any\nchoice, there's a tradeoff. There's a tradeoff. On the one hand, if you work\nharder, you get more stuff. So you bring home more income. You can buy more\npizzas and cookies, OK? Remember, we talked about\nincome as a fixed thing your parents gave you, but\nin reality, sorry, kids, you're going to have to\nmake your own money someday. In reality, you're going\nto make a Y. It's not going to be given to you. And so if you want to buy\nmore pizza and cookies, you're going to have to\nraise your Y. It's not going to be given, OK? So the reason you\nwant to work harder is to buy more\npizza and cookies. The reason you don't\nwant to work harder is because you're not\nan MIT student, OK? That is, normal people actually\ndon't like work, newsflash."}, {"content": "OK? Normal people\nactually like leisure. There's a thing called\nleisure, it turns out, and normal people like it, OK? So the tradeoff for\nregular people-- so it's a hard\nthing teach at MIT-- is that basically, the\ntradeoff is if you work harder, you get more stuff,\nbut you spend more time doing something you\ndon't want to do. Now, this is weird. When we talked about\ntradeoffs before, we talked about the tradeoff\nbetween goods, pizza and cookies. Now we're talking\nabout the tradeoff between a good and a bad. The good is more stuff to eat. The bad is working harder,\nand we don't really know how to model that. So the trick we're\ngoing to use here is we're going to flip\nthe bad into a good. Instead of modeling labor,\nwe're going to model leisure. So to get labor supply, we're\ngoing to model leisure supply, and then just flip it around\nto get labor supply, OK? So that is, we're going to say,\nyour ultimate labor supply, the amount of hours you\nwork, the amount you work, the amount of hours\nyou work, call them H, is equal to 24 minus leisure. Let's call it leisure, because\nleisure's called little l. Leisure's little l. The amount of hours you work is\n24 minus the hours of leisure you take. What that means is I don't\nhave to model the bad. I can model the good and just\nuse this simple reflection equation to get the bad, OK? So this is the\ntrick in economics. It's a good modeling trick. We don't model bad\nso we don't have to do the tradeoff between\nthe bad and the good. We don't have to do the\ntradeoff between two goods. So turn the bad into a good. Don't model work, model leisure. Don't model your hours\nyou work, model how many hours of leisure, OK? This is a general\nmodeling trick. So what we want to\nask is, now, not how do you derive the\nsupply of labor, how do you derive the\ndemand for leisure? How do we derive how\nmuch leisure people want? Well, once I say it that\nway, you know what to do, which is what I just said. There are two goods,\nconsumption and leisure. I wonder how much of\none good you choose-- of each good you choose. Well, that's a consumer\nchoice problem. You know how to do that, OK? So basically, take\nfigure 15-3, OK? In figure 15-3, now, instead\nof doing pizza versus cookies, now our decision\nis all consumption. So we're thinking about\nconsumption as a bundle, OK, versus leisure. So on the y-axis is\nthe goods you choose. On the x-axis is how much\nleisure you take, OK? It says N but actually it\nshould be little l, OK?"}, {"content": "Should be little l."}, {"content": "So let's call that little l, OK? So basically, as you go\nmore positive on the x-axis, that's more leisure. But because this\nequation, that implies as you go to the left on the\naxis, that's more work, OK? Yeah. H is hours of work. H is hours of work. So as you go to the\nleft, you work more. As you go to the right,\nyou take more leisure. But we're modeling the\ngood, which is leisure. And then we just go\nto our standard-- we go to our standard\nconsumer choice equation. We have a budget\nconstraint and preferences. The indifference curve comes\nfrom your utility function. It comes from your indifference\nbetween how much you consume and how much leisure you take. And the indifference curve comes\nfrom like any consumer choice decision. But instead of choosing\nbetween pizza and cookies, now it's how much stuff you\nwant versus how much leisure you want to take. So it's the same sort\nof indifference curve. The budget constraint comes\nfrom what the market tells you is the cost of leisure. What is the price of leisure? What is the price of leisure? Someone else? Someone else got it? Yeah, AUDIENCE: Your wage. JONATHAN GRUBER: Your wage. Why is that the\nprice of leisure? AUDIENCE: Because\nevery hour you don't work is another hour\nof wage you don't get. JONATHAN GRUBER:\nWhich we call what? AUDIENCE: Opportunity cost. JONATHAN GRUBER:\nOpportunity cost. Remember, prices\nand opportunity cost are the same thing in economics. Here's once again where it gets\ninteresting to apply what we've learned, which is\nthat basically, this is why, once again, they call\neconomics the dismal science. Instead of having\nfun sitting around, we're telling you,\nyou know, by the way, you could be working\nand making a wage. So you're actually spending\nmoney by taking leisure. By taking leisure, you\nare spending money. What are you spending? You're spending the money\nyou could be earning. So the opportunity--\nso leisure has a price, and the price of\nleisure is the wage. It's what you could be\nearning if you were working. So the budget constraint\nhas the slope of minus w. So if you look at the\nbudget constraint, you could take 24\nhours of leisure and have zero consumption, OK? That's the x-axis intercept. Or you take no leisure and have\n24w worth of consumption, OK? So basically, that is\nthe tradeoff you face."}, {"content": "One other modeling\ntrick-- couple of them-- so a couple of\nmodeling tricks here. Modeling trick one is modeling\nthe good, not the bad, OK? Modeling trick two is, I\nwrote on the x-axis goods, but we don't think\nin quantities, we think in dollars. So to make life\neasier, I just said, let's assume the price of\nthe average good is $1. That way you can-- that's called-- that's\njust a normalization, OK, which allows you to think\nin terms of dollars of goods rather than quantity of goods. That's another modeling\ntrick we'll do. We call it making a\nnumerator good, OK? You don't have to\nremember that term, but the point is\na trick we'll do is we want to model\ndollars, not quantities. We just make the\nquantities cost $1, and then we can model\nquantities basically as dollars. So that's the trick we're doing. So the y-axis is dollars,\nbut it's also quantities, because we made the price\nof everything be $1, OK? It's just another trick\nthat makes life easier. OK, so two modeling tricks\nhere, the numerator trick, which is making the price $1\nso quantities become dollars, and the bad is good trick,\nwhich is model the good, and then reverse\nthat to get the bad. Having done that,\nwe know what to do. We get an optimum,\nwhich is the tendency between the indifference curve\nand the budget constraint, and we're done. And so what do you do?"}, {"content": "You choose-- we're going to call\nthis L."}, {"content": "We'll call it little l. You choose little l\nstar hours of leisure, which means you choose 24 minus\nlittle l star hours of work, OK? So basically, you sat down. You made the\ndecision, how much do I want to eat versus how\nmuch do I want to watch TV. You make that tradeoff, and that\ndetermines how hard you work, OK? Now-- yeah. AUDIENCE: Aren't there things\nthat are kind of necessary? Like for example, if\nyou wanted to-- like if your preference was\ncompletely to work, then wouldn't we be like\nan inefficient worker if we didn't sleep? Doesn't-- JONATHAN GRUBER: Well,\nand in some sense, that would be in your\nutility function, or it would be in\nyour utility function and/or your budget constraint. That would be true, absolutely. But that would be a feature. That wouldn't change this\nmaximization problem. It'd just change\ngeneral structure of the equations that go into\nthe maximization problem, OK? So basically, now, what's really\ninteresting about this is now we finally understand why\nwe learned all that shit about income and\nsubstitution effects. Remember, let's think\nof substitution effects. And you're probably saying\nlike, \"Why do I care? Price goes up. Quantity goes down. Why do I care?\" Here's why you care, because now\nit gets really interesting, OK? Because when we're doing\nsubstitution effects for a good, they work together. As long as the good was\nnormal, they work together. When the price went up, you\nsubstituted away from the good and you are poor. So it gets substituted\ndown for two reasons. Now, a normal leisure effect\nis an inferior labor effect. What I mean by that is that\nwhen your wage goes up, you work more through the\nsubstitution effect, but now you're richer. And when you're richer,\nyou buy more of everything, including leisure. So if you take more\nleisure, you do less labor. So the income effect naturally\ngoes against the substitution effect. I'll go through this\na couple of times. Don't worry. The income effect naturally goes\nagainst the substitution effect here. For consumption goods,\nthe income effect naturally work together, OK? We almost never saw sort\nof a Giffen good type phenomenon, where the\neffect could sort of switch the overall effect. For labor, that's\nmuch more likely, and it's much more likely not\nbecause of any inferior good. It's because leisure\nis a normal good, and labor is the\nopposite of leisure. So once again, let\nme say it again. The wage goes up. The substitution effect--\nthink of leisure as a good. When the wage goes up, that's\nthe price of leisure going up. When the price of\na good goes up, the substitution effects\nsays you want less of it, OK? So when the wage goes up,\nthe substitution effect says that leisure\ngoes down, right? Because you want to\nsubstitute-- wait, leisure just got more expensive. You now feel worse sitting\naround watching TV, because you could be out\nthere making more money. Yeah. AUDIENCE: Wouldn't\nincome-- [COUGHS] JONATHAN GRUBER: I haven't\ngot to income effect. Let me finish, then\nyou can ask it. AUDIENCE: Wouldn't\nincome effect be-- JONATHAN GRUBER: I haven't\ngotten to the income effects. Let me ask finish, then\nyou can ask it, OK? So the substitution effect says\nthat leisure goes down, OK? The income effect says\nthat you are richer, right? Your wage went up. You're richer. When you're richer, you want\nmore of all normal goods. Leisure for non-MIT\nstudents is a normal good. So you want more of it. So here, with consumption\ngoods, when they were normal, the income and substitution\neffects work together. With labor and leisure,\nthey work opposite. So what this is, the\nsubstitution effect says take more leisure,\nwhich means work-- take less leisure means work\nharder, work more hours. But the income effect\nsays take more leisure, which means work less hours. So you don't know what\nthe net effect is. So that's why we do income\nand substitution effects, because in a case like this,\nthey get much more interesting. Yes, now your question. AUDIENCE: Is this income effect\nin terms of income over time? JONATHAN GRUBER: No, this is\nyour income, your actual cash income. You are now richer,\nand when you're richer, you spend more on everything. So think of it this way."}, {"content": "Once again, imagine\nyou're not an MIT student. You're a normal guy. OK, if we won the lottery,\nif you guys won the lottery, you would use that\nto do a startup. If a normal person\nwon the lottery, they'd use it to not work, OK? That's the income effect. OK, when normal\npeople win lotteries, they don't go work harder. They don't work, OK? So that's the point. You are now richer\nbecause your wage went up. So you work less,\nand that offsets it. So let's show this in a graph. Let's go back to our income\nand substitution effect graph that we did before,\nfigure 15-4, OK? Now we're back to-- once again, this is just\napplied consumer theory, OK? Let's go back to the income\nand substitution effects. We start with budget\nconstraint one at wage one, and we have our initial tangency\nat A, OK, with leisure of N1 or little l1. Now our wage goes up. Our wage goes up. Therefore, the budget\nconstraint pivots up. Think of what that means. You can still only have\n24 hours of leisure. That's a fixed point. But as you take less\nleisure, you make more money. So the budget trade\nnow pivots up. Well, that has two effects. The first is the\nsubstitution effect."}, {"content": "Remember how we get that. We draw an imaginary\nbudget constraint at the new price ratio. The price ratio is\njust W because I assume the price of goods is 1. The new price ratio, tangent\nto the old indifference curve, that is point B. So\nthe substitution effect says, take less leisure, OK? The price of leisure has gone\nup, so holding utility costs, you want to take less leisure. The income effect,\nhowever, says, you are now richer\nso take more leisure. So the income effect\ngoes the opposite way of the substitution\neffect naturally. You don't need a weird\nthing for that to happen, like with pizza and cookies. It comes naturally. So for normal goods, the income\neffect goes the opposite way. Now, in this case, we end up\nwith leisure still going down. We end up with, the wage\ngoes up, leisure goes down, and therefore labor\nsupply goes up. So we end up with our\nstandard intuition, which is, I tell you, if I'm\ngoing to pay you more, you're going to work\nharder or less hard? The standard intuition\nis I work more hard, OK? But as figure 15-5\nshows, it would not be super odd to get a\nGiffen good effect here, which is, the wage goes up. The substitution effect\nshifts you to the left, but the income effect shifts\nyou even more to the right, and you actually end\nup with more leisure. So once again, my intuition, if\nI say to you the price of pizza went up, what happens to\nyour demand for pizza? You think of a standard--\nyou say, \"Well, I'm going to demand less pizza.\" If I say to you\nthe wage went up, what happened to\nhow hard you work? It's not clear."}, {"content": "Think of a simple example. Think of yourself\nactually back before you were an MIT student,\nwhen you were a kid saving for something. You were saving to buy a\nbike, and the bike was $150. OK, bike was $200, and you're\nearning $10 an hour, OK? So you had to work 20\nhours to get the bike. Now I gave you a\nraise to 15 hours-- to $15 an hour or $20 an hour. Would you work\nharder or less hard? Well, if all you want is the\nbike, you'd work less hard. You don't have to work 20 hours. You only have to work 10 hours. So in fact, a higher wage\ncaused you to work less hard. That's not that\nbizarre a case, right? That makes sense. The point is, it's\nactually quite sensible that you couldn't end up with\nthe labor supply being a Giffen good, with a higher wage\ncausing you to work less. It's not a crazy outcome. Giffen goods and\nconsumer goods are crazy. It's not at all crazy\nto think that in cases like having a target,\na purchase target, a higher wage would cause\npeople to work less. Yeah."}, {"content": "AUDIENCE: So does the law\nof nonsatiation not apply? JONATHAN GRUBER:\nAbsolute applies. Absolutely applies. There's no violation. We haven't violated\nany of the laws. All we've done is just\nsaid income effects-- it didn't apply with\nGiffen goods too. It's all just saying income\neffects dominate substitution effects, which we\nthought was sort of going to be pretty bizarre\nin the consumption good context, but it's not at all bizarre\nin the labor supply context. So this is pretty wild. What this says is\nthat basically, you've got a situation where\neven in the normal world, you can get that\npaying workers more makes them work less, which\nis kind of bizarre, OK? Questions about that, about\nthat intuition, or the math, or the graphs?"}, {"content": "Well, the math we haven't\ndone, but the graphs? We'll do the math on Friday. The graphs or anything?"}, {"content": "OK. Let's then say, well, does\nthat happen in reality? What does the evidence say? Let's go to the evidence."}, {"content": "What does the evidence say? And there may be sort\nof no question more worked on in economics than\nthe elasticity of labor supply or the shape of the\nlabor supply curve. There is thousands of articles\nwritten on this question, OK?"}, {"content": "And what I want to do here\nto make the intuition easy, I want to go back to\nthe literature circa probably 40 years\nago, when it was sort of the initial burst\nof interest in this, in like the 1970s."}, {"content": "In 1970s, there was a\nburst of interest in this. And what the literature did\nwas it looked separately at men and married women,\nbecause most of women were married, and back then we\ndidn't care about single women, OK? OK, it was a dark time, OK? So the literature\nlooked at men and women, and married women,\nand asked what was their elasticity\nof labor supply. Well, let's think for a\nsecond about what we'd expect, and to do that, let's think\nabout the substitution effect and the income effect. Let's start with men, the\nmale substitution effect. Let's go substitution effect. Men versus married women,\nwho has a bigger substitution effect and why? That is, when the wage goes up,\nwho has a bigger substitution response to that and why? Men or married women? Think about the world-- think about the Mad\nMen world or the world, you know, circa 40 years ago. You guys seen\nenough TV and stuff to know how life was\na little bit, OK? So who's going to respond? Who's the bigger-- yeah. AUDIENCE: Are you assuming\nmen were primary providers? JONATHAN GRUBER: Well, they\ncertainly were in the 1970s. AUDIENCE: Oh, OK. In that case, the men. JONATHAN GRUBER: Men have a\nbigger substitution effect? AUDIENCE: Yeah, they'll\nwork more, probably. JONATHAN GRUBER: OK,\nthat's one option, yeah. AUDIENCE: It'll be married\nwomen, because they're only working if they have to. JONATHAN GRUBER: Right. So it's actually married\nwomen, because men were already working 40 hours. They can't-- there's no-- So think about a\nmarried man in 1975. OK, men didn't raise their kids. Men quite frankly didn't\ngive much of a shit about their kids, OK? Men just worked. That's what men did in 1975, OK? They worked, and they\nworked their 40 hours, and then went home. OK, maybe they worked less\nor more than 40 hours, but certainly, the\nnotion of saying, \"Well, the wage went up. Maybe I'll take more\nleisure,\" never really crossed a man's mind in 1975. Because what were\nthey going to do? They have no one\nto play golf with. They didn't want to spend\ntime with their kids. What were they going to do? Whereas women had a real\nsubstitution possibility, OK? This was an era women were\nentering the labor force. There were real\nopportunities for work, but it was also fine\nto hang out at home. You had-- a lot of your friends\nwere hanging out at home. You could take care of kids. There were a lot\nof things to do. So women had a much larger\nsubstitution effect than men, OK? Because men-- remember, what's\nthe substitution effect? It's about the next\nbest alternative. For men, there was no\nnext best alternative. It was just work. Basically, between 9:00\nto 5:00 on a weekday, there was nothing\nelse to do, OK? For women, there was\nother things to do, which is, you can hang out with\nfriends who weren't working, or you could take\ncare of the kids. Yeah."}, {"content": "AUDIENCE: But what about\nlike working overtime? JONATHAN GRUBER: OK, well,\nlet's-- but once again, if I'm a man, you might\nthink that I could then-- but then once again, if I work-- the substitution effect could\nwork that way for overtime. But let's talk about\njust the decision to work at all, in some\nsense, or the decision to work sort of\nyour first 40 hours. Overtime is hard, because then\nyou get paid more, et cetera. OK, now let's go\nto the other side."}, {"content": "Let's go to the income effect. So let's not say this is zero. Let's say it's small, because\nthis is big and this is small. Because you can\nwork a little bit overtime or something\nlike that, and some men did care about the kids. I'm obviously being facetious. So it could be, some men\nwere willing to spend time with their kids, et cetera. OK, now let's go to\nthe income effect. For whom is the\nincome effect going to be bigger, men or women? For whom is the income\neffect going to be bigger? Yeah."}, {"content": "AUDIENCE: Maybe men. JONATHAN GRUBER: Because? AUDIENCE: Because they\nhave a goal of like, they need x amount of\nmoney to just provide for their families. So if they get this\nhuge raise in wage, then they become wealthier,\nand they could start doing more leisure in the week. JONATHAN GRUBER: Exactly. There's actually two\nreasons it's men. One, you're more likely to\nhave your target income. Two is, you can't have an\nincome effect if you don't work. The income effect is\nproportional to how hard you are working. If you weren't\nworking, then there's no income effect, right? Income effect is essentially--\nthe income effect for labor is essentially the\nhours times dH dy. What Manny said\nwas the reason why dH dy might be bigger\nfor men than women, because they have these targets. More relevantly, if\nwomen weren't working, they didn't have\ndH, so this is zero. So the income effect is zero. So for men, this was big, and\nfor women, this was small, OK? Put this together,\nand what does it suggest about the relative\nshapes of labor supply for men and women? Someone raise their\nhand and tell me. What does it suggests\nwhat the labor supply curve would look like for\nmen and women in this era? OK, given the\nintuition we talked about here, what does it\nsuggest the female and male-- the married women labor supply\nand the male labor supply curve should look like? You guys can get this, come on."}, {"content": "Well, let's talk--\nwhat did we talk about?"}, {"content": "We talked about the\nsubstitution effect. If the wage goes up, it leads\nto more leisure, which means it leads to more labor supply. By the income effect,\nif the wage goes up, it leads to less labor supply. So for men, with-- for women, with a big\nsubstitution effect and a small income effect,\nthis suggests a standard steep upward-- standard upward-sloping\nsupply curve. Think of the income\neffect being zero. Then we get the standard\nsubstitution effect. We know the sign of that. So for women, this suggests an\nupward-sloping supply curve, just like a substitution\neffect suggests a downward-sloping demand curve. For men, it's not clear. You could very much get\na Giffen effect here, because basically, there's not\nmuch option for substitution, but they might work a lot\nless if they get rich, OK? So that is sort of this-- what I like with this\nexample-- it's hard, but I like that this\nexample sort of illustrates how substitution and income\neffects can come together to get a bottom line answer. What do we know? What we know is that actually,\nevidence is that female labor supply was very elastic,\nthat circa this era, female labor supply\nwas in the elasticity of between 0.5 and 1. That if you raised women's wage\nby 10%, there was a 5% to 10% increase in their\nlabor supply, which is pretty not elastic-elastic,\nbut reasonably elastic, OK? Whereas for men it\nwas pretty much zero."}, {"content": "It wasn't negative. It wasn't positive. It was basically zero. Basically, men just worked 40\nhours and then went home, OK? So basically, in an era where\nfor women, the labor supply was very elastic and of\nthe standard direction, higher wages lead\nyou to work harder, an upward-sloping supply curve. But for men, it was pretty\nmuch a vertical supply curve, maybe even a\nbit backward bending, maybe even a wrong\nsign supply curve. But pretty much, you could\nthink of it as zero, OK? Now, what do we think has\nhappened in the 40 years since these two numbers? So elasticity of woman\nof between 0.5 and 1, and men of zero,\nwhat do we think has happened to these two\nnumbers in the 40 years since these studies, and why? What do you think has happened\nto these elasticity estimates and why? Yeah."}, {"content": "AUDIENCE: Are we talking\nabout these together? JONATHAN GRUBER: Let's\ntalk about women. What do you think has happened\nto the female estimate? AUDIENCE: Probably\ngotten less elastic. JONATHAN GRUBER: Because? AUDIENCE: More of them are\nworking in a primary role. JONATHAN GRUBER: Right. Well, first of\nall, this is going to come down, because in fact,\nit's now more standard just to work, right? In fact, now, for a woman\ntoday, in many communities, it's like being a\nman in 70s, which is if you don't go\nto work, there's no one to hang out with, OK? So basically, this is\ngoing to get smaller. And they're more of a\nprimary winner in the family. This is going to get bigger. So in fact, female labor\nsupply has fallen more to like about an\nelasticity about 0.2. It's actually fallen over time."}, {"content": "Now, for men, the question is,\ndo you get the opposite effect? Actually, men sort of care\nmore about their kids now, and there's more sort of\nactivities going on during the day, but in fact it hasn't. In fact, male labor supply\nstill is pretty inelastic. What's happened is kids\nare now in childcare. So basically, we've gone from a\nworld where, as wages went up, women went-- men worked. Women either worked or didn't\nwork, depending on the wage, and if they worked, the\nkids went in childcare. Now men work and women work,\nand kids are in childcare. And that's basically the change,\nthe evolution of the labor-- roughly speaking, obviously. Still, female labor\nforce participation is only about 70%, OK? Many women still do stay\nhome and raise their kids, and are in and out of\nthe labor force, OK? But by and large,\nwe moved to a world with just overall less\nelastic labor supply. Yeah. AUDIENCE: Between the average\ntwo-income household is richer now, or-- JONATHAN GRUBER: No. The average-- well,\nOK, we're going to get into this when we talk\nabout income distribution. What this has done is allowed\nthe average two-family household to tread water. So it's, the average\ntwo-family household today has the same income\nas they did in the 1970s. Why? Because workers earn a ton less\nin real terms than they did, and that's facts\nabout inequality we'll come to, that basically,\nthe average family in America, despite having-- going from the wife not\nworking to the wife working is no better off they\nwere 40 years ago. And that has lots implications\nwe'll talk about, OK?"}, {"content": "So any other\nquestions about that? So let me end with one final\nexample, an application, OK? Which is to the problem we have\nin the world of child labor."}, {"content": "It's a huge problem\naround the world, is kids being forced to work. It was a huge problem in the\nUS till the 20th century. It's a huge problem\naround the world, because A, work can often\nbe dangerous and bad for their health, but B,\nthey can't be going to school and having the opportunity\nbetter themselves. If a kid is spending\nall day working, then that kid is\ndestined to a life of working in the\nsame crappy job, because there's no way to\nget the skills that allows them to grow and go further. Now, one-- we will talk in the\nnext few lectures-- in a few lectures about\ninternational trade. And one criticism of\ninternational trade is people say, \"Well, if\nyou allow these developing countries to sell more stuff\nto the developed world, that will-- they'll put\nthe kids to work more.\" So if we have free trade and\nVietnam can suddenly sell a bunch stuff to America, that's\nmore kids they;re going to put to work making that stuff. So one common argument you\nhear against free trade is it's bad for kids, but in\nfact, that argument is not necessarily right, because it\nignores an important point. Manny? AUDIENCE: [INAUDIBLE] JONATHAN GRUBER: No,\nthat's a different issue. The point-- that's right,\nbut the point it ignores is free trade makes\nfamilies richer. And the families\nare richer, they may want to buy more\neducation for their kids. So on the one hand, it's true. Free trade makes kids more\nvaluable in the labor force. On the other hand, it\nmakes family richer and they want more\neducation for their kids. So to look at that two\nDartmouth professors did a study, who\nlooked at Vietnam, and looked at what happened\nwhen Vietnam liberalized trade in rice. So let's go to figure 15-6. Now, we haven't gotten\ninternational trade yet, so I'm just going to sort\nof hand wave through this. You don't need to really\nunderstand this graph, except what the bottom line is. OK, what happened was\nbefore trade liberalization of Vietnam, before\n1989, you could only sell rice made in\nVietnam in Vietnam. So what that meant\nwas the supply of rice was s sub v. The demand\nfor rice was d sub v, and the amount of rice\nsold was q sub v. And kids worked in the rice paddies. When they liberalized\ntrade, suddenly Vietnam could sell to a\nmuch larger market. They could sell to the\nworld market, d sub w. That's a bigger market. So they were able to shift\nup their supply curve and sell more rice. They could sell more\nrice, because now they're selling to the whole\nworld, not just to Vietnam. You don't need to notice this\nin the graph so much intuition. If you give someone\na bigger market, they're going to\nmake more stuff, OK? Yeah. AUDIENCE: But doesn't that\nalso put them in competition in other countries, whereas\nif it was just like-- if each country is just\nselling to themself, then Vietnam would have-- JONATHAN GRUBER: No, they\nliberalized in the sense that they let it send out. I didn't say they let more in. AUDIENCE: Oh. JONATHAN GRUBER: OK,\nbut we'll come back to international trade, OK? So basically, the\npoint is, there was this demand shock that\nallowed them to sell more rice. So what effect does that have\non the market for child labor? Let's go to the highly\ncomplicated last figure and let me walk\nyou through this. Here is the market\nfor child labor, OK? On the x-axis is the\namount of child labor. On the y-axis the\nwage of kids, OK? We start at point one, initial\ndemand and initial supply, wage 1, L1. Now we liberalize\ntrade, and that leads to more demand\nfor child labor, because we want to\nproduce more rice. So that shifts us out\nto D2 and point two. So we have more child labor. That's bad. But what this ignores is\nfamilies are now richer, and with the income effect, they\nwill buy their kids education. They'll pull their kids out of\nworking and put them in school. That's represented as a shift\nto the left of the supply curve. So we move from point\ntwo to point three through the income effect. Families are now richer. And indeed, if the income\neffect is large enough, you could move to point four. You could actually have a\nreduction in child labor. Why? Because the benefits\nof more kids working in terms of producing\nmore rice is exceeded by the value\nof the firms of taking-- of the families of\ntaking the extra money they're making and putting it\ninto education for their kids. And in fact, the studies showed\nthat we did move to a point like point four, OK? We actually found\nthat child labor fell when they\nliberalized trade, that the intuitive\nargument, that gee, if they sell more, more kids are\ngoing to work, it's wrong. That in fact, when you sell\nmore, yes, more kids-- demand for more kids, but\nfamilies are so rich, they put their kids in education\nrather than their fields, OK? And that is a wonderful sort\nof counterintuitive story of how what-- I'll talk about economies\nlike free trade, how free trade can actually have\nan unexpected positive effect. We might think it's negative."}, {"content": "And there's a question."}, {"content": "Come up if you want to talk,\nbut we've got to end now. So thank you for\nsaying a minute extra, and I will see you\nguys on Wednesday."}], "16. Input Markets II\u2014Labor and Capital": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER: All\nright, let's get started. Today, we're going to continue\nour discussion of factor markets. If you recall, last\nMonday, we started talking about the labor market. And we talked about how workers\nmake the decision between work and leisure. And we talked about\nthe implications for setting the wage\nrate in the labor market. What I want to do today is\nreturn to that labor market equilibrium and talk\nabout the important case of the minimum wage. So today, I want to talk about\nthe labor market equilibrium and how it's affected\nby the minimum wage because it's an interesting case\nwhich allows us to introduce some complications as to how we\nthink about the labor market. So let's go back and think\nabout the labor market. So let's go to figure 16-1. The labor market,\nlike any other market, has a price and a quantity. The quantity is the\namount of labor supply. That's on the x-axis. The price is the wage. That's on the y-axis. The supply curve\nthat's upward sloping-- typically we'll assume an\nupward-sloping supply curve. But as we discussed last time,\nthat doesn't have to be true. If income effects dominate\nsubstitution effects, which they very well may,\nyou could actually have a backward-bending or\ndownward-sloping supply curve. So we talked about\nthat last time. Having taught that\ninteresting case, typically, we'll\nassume supply is upward sloping or at least\nnot backwards bending, not downward sloping. But remember, that's\nan assumption. So this upward-sloping\nsupply curve is not necessarily as obvious\nas a downward-sloping demand curve is. Downward-sloping demand\nwill almost always exist unless there's\na weird Giffen good, whereas\nupward-sloping supply is a little more questionable. So we have the equilibrium,\nand we have this equilibrium at L1 workers at a wage W1. So now we know where\nthis comes from. So basically, going\nall the way back to producer theory where\nwe just gave you a W, now we're telling\nwhere the W comes from. We're telling you where the\nwage comes from that you then plug into the firm's\noptimization for them to produce goods. Now, let's imagine that\nwe have a minimum wage. So let's go to figure 16-2. So this is a\nregulation which says that you're not\nallowed to pay workers below some minimum level. And let's say we set that\nminimum wage at the level W2 above the market wage W1. Quick question. What would happen\nif we passed a law and set a minimum wage\nthat was below W1? So there'd be a\nregulation which insists you couldn't pay workers\nbelow W2, but W2 is below W1. What would that do\nto the labor market? Nothing. And here's the key point. Markets in economics\nwill always endeavor to avoid government\nregulations if they can. So if a government regulation\nis not binding, it won't matter. Markets will just avoid it. So the interesting case is\nonly where the minimum wage is binding, as in the figure 16-2. So what happens? Well, if you set a\nminimum wage at W2, workers at that high wage\nwould love to work a lot. That's a high wage. They're high in\nthe supply curve. They would like to\nwork L sub s hours. They would like to\nsupply L sub s amount of labor supply to the market. Firms, however, if forced\nto pay a high wage, W2, are going to\nsay, wait, I'm only going to pay that high wage if\nthe marginal revenue product of labor is sufficiently high. Remember, we talked about the\nmarginal revenue of product last time. It's the marginal product\nof labor times the price. So if you're going\nto raise the wage I'm going to have to pay workers,\nunless that affects the market price, I'm going to need to\nhave a higher marginal product of labor, right? The demand equation\nwas, I said, the wage equal to the marginal product\nof labor times the price. Well, if the price\nhasn't changed with the minimum\nwage going in, I'm going to need a high--\nif the wage is forced up by the minimum wage, I'm\ngoing to need a higher marginal product of labor. How do I get a higher\nmarginal product of labor? By hiring less workers because\nthe marginal product of labor's diminishing. So if you're going to force\nme to pay a higher wage, you're going to force\nme to only hire workers until the point where the\nmarginal product of labor justifies that higher\nwage, which means I'm going to hire fewer workers. So firms demand only L sub d. Well, workers can't get jobs\nfirms don't want to give. So the equilibrium is L sub\nd jobs at a wage W sub 2, OK? What does this do to welfare? We can see before, before the\nminimum wage was in place, the market featured a consumer\nsurplus that-- here, consumers are firms, right? But there was a consumer\nsurplus of A plus B plus C. That is, firms\nwere willing to pay what was on the demand curve. They only had to pay W1. So their surplus\nwas A plus B plus C. Workers were willing to\nwork at a wage that's given by the supply curve S sub 1. They were paid at W sub 1. So they got a\nsurplus of D plus E. So here, the firms get\nthe consumer surplus. The workers get the\nproducer surplus because the workers\nare now the producers. Now let's say you roll\nin a set minimum wage. Well, two things have happened. One thing is you've then\ntransferred some resources to workers. That's the area B. You've taken\nthe area B that firms used to get, and now workers get it. That's the idea. You want to make\nworkers better off. So you transferred to\nworkers the area B. On the other hand, you've\ncreated a deadweight loss of the area C plus\nE. You've created deadweight loss in\nthe area C plus E because now there\nare fewer jobs. There are workers\nwho would happily work at a higher\nwage who are not being allowed to work by\nthe limited demand that comes from the minimum wage. So the bottom line is you end\nup with fewer workers, a higher wage, and ambiguous\nwelfare implications. Clearly, social\nwelfare goes down. Whether worker\nwelfare goes up or not depends a bit on the size of\narea B versus the size of area E. It's not clear if worker\nsurplus goes up or not. It depends on size of B\nversus E. In this diagram, workers are a net better off,\nbut it doesn't have to be true. What's clear is that social\nwelfare has gone down. Because remember,\nas I talked about, the cheat, the shortcut I\ntalked about when we talked about oligopoly, is,\nroughly speaking, welfare is proportional to\nthe quantity in the market. Essentially, the\nfurther you deviate from the perfectly\ncompetitive quantity, the bigger the deadweight loss. So that's what happens if\nyou put in a minimum wage. Questions about that?"}, {"content": "OK? Well, that seems\npretty straightforward, and that's what I\nlearned growing up as a kid in economics class. But then some empirical\neconomists, some very famous empirical economists,\nstarted doing a series of articles that\nactually studied, gee, what happens when the\nminimum wage does change. They did things\nlike, for example, comparing what happened\nwhen New Jersey raised its minimum wage but the state\nof Pennsylvania next door did not, and looked at fast\nfood workers in New Jersey, where the minimum\nwage went up, compared to fast food workers\nin Pennsylvania where the minimum\nwage didn't go up. And what they found was\nthere was no difference in employment, that jobs\ndidn't fall in New Jersey even though the\nminimum wage went up. And a series of\nfollow-on studies continue to find that, actually,\nhigher minimum wages didn't seem to cause jobs to\nfall, which is directly in contradiction\nwith this graph. So what's going on? That led to a big\nquestion and revision of what's going on in these\nmarkets that leads to that. And there's really\nthree possibilities for what's going on. Possibility one is that the\nminimum wage wasn't binding. Maybe New Jersey set a minimum\nwage below the market wage. But actually, empirically,\nthat's not true. We can look at what workers were\npaid before the minimum wage. It was well below where\nthe minimum wage was set for restaurant\nworkers that were studied in that most famous study. So this is not true. The minimum wage was binding. There's a second\npossibility that's absolutely consistent with a\nperfectly competitive market. What's a possible\nanswer for why I could impose a minimum wage in\na perfectly competitive labor market and have\nemployment not go down? Yeah?"}, {"content": "AUDIENCE: Price goes up. JONATHAN GRUBER: The price\nthat the firm charges goes up. But in a perfect\ncompetitive labor market, that still wouldn't happen. You might see some\nprice adjustment, but you'd still\nsee some adjustment in the marginal\nproduct of labor. But what else\nabout this diagram? Yeah. AUDIENCE: The firm's demand for\nlabor is perfectly inelastic. JONATHAN GRUBER: The firm's--\nactually, you're close. It'd be the worker's supply of\nlabor is perfectly inelastic. It's the right idea. If workers are perfectly\ninelastic in their supply of labor, then the\nsame amount of workers will work no matter\nwhat the wage. So basically, you're just\ngoing to essentially end up-- you'd also, in fact--\nthat's a good point-- also get inelastic demand,\nthe same thing. If either supply or\ndemand is inelastic, you'll end up with no\neffect of a minimum wage. So that's another possibility. But in fact, we've\ndone a lot of studies. So you could have\ninelastic supply or demand. But in fact, we've done lots\nof studies of supply and demand in these markets,\nand that's not true. Remember, supply was\nlargely inelastic for men, but it was somewhat\nelastic for women. And these low-income\nmarkets have a good mix of men and\nwomen working in them. Demand has been shown\nto be somewhat elastic. So neither supply nor\ndemand's very elastic, but they're sufficiently elastic\nthat that rules out as zero. So the third possibility and the\none economists have focused on is that we're not in a\ncompetitive labor market. They're focused on a\nnoncompetitive labor market. Just like we discussed\nnoncompetitive markets for goods with a\nmonopoly and oligopoly, you can have noncompetitive\nmarkets for labor. It's the basic same idea. So now let's look at-- so when we thought\nabout-- let's go back, think about perfect\ncompetition, the basics of perfect competition. We thought about\nperfect competition. The basic idea was, remember,\nI talked about laying out a bunch of rugs in a market\nwhere you could literally shop costlessly across\nall the people selling their little fake Eiffel towers,\nlittle statue Eiffel towers. And you could perfectly shop. It was easy to go\nfrom carpet to carpet. There was full information."}, {"content": "The prices were posted. And so basically\nwhat you ended up was perfectly elastic demand\nfacing any given firm. Any given firm, if\nthey tried to charge one cent more for their Eiffel\ntower, no one would buy it. If they charged one cent less,\nthey'd immediately run out. Everyone'd buy it."}, {"content": "Well, when we are\nmodeling labor markets-- and I discussed this last\ntime, but not very well."}, {"content": "So I want to come back to it. When we're modeling\nlabor markets, we're thinking about the same\nfeature of perfect competition. But here, it's not\nconsumers shopping over where to buy their goods. It's workers shopping\nover where to work. It's workers saying, gee, in\na perfectly competitive labor market, the idea is I know\nwhat I could earn at any firm and I can easily\nshop across firms, see where I'm going to work. So if any firm tried to pay me\none cent less than the market wage, I'd never work there. And if they tried to pay me one\ncent more than the market wage, every worker in the world\nwould want to work there. So in a perfectly\ncompetitive labor market, any given firm faces a perfectly\nelastic supply of labor. So we can see that\nin figure 16-4, which we actually showed-- and\nI'll let you skip this since we covered it-- 16-4, which I actually\nshowed in the last lecture. Remember the last lecture. I was focused on this\ndownward-sloping demand curve, but I casually threw in\nthis flat labor supply curve and botched explaining it. Now I'm explaining it,\nhopefully more clearly, which is to any given firm,\nthe labor supply curve is perfectly elastic because\nworkers can perfectly shop across job opportunities. So if that firm tried to pay\nless, they'd get no workers. So they faced a perfectly\nelastic supply of labor. But just like, in\nreality, there's no such thing as a perfectly\ncompetitive product market, in reality, there's\nno such thing as a perfectly\ncompetitive labor market. In fact, we can't shop easily\nacross all possible jobs and know what every\njob could pay. And the fact that we can't means\nthat firms on the labor market side will have market power. Just like we talked about\nmonopolists and oligopolists having market power\nover consumers through barriers to\nentry, firms will have market power over workers\nbecause workers can't perfectly shop across their\njob alternatives. So as a result, firms\nmay be able to get away with paying you less than\nwhat you might earn elsewhere. In a perfectly\ncompetitive labor market, a firm could never\npay you less than what you're worth elsewhere\nbecause you'd just go work somewhere else. But now, if McDonald's wants to\npay you less than you might get at Wendy's, but it's hard to\ngo find out what Wendy's going to pay you-- you have to go\na distance down the road, and you have to ask\nthem, and you're shy and it's embarrassing-- then\nMcDonald's might be able to get away with paying you less than\nyou might earn at Wendy's. So this is very much\nparallel to monopoly. In fact, we call\nthis a monopsony. A monopsony is a\nlabor market where firms have market\npower over workers just like a monopoly is a\ngoods market where firms have market power over consumers. Now, this is not so crazy."}, {"content": "And in fact, it applies\nvery much to me. Think about my situation at MIT. I've been here 25 years. I just got my 25th\nyear rocking chair, although actually it's\nnot a rocking chair because it comes in the box\nwith the rockers off it. And it arrived in my office,\nso it's sort of a short chair. My wife's 5 foot, and\nshe always complains how chairs are too big for her. So she sat, and she's like,\nit's a perfect chair for me. So now I have a nonrocking\nrocking chair in my office that she sits in. But anyway, I've been\nat MIT for 25 years. It's going to be really\nhard for me to move. I like my house. I like my colleagues. I like my friends. Kind of, I like my\nview out the window. It's going to be kind\nof hard for me to move. Moreover, it'd be pretty\nhard for me to figure out what I'd get paid if I moved. I can't go to other\nuniversities and say, hey, what would you\npay me if you hired me? That's be awkward. I can't really ask my\ncolleagues what they make. That's awkward. So at the end of the day,\nMIT has market power over me because I don't\nreally want to move and I can't really\nfigure out what I'd get paid if I did move. And MIT will exploit\nthat market power over me by paying me less than\nI might earn elsewhere. And we know this as a\nfact because in academia, the only way to get a raise is\nto go get an offer from someone else and have them say how\nmuch more they'll pay you, and then you take that to your\nboss and they say, match this. But if you're not\nwilling to do this, as, frankly, MIT knows\nI'm not willing to do, then MIT can\nessentially underpay me. So basically, any\nresponsible profit-maximizing or even nonprofit employer\nwill exploit this market power and they'll pay me less\nthan my market wage. And that means that MIT\nwill earn surplus on me. In a perfectly\ncompetitive labor market, the firm earns no\nsurplus on the worker. They pay the worker their\nmarginal revenue product. So if you go to this figure,\nwhat am I paying the worker? What I'm paying them is\nexactly the marginal revenue product just like, in\na competitive market for the goods, a firm is selling\nat exactly their marginal cost. So just like a firm makes\nno surplus in a perfectly competitive goods market,\na firm hiring workers makes no surplus in a\ncompetitive labor market. But in a monopsony market, the\nfirm makes surplus over me. They pay me less than they'd\nhave to because I don't shop and find a better opportunity. Now, are there questions\nabout how that market works? I'm not going to do all\nthe math and graphs. It's all the same as monopoly,\njust flipping demand and supply curves. It's a pain in the ass."}, {"content": "I'm not going to do it. I just want you guys to\nunderstand the intuition. So please, since I\nwent through this, are there questions about\nthis or how it works?"}, {"content": "OK. Now let's take this\nnoncompetitive labor market and let's throw\nin a minimum wage. Well, as before,\nif the minimum wage is below what the firm\nwas already paying, there's no effect. So let's assume it's a\nbinding minimum wage. Now, let's say the\nbinding minimum wage is above what my true\nmarket wage would be, what my wage would be in the\nperfectly competitive market. So in a perfectly\ncompetitive market, my wage would equal my marginal\nrevenue product of labor, right? That's in a competitive market. In this noncompetitive\nmarket, my wage is below my marginal\nrevenue product of labor. Firms are exploiting me\nbecause I can't effectively shop for a better job. I don't want to or\nit's hard to do so. Now, in this\nnoncompetitive market, if we set a minimum\nwage that's higher than the marginal\nrevenue product of labor, then the analysis is just\nlike it's a competitive firm. Once that marginal\nwage is higher than the marginal\nrevenue product of labor, it's just like a\ncompetitive firm. So it's not that interesting. The interesting case is, what\nif the minimum wage comes in and it's above the wage I make\nbut below the marginal revenue product of labor? So let's say McDonald's,\nsomeone working there yields a marginal revenue\nproduct of labor of $10, but they're only being paid $7. Let's say you roll in\nminimum wage of $9-- so above what they're\nbeing paid now, but below their actual marginal\nrevenue product of labor. Will the firm fire that worker? Why not? Yeah. AUDIENCE: They're still paying\nthem-- they're still making a profit off of that worker. JONATHAN GRUBER: They're\nstill making surplus, which is as long as the\nmarginal product of labor's bigger than the wage,\nthey love that worker. So before-- so let's write\ndown the numbers as an example. So imagine my marginal revenue\nproduct of labor at McDonald's is $10, but my wage is $7. And then you come and you\nset a minimum wage of $9. Well, 10 is still\ngreater than 9. So the firm has no\ndesire to fire me. So all you've done is\njust given me money. And where'd that\nmoney come from? The surplus the firm earned. So all you've done is\nshifted the surplus from-- you've shifted producer\nsurplus to consumer-- I'm sorry, consumer surplus--\nconsumers are the firms-- to producer surplus,\nthe workers. So in a monopsony\nmarket, a minimum wage doesn't cause deadweight loss. It just shifts surplus around. And that's a really\nimportant outcome because that, once again,\nsays the government isn't always bad here. This is just like--\nif you want to think about this graphically, go\nback to exactly the analysis we did of regulating monopolies. Remember we talked about\nregulating monopolies. We talked about, if a regulator\ncomes in and sets a price below the monopoly price but\nabove the competitive price, it reduced the deadweight\nloss of monopoly. It's the same thing. And if you set a minimum\nwage above the market wage but below the marginal\nrevenue product of labor, then you simply transfer\nsurplus to workers without causing deadweight loss. Now, that raised the\nquestion, of course, is the minimum wage\nin between the wage of the marginal\nproduct of labor? Well, we don't know,\nbut let's go back to the studies that\nmotivated this. The very fact that\nthe minimum wage doesn't seem to\ncause unemployment suggests we are\nhitting the sweet spot, suggests we are hitting\nthe sweet spot, that we're basically managing, with the\nminimum wage policy, at least to date, to essentially\njust find a way, without the government\nspending any money, to shift resources from\nbusinesses to workers. So what does this mean? Well, it means that around the\nlevel of current minimum wages, we can raise the minimum\nwage by a small amount pretty costlessly. It doesn't necessarily mean\nthat a $15 minimum wage is OK. So in some sense,\nthe existing-- this is the important thing\nabout empirical economics. You only learn the answer in\nthe range that you study it. So for example,\nthere've been studies that have looked at what happens\nif you have a $10 minimum wage, and those show no unemployment. There haven't been studies\nthat show what happens if you have a $15 minimum wage. Now, Seattle just actually\nput in a $15 minimum wage about two years ago. So we actually can\nrun the experiment. And the early evidence\nis the Seattle $15 minimum wage did lower\nemployment, that the Seattle $15 minimum wage actually went\nabove the marginal revenue product of labor. And once it's above, you're\nback in the competitive case. You're back in the case where\nyou're lowering employment. Yeah? AUDIENCE: How can you increase\ncompetitiveness in the market? JONATHAN GRUBER: Well,\nthat's the other question, is how could you\nincrease-- so you tell me. How could you increase\nthe competitiveness of a labor market? AUDIENCE: You make it easier\nto tell how much money you would get at each place. JONATHAN GRUBER: So Norway\nhas a day every year they call Envy Day,\nwhich was yesterday, I believe, where they literally\ncan go online and look up anybody's income in Norway. They literally make public\nevery single person's tax return in Norway. And you can go online and\nlook at what everybody makes."}, {"content": "That would do it. So you could provide\nmore information. You could make it easier\nto move between jobs. For example, there's a lot\nof restrictions in our labor market, like noncompete\nclauses, which say that if you\nwork for one firm, you can't ever go\nwork for another firm in that industry for x years. That gives some monopsony\npower to firms, et cetera. So we could do things which try\nto loosen the flow of the labor market, and that would\nclose this gap between wage and marginal revenue\nproduct of labor. Now, let's go back to Seattle,\njust to conclude this. This doesn't mean the\nSeattle policy was a bad one. The bottom line is what\nwe learned from Seattle was that basically,\nemployment fell a small amount and a bunch of workers\nmade a bunch more money. So is that good or bad? Well, it depends. If you're one of the\npeople that lost their job, it's really bad. If you're one of the workers who\ngot a raise up to $15 an hour, it's good. How do you weigh them\nagainst each other?"}, {"content": "That's exactly what we'll talk\nabout in a couple lectures. So once we start talking\nabout normative economics, about is a policy good or bad,\nthere's typically trade-offs. And this is a classic example. What we're learning here is, is\nthe minimum wage in the range we are now, right now, the\nfederal minimum wage at $7.25-- the evidence suggests\nit could easily rise without causing that trade-off. The evidence suggest\nwe could increase the federal minimum wage\nby some nontrivial amount, at least up to $9 or\n$10, without causing much of a trade-off. But once you get too\nfar ahead of that, there starts to be a trade-off."}, {"content": "Question about that?"}, {"content": "Yeah. AUDIENCE: Are there any states\nwhere it's actually still that low? JONATHAN GRUBER: Oh, yeah. Many states don't have\ntheir own minimum wage. Massachusetts is at $11,\nbut we're pretty unusual. We're one of the higher ones. A number of states have $7.25\nas the minimum wage, OK? And the evidence seems to be,\nfrom states like Massachusetts and others which are on the\n$10, $11 range, it doesn't seem to lower employment. It seems like we could clearly-- we'd be safe raising that\nfederal minimum wage. We would simply be\ntransferring resources and not causing unemployment. Yeah? AUDIENCE: Is there\nanything about the cost of living in areas where the\nminimum wage is more expensive? Is it possible that if a\nMcDonald's worker makes more money in this\nstate, McDonald's is more expensive in that state? JONATHAN GRUBER: That's\na great question. So what I assumed was I\nassumed firms would just say, oh, you got me. I'm going to throw some\nof my profits at workers. Firms don't have to do that. Firms could say, well, if\nyou make me pay workers more, I'm going to raise my price. Now, if it's a\ncompetitive output market, that shouldn't happen, right? Because in a competitive\noutput market-- well, no. Marginal cost goes up. It's not clear. It's not clear whether\nthat would happen or not, and the evidence is\nthat it's unclear whether higher minimum\nwage causes higher prices or whether it just\ncomes out of profits. We don't know yet, OK? All right, so that's what I\nwant to say about labor markets. Now I want to move on and\ntalk about capital markets. Now, as confusing as our\ndiscussion of labor markets was, that's easy compared\nto capital markets. Capital market's a lot\nharder to understand. And that's because\ncapital itself-- labor's something you\nget your hands around. It's the time you spend at work. Capital is this sort\nof amorphous thing that I've kept\npushing off defining. So I'll define it now. We talk about capital as this\nvague collection of buildings and machines and the other\nstuff that goes into production. And we know where\nlabor comes from. It comes from our work. But where does\ncapital come from? Well, capital is\na harder concept, but there's one unifying thread\nthat all elements of capital have, which is they\nrepresent the diversion of current consumption\ntowards future consumption. Capital is about\ndiverting consuming today towards consuming in the future. In fact, the original concept\nof capital came from farmers. Farmers, every year, when\nthey would pick their grain, they had a choice."}, {"content": "They could eat all\nthe grain, or they could save some to plant\nfor next year's grain. Now, the more they saved, the\nmore they'd have next year, but the less they'd have today. So farmers faced a trade-off-- literally, consumption today\nor consumption next year. That's what we mean by capital. In other words, in\ntoday's market economy, the link is not that direct,\nbut it's the same basic idea-- that firms have a choice,\nfirms and their investors have a choice. They can take what they\nmake and eat it now, or they can invest it in\nhaving more in the future. So basically, when we\nthink about capital, we're not going to think about\ncapital as physical capital. We're really thinking about\ncapital as financial capital. What links all types of capital\nis their financial aspect. What links machines and\nbuildings is all the aspect that, by putting\nmoney into them today, you have less you can\nspend on fun stuff today, but more you'll be\nable to spend tomorrow. And it's this\nfinancial aspect that links all forms of capital. Now, how do firms get\nthe money to invest in machines and buildings\nand stuff like that? They get it through going\nto the capital market. Where do firms get this\nmoney that they invest? They get it through going\nto the capital market, which is basically the pool of\nmoney that firms can draw on to make their investments. So think of it\nliterally as I'm a firm. I want to build a building\nand buy a machine. I literally go over, and\nthere's a big pool of money. And I have to take the money out\nof there to go buy my machine or build my building. And where does the money\nin that pool come from? It comes from household\nsavings decisions. So the capital\nmarket is a market where the demand for capital\ncomes from firm's interest in investing and having\nmore in the future. The supply of capital comes\nfrom people's decisions to save. And essentially,\nthe money firms use to buy stuff is\nborrowed from people. And that's the bottom line\nof how capital markets work. So just as the\nsupply of labor that determines how many\nworkers a firm can hire comes from your decision\nof how hard to work, the supply of capital\nthat determines how many machines a firm can\nbuy comes from your decision of how hard to save. So let's look at figure 16-5,\nequilibrium in capital markets. Let's start with the demand. We already talked, last\nlecture, demand for capital. The demand for capital comes\nfrom the marginal revenue product of capital. It's the marginal product\nof the next machine. So the demand comes from\nthe marginal product of the next machine times\nthe price the firm can get for its output, which\nis the marginal revenue product of capital. So it's the same\nlogic as for labor."}, {"content": "There's nothing\ninteresting there. Same logic as for labor. The supply's what's\nmore interesting here. Where does supply come from? The supply comes from\nhousehold savings, how much money is\naround for firms to actually get to\nget these machines. And how do they get it?"}, {"content": "They borrow. And what do they borrow at? They borrow at the\ninterest rate I. So I represents the\nrate that firms pay households to get their money. So think of this as-- we'll\ntalk about how it really works. But in theory, the idea is\nthink of literally a marketplace in the center of town. Downtown Boston, Haymarket,\nthere's this marketplace. And a firm comes and says,\nI need to borrow money to buy a machine."}, {"content": "And a person's there\nwith their savings and they say, well, I'll\nloan you some money. What interest rate\nyou going to give me? And that's the\nmarket for capital. So where the supply of capital\nmeets the demand of capital yields the interest rate. So basically, what this means is\nas the interest rate's higher, what that means is I have\nto pay people back more to borrow their money. So an interest rate of 10%,\nif I borrow $10 from you, I pay you back\n$1.10 next period. If I borrow $10, I pay you\nback $1.10 next period. If the interest rate's\n20%, if I borrow $10-- if I borrow $1-- I'm sorry. If I borrow $1 from you, I\npay you $1.10 next period. If I have 20% and I borrow $1, I\npay you back $1.20 next period, et cetera, OK? So basically, that\nis essentially how the transaction works. And the key point\nhere is the reason the supply curve is\nupward sloping is the more you're willing\nto pay me for my money, the more I'm\nwilling to lend you. So if you come to me\nand say give me $1 and next year I'll give you\nback $1, I'm like, I don't know."}, {"content": "Why would I do that? If you say, give me $1 and next\nyear I'll give you back $1.10, you're like, OK, now\nI'm interested. $1.20, I'm very interested. $1.50, for sure. Literally, I just\ngive you my money and, next year, I\nget back 50% more?"}, {"content": "Why not? So basically, the higher\nthe interest rate, the more I'm willing\nto loan the firm and, therefore, you get an\nupward-sloping supply curve. Now, of course,\nin reality, people don't actually-- we don't sit\nin Haymarket, downtown Boston, and give money to firms. In reality, this\ntransaction happens through capital markets. And essentially, there are three\nmechanisms by which implicitly I loan money to firms. The first is I could\nliterally buy corporate debt. I could literally loan\nthe money to firms. I could literally go\nand the firm could say, I, General Motors,\nam issuing a bond. This is through\nbond, issuing a bond. And the way that bond works is\nI promise that for every dollar you spend buying my bond,\nyou'll get 1 plus I dollars back at the end-- or next year, say, depends\non how long the bond is. So literally, you're loaning the\nmoney to the firm by buying-- you're buying their\npromise to pay you back. Now, a second way you can\nloan money to the firm is through investing\nin their equity. You can buy their stock. The way this works is GM says\nto you, buy a piece of me and you'll get paid back not\nsome fixed interest rate, but you get paid back\naccording to how well GM does. So with corporate\ndebt, I get paid back something that's predetermined. When I buy stock or\nequity, I don't get back a predetermined amount. I get back some-- it depends\non how well the company does. But it's the same basic idea. I'm giving the company\nsome money today in return for my getting\nmore money, I hope, tomorrow. That's the diversion\nof consumption from today to tomorrow. And the third thing I could do\nis I could put it in the bank. Now, how is that\nloaned to companies? Because the bank then\nloans it to companies. Why do banks say they'll pay\nyou interest on your money? Why did banks going crazy-- I'll give you 1-- it used to be interesting. Now it's 1%, 2%. When I was a kid, I\nwas like 10%, 12%. We'll give you lots of money. And we'll talk later about\nwhy it was so much higher when I was a kid. Why are banks so\neager to do that? It's not out of the\ngoodness of their heart. It's because when you give\nthem dollars, they turn around and loan them. They add a bunch to\nthe interest rate and loan them out to firms. So those dollars\nyou're giving the banks and they're paying\nyou 2% interest, they loan to firms at 6%. And that's why bankers are rich. So basically, the reason a bank\nexists is because it's a way-- corporate debt\nand equity markets are hard and complicated. It's much easier to put\nyour money in a bank. You put your money in a bank. But when you put\nyour money in a bank, you're essentially\nloaning it to companies. That's essentially\nwhat you're doing. So through these mechanisms,\nwe have a capital market where essentially, by my\nputting money away and diverting from today's consumption,\nI'm loaning to a firm. They'll produce\nmore, and they'll pay me back more in the future."}, {"content": "Questions about that? OK, so let's talk about where\nthe supply curve comes from. We know where the\ndemand curve comes from. It just simply comes\nfrom the marginal revenue product of capital. Where does supply\ncurve comes from? The supply curve comes from what\nwe call intertemporal choice. As I said, economists like\nputting fancy names on things. That helps us get\npaid more money. It just means choosing over\ntime, intertemporal choice. Intertemporal choice\nis essentially about how do you decide\nhow much to save. What's going to\ndetermine that is going to be your\ndecision of how much you value money today versus\nvaluing money tomorrow. So for ease, let's imagine\nI'm considering two periods, this year versus next year. When I talk about periods, I'm\ntalking about days and years and whatever. It's the basic logic. It's about now\nversus the future. Whether I say days or\nyears, it doesn't really matter right now. The point is I'm just talking\nabout today versus the future. So let's talk about this\nyear versus next year. And let's imagine prices\naren't going to change. I'll come back to\nprices next lecture. But let's imagine the price of\ngoods aren't going to go up. There's no inflation\nin this economy, which is roughly true today. And let's suppose I'm\ngoing to take next year off to care for my children."}, {"content": "Lord knows why I'd want to\ndo that when the youngest one's 19, but imagine\nthey still need my care. So let's say I'll take next--\nthis example gets dated. Let's say I take next year\noff to care for my children. And let's say my income\nis $80,000 a year. Now, here is my-- but I'm going to take\nnext year off unpaid. So I'm going to work\nthis year for 80k. Next year I'm going\nto take off unpaid. So I have a couple of choices. I could work this year,\nearn my 80k, spend my 80k, and have nothing\nnext year to live on. I could work this\nyear and eat nothing and save all of\nthe 80k to live on, or some combination in between. And we could illustrate--\nbut the key difference is every dollar\nthat I don't consume this year that I save to consume\nnext year earns interest. And that's where\nthe trade-off comes."}, {"content": "So let's look at figure 16-6. This is a familiar-looking\noptimization diagram. Now my optimization is not\nover pizza versus cookies, but my optimization is over\nconsumption this period versus consumption next period. It's a bit mind-blowing. We're a little\nscience-fictiony here, right? We're now not talking about\nchoosing between two goods, like leisure and consumption\nor cookies and pizza. Now I'm talking about two time\nperiods, consumption today versus consumption tomorrow. But that's the key\nthing about the tools we learn with consumer choice. Those tools are\nincredibly powerful."}, {"content": "You just need to shove your\nproblem into that framework. And we're going to shove our\nproblem into this framework. The problem we're facing is how\ndo I decide how much to save. Well, savings is a bad\njust like labor's a bad. What do we do when we\nhave a bad to model? We don't model the bad. We model the complementary good. So our choice is, how\nmuch do I consume today? My choice is, how much\ndo I consume today and how much am I going to save? Well, saving is a bad, but the\nother way to think about it is, how much am I\ngoing to consume today versus how much am I\ngoing to consume tomorrow? Then that's two goods and I can\nmodel them against each other. And that's what I\ndo in figure 16-6. I model consumption today\nversus consumption next year. So here's my choices. As I said, if I consume\neverything today, I'm at the\nx-intercept at 80,000. I have 80,000 to consume\ntoday, nothing next year. If I consume everything\nnext year, what do I get? Well, let's say the\ninterest rate is 10%. What that means is then\nI'll have $88,000 next year. Why will I have more next year? Because by saving,\nI earn interest. By diverting my consumption to\nthe future, I earn interest. At 10%, that means I would\nhave $88,000 next year. So my budget constraint is the\nline with the slope minus 1 plus I. My budget constraint is\nthe line with the slope minus 1 plus I. In other words,\nthe price of consumption today in terms of consumption\ntomorrow is minus 1 plus I. OK, let me think about it."}, {"content": "Let me say that again."}, {"content": "It's really confusing. The price of consuming today\ninstead of consuming tomorrow, assuming no inflation--\nso prices are the same in the market-- is minus 1 plus I. Think about that. I find it useful to think back\nto the labor case for parallel. In the labor case, what did we\nsay was the price of leisure? What was the price of leisure? Someone raise their\nhand and tell me. In the labor-- yeah? AUDIENCE: The wages. JONATHAN GRUBER: The wages. Why? AUDIENCE: Just because that's\nthe opportunity cost of not-- JONATHAN GRUBER: Right. So by that same\nlogic, can tell me why is the price of\nconsuming today 1 plus I? AUDIENCE: Because if\nyou choose to save, then we're effectively richer. JONATHAN GRUBER: Exactly. The opportunity\ncost-- remember, we are an annoying discipline\nwith a dismal science. We're telling you, hey, enjoy\nthat cookie, but by the way, if you weren't eating that\ncookie, you could have 1 plus I cookies tomorrow. So just like we nag you for\nsitting around watching TV, we nag you for eating\ntoday by saying, hey, the more you consume today,\nthe less you can have tomorrow. And in fact, that trade-off\nis that for every cookie you consume today, you forgo\n1 plus I cookies tomorrow. So that's the budget constraint. The slope is the opportunity\ncost of consuming today in terms of\ntomorrow's consumption or next year's\nconsumption, which is 1 plus I. That's the slope\nof the budget constraint, is the opportunity cost. And then, then we say, OK, well,\nthat's the opportunity cost. That's the budget constraint. Well, how do I decide? Well, then we know how to\nmake these decisions, which is go to utility function. You can write down the\nutility function, which is a function of C1 and C2. Now, what is C? C is all my pizza and cookies,\nbut we're aggregating it up. Just like our utility\nfunction last time was a function of\nleisure and consumption-- we said consumption was\nthe bundle of goods you eat and leisure is this thing. Now we're saying, OK,\nour utility function now is a function of this trade-off. Now, you might\nsay, wait a second. How can both those\nbe utility functions? And the answer is you have\nsome meta-utility function that includes consumption today,\ntomorrow, leisure, pizza, cookies, et cetera. But we can think about\nthis in sequential steps. First, we decide how we're\ngoing to split our income. Then we can decide what to\nspend it on each period. Then you can do a separate\nconsumer maximization decision. But our first\nquestion is simply how am I going to split my income. Well, that's going\nto be a function of my taste for consumption in\nthis period versus next period and the price the bank will\npay me for delaying consumption till next period. Now, what happens? Questions about that? Now, what happens\nin the scenario when the interest rate goes up? What do you think happens if\nthe interest rate goes up? Yeah?"}, {"content": "AUDIENCE: There's [INAUDIBLE]. JONATHAN GRUBER: Right. So what do you\nthink you should-- what do you think will happen\nto your consumption pattern? Yeah? AUDIENCE: You should\nspend less today. JONATHAN GRUBER:\nSpend less today and save more because\nit's rewarded. And why is that not\nnecessarily true?"}, {"content": "Yeah? AUDIENCE: Because you might only\nneed a certain amount of money to live. So you don't have to\nsave as much today because you'll make-- JONATHAN GRUBER: Because\nof what two effects? Income and substitution effects. You gave exactly the intuition\nthat the substitution effect gives you. The substitution effect\nis exactly right. If the interest\nrate goes up, that's like the price of\nconsumption today going up. And if the price of\nsomething goes up, the substitution effect\nsays you do less of it. But if interest rate\ngoes up, you're richer. And if you're rich, you\ndo more of everything, including consuming today. The income effect\ngoes the other way. It's like labor. Once again, income and\nsubstitution effects is why we bothered\ntelling you so. Because income and substitution\neffects, in these cases, go against each other. Let's look at figure 16-7, OK?"}, {"content": "In figure 16-7, we\nstart at point A. Now imagine the interest\nrate doubles to 20%. Now imagine the\ninterest rate doubles. As you said, that pivots the\nbudget constraint upwards. You could still consume\nonly $80,000 this year, but now for every dollar you\nsave, you get $1.20 next year. That has two effects\non your decision. The substitution effect, we get\nby drawing an imaginary budget constraint-- that's\nthe dash line-- tangent to the original\nindifference curve but at the new slope. By definition, that means\nyou consume less today. You consume less\ntoday by definition. If the price of\nsomething goes up, the substitution effect\nalways says you do less of it. You consume less today,\nwhich means you'll save more. Remember, savings is just\nincome minus consumption in period one. So just as labor was\n24 minus leisure-- and so if we just solve for\nleisure, we could get labor. Savings is just income minus\nconsumption in period one. So if we solve for consumption\nin period one, we get savings. People see that? So basically, the point here\nis the substitution effect says, well, gee, the price\nof consumption in period one just went up. It's more costly in terms\nof future consumption. I'm going to do less, but then\nmy savings is going to go up. Substitution effect\nsays you save more. But the income effect\nsays, wait a second. You're now richer. Every dollar of your\nsavings you are doing now yields twice as\nmuch in interest. If you're richer, you'll consume\nmore of everything, including period one consumption. So the income effect takes\nyou back the other way. Now, whether the income\neffect dominates are not, we don't know. In this case, it\ndoesn't dominate. In this case, you\nstill, on net, end up consuming less in period\none and saving more. But we don't know what's\ngoing to dominate."}, {"content": "And in fact, the evidence\nhere is incredibly weak. I won't spend a long\ntime on the evidence because it's not nearly as\ninteresting and strong as labor supply. The evidence is incredibly\nweak even about the sign. And let's come to the intuition\nthat was given for why. Well, think about how people\nmake savings decisions. Lots of people\nhave savings goals. I want to have x by\nthe time I retire. Typical way if you ask\npeople about their savings-- if you ask them,\nthey typically say I want to make sure I\nhave x in the bank in case I'm in an accident. I want to make sure I have\ny by the time I retire. Well, in those models, if\nthe interest rate goes up, savings rates go down. Because after all, to hit a\ntarget with a higher interest rate, I can save less. So it's actually\nnot that surprising that you'd have\na higher interest rate leading to less savings. It's kind of\nintuitive, actually. If people have savings\ntargets, a higher interest rate would lead to less savings\nbecause they can get to their target more easily. So actually, we don't even\nknow which way this goes. It's, I think, one of the\ngreat unsolved mysteries in economics empirically,\nis, once again, we typically assume-- and with a gun to\nmy head, I would say it's probably true that\nhigher interest rates leads to more savings. But the evidence on which\nthat rests is pretty weak."}, {"content": "And the key point for you is\nto understand it's uncertain and it depends on whether\nincome and substitution effects dominate. Questions about that?"}, {"content": "OK. So now let's step back\nand put it all together and think about you making\nyour decision about life. You can think about\nyour decisions about your life in three steps. Step one is you decide\nhow hard to work. Step one is you decide, how\nmuch money do I want to make? Well, that's about\nmaximizing utility over consumption and leisure. Step two is, having decided\nhow much you're going to make-- and that yields your labor. Step two is, deciding how\nmuch you're going to make, you decide, well, how do I\nwant to spread that over time? How much do I want to consume\ntoday versus tomorrow? Well, that's about\nintertemporal choice. That's about deciding\non C1 versus C2, and that's going to\nyield your savings. Step three is, now that\nI know how much I'm going to consume\neach period, now I want to maximize utility\nacross all my goods I might want to\nconsume-- x2, across all the goods I want to consume. That was our original\ncookies and pizza example. So you could think of\nit as a hierarchical set of consumer\noptimization problems that you're going to solve. Now, you might say,\nwell, gee, Jon, that's sort of confusing\nbecause, in fact, the interest rate and how much am I\nsaving could determine how hard I work, right? Let's say the interest\nrate goes way up and I have a savings target. I have to work less hard\nto hit that savings target. And I'd say to\nyou, good for you."}, {"content": "Take more advanced economics. More advanced\neconomics, we recognize this is one integrated whole\nand we allow these systems to affect each other. But for here, just think of\nthem as separatable steps, independent steps. But in practice,\nI hope you can see the steps will be integrated\nand they'll affect each other. Think of it. If the price of a good\nyou really want to buy goes up a lot, not only will\nyou buy less of that good; you might save more to\nbuy it and work harder. So you can imagine how\nthese things are integrated."}, {"content": "But for now, we'll keep\nthem separable, OK? Questions about that?"}, {"content": "OK. Next time, we're to\ncome back and talk about all the interesting\nstuff in capital markets and how we make decisions\nabout how much to save and things like that."}], "Overview Artificial Intelligence Course | Stanford CS221: Learn AI (Autumn 2019)": [{"content": "All right. Let's get started. Please try to have a seat if you can find a seat and let's, uh, get the show on the road. So welcome everyone to CS221, this is Artificial Intelligence. Uh, and if you're new to Stanford, welcome to Stanford. Um, so first let's do some introductions. So I'm Percy, I'm gonna be one of your instructors. I'm teaching this class with Dorsa over there. So if Dorsa wants to say hi, stand up. Hi guys, I'm Dorsa. Um, I'll be co-teaching [NOISE] this class with Percy. I'm a professor in robotics and robotic interactions. Super excited about teaching this class and [inaudible]. Great. So we're going to be trading off throughout the quarter. And we also have a wonderful teaching team. So these are your CAs. So if all the CAs could stand up and I'll give you each person an opportunity to say three words about what you're interested in. So um, let's start with [inaudible] because you're the head CA. Hello. My name is [inaudible]. I'm a PhD student, and I'm interested in natural language processing. Yay."}, {"content": "[LAUGHTER] Hi. My name is [inaudible]. I'm a second year masters student. I'm interested in, um, machine learning and data mining. Hi. I'm [inaudible]. I'm a second year masters student and I'm interested in machine learning and natural language processing. Hi everyone, my name is [inaudible]. masters student and I'm interested in computer vision. [BACKGROUND] [NOISE] Let's go over there. [BACKGROUND] [NOISE] Great. Now, any new TAs in the back? No. Well, um, well, they're all on the slide. Okay. So uh, as you can see, we kind of have a very diverse team and so when you're thinking about kind of final projects later in the quarter, you can tap into this incredible resource. Um, so three quick announcements. Um, so there's going to be a section every week which will cover both kind of review topics and also advanced, uh, uh, topics. So this Thursday there's gonna be an overview. Um, if you're kinda rusty on Python or rusty on probability, come to this and we'll get you up to speed. Um, homework, the first homework is out, it's posted on the website. It's due next Tuesday at 11:00 PM. So remember the time, that matters."}, {"content": "Um, all submissions will be done on Gradescope. There's gonna be a Gradescope coast- code that will be posted on, uh, Piazza. So look out for that, um, later."}, {"content": "Okay."}, {"content": "So now let's, let's begin. So when I first started teaching this class, uh, seven years ago, I used to have to motivate why AI was important and why if you study it you'll have a lot of impact in the world. But I feel like I don't really need to do this. Now it's kind of inescapable that you pick up the news in the morning and you hear something about, you know, AI. And indeed we've seen a lot of success stories, right? AIs that can play Jeopardy or play Go, Dota 2, pro- even poker, all these kind of games at super human level performance. It can also, you know, read documents and answer questions, do speech recognition, uh, face recognition, um, even kind of medical imaging. And all these tasks are, uh, you read about how successful these, uh, technologies have been. Um, and then if you take a look at outside the kind of the technical circles, there's a lot of people, um, in policy, um, and trying to ask what is going on with AI. And you, you hear about, uh, these kind of very, uh, broad claims of how transformative AI will be, um, to the future of work and, um, to society and so on, and even some kind of bordering on, uh, pretty castro- you know, catastrophic consequences. So what's gonna happen in the future, no one knows, but it is fair to say that AI will be transformative. Um, but how do we get here? And to do that, I wanna take a step back to the summer of 1956. So the place was Dartmouth College, John McCarthy, who was then at MIT, and then, uh, after that he founded the Stanford AI Lab, um, organized a workshop at Dartmouth College with, um, some of the best and brightest minds of the time; Marvin Minsky, Claude Shannon, and so on. And they had this not so modest goal of trying to think that every aspect of learning or any feature of intelligence could be precisely captured so that a machine can be just, uh, simulated. So they were after the, the big question of how do you kind of solve, um, AI. So now they didn't make that much, uh, progress over the, the summer, but a lot of programs and interesting artifacts came about from that time. Um, there were programs that could play checkers or prove, uh, theorems, and sometimes even better than what, um, you know, the human proof will look like. Um, and there was a lot of optimism. People were really, really excited, and you can see these quotes by all these excited people who proclaimed that AI would be solved in a matter of years. But we know that didn't really happen and there's this kind of folklore example, um, people are trying to do machine translation. So you take an English sentence like 'The spirit is willing but the flesh is weak', you translate into Russian, which is what, um, the choice language by the US government was at that time, and you could, uh, translate back into English; and this is what you get, 'The vodka is good but the meat is rotten'. Um, so the government didn't think that was too funny, so they cut off the funding [LAUGHTER] and, um, it became the first AI winter. Um, so, so there was a period where, you know, AI research was not very active and was not well- very well funded. Um, so what went wrong here? Um, these were really smart people, right? Um, they just got a little maybe ahead of themselves. So two problems; one is that the compute was simply not there, right? It was millions or even billions of order of magnitude compared less than what we have, uh, right now. And also, the problems, the way they formulate them, intrinsically relied on camp- exponential search which, um, no matter how much compute you have, you're never going to, you know, um, win that race. Um, they also have limited, you know, information, and this is maybe a kind of a more subtle point that if I gave you infinite compute and I asked you to translate, I don't think you would be able to figure it out because it's not a computation problem. You just need to learn the language and you need to experience all the subtleties of language to be able to, you know, translate [NOISE]. But on the other hand, AI wasn't solved, but a lot of interesting, um, contributions to computer science came out of it. Lisp was- is- uh, had a lot of ideas that underlay ma- many of the high level programming languages we have, garbage collection, um, time-sharing, allowing, uh, multiple people to use the same- one computer at the same time, which is something that, uh, we kind of take for granted. And also this paradigm of separating what you want to compute, which is modeling, and how you do it, which is inference, which we'll get to a little bit later. Okay. So um, people forget quickly and, um, in the '70s and '80s, there was a renewed generation of people getting excited about AI again. Um, and this time it was all about knowledge, right? Knowledge is power and, um, there were a lot of expert systems which were created. And the idea is that if you could encode expert's knowledge about the world, then you could do kind of amazing things, and at the time the knowledge was encoded in generally a set of rules. Um, and there were a lot of programs that was written, and you'll notice that the, the scope is much narrower now. The goal isn't to solve it- all of AI, but to really focus on some choice and problems like diagnosing the diseases or converting customer's order parts into parts, and, uh- customer orders into parts and, uh, this was the first time that AI, I think, really had a real impact on industries. So uh, people were actually able to make useful, you know, products out of this. And knowledge did actually play a key ingredient in curbing this, you know, exponential growth that people were worried about. But of course, um, it didn't last long. Um, knowledge as deterministic rules was simply not rich enough to capture all the kind of nuances of the world. It required a lot of manual effort to maintain and, um, again, um, a pattern of over-promising and under-delivering that seems to plague, um, AI people, led to the collapse of the field and the kind of a second AI winter. Um, okay, so that's not the end of the story either."}, {"content": "But actually it's not kind of really the beginning either. Um, so I'm going to step back further in time to 1943. So what happened in 1943? So there was, um, a neuroscientist, McCulloch; and logician, Pitts, who were wondering and marveling at how the human brain is able to do all of these kind of complicated things. And they wanted to kind of formulate a theory about how this could all happen. So they developed a theory of, um, artificial neural networks, um, and this is kind of you can think about the root as of, you know, deep learning in some sense. Um, and what's interesting is that they looked at, um, neurons and logic, which are two things that you might not kind of necessarily associate with each other, and showed how they were kind of connected mathematically. And a lot of that early work in this era were of- around artificial neural networks, was about studying them kinda from a mathematical perspective. Um, because at that time, the compute wasn't there, you couldn't really run any kind of training new models or um. And then 1969, something interesting happened. So there's this book by Minsky and Papert called Perceptrons. And this book did a lot of mathematical analysis. And it also showed that linear models, one of the results of many, was showing that linear classifiers couldn't solve the XOR problem. Um, the problem is- another way to think about the problem is basically given two inputs, can you tell whether they are the same or not, or different. And, um, so it's kind of not a- shouldn't be a hard problem but linear classifiers can do it. And for some reason, which I don't quite understand, it killed off neural nets research even though they had said nothing about if you had a deeper network, what it could do. Um, but it's often cited that this book, ah, swung things from people who were interested in neural networks to the field of AI being very symbolic and logic driven. Um, but there was always this kinda minority group, um, who were really invested in and believed in, um, the power of neural networks, and I think this was always just kind of a matter of time. So in the '80s, there was a renewed interest. Um, people kind of discovered or rediscovered the backpropagation algorithm which allowed a kind of, for a generic algorithm that could train these multilayer neural networks because single layer remember was insufficient to do a lot of things. And then one of the kind of the early success stories, as Yann LeCun in 1989, applied a convolutional neural network and was able to recognize hand digit- written digits, and this actually got deployed, um, by the USPS and was reading kind of zip codes. Um, so this was, you know, great, ah, but it wasn't until this decade that the, um, this area of neural networks really kind of took off, um, under the moniker deep learning. Um, and, you know, AlexNet in 2012 was kind of a huge transformation, um, where they show gains on the, kind of ImageNet ba- benchmark and overnight transformed the computer vision community. Um, AlphaGo as, you know, many of you know, and many kind of other, um, and there were kind of the rest is history. Okay, so- so there's this kind of two intellectual traditions. Um, you know, the name AI has always been associated with the kind of John McCarthy logical tradition, that's kind of where it started. But, um, as you can see that there is also kind of this neuroscience inspired tradition of AI, and the two are kind of really had some deep philosophical differences and over the decades fought with each other kind of quite a bit. But I want to pause for a moment and really think about, [NOISE] maybe if there were actually kind of deeper connections here. Remember McCulloch and Pitts, they were studying artificial and neural networks, but the connection was to logic, right? So from even in the very beginning, there is kind of this synergy that, you know, some- some people can kind of often overlook. And if you take a look at AlphaGo, which [NOISE] if you think about the game of Go or many games, it's a mathematically, you can write down the rules of Go in logic in just a few lines. So it's a mathematically well-defined logical- logic puzzle in some sense. But somehow, the- the power of neural networks allows you to develop these models that actually play Go really- really well. So this is kinda one of the deep mysteries that has, kind of, uh, I think is kind of o- opens standard challenge, you know, in AI. Um, as with any story it's not a full picture, and I want to point out on this slide that, AI has drawn from a lot of different, you know, fields, many of the techniques that we're gonna look at, for example, maximum likelihood, came from your statistics or games came from economics, optimizations, gradient descent, hence from- was, you know, in the '50s completely unrelated to AI. But these techniques kind of developed in a different context. And so AI is kind of like, you know, it's kind of like a New York City. It's- it's like a melting pot where a lot of the- these techniques that kind of unified and apply to kind of interesting problems. And that's what makes it, I think really interesting because of the- the new [NOISE] avenues that are opened up by kind of unique combinations of, um, existing techniques. Okay, so- so that was a really bre- brief history of, you know, where- how we got here. Um, now I want to pause for a moment and think about, you know, what is- what is the goal? What- what AI people are trying to do? And again this- this is kind of there's two ways to think about this which and- sometimes the conflation of these causes a lot of confusion. Um, so I like to think about it as AI as agents, and AI as tools. So the first view asks the kind of standard question of, how can we create or recreate intelligence? And the second one asked, you know, how can we use technology to kind of benefit, you know, society? [NOISE] And these two are obviously very related and they have, ah, a lot of shared technical, um, overlap, but, you know, philosophically they're kind of different. So let me kind of explain this a little bit. So the idea with AI agents is, and this is, I think a lot of what, um, um, gets associated with AI, um, and especially as, you know, with science fiction. That kind of, ah, po- portrayal certainly kind of encourages this kinda view where [NOISE] you're human- we're human beings. And what you do is you look in the mirror and you say, wow, that's must- that's a really smart person. And you think okay, how- how- what- what- what can humans do that is, you know, so amazing. Well, they can, um, they can see and they can perceive the world, recognize objects. Um, they can grasp cups and drink water and not spill it. [NOISE] Um, they can communicate using language as I'm doing to you right now. Um, we know facts about the world, [NOISE] declarative knowledge such as what's the capital of France and procedural knowledge like how to ride a bike. We can reason with this knowledge and maybe ride a bike to the capital of France. And then, really importantly, we're not born with all of this, right? We're born with basically nothing, none of these capabilities, but we are born with the capacity and potential to acquire these over time through experience. And learning it seems to be kind of this critical ingredient, which drives a lot of the success in AI today but also with, um, you, know, human intelligence it's clear that learning plays such a central role in getting us to the level that we're operating at. So each of these areas has kind of spawned entire sub-fields, and people in it are kind of wondering about how you can make artificial systems that have the language, or the motor, or the visual perceptual capabilities that, you know, humans have. But are we there yet? Um, and I would- I would like to think that we are, ah, very far. So if you look at the way that machines are, have been successful, it's all with a narrow set of tasks and, you know, millions or billions of examples, and you just crunch a lot of computation, and you can really kind of optimize, um, every- any tasks that you're going to come-come up with. Whereas humans operate in a very different regime. [NOISE] They don't necessarily do any, you know, one thing well, but they are have such a kind of diverse set of, you know, experiences, can solve a diverse set of tasks and learn from each individual tasks from very few examples. And still it's a kind of a grand challenge, in from a, uh, cognitive perspective, how you can build systems with this level of capability in that humans have. So the other view is, you know, AI tools. Basically we say okay well, you know, it's kind of cool to think about how we can, uh, you know, recreate intelligence. But, you know, we don't really care about making more, um, things like humans. We already have a way of, you know, doing that, that's called babies. [LAUGHTER]. Um, so when instead what we'd really like to do is not making something that's like a human but making systems that help humans. Because, you know, after all, we're- we're humans, I guess it's a little bit selfish but, um, we're in charge right now. Um, and- and a lot of this- this view and a lot of the success stories in AI are really different from the things that you expect, you know, this, uh, this humanoid robot to come into your house and be able to do. For example this is a project from Stefano Ermon's group. Um, there's a lot of poverty in the world and, um, part of it is- is just kind of understanding what's- what's going on and they had this idea of using, uh, computer vision on satellite imagery to predict things like, you know p-, uh, GDP. Um, so this is obviously not a task that, you know, the- our ancestors in Africa were like, you know, getting really good at. Um, but nonetheless it uses convolutional neural networks which is a technique that was inspired by, um, you know the brain and so that's- that's kind of interesting. Um, you can also have another application for saving energy by trying to figure out when to cool on datacenters. Um, as AI, is, uh, being deployed in more kind of mission critical s-, uh, situations such as self-driving cars or authentication. There are- there are a f- few th- new issues that come up. So for example, there are- thi- this phenomenon called adversarial examples, um, where you can take, um, these cool-looking glasses, you can put them on your face, and you can fool the computer, um, as- of- save our- our face recognition system to think that you're actually, you know, someone else. Um, or you can post these, uh, s- stickers on stop signs and you'd get this, uh- s- save our system to think that it's a, um, a speed limit sign. So there's obviously- there's- clearly these are, you know, big problems if we think about that the widespread deploy- deployment of AI. Um, there's also a less catastrophically but also p- pretty, um, you know, upsetting which is, uh, biases that you- many of you probably have read in the news about. So for example, if you take Malay which is a language that, uh, doesn't distinguish, um, in this writing form between he and she and you stick it into Google Translate. Um, you see that she works as a nurse but he works as a programmer, which is encoding certain, uh, societal biases, um, in the actual models. And one kind of an important point I wanna bring up is that, you know, it's -- it's how is machine learning and AI kinda working today? Well, it's, um, you know, society exists. Society is generating a lot of data. We're training on this data, and kind of trying to fit the data and try and mimic what it's doing and then using predictions on it. What could possibly go wrong, right? Um, and so- so certainly people- a lot of people have been thinking about, um, how these biases are kind of creeping up and is an open and active area of research. Something a little bit more, uh, kind of s- sensitive is, you know, asking well,  these systems are being deployed to all these- all these people whether they kinda want it or- or want it or not. Um, and this, uh, this actually touches on, you know, people's, uh, you know, livelihoods. It actually impacts people's lives in a serious way. Um, so Northpointe was this company that developed a- a software called COMPAS that tries to predict how risky, um, criminal risk or how someone- how risky someone is essentially. Um, and ProPublica this organization realized whoa, whoa, whoa, whoa. You have this system that, uh, given an individual didn't reoffend is actually, um, more- twice as likely to classify blacks as incorrectly as, you know, non-blacks. So this is, uh, seems pretty problematic. And then Northpointe comes back and says actually, you know, I think we- I think we're being fair. Um, so given a risk score of 7, uh, we were fair because 60% of whites reoffended and 60% of blacks reoffended. Um, the- the point here is that there's- there's- there's actually no, um, solution to this in some sense sadly. Um, so people are finding or formulating different notions of fairness and equality between, um, how you predict or record it on different kind of, um, groups. But, um, or you can have different notions of fairness and which all seem reasonable from first principles but mathematically they can be, um, incompatible with each other. So this is- this is again an open area of research where we're trying to figure out as a society how, um, to deal with the schema that machine learning might be using these in kind of critical situations. Okay. So summary so far, um, there's an agent's view. Um, we're trying to really kind of dream and think about how do you get these capabilities like learning from very few examples that humans have into, you know, machines and a whole- maybe opening up a kind of a- a different set of technical capabilities. But at the same time, and we really need to be thinking about how these AI systems are affecting the real world. And things like security, and biases, and fairness all kind of show up. It's also interesting to note that, you know, a lot of the challenges in deployment of an AI system don't really have necessarily to do with, um, you know, humans at all. I mean, humans are incredibly biased but that doesn't mean we want to build systems kind of in our- in, um, that mimic humans and kind of inherit all the kind of the flaws that humans have. Okay."}, {"content": "Any questions about this? Maybe I'll pause for a moment."}, {"content": "So let's go on. Um, so what I wanna do next is give an overview of the different topics, um, in the course. Um, and the way to think about all this is that, um, in AI we're trying to solve really complex problems. The real world is really complicated. And- but at the end of the day we want to produce some software or maybe some hardware that actually runs and does stuff, right? And so there's a very considerable gap between these things. And so how do you even approach something like self-driving cars or, um, you know, d- diagnosing diseases? You probably shouldn't just like go sit down at a terminal and start typing because then, um, there- there's no kind of- no overarching structure. So what this class is going to do is to give you one example of a structure which will hopefully help you approach hard problems, and think about how to solve them in a kind of more principled way. Um, so this is a paradigm that I call the, um, modeling inference and learning paradigm. Um, so the idea here is that there's three pillars which I'll explain in a bit. And, uh, we can focus on each one of these things kind of in turn. So the first pillar is modeling. So what is modeling? The modeling is taking the real world, which is really complicated and building a model out of it. So what is a model? Model is a simplification that is mathematically precise so that you can, you know, do something with it, uh, on a computer. Um, one of the things that's necessary is that modeling, um, necessarily has to simplify things and, you know, throw away information. Um, so one of the kind of, uh, the, you know, the art is to figure out what information to pay attention to and what information to keep. Um, so this is going to be important for example when you work on your final projects and you have a real world problem, you need to figure out, um, you can't have everything and you have to figure out judiciously how to, um, manage your- your resources. So here's an example. If you want to for example build a- a system that can find, uh, the best way to get from point A to point B in a graph- in a- in a city you can formulate the model as a- a graph where nodes are points in the city, and edges rep- represent ab- ability to go between these points with some sort of cost, um, on the edges. Okay. So now once you have your model you can do, uh, inference. And what inference means is asking questions about your model. So here's a model you can ask for example how- what is the shortest path from, um, this point, uh, to this point. Right. And that's because now your model land is a mathematically well-defined, uh, problem now you can- it's within the realm of, uh, you know, deve- developing algorithms to, you know, solve that problem. And most of the inference is ki- being able to do these computations, um, really efficiently. And finally learning addresses the problem, where does this model come from? So in any kind of realistic setting, um, the model might have a lot of parameters. Maybe it has, you know, millions of parameters and how do you s- if it- if it- wants to be faithful to the, you know, real world that how do you get all this, uh, information there. Um, manually p- encoding this information turns out not to be a good idea. This is, um, in some sense what, um, AI from the '80s was trying to do. Um, so the learning paradigm is as follows. What we're gonna do is specify a model without parameters. Think about it as a skeleton. So in this case we have a graph but we don't know what the edge weights are. Um, and now we have some data. So maybe we have data of the form people tried to go from X to Y and they took 10 minutes, or an hour, or so on, um, and then from this data we can learn to fit the parameters of the model. We can assign, um, costs to the edges that kind of are representative of what the data is telling us, okay? So now in this way, we can write down a model without parameters, feed the data, apply a generic learning algorithm and get a model with parameters. And now we can go back and do, um, inference and ask questions, you know, about this. Okay. So this is kind of the- the- the paradigm. And I want to really emphasize that, you know, learning is not- as I've presented is really not about any one particular algorithm like nearest neighbors or neural networks. It's really a kind of a philosophy of how you go about approaching problems by defining a model and then not having to specify all the details but filling them in later. Okay. So here is the plan for the course. We're gonna go from low-level intelligence to high-level intelligence; and this is the intelligence of, um, of the, of the models that we're gonna be talking about. So first we're gonna talk about machine learning, and like I've kind of alluded to earlier, machine learning is going to be such a kind of an important building block of- that can be applied to any of the models that we kind of develop. So the central tenet in machine learning is you have data and you go to model, its main driver of a lot of su- successes in AI because it allows you to, in software engineering terms, move the complexity from code to data. Rather than having, you know, a million lines of code which is unmanageable, you have a lot of data which is collected in kind of a more natural way and a smaller amount of code that can operate on this data and this paradigm has really been, it's really been powerful. One thing to think about in terms of machine learning is that it, it is, requires a leap of faith, right. So you can go through the mechanics of down- downloading some machine learning code and you train them all but fundamentally it's about generalization, right. You have your data, you fit a model, uh, but you don't care about how it performs on that data; you care about how it performs on new experiences. And that leap of faith is something that's, um, I think gives machine learning its power but it's also a little bit, um, at first glance perhaps magical. Um, it turns out you can actually formalize a lot of this using, um, probability theory and, and statistics but that's kind of a topic for another time. Okay. So after we talk about machine learning, we're going to go back and talk about the, the simplest of models, right. So a reflex model is this. So here's a quiz."}, {"content": "Okay. What is this animal? Okay, zebra. How did you get it so fast? Well, it's kind of a reflex, where your human visual system is so good, um, at, at doing these things without thinking. Um, and so reflex models are these, um, are models which just require a fixed set of computations. So examples like are linear classifiers, deep neural networks, um, and most of these models are the ones that people in machine learning um, use. Models is almost synonymous with, um, reflex on- in machine learning. The important thing that there's no feed for it."}, {"content": "It just like you get your input bam, bam, bam, and here's your output. Okay, so that's, that's great because it's fast. But there's some problems that require a little bit more than that. Right. So for example here's another problem. Okay, quick, white to move. Where does she go? Okay, there's, there's probably like a few of you who are like chess geniuses, um, but for the rest of us, um, I have no idea. I don't know, wait, who's moving again? Um, so, so in these kind of situations, we need something perhaps a little bit more powerful than a reflex. We need agents that can kind of plan and think, um, ahead. So the idea behind state-based models is that we model the world as a set of states which capture any given situation like, uh, a position in a, in a game and actions that take us between states which correspond to things that, um, you can do in the, in this game. Um, so a lot of game applications fall in this as category of robotics, motion planning, navigation. Um, also some things that are might not be- you might think of, um, planning as such as gen- you know, generation, um. In natural language or generating an image, um, you are, uh, can be cast in this way as well. So there's three types of state-based models each of which we'll cover in, um, you know weeks of time. So search problems are the classic, uh, you control everything so you're just trying to fi- find the optimal path. There are cases where there's randomness. For example if you're trying to go from point A to point B, maybe there's traffic that you don't, you know, don't know about or, um, in a game there might be dice that are- die which are rolled, and, uh, there's a third category which are adversarial games which is cases where your playing an opponent who's actively trying to destroy you. So what are you gonna do about it? Um, so one of the games that we're gonna, uh, be talking about, uh, when we talk about games is Pac-Man; and one of the assignments is, um, actually building, um, a Pac-Man agent such as this. So, uh, while you're looking at this, think about how- what are the states and what are the actions and how would you go about you know devising a strategy for Pac-Man to eat all the dots and avoid all the ghosts? So that's something, uh, to maybe look forward to. There's also gonna be a competition. So we'll see how- who ends up at the top. Okay, so state-based models, um, are very powerful and a value to kind of have foresight. Um, but some problems are not really most naturally cast as state-based models. For example, you know, how many of you play Sudoku or have played it before? So as the goal of Sudoku is to fill in these, uh, um, blanks with numbers so that, um, every row and column and three-by-three sub-block has the digits 1 through 9. So there's a bunch of constraints. Um, and there's no kind of sense in which you have to do it in a certain order, right. Whereas the, the order in how you move in chess or something is, you know, pretty important. Um, so, so these type of problems, uh, are captured by these variable-based models where you kind of think about a solution to the problem as an assignment to the individual variables, under some constraints. So constraint satisfaction problems, we'll spent a week on that, um, these are hard constraints. For example two people can be- or a person can't be in the two places at once for example. Uh, there's also Bayesian networks which we'll talk about which are variable-based models with, uh, soft dependencies. For example if you're trying to track, um, you know, a car over time, these are the positions of the car. These variables represent the position of the cars and these, uh, E's represent, uh, the- the sensor readings of the position of the car at that particular position and inference looks like trying to figure out where the car was given all this kind of noisy sensor reading. So that's also gonna be another assignment where you're going to deal with."}, {"content": "Okay. So finally, um, now we get to high-level. What's- so what is high-level intelligence here? Um, and I put logic here, um, for a reason that you'll see clear."}, {"content": "Yeah, is there a question? The Sudoku, can you explain why it's not a state-based model? Yeah, so the question is why is not the- why is the Sudoku problem not a state-based model? Um, you can actually formulate this as a state-based model, um, by just thinking about the sequence of, uh, assignments. But it turns out that, um, you can formulate in a kind of more natural way as a variable-based model which allows you to, uh, take advantage of some kind of more efficient algorithm to solve it. Right, it's- think about these models as kind of different, um, analogy as like a programming language. So yes, you could write everything in you know C++ but sometimes writing in you know, Python or, or SQL for some things might be more- might be easier. Yeah. [inaudible] state based problem where you have both adversarial elements and an element of randomness? Yeah, so the question is how do you categorize state-based models where there is both randomness and an adversary? Um, we're also gonna talk about those as well. Um, and those would be- I, I would classify them as adversarial but there is also a random component that you have to deal with, games like backgammon. Yeah, question. [inaudible] Yeah, so the question is about whether, uh, some of these are more continuous and some of them are more discrete. Uh, I don't necessarily think of, uh, so a lot of the reflex models actually can work in continuous state spaces, for example images. Um, actually it's, it's almost a little bit of the opposite where, um, the logic-based models are in some sense more, you know, discrete but you can also have continuous elements, you know, in there, um, as well. Um, so in this class, we're mostly going to focus on kind of discrete objects because they're just going to be simpler to work with. Okay, so what is this logic? So the motivation here is that suppose you, um, wanted a little companion who, um, you could boss around and, um, help or help you do things, let's say; that's a better way to say it. Um, so you'd like to be able to say okay, you know, tell us some information, um, and then later you wanna be able to ask some questions and have the system be able to reply to you. Um, so, um, you know how- how would you go about doing this? One way you could think about is building a system that you can actually talk to using natural language, okay. So I'm actually going to show you a, a little demo, um, which, uh, is going to come up in the last assignment on logic; um, and well, let's see what you think about it. Uh, okay, so this is going to be a system that is, um, based on logic that I'm going to, um, tell the system a bunch of things and I'm going to ask some questions. So, um, I want you all to follow along and you see if you can, you know, play the role of the agents. Okay. So I'm going to teach you a few things like, um, Alice is a student, okay. So it says I learned something. Now let's, let's quiz, um, is Alice a student? Okay."}, {"content": "Good. So that worked. Um, is Bob a student? What should the answer be? I don't know who's Bob. Um, okay. So now let's do, um, students are, uh, people. Um, Alice is not a person. I don't buy that [LAUGHTER] okay. So, um, okay it's, you know, it's doing some reasoning, right? It's using logic, it's not, uh, just, um. Okay. So now, let's do, um, Alice is from Phoenix. Phoenix is a hot city. I know because I've lived there. Um, cities are places, and if it is snowing, uh, it is, um, then it is cold. Okay, got it. So, um, is it snowing? I don't know."}, {"content": "Um, so how about this?"}, {"content": "Okay. So if, um, a person is from a hot place and it is cold, then she is not happy, okay. True."}, {"content": "Right, um. I guess those of you who have spent all your live in California would maybe appreciate this. But, um, okay, so ho- is it snowing now? How many of you say yeah, it's snowing? How many say no? You don't know?"}, {"content": "Okay. [inaudible] Ah, ah, [LAUGHTER] um, how about if I say Alice is, ah, happy. Okay, so is it snowing now? No, it should be no. Okay. So you, you guys were able to do this."}, {"content": "Okay. So this is kind of an example of a interaction which, um, if you think about it has is ve- very different from where you would see kind of in a typical, um, you know, ML system where you have to show it millions of examples of one particular thing and it can do a kind of one task. This is much more of a very open-ended set of, um, I wish to say that the, the experiences are super rich but they're definitely diverse. I teach- I just give one statement. I say it once and then all of a sudden it has all the ramifications and kind of consequences that built in and it kind of understands in a kind of a deeper level. Of course this is based on, you know, logic systems. Um, so it is brittle but this is kind of just a proof of concept to give you a taste of what I mean when I say logic. So, ah, these systems need to be able to digest this heterogeneous information and reason deeply with that information. And we'll see kind of how, um, logic systems can do that. Okay. So that completes the tour of the topics of this class. Um, now I want to spend a little bit of time on course logistics. Uh, so I wanna- all the details here are online. So I'm not going to be complete in my coverage, um, but I just wanna give you a general sense of what's going on here. Okay. So what are we trying to do in this course? Um, so prerequisites, um, there's programming, um, discrete math and, ah, probability. So you need t be able to code and you need to be able to, um, do some math and, uh, some kind of basic proofs. Right? So these are the classes that are, um, required or at least recommended that you- or if you have some equivalent experience that's, you know, fine too. Um, and what we- what should you hope to get out of this course? Right. So one had- the course is meant to be giving you a set of tools using the modeling inference learning paradigm. It gives you a set of tools and a way of thinking about problems that hopefully will be really useful for you when you go out in the world and try to solve real world problems. Um, and also by- as a side product I also want all of you to be more proficient at your math and programming because those are kind of the core elements that, ah, enable you to do kind of interesting, you know, things in AI. So a lot of AI and you, you read about it, it's very flashy but really the foundations are still, um, just you know math and programming in some sense. Okay. So the coursework is homeworks, exam, and a project. That's what you have to do, um, Homeworks, there's eight homeworks. Each homework is a mix of writing- written and programming problems centered on a particular application covering one particular type of model essentially. Um, like I mentioned before there's a competition for extra credit. There's also some extra credit problems in the, in the homeworks, um, and when you submit code, we're gonna run- we have an auto-grader that runs. It's gonna run on all the test cases but you get a feedback of only a subset. So you can, um, it's like, you know, in machine learning, you have a train set, and you have a test set. So don't train on your test set. [LAUGHTER] Okay. So um, the exam is, ah, testing your ability to use the knowledge that you learn to solve new problems. Right. So there's, um, I think it's worth taking a look at exam because this, this kind of surprises people every- the exam is a little bit different than the types of problems that you see on, on the homework and there are kind of more problem, you know, solving. So the exam isn't going to be like a multiple choice like, okay, you know, um, you know, when was Perceptrons published or something like that. It's gonna be, here's a real life problem. How do you model it and how do you come up with a solution? Um, they're all going to be written. It's closed book except for you have a one page of notes and this is a great opportunity to actually, um, review all the material and actually learn the ah, the content in the class. Um, so the project I think is a, a really good opportunity to take all the things that we've been talking about in the class and, um, try to find something you really care about and try to apply it. Work in groups of three and I really recommend finding a group early, um, and as I emphasize it's your responsibility to find, you know, a good group. Right? Um, don't come to us later like one week before the project deadline and say, \"Oh, you know, my group members they, um, they ditched me,\" or something. We really try to, try to nail this down use Piazza to- or your other social networks to find a good group. So throughout the quarter there's going to be these milestones for the projects. So, um, to prevent you guys from procrastinating into the very end, um, so there's gonna be a proposal where you try and brainstorm some ideas, progress report, a poster session which is actually a whole week before the final report is due, um, and the project is very open. So this can be, um, really liberating but also might be a little bit daunting. Um, we will hopefully give you a lot of structure in terms of saying okay, how do you define your task? How do you implement different, um, baselines or oracles? Which I'll explain later. How do you evaluate? How do you, um, analyze what you've done? And each of you will- each project group will be assigned a CA mentor, ah, to help you, ah, through the process and you're always welcome to come to my office hours or Dorsa's, or any of the CAs to get additional, um, help either brainstorming or figuring out what the next step is. Ah, some policies, ah, all assignments will be submitted on Gradescope, um, there are seven total late days you can use, and most two per assignment. After that there's no credit. Um, ah, we're gonna use Piazza for all communication so don't email us directly. Leave a post on Piazza. If- I encourage you to make it public if it's, it's not sensitive, but if it's, you know, personal, then obviously make it private, um, and try to help each other. We'll actually award some extra credit for students who help answer, um, other student's questions. So all of the details are on the course website. Okay. So one last thing and it's really important and that's the Honor Code. Okay. So especially if you're, um, you know, you've probably heard this if you've been at Stanford. If you haven't, then I wanna really kind of make this clear. So I encourage you all to have- collaborate, discuss together. But when you- when it comes to actually the homeworks, you have to write up your homework and code it independently. So you shouldn't be looking at someone's writeup. You shouldn't be looking at their code. Um, and you definitely shouldn't be copying code off of GitHub. Um, um, that's hopefully should be, you know, obvious and maybe less obvious, you should not- please do not post your homework assignments on GitHub. I know you're probably proud of the fact that your Pac-Man agent is doing really well but please don't post on GitHub because then that's going to be our Honor Code violation. Um, when debugging, um, with- if you're working together, it's fine to as long as it's kind of looking at input-output behavior so you can say to your partner, \"Hey, I put in this, um, input to my test case and I'm getting a 3. What are you getting?\" So that's fine but you can't."}, {"content": "Remember don't look at each other's code. Um, and to enforce this, we're gonna be running MOSS, which is a software program that looks for code duplication, um, to, to make sure that, ah, the rules are being followed and, you know, changing one variable name is- or you'll be so- anyway enough said. [LAUGHTER] Just don't, don't, don't do that. Okay? Any questions about this? I wanna make sure this is important or about any of those logistics. Yeah. [inaudible] The final project, ah, you can put on GitHub. Yeah. Yeah. Yeah, private GitHub repos, uh, is fine. Yeah, question in the back? Is it necessary to have a group or can you do a solo project? Uh, the question is can you, can you do a solo project? You can do a solo project, you can do a project with two people, or you can do a project with three. I would encourage you to try to work in, uh, groups of three because you'll be able to do more as a group, and there is definitely, uh, you know, it, it, it's not like if you do a solo project we'll be expecting like one third of the, the work. So okay."}, {"content": "Anything else? All right."}, {"content": "Okay. So in the fi- final section, I want to actually delve into s- some technical details. Um, and one thing we're going to focus on right now is, um, the, kind of inference and learning components of, of this course. So I'm going to talk about how you can approach these through the lens of, you know, optimization. So this is going to be, uh, it might be a review for some of you but hopefully, it's gonna be a, a good, um, you know, way to get everyone on the same page. Okay. So what is optimization? There's two flavors of optimization that we care about. There's, uh, Discrete Optimization, where you're trying to find the best, uh, discrete object. For example, you're trying to find the best, uh, path or the path P that minimizes the cost of that path. Um, we're going to talk about one algorithmic tool, um, based on Dynamic Programming which is a very powerful way of solving these, um, complex optimization problems. Um, and the key, you know, property here is that the set of paths is huge and you can't just, uh, trial them and compute the cost and choose the best one. So you gonna have to choose something clever. The second brand of optimization is continuous optimization and formally this is just finding the best of vector of real numbers that satisfies or minimizes some objective function. So a typical place this shows up is in learning where you define, uh, objective function like the training error and you're trying to find a weight vector W. So this notation just means it's a list of numbers, D numbers that minimizes the training error. And we're going to show that gradient descent is, uh, uh, easy and a surprisingly effective way of solving these, um, continuous optimization problems. Okay. So to introduce these two ideas, I'm going to look at two, um, problems and trying to kind of work through them. So this might be also a good, um, you know, way to think about how you might go approach a, you know, homework problems. And I'll try to kind of talk you through this, um, in a bit more detail. Okay, so the first problem is, um, you know, computing edit distance. Um, and this might not look, you know, like an AI problem, but a lot of, ah, AI problems have this as kind of a, you know, building block if you wanted to do some sort of matching between, um, you know, two words or two, um, biological sequences. So the input is you're given two strings. Um, we're gonna start writing over here on the board just to work this out. So given two strings, um, S and T. Um, so for example, um, a cat and um, the cats. Okay. So these are two strings and you wanna find the minimum number of edits that is needed to take transform S into T. And by edits I mean you can insert, um, a character like you can insert S, you can delete characters, I can delete this A and you can substitute one character for another. So you can replace this A with a T. Okay."}, {"content": "Um, so here's some examples. What's the edit distance of cat and cat? It's 0, you don't have to do anything. Cat and dog is 3, cat and at is 1, you insert the A or insert a C. Um, cat and cat is 1, um, and a cat and the cats is 4. Okay. So the challenge here is that there are, ah, quite a different number of ways to insert and delete. Right, so if you have a string of- that's very long there's just way too many things to like just try out all of them. Okay, so then, how do we, how do we go about, um, coming up with a solution? So any ideas?"}, {"content": "Yeah. [inaudible] simplify the output in terms of saying that the substitution tells us we considered [inaudible] deletion peoples who considered a substitution or vice-versa by saying like an empty character. Yeah, yeah. So let's try to simplify [NOISE] the, the, the problem a bit. And building up on your what you, um, what was said. So, um, one thing to note is that okay, where so the general principle, let me just write the general principle, um, is to, you know, reduce the problem to a simpler problem because then you can hopefully solve- it is easier to solve, and then you can maybe keep on doing that until you get something that's trivial. Okay."}, {"content": "So there's maybe two observations we can make. One is that well, we're technically saying we can, um, you know, insert into S right but if we insert into S, it makes the problem kind of larger in some sense, right? I mean that's not, that's not good. That's not reducing the problem. But, but whenever we insert into S, um, we probably want to insert things which are in T. We wanna like cancel something out, right? So we wouldn't insert a K there for any reason. We probably wanna insert a S in which case no S matches that and then we've reduced that problem, right? So we can actually think about, you know, inserting into S to S as equivalent to kind of deleting from, um, from T. Okay, does that make sense? All right. So another observation we can make is that, you know, we can start inserting anywhere. We can start inserting here and then jump over here and to this. But this just introduces a lot of, um, you know, ways of doing it which all kind of result in the same answer. So why don't we just start more systematically at one end and then just proceed and try to chisel-off the problem, um, kind of let's say from the end. Okay, so start at the end? Okay, so, so now we have this problem and to draw a problem in a little box here. Um, so let's start at the end. Yeah, question. What's the reasoning used to reach that principle start at the end? [NOISE]. [NOISE] the question is why are we starting at the end as oppo- well, the idea is that if you start at the end then you have kind of a more systematic and consistent way of, you know, reducing the problem. So you don't have to think about all the permutations of where I can delete and substitute. Why is it more systematic to go from the right to the left than from the left to the right? We can also do it left to right. So the end or the start is both fine. This is just- I just picked the end. Yeah. Are we not starting at the end and then give us the optimal strategy? Yeah, the question is how do we know that starting, um, at one end can give you the optimal strategy? Um, so, you know, if you wanted to prove this more rigorously there's some work but, um, I'll just try to give you a, you know, an intuitive answer. Um, suppose you didn't start at the end, and you just made a sequence of steps like I insert here, I delete here, and then I went over here and um, did all those operations to S. I could have equivalently also just sorted those by, you know, where it was happening and then just proceeded from one end to the other, and I would arrive at the exact same answer. So without loss of generality, I can start at that."}, {"content": "Any other questions? Okay."}, {"content": "So yeah. Instead of doing this wouldn't the more viable [NOISE] approach be that trying to recognize some patterns instead of doing this. I think between the two strings \"s\" and \"t\" like some form of- some sort of [NOISE] pattern [inaudible] string. Yeah. So the question is, maybe you can recognize some patterns. Uh, it's like okay, oh, cat. That's- that's- maybe those should be lined up. Um, I guess these examples are chosen so that these patterns exist, but we want to solve the problem for cases where, um, the pattern might not be obvious. So it could be- we want to work it for- it to work for all strings. Maybe there is no pattern, and we still would want to- kind of an efficient algorithm to do it. Yeah. Can't we just like use dynamic programming? Like we go one by one, there was always like [inaudible] - Yeah. Either we're doing, um, substitution, or, um, otherwise it's like the same character. Or we have to insert- Yeah. - um, and then we keep going, and you just like [NOISE] remember each like to- to strings that we have at one point- Uh-huh. -so that if we calculated that we don't have to do it again. Yeah."}, {"content": "Yeah. That's it. Yeah. Yeah. Yeah. Great idea. Let's do dynamic programming. Um, so that's what I'm kind of trying to build up from- uh, build up to. Okay so, um, so if you look at this- so dynamic programming is a kind of a general technique that essentially allows you to express this more complicated problem in terms of a simpler problem. Uh, so let's start with this problem. If we start at the end, um, if the two match then, well we can just immediately, um, you know, delete these two and that's- it's gonna be the same, right? So we can get- we are gonna get some free rides there. Okay, but when they differ, um, now we have many options. So what we could- what could we do? Well, we could, um, um, you know substitute. Okay, we can change the \"t\" to an \"s\". So what does that leave us with? So I can do a cat, [NOISE] \"t\" is the- the cat, the- [NOISE] Okay, so I can substitute. [NOISE] Um, [NOISE] okay. Um, what else can I do? [NOISE] Someone say something I can do. [NOISE] So I can insert, um, insert where into- [OVERLAPPING] So I can insert an \"s\", right? Yes. [NOISE] But that's the same as, you know, [inaudible] deleting from \"t\". So by, uh- you can basically also just delete this \"s\". Um, so this is our cat, [NOISE] and I deleted this \"s\" from \"t\". Okay, so this is, um, let's call it, uh, you know, um, I guess let's call this insertion- it's technically insertion [NOISE]. And then finally what can I do? [NOISE] I can also remove \"t\". So [NOISE] a, ca, the, cats. Okay, so this is delete. [NOISE] And right now you're probably looking at this like, well, obviously, you know, you sho- you should do this one. But in general it's hard to tell. What if I just give you some arbitrary strings, you know, who knows what the right answer is. Um, so in general how do you pick? Yeah. In the second one, the \"t\" is supposed to be for cats. [NOISE] [inaudible] You mean this one? Yeah. So here I inserted an \"s\", right? But then because there's two s's here, I just canceled them out and [NOISE] what was left [inaudible] So you can think about this as really deleting from- What if I'm considering [NOISE] [inaudible] Like in the original problem you said we're transferring \"s\" to \"t\". Yeah."}, {"content": "Yeah."}, {"content": "Yeah. So, um, um, because of this I'm kind of trying to re-frame the [NOISE] problem a little bit. Okay, so which one should I choose?"}, {"content": "Yeah. What about the substitution the other way? Um, the substitution the other way meaning change- \"s\" to \"t\". Sorry there's too many s's and t's here which [LAUGHTER] is going to be a bit unfortunate. And then replace the last s in cats with \"t\". Oh, you could- How do we eliminate that [inaudible] [NOISE] Um, that's- you can think about that as kind of equivalent. So, if you identify two letters that you want to make the same, then [NOISE] you could- you can replace the one to be the other, or the other to be that. I mean if- officially we've been kind of framing it as we're only editing \"s\" which is the reason that it's asymmetric. [NOISE] Okay, so which one of these? Door \"a\" door \"b\" or door \"c\"? Yeah. Would you look [inaudible] between \"s\" and \"t\" for every step [NOISE] [inaudible] because there's \"cat\" in both of them? Yeah, so you could try to look inside but, um, but remember these are- might be really complicated. So you- we wanna kind of a simple mechanized procedure to tell. [NOISE] What about the next letter? The next letter. \"t\" [inaudible] Um, yeah let's- let's pretend these are- you- you can't see inside them. Okay."}, {"content": "[LAUGHTER]. Keep going with each of the different cases. Yeah, okay, so let's keep on going. [NOISE] So, I'm not going to draw everything, but you can also try to break this down into- maybe there's three actions here, and three actions here. All right. Um, and at the end of the day you hopefully have a problem that's simple enough, that, um, where \"s\" equals \"t' or something then you're done. Um, but then, you know, how- how do I- how do I know? Suppose I've solved this. Suppose if someone just told you, okay, I know this cost, I know this cost, I know this cost. What- what should you do? [inaudible] Yeah, you should take the minimum, right? Like remember we want to minimize the edit distance. So, um, there's three things you can do. Each of them has some costs of doing that action which is, you know, one. Every edit is the same cost. And then there's a cost of, you know, continuing to do whatever you're doing. And so we're just gonna take the minimum over those. Yeah. [inaudible] How do we know that that's, like- that's the maximum amount of distance that we have to take? Yeah, so I was trying to argue that, um, with- if you're going to right to left, it's, uh, without loss of generality. Because if you've- went left to right, or in some other order, you can also replay the edits, um, in order. [inaudible] [NOISE] one letter that you needed one assertion like [inaudible] like upstream. But if you went from like the left it looks like as if you're [inaudible]. [NOISE] Yeah. [inaudible] Okay. Yeah. I think it works. [NOISE] Um, okay, so- so let's, um, try to code this up and see if we can make this program work. Okay, so, um, I'm gonna do editDistance. Can everyone see this? Okay, so, um, so I'm gonna define a function that takes two strings, and then I'm going to um, define a recurrence. So, recurrences are- are, I guess, one word I haven't really used, but this is really the way you should th- kind of think about, uh, dynamic programs, and this idea of taking complex problems and breaking it down. It's gonna show up, in you know, search problems, MDPs, and, you know, games. So, I guess it's something that you should really be comfortable with. So, let's um, define recurrence, uh, as follows. Um, so remember at any point in time, I have, uh, let's say a sub problem, and since I'm going right to left, I'm only considering the first, um, \"m\" letters of \"s\" and the first letter \"n\" letters of \"t\". Okay, so recurse is going to return the minimum edit distance between two things, the first \"m\" letters of \"s\", and the first \"n\" letters of \"t\". Um, I'm gonna post this online so you guys don't have to, like, copy- try to copy this."}, {"content": "Um, okay, so, um, okay, suppose I'm gonna- I'm gonna define this function. Uh, if I have this function what should I return? Recurse of-. [inaudible] So \"m\" is an integer, right? So \"n\" is an integer, so I'm going to return the length of \"m\" and the length of \"n\". Okay, so that's kind of, uh, the initial state. [OVERLAPPING] Sorry. Yup. Okay."}, {"content": "Um, All right. So now you need to fill out this function. Okay, so let's- let's um, consider a bunch of cases. So here's some easy cases. Suppose that, um, \"m\" is zero, right? So I have- comparing an empty string with something that has \"n\" letters. So, what should the cost of that be? [NOISE] I heard some mumbling."}, {"content": "[OVERLAPPING]. It should be \"n\" [NOISE] and symmetrically if \"n\" is 0 then result should be \"m\", um, and then if now we come to the kind of initial case that we consider which is the end [NOISE] match a match. So, if \"s\" um, the last letter of \"m\", you know, this is 0-based indexing. Um, so that's why there's a minus 1. So, this matches. [NOISE] Then what should I do? [NOISE] So, now we reduce this to a sub problem, right? [inaudible] So, I have \"m\" minus 1 and \"n\" minus 1. Okay. And now comes the fun case which we looked at. So there's- um, in this case the last letter doesn't match. So, I'm gonna to have to do some sort of edit, can't just let it slide. Yeah."}, {"content": "Question. Would you- do you need a full \"s\" to \"t\" compare or \"s\" through \"m\" and then \"t\" through \"n\" to compare? Worse than doing a full s, a compare. [OVERLAPPING] rather than waiting until, um, first- Yeah. -stream at the last slide than that. There- there's probably a way you can make this more efficient. I'm just gonna try to get the basic thing in there. Okay. So substitution. Okay. So what's a cost of a substitution? I pay 1 to do the substitution, but and in- as a reward I get to, um, reduce the problem to n minus 1 and n minus 1, right? So I lop off a letter from s and I lop off a letter from t. So what else can I do? So I can, um, you know, delete. [NOISE] So that also costs 1. And when I delete, I delete from s and then n. So this remains the same. And then now you can think about the insertion, um, is n minus 1, right? Because remember insertion into s is deletion from t, that's why this is n minus 1. Okay."}, {"content": "And then the result is just gonna be a minimum of, uh, all these things. Okay. Return result. Okay. So just, uh, and then, how do I call this function? Um, a cat, the cats. [NOISE] So let me print out the answer. Um, let's see if it works. Okay. Print out 4. Therefore, I conclude it works now. [LAUGHTER] I mean if you were doing this, uh, you would probably want to test it some more, but in the interest of the time, I'll kind of move on. So let me just kinda refresh."}, {"content": "Okay. So I'm computing this at a distance between two strings and we're gonna define a recurrence that works on sub problems, where the sub problem is the first m letters of s and the first n letters of t. And the reason I'm using integers instead of, um, strings is to avoid like string copying, um, implementation detail, but it doesn't really matter. Um, so base cases. So you wanna reduce your problem to a case where it's- it's trivial to solve. Um, and then we have the last letter matches. And then we have a letter doesn't match and you have to pay some sort of cost. I don't know which action to take. So I'm gonna take them, you know, minimum of all of them. And then I call it by just calling, you know, recurse. Okay. So this is great, right? So now I have a working thing. [NOISE] Um, let's try another test case. So I'm gonna make this. Um, so if I do times 10, this, uh, basically, uh, replicates this string 10 times. So it's a- it's a long string-longer string. [NOISE] Okay. So now I'm gonna run it. [OVERLAPPING] Maybe I shouldn't wait for this. Is there a base case? Um, there is a base case, I- I think that it expanded- it's- what- what's wrong with this code? Very slow. Um, yes, it's very slow. Why is it slow? [BACKGROUND] Yeah, right? So- so I'm recursing. [NOISE] Every point recurses three times. So you kind of get this exponential, you know, blob. Um, so there's kind of a- how do you solve this problem? [BACKGROUND] Yeah. You can memo I think I heard the word memoize, which is another way to kind of think about. Memorize plus, um, I guess, recurrences is dynamic programming, I guess. Um, so I'm gonna show you kind of this, um, way to do it which is pretty, uh, uninvasive. Um, and generally I recommend people. Well, get the slow version working [NOISE] and then try to make it faster. Don't try to be, you know, too slick at once."}, {"content": "Okay. So I'm gonna make this cache, right? And I'm gonna say if m, n is in the cache, then I'm gonna return whatever's in the cache. So cache is just a dictionary mapping. Um, the key which is, um, identification of the problem I'm interested in solving, and the result which is the answer that I computed. So if I already computed it, I don't need a computer again, just return it. And then at the end, if I have to compute it, then, um, I have to put this in the cache. [NOISE] Okay? So three lines or four lines, I guess. Yeah. [BACKGROUND] [NOISE] Yeah. That's a great point. Uh, this should be outside of the recurse object. Yeah."}, {"content": "Glad you guys are paying attention. Um, otherwise, yeah, it would do basically nothing. Any other mistakes? [LAUGHTER] Yeah. Um, there is also function decorators that like implement memoizing for you. In this class, are you okay if we use that or would you rather us like make our own in this case? Um, you can use the deco- you can be fancy if you want. Okay."}, {"content": "Um, yeah. But- but I think this is, you know, pretty transparent. Easy for learning purposes. Okay. So let's run this. So now it runs instantaneously as opposed to- I actually don't know how long it would have taken otherwise. Okay. And sanity check for t is probably the right answer because there's four was the original answer and multiply by 10. Okay."}, {"content": "any other questions about this? [NOISE] So this is an example of, you know, kind of basic, uh, dynamic programming which are, uh, you'd solve a problem trying to formulate it as a recurrence of a complicated problem in terms of smaller problems. Um, and like I said before this is gonna kind of show up, um, um, over and over again in this class. Yeah. [BACKGROUND] Yeah. So the question is why does this reduce, uh, redundancy. [NOISE] Is that right?"}, {"content": "Um, so maybe I can do it kinda pictorially. Um, if you think about, let's say, you have a, um, a problem here, right? And this gets, um, you know, reduced to, um, um, I'm just making kind of a arbitrary, um, diagram here. So this problem gets reduced to these two. And this problem gets reduced to these two, um, and- and so on, um, right? So if you think about- if you didn't have memoization, you will just be paying for the number of paths. Every path is a kind of you have to compute from scratch. Whereas, if you do memoization, you pay the number of nodes here, which a lot of this has shared like here. Um, you know, once you compute this, no matter if you're coming from here or here, you're kind of using the same value. Okay. So let's- let's move on. So the second problem, um, we're gonna talk about is, uh, has to do with continuous optimization. [NOISE] And the motivating question here is how do you do, um, regression? Which is a kind of a bread and butter of, um, you know, machine learning here. [NOISE] So here we go. Regression. Okay."}, {"content": "So imagine you get some points. Okay, so I give you a point which is 2, 4. Then I give you another point, let's say 4, 2. And so these are data points, you want to, let's say, predict housing price from, you know, square footage or something like that. You want to predict health score from, um, your blood pressure and some other things. So this is pretty common in machine learning. And the question is how do you fit a line? I'm going to consider the case where your line has to go through the origin, just for simplicity. Um, so you might want to like find, you know, a fit. Two points is maybe kind of a little bit degenerate, but that's the simple example we are going to work with. In general you have lots of points and you want this to fit the line that best kind of, uh, is close to the points. Okay, so how do you do this? So there's a principle called least squares, which says, well, if you give me a line which is given in this case by a slope w, I'm going to tell you how bad this is. And badness is measured by looking at all the training points, and looking at these distances. Right. So here I have, you know, this particular, uh, a particular, let's say point x_i. If I hit it with a w, then I get, basically the, uh, you know, the y-intercept here, not the y-intercept but the- like the y value here. That's my prediction. The real value was y_i, which is, you know, up here. And so if I look at the difference, I want that difference to be zero. Right. So in, in least squares, I square this, and I say, I want this to be as small as possible, right. Now, this is only for one point. So I'm going to look at all the points. Let's suppose I have n points, and that's a function that I'm going to call f of w, which basically says, for a given weight vector, which is a slope, give me a number that characterizes how bad of a fit, um, this is. Where 0 means that I fit everything perfectly, and large numbers mean that I fit poorly. Okay?"}, {"content": "All right. So, so that's your regression. So how do I solve a regression problem? So how do I optimize this? Can you do this in your head? So if I actually had these two points, what should w be? Okay, it doesn't matter. We'll, we'll compute it. So how do we go about doing this? So one principle, which is maybe another general takeaway is, abstract away the details. Right. Um, this is also true with the dynamic programming, but sometimes, you know, you get- if you're too close to the board, and you're looking at, oh man, these, these points are here and I need to fit this line. How do I do that?"}, {"content": "You kind of get kind of a little bit stuck. Why don't we think about this f, as say some function? I don't, I don't really care what it is. And let's plot this function. Okay. So now this is a different plot. Now, this is, ah, the weight, and this is f of w. [NOISE] Always label your axes. And let's say this function looks like this. Okay. So which means that for this slope, I pay this, you know, amount, for this slope, I pay this amount and, and so on. And what I want to do, I want to minimize f of w, which means, I want to find, um, the w which, um, has the least value of f of w, right? Question?"}, {"content": "Okay. So you take the derivative. So what is the derivative giving you? It tells you where to move, right? So if you look over here, so you can- in general, you might not be able to get there directly, in this actually particular case you can because you can solve it in closed form, but I'm going to try to be more general. Um, so you start here. This, this derivative tells you, well, the function is decreasing if you move to the right. So then you should move to the right. Whereas over here, if you end up over here, the derivative says, the function is decreasing as we move to the left. So you should move to the left, right? So what I'm going to introduce is this, uh, algorithm called gradient descent. It's a very simple algorithm. It basically says, start with some place, and then compute the derivative, and just follow your nose. Right? If the derivative says it's negative, then just go this way. And now you're on a new point, you compute the derivative again, you descend, and now you compute it again. And then maybe you compute the derivative and it says keep on going this way and maybe you overshoot, and then you come back. And then, you know, hopefully you'll end up at the minimum. Okay."}, {"content": "So let's try to see what this looks like in code. So gradient descent is one of the simplest algorithms, but it really underlies essentially all the algorithms that you people use in machine learning. So let's do points."}, {"content": "We have two points here. Um, and I'm going to define, um, some functions. Okay, so f of w, so what is this function? So I'm going to sum over all the different, um, you know, and basically at this point it's converting math into Python. So I'm going to look at all the points. So for every x, y, what the model predicts is w times x minus y. And if I square that, that's going to be the error that I get on that point. Then, if I sum over all these errors then I get my objective function. Okay. Array of- so yeah. So you can put array here if you want, but it doesn't matter. It's, it's actually fine."}, {"content": "Okay. So now I need to compute the derivative. So how do you compute the derivative? So if your calculus is a little bit rusty, you might want to brush up on it. So what's the derivative? Re- remember we're taking the derivative with respect to w, right? There's a lot of symbols here. Always remember what you're taking derivative with respect to. Okay. The derivative of the sum is the sum of the derivative. So now I need to take the derivative of this. Right. And what's the derivative of this? Something squared, um, you bring the two down here, and now you multiply by the derivative of this. And what's the derivative of this? Should be x. Right? Because this is a- y, this is a constant, and w derivative- w times x with respect to w is x. Okay."}, {"content": "So that's it. Okay, so now let's do gradient descent. Let's initialize with w equal 0. Then I'm going to just, um, you know, iterate a hundred times. Normally, you would set some sort of stopping condition, but let's just keep it simple for now. Okay, so for every moment, I'm going to- I have a w, I can compute the value of the function, and also take the gradient of the derivative. Gradient just means derivative in higher di- dimensions, which we'll want later. Um, okay. And then, what do I do? I take, uh, w, and I subtract the, the gradient. Okay. So remember- okay, I'll be out of here. Okay. So, uh, I take the gradient. Remember I want to have the gradient. Uh, gradient tells me where the function is increasing, so I want to move in the opposite direction. And eta is just going to be this, uh, step size to, um, keeping things under control. We'll talk more about that next time."}, {"content": "Okay, so now, I want to do, print out what's going on here. So iteration, print out the function, and t value. Okay. All right, so let's compute the gradient. And, um, so you can see that the iteration, we first start out with w equal 0. Then it moves to 0.3, then it moves to 0.79999999 and then it looks like it's converging into 0.8. And meanwhile, the function value is going down from 20 to 7.2 which happens to be the optimal answer. So the correct answer here is 0.8. Okay, so that's it. Next time we're going to keep, uh, we're going to start on the machine learning lecture."}], "Sam Altman on His Feud with Elon Musk\u2014and the Battle for AI's Future": [{"content": "what is the fundamental conflict between Elon Musk and his various allies meta being one of them and you guys like what what is the disagreement fundamentally about look I'm I don't live inside elon's head so this is a little bit of of speculation uh Elon definitely did a lot to help open eye in the early days and in spite of all of this I'm very grateful and I think he's just a sort of legendary entrepreneur um he's also clearly a bully and he's also someone who clearly likes to get in fights you know right now it's me it's been Bezos Gates Zuckerberg lots of other people hi honestly listeners Barry here and I'm so excited for you to listen to this wide ranging and fascinating conversation with open AI Sam Altman before you watch it I wanted to come and talk to you about a big endof year Push by the end of 2024 in just a few days we want to get to a million Free Press subscribers a million people who Value Independence and curiosity and who above all want a news source that reflects reality if you're here if you're on this YouTube page we know it's not just because you believe in Fearless old school journalism for yourself it's because you think it's a necessity for democracy free pressers tell us again and again that we're not just a media company we're a public trust I'm confident that by becoming one of the first million free pressers you will be getting in on the ground floor so before you watch this video take out your cell phone or open a new tab and go to vf.com subscribe and become a free presser today if you're already signed up you can earn a free year subscription or even a pair of TGIF Socks pre-worn by Nelly if you refer your friends or family members okay one more time before we get to Sam Altman go to the free press's website at vp.com ssubscribe and help us get to our goal of a million free pressers by 2025 we are so close and we really appreciate your support on to the show from the free press this is honestly and I'm Barry Weiss just a few years ago as AI technology was beginning to spill out of startups in Silicon Valley and hit our smartphones the political and cultural conversation about this nent technology was not yet clear or at least it wasn't clear yet to civilians like me I remember asking former Google CEO Schmidt on honestly in January 2022 if AI was just like and this is actually what I said the sexy robot in exmachina I literally said to him what is AI how do you define it I do not understand I cringe listening back to that because today in the waning days of 2024 not only has it become clear what AI is and how to use it chat GPT averages more than 120 million daily active users and processes over a billion queries per day but it's also becoming clear what the political and cultural ramifications and the arguments in the debates around AI are and what they're going to be over the next few years those are the big questions who gets to lead us into this new age of AI technology what company is going to get there first and Achieve market dominance how those companies are going to be structured so that bad actors with bad incentives can't manipulate this technology for evil purposes what role the government should play in regulating all of this at the center of these important questions at least for right now are two men Sam ultman and Elon Musk and if you haven't been following they aren't exactly in alignment I don't trust open AI I don't trust Sam Alman and I and I don't think we want to have the most powerful AI in the world control by someone who is not trustworthy it'd be profoundly unamerican to use political power to the degree that Elon has it to hurt your competitors and Advantage your own businesses they started off as friends and business partners in fact Sam and Elon co-founded openai the company that makes chat GPT in 2015 but over the years Elon Musk grew increasingly frustrated with open AI until he finally resigned from the board in 2018 the feud between ultman and musk escalated this past year when Elon sued Sam and open aai on multiple occasions to try and prevent open AI from launching a for-profit arm of the business a structure that Elon claims is not only never supposed to happen in open AI he likes to remind people that a nonprofit transparent company should not become a closed for-profit one but he argues that changing its structure in this way might even be illegal now on the one hand this is a very complex disagreement to understand every single detail of it you probably need a law degree and special expertise in American tax law neither of which I happen to have but you don't need any special degree or specialization to understand that at its heart the feud is about something much bigger and more existential than open ai's business model although that's extremely important and something we discuss today what this is really about I think foundationally is a fight over who will ultimately control this technology and technology that some say if used incorrectly could very well make human beings obsolete so the stakes are low here to tell his side of the story is Sam ultman we talk about where AI is headed why he thinks super intelligence in other words the moment where AI surpasses human capabilities is closer than ever we talk about the Perils of AI bias and censorship why he donated a million dollars to Trump's inaugural fund as a person who had long opposed Trump what happens if America loses the AI race to a foreign power like China and of course what went wrong and is going wrong between him and the richest man on earth we'll be right [Music] back Sam Alman thank you so much for coming on honestly thank you the last time we spoke and I know you've given a zillion interviews since then but it was in April of 2023 and it feels like a world away Chachi PT had just launched and people were just at the very beginning of trying to figure out like in the abstract what this technology was and how it might transform their everyday lives and now sitting here in December of 2024 chat GPT is a household name so is open Ai and of course some of your competitors are too like perplexity and Gemini and Claude average Americans are using these tools every day everything from math tutoring to debugging code to dra emails and it's very very good at doing that tell me about how chat GPT and I guess AI technology more broadly has changed since we last spoke a year and a half ago and whether or not it's where you expected it to be today or further along so I think there's two different things we talk about one is how much the technology itself has changed and that has gotten way better I if you think about the AI we were excited about back in April of 2023 it was so primitive relative to what we have now and the things that the technolog is capable of are pretty mind-blowing to me but even more than that the the rate at which it will continue to get better over the next year and if we came back in another 18 months and talked about what it can do I think it'll feel like as big or maybe even bigger as a gap from April 2023 to December of 2024 um as projecting that same amount of time I guess that's more like 20 months going forward the other thing that's happened is it's really integrated into society like back then it was still a curiosity something may people had heard of people really use it a lot for like a lot of their work their personal lives their it's I've never seen a technology become widely adopted this fast not just as something people like dabble with but something that people like really use in all the ways you were talking about so that that part of the adoption curve happened much more quickly than I thought I expected the technology to happen quickly give me a sense of like how are you using the tool that you have helped create in your daily life like the way that most people know we're using it Tyler Cowen and lots of people who are like passionate early adopters it almost seems to have like replaced Google for them and it's just like a much much deeper Google is that how for I use it in all sorts of ways but the newest one um a few months ago we reled we released search integration and now chat GPT can search the internet for kind of real-time information and of everything we've ever shipped that was the one that felt like it doubled my usage all at once and since then I mean I must have still used Google for something but I can't remember what it is wow and I switched chat gbt to be my default search in Chrome uh and I have not looked back the degree to which that behavior changed in me for something that was really deeply ingrained and now the fact that like when I remember the way that I used to search um feels like kind of oh man that was like a pre- iPhone kind of equivalent that's the sort of like level of shift that I feel about it um that's that's been the most surprising change to me in the last few months is that I don't I do all my searching now inside of chat what do you call it do you call it searching or is there a verb in the way that Googling is a verb I still call it search I mean I just like people other people say like I chatted it or I chat whatever people say I chatted it a lot like people seem to just only call it chat but I I I would say I just use search Sam in September so just a few months ago you published this Manifesto on your website predicting the emergence of super intelligence in the next few years or as you put it and memorably in the next few thousand days explain to us what super intelligence is tell us how we'll know if it's actually here and how it stands to change people's lives over the next decades one one thing that I use as a sort of my attempt at my own mental framework for it is the rate of scientific progress um if the rate of scientific progress that's happening in the world as a whole tripled maybe even like 10x you know the discoveries that we used to expect to take 10 years and the technological progress that we used to expect to take 10 years if that happened every year and then we compounded on that the next one and the next one and the next one that me would feel like super intelligence had arrived and it would I think in many ways change the way that Society the economy work it what it won't change and I think a lot of the sort of AI commentators get this wrong is it won't change like the Deep fundamental human drives uh and so in that sense you know we've been through many technological revolutions before things that we tend to care about and uh what what drive all of us I think change very little or maybe not at all through most of those but the world in which we exist will change a lot okay well Sam one of the reasons we wanted to have this conversation with you today is not just because we want to hear about the ways that AI is going to transform the way that we live and work but because you're in a very public battle right now with your original open AI co-founder Elon Musk and I think it's safe to say that most listeners of this show will like vaguely know that there's a conflict between Elon Musk having to do with this one of his companies one of his many companies but there's certainly not following the nitty-gritty details of of the various lawsuits and of and of the conflict more generally so I want to try and summarize it for you in the most Fair way that I can and then you'll tell me if I've gotten it wrong or or where I've where I've overstepped so open AI begins in 2015 and it starts as a nonprofit and in a blog post introducing open AI to the world in December of that year you wrote this open aai is a nonprofit artificial intelligence research company our goal is to advance digital intelligence in the way that is most likely to benefit Humanity as a whole unconstrained by a need to generate Financial return since our research is free from Financial Obligations we can better focus on a positive human impact and this was a huge aspect of the brand then fast forward four years in 2019 open AI moves to what it called a hybrid model with a for-profit arm that got a billion doll investment from Microsoft in that year since then Microsoft has ped something like $1 13 billion it might be a higher number more into the company and Elon was one of the co-founders as I mention since the beginning but his relationship with the company soured over time because he disagreed with the shift that I just described the shift from this nonprofit model to a hybrid model and he eventually leaves the company and steps down from the board and that takes us to this year in which Elon has sued you and openai on several different occasions so far this year and he has gone given many interviews and posted countless amount of tweets or X's or whatever we're supposed to call them about this conflict all of the lawsuits claim that you were in some kind of contract violation by putting profits ahead of the public good in the move to advance Ai and then last month and this is the most recent of vment Elon asked the district judge in California to block open AI from converting to this for-profit structure okay that was a mouthful did I summarize it properly and is there anything crucial that I left out or you summarize it properly but uh I mean it was Elon that most wanted to convert not not even convert it was Elon that Most Wanted open AI to be a for profit at one point and had made a bunch of proposals that would have also things like opening I being part of Tesla but mostly just create a new for-profit that he was going to be in control of and you know so other than that I think a lot of the summary there is is correct I have a bunch of thoughts and opinions on it but as a statement of facts that was otherwise mostly correct give us like the 10,000 foot version what is the fundamental conflict between Elon Musk and his various allies meta being one of them and you guys like what what is the disagreement fundamentally about look I'm I don't live inside elon's head so this is a little bit of of speculation uh Elon definitely did a lot to help open eye in the early days and in spite of all of this I'm very grateful and I think he's just a sort of legendary entrepreneur um he's also clearly a bully and he's also someone who clearly likes to get in fights you know right now it's me it's been Bezos Gates Zuckerberg lots of other people and I think fundamentally this is about opening eyes doing really well Elon cares about doing really well Elon started uh and now runs a very direct competitor that's trying to do exactly what open AI does uh and I'll point out is a structure uh you know as like a public benefit Corp and I heard Elon has majority ownership and control and seems like a reasonable thing he would do I think a lot of the press has been misreported we're not like the non even if we go through with of the any of the conversion ideas or Evolution ideas we're talking about it's like the nonprofit goes away the nonprofit doesn't like stop being nonprofit becomes a for-profit we've talked publicly about maybe we evolve our current LLC into a PBC but anything we do would strengthen the nonprofit the nonprofit would continue to exist would continue to serve hopefully better serve the same purpose and the overall mission of the company that you talked about which is develop this incredible technology do it in a way that we think is maximally beneficial to humans and get it out into the world for people we keep doing that I'm incredibly proud of our track record on doing that so far people as you were saying earlier use chat GPT and love it there's an incredible free tier of chat GPT uh we lose money on it it's not ad supported or anything we just want to put AI in people's hands we continue to want to deploy this technology uh so that people co-evolve with it understand it that the world is going through this process it's going through right now of contending with AI and eventually AGI and thinking how it's going to go and everything we're doing I believe Elon would be happy about if he Wen in control of the company he left when he thought we were like on a trajectory to certainly fail um he and also wouldn't do something where he had like total control over open AI but I think it's like a little bit of a sideshow and the right thing for us to do is just keep doing incredible research keep shipping products people love and and most importantly like keep pursuing this mission of AGI to benefit people and getting that out into the world for someone who's just sort of tuning into this topic why is it important Sam that open AI has a for-profit arm or converts in the way that you've been talking about why why is that essential to your growth when we started openi we thought it's hard to go back and remember how different things were in 2015 um that was before language models and chatbots it was way before chat gbt we were doing research and Publishing papers and working on AIS that could play video games and control Rob about of hands and things like that and we we were supposed to get a billion dollars but ended up not we thought with a billion dollars we could make substantial progress towards what we were trying to do as we learned more and got into the scaling language model world we realized that it was not going to cost 1 billion or even 10 but like 100 billion plus and we couldn't do that as a nonprofit so that was the fundamental reason for it okay so like it's Bas and maybe another way to say it is like it's absolutely essential for the computational power to create okay every other effort pursuing AI has realized this and has set up in some way where they can sort of Access Capital markets you've said a lot of different things about Elon in recent days you gave this interview at dealbook where Andrew Ros sorin is sort of asking you how you feel about the conflict and you say sad and you also say that you think elon's companies are awesome and then he asked you you know do you think he's going to use his Newfound political influence to kind of punish you or punish open AI or punish his competitors and you said in that interview that you thought he was do the right thing how do you square that with what you just told me which is that elon's a bully bullies don't typically do the right thing I think they can totally be like I think I think there are people who will really be a jerk on Twitter who will still not like abuse the system of a country they're now in a sort of extremely influential political role for that seems completely different to me until now much of this battle you know for those of us who are like perpetually online and perpetually on Twitter we have been following the conflict via like tweets lobed sub tweets it's all sort of been playing out in real time on Twitter for us to watch open AI though has sort of been in like response mode sometimes or mostly kind of ignoring everything that's sort of how i' characterize it that changed a few days ago when you guys published this very very long memo on open it's like a blog post on open ai's website people should go and read it again we'll put it in the show notes and it's sort of like complete it's it's like a timeline going back to 2015 proving from your perspective that you know via emails and screenshots of texts and explanations of those screenshots and those texts that Elon wanted open aai to or or Elon rather was open to open AI being a for-profit going all the way back then I read all 29 Pages for those who don't want to do that they could go to chat GPT and ask them to summ asked chat to summarize it here's how chat gbt summarized it this article details the rift between Elon Musk and open AI leadership par particularly Sam Alman stemming from musk's dissatisfaction with open AI shift from a nonprofit to a hybrid for-profit model this Feud is crucial chat told me because it underscores the broader ethical dilemma of how AI should be developed and controlled whether it should prioritize public good or corporate profit especially as powerful AI Technologies become increasingly influential in society in the economy I thought that was pretty good what do you think no but on your general point we you are right that we do not sit there and like throw tomatoes back and forth on Twitter um the reason for this one was we had to make a legal filin and we wanted to provide some context we published about this once before also when we had to make a legal filing I've lost track of how many times that Elon has sued us I think it's like four you know withdraws changes goes for this preliminary injunction whatever our job is to build AGI in a way that benefits humanity and figure out how to safely and broadly distribute it um our job is not to engage in like a Twitter fight with Elon but when we have to respond to Illegal filing we will Pro we will and sometimes we'll provide context I think we've only done this twice in the early days of open aai the brand like the way I encountered the brand of it was transparency and nonprofit like those were the things that it over and over emphasized and the reason you said that you couldn't take any equity and the reason you took such a small salary is because you said I you know I don't want to be conflicted I want to always be motivated to do the thing that's best for Humanity the day after open AI launched in December in 2015 you described it to Vanity Fair as a nonprofit company to save the world from a dystopian future you also said that trying to make open AI a for-profit would lead to quote misaligned incentives that would be suboptimal to the world as a whole I guess I want to ask like do you still agree with that but simply you've had to adapt to the reality which is that developing these models takes billions and billions and billions of dollars two things one I I think I was like a little bit wrong about that um and I have been although I have had concerns um I have been impressed by how much not just us but the other AI Labs even though they have this like wild sort of Market or economic incentive have really been focused on developing safe models I think there's many factors that went into that we did get a little lucky on the direction the technology went but also if you deploy these models in a way that is harmful to people you would like very quickly I believe lose your license to operate if it was an obvious one now there are subtle things that can go wrong like I think social media is an example of a place where maybe the Harms W so obvious at the time and then there was an emergent property at scale and you could imagine something happening but the incentive problem has been better than I thought at the time and I will cheerfully say I was like a little bit naive about how the world Works 10 years ago and I feel better now naive how oh the the the pressure the societal pressure on big companies and the sort of the power of researchers to push their companies to do the right thing even in even in the face of this gigantic profit motive have been pretty good but there is something that I don't feel naive about that I felt at the time too which is it continues to be fairly crazy to me that this is happening in the hands of a small number of private companies to me this feels like the Manhattan Project are the Apollo program of our time and those were not done by private companies and I think is like a mark of a well-functioning society do you think that we need a Manhattan Project here I think the companies are going to do the right thing and it's going to go well and I I don't think government effort in this current world would work at all I don't think it'd be good if it did honestly I just I I wish we were in a world where I said this is you know where I felt like that was the way it should and was happening meta right now is also siding with Elon a few days ago meta asked California's AG to block open AI from becoming a for-profit this is what they said in their letter open ai's conduct could have seismic implications for Silicon Valley if open ai's new business model is valid nonprofit investors would get the same for-profit upside as those invest in the conventional way in for-profit companies while also benefiting from benefiting from the tax writeoffs bestowed by the government this Echoes what musk said last year when he said I'm confused as to how a nonprofit which I donated to somehow became a market cap for profit in other words if this is legal like why isn't everyone doing this I don't know why I Med accept that letter but I do know they know that's not how it works I I know that part's in bad faith if if you in any of these worlds our nonprofit will keep going and the people that invest in the nonprofit uh don't like you don't get to have a benefit from a nonprofit donation ACW to a sort of for-profit equity of course and and they know that too you can imagine lots of other reasons that meta might have sent this letter you can imagine they wanted I mean you can imagine they wanted to Curry favor with Elon you can imagine that they felt like it would help them compete with us um you could imagine that they were like annoyed with us for a perceived anti-open Source stance which I don't think is accurate or something that I feel I don't know you should ask them what the reason was for the civilian who's hearing how does a nonprofit become a for-profit what's the answer it doesn't like the nonprofit stays as the nonprofit I believe that the opening eye nonprofit is on a trajectory I hope if we do well to be the largest and most impactful nonprofit of all time that nonprofit doesn't become anything else like many other things this our world our ecosystem can have a for-profit business also but that doesn't the nonprofit does not convert the nonprofit does not go anywhere the nonprofit does not stop doing nonprofit things at the end of the day Sam who is going to profit most from the success of open AI everyone I'll tell you what I hope everyone gives their analogy for um What technological Revolution this is most like you know it's the Industrial Revolution it's like electricity it's like the web the thing I hope for is that it's like the transistor we discovered a new important fundamental physical law whatever you want to call it um we did a bunch of research so did others and it it will seep into all aspects of the economy products everything and you and I today uh are using many devices with transistors in them to make this podcast possible computer has some your microphone has some the all of the internet equipment between and me has a lot but we don't sit here and think about transistors and the transistor company does not sit here and make all of the the money it is this this new Incredible scientific discovery that's seeped into everything we do and everybody made a lot of money that's what I hope AI will be like and I think there's many reasons why it's the best analogy will you have Equity or do you have Equity or what kind of stake do you have in this new capped for profit well so we haven't formed a new entity yet um we have obviously considered uh forming a new entity or maybe converting our existing ALC into one is more accurate um I have a tiny sliver of equity from a old YC fund um I used to have some via sequa fund but that one turned out to be easier to like sell and not keep the position in um so I have a very small amount that was like quite insignificant to me in terms of what I will or won't have going forward I don't I know it's not like there's no current plan or promise for me to get anything I I will and I if I got anything it would not be there were like outlandish rumors about some number that would not happen do you get why people are fixated on that for sure as I've said many times before if I could go back in time I would have taken Equity I think again I understand more about why my earlier misgivings were misplaced I also get that it's weird for me to take it now after not earlier on the other hand I would love to never have to answer this question again and be like normal company I run it I've got some Equity investors don't have to worry that I'm like misaligned there does the whole like a of Suspicion of not having any is one of the decisions I regret the most of opening eye structure things but I understand why people are fixated on it uh that makes sense if you could go back in time how would you have done this from the beginning like let's wind back the clock to 2015 if an oracle had said to me on what was it November of 2015 before we set out number one you're going to need 100 plus billion dollars number two even though you have no idea today how you're going to ever productize this and you think of yourself as a research lab eventually you're going to become a company that does have way to productize it and business model it so you can explain to investors why they're not just funding a research lab um and number three that the incentives of people working on this are going to be more naturally kept in check because it's not going to be what I and many others thought at the time of like one effort that is way far ahead of everyone else but something more like the transistor that seeps out and so there will be better equilibrium Dynamics if an oracle had told me all three of those things that turned out to be true I would say great let's be a public benefit Corp how essential was Elon to getting open AI off the ground like if if the Oracle also told you about this fight that would ensue with someone that you regarded as your close friend would you have said you know don't need him can do it myself no he was really helpful I'm super appreciative I think it was the first time I ever saw Elon Musk was on stage at a conference you were interviewing him you guys had a wonderful Dynamic you seem like you were really good friends he has said some really harsh things about you he's compared you to Littlefinger in the Game of Thrones most devastatingly said I don't trust him and I don't want the most powerful AI in the world to be controlled by someone who isn't trustworthy why is he saying that I think it's because he wants the most powerful a in the world to be controlled by him and again I've seen elon's attacks to many other people many friends of mine you know everyone gets their period of time in his Spotlight but this all seems like standard behavior from him I'm trying to put myself in a position of a former friend a former co-founder of mine saying those kinds of things about me you you seem relatively calm about it no I'm upset by it for sure I I was talking to someone recently who uh I did think of as close and they said like Elon doesn't have any friends Elon doesn't do peers Elon doesn't do friends that was sort of a sad moment for me um because I do think of him as a friend but I I don't know I can look at this like somewhat dispassionately I remember what it was like when he said opening I has has a 0% chance of success and you know you guys are idiots and I'm ping funing and I'm going to do my own thing there were moments since then where it felt like he kind of wanted to reconcile and figure out a way to work together and I remember moments where he's just like you know off doing his thing on Twitter but if it were only towards me I think it'd be much more painful but you know I think you see who he is on Twitter and so I can like hold it somewhat impersonally and just be like this is about Elon this is not about me it still sucks um I've had a long time to get used to it I guess this recent blog post um the that that went up on open AI site said that Elon should quote be competing in the marketplace rather than in the courtroom and the cynical view of course is to say and you've alluded to this in this conversation that Elon who now owns an open AI competitor himself called xai is suing you not out of some concern over AI safety or anything else but really just to get in on the competition what do you say to that you know is this really is the cynical view true is this really just a fight to be the first to dominate the market or you should ask him I hope yeah I hope to I invited him on great you're not just known as one of the most important AI CEOs AI developers in the world you're also a very very well-known proponent of AI regulation and the cynical view here right is that in the very same way that you could cast dispersions on elon's motives you could look at the way that you have lobbied for AI regulations as a way to stifle competition and benefit your company obviously you've heard that argument before I I think too much regulation clearly has huge negative consequences in society right now and many places we have too much I mean Elon has also been a lot of proponent of calling for AI regulation as have as has the heads of most other large efforts when you step on an airplane you think you you know very high likelihood it's going to be a safe experience when you eat food in the US you don't think too much about food safety uh some regulation is clearly a good thing now I can imagine versions of AI regulation that are really problematic and would disadvantage smaller efforts and I think I think that would be a real mistake um but for some safety guard rails on the most powerful systems that should only affect the people at the frontier that only affect opening eye and a small handful of others I don't think we're at the level yet where these systems have huge safety impli implications but I don't think we're like wildely far away either but the argument that some of these startups are making startups like um there's an AI startup called hugging face which is an unbelievable name um the founder of ay company called stability AI they're basically saying what Sam and the other big guys the incumbents are trying to do open aai Google and apple basically asking government to kind of build a moat around you and stifle the competition through regulatory capture what do you say to those people and this is sort of like the the argument between big Tech and little Tech we can frame it in all kinds of ways what do you say to those people who are saying we want to get in on the competition the regulation that people like Sam and others at many other times are pushing for will hurt us and benefit them well if what they're saying is we're behind opening eyes so it doesn't matter and what we're calling for is only regulation at the frontier like only like only stuff that is new and untested but you know otherwise put out whatever open source model you want I don't think it's reasonable for them to make that argument I I I don't know I'm curious what you think if we if we do let's say we succeed and make a super intelligence you know we make this computer program that is smarter maybe more capable than all of humanity put together do you think there should be any regulation on that at all or just they just say none I definitely think first of all I don't even understand what we're talking about when we talk about super intelligence like you understand what that means and the implications of it in a way that I just don't um so that's number one and number two you know if if this technology is as powerful as people like you and Elon and so many others that are closer to it say that it is of course I think it should be regulated in some way how and when is obviously like the relevant question for sure how and when matters a lot but but uh I agree with that and and I could easily see it going really wrong recently Mark andrion was on this show and he talked to me about his perception of what the Biden Administration was trying to do around AI technology he came on and made the argument and told a story really that he experienced he says that the Biden Administration was trying to sort of completely control Ai and what they were aiming to do was to make it so closely regulated by the government that in his words there would only be sort of two or three big companies that they would work with and that they were trying to ultimately protect them from competition is that true do you know what he's referencing was open AI one of those companies I don't know what he's referencing I also will say very very clearly I think regulation that reduces competition for AI is very bad thing that's so openi was not one of those companies no I don't actually know what that's about but it's we've certainly as far as I know have never you weren't in a room ever with the Biden Administration other AI companies no I don't I don't I don't even think like the Biden Administration is competent enough to I mean we were in a room with them but never and other companies in the administration but never like here's our conspiracy theory we're going to make it only you few companies they can build Ai and then you have to do we say never anything like that what was your feeling in general about the Biden Administrations posture toward Ai and Tech more generally you just you just said like you didn't think they'd have the confidence to I think Gina Rondo was is fantastic you know every conversation I had with her I thought she kind of got it um overall I would say the administration was not that effective uh the things that I would most that I think should have been the administrations priorities and I hope will be the next administration's priorities are building out massive a infrastructure in the US having a supply chain in the US things like that when Mark was on I asked him to kind of Steelman the Biden administration's perspective or Steelman the perspective that this should be heavily regulated and he basically drew the analogy to the Manhattan Project and the development of the atomic bomb when the government felt that it needed to make sure that this new science and Innovation remained classified first of all do you think that that's a good analogy and if so if if it is as powerful as nuclear weapons wouldn't it make sense for this to be not open Ai and Gemini and Claud but rather a project of the federal government I think all the analogies are tough cuz they work in some ways and don't work in other ways like you can you can point to things that are similar to the nuclear era you can talk about like you know it takes enormous resources and huge amounts of energy to enrich uranium on one hand or to produce these models on the other um so you can find things like that that work and then the use of one of these models and the use of a new nulear weapon are like quite different things and sort of the geopolitical implications are also quite different things I think to Steelman the argument of people who say things like it's like nuclear weapons I think what they mean is that it's it's extremely expensive and ex has extreme geopolitical consequences we don't know exactly what those are or how to think about them but because we don't know exactly what they are shouldn't we have like a principle of letting the government decide I can imagine other governments at other times in history where we would have we should be very thrilled about that outcome I think putting the current United States government in charge of developing AGI faster and better than our competitors would not likely go well I think the the kind of the decline in state capacity in this country is not a new observation but a mournful one at the beginning of the nuclear age we had people in this country who functioned almost like Chief science officers right I'm thinking about people like vanav Bush who helped launch the Manhattan Project and came up with a National Science Foundation and kind of guided American policy for those first few like very crucial years of n of of nuclear energy does that person right now whether or not they're in DC or not does that person exist like if we wanted to have someone like that who sort of understood the technology had no Financial stake in it and could talk whether it's President Biden or Trump or whoever comes after him sort of the pros and cons not just of the development of AI here but the competition with China like does that does that person exist actually right now in America like could you be that person arguably I think the the willingness it's coming back a little bit but for a long time the willingness of the American public to be excited about future developments in science and technology has been gone I sort of think it went away with the nuclear weapons actually if I had to pick one moment in time there was sort of a you know a weird like few decade hangover before it there was the generational change when the bomb was dropped kind of got older and in power like I don't think America ever embraced the excitement and belief in science and technology driving the world forward to the same degree as as we used to you read these stories about what people like that used to do and how revered they were and how people believed that scientific technological progress more broadly was going to make the world better um that seems missing now and I don't think it's because we don't have an individual who could do that I think it's because the government doesn't want it and the public doesn't want it I mean what do you make of not just the political Vibe shift but the cultural Vibe shift that we've been experiencing since November 5th like if you made that argument to me 8 weeks ago i' would say yeah Sam's probably right now it feels like a different country there's a huge cultural Vibe shift and I think there's a very positive there's positive momentum in many ways I'm not sure that it exists for hey we think science is really important again and science is what's going to save us and you know solve all of our problems do you think that or do you think it's like that's the one area where I haven't felt it I just think that there's a shift in the direction of growth is a good thing technological progress is a good thing nihilism is feels like it's p and falling out of favor like I feel that change happening in a dramatic way now maybe it's because I spend a lot of time on X and like a lot of it's sort of like fomenting there and sort of Leaping from the online into the real world so you know if if you went and like talked to the average PhD student uptown at Colombia I don't think that they would have the same experience I do because everything's so vulcanized as I said earlier I think it is getting better even on S like I I strongly agree with you on the kind of General shift towards excitement about growth and success and having the country and the economy do well um I some I I do somewhat agree as I was saying earlier that I think even excitement about science is in a better place than it's naugher but I when you talk about those people who were like the scientific ambassadors of the country and who people like really listen to and were excited about and you know preach to a willing audience I'm still not sure I feel that I think there's that excitement for business but not for science well one of the companies that I feel excited about um perhaps it's controversial to say this but I just think the founders is one of the most interesting people in the country is Paul mer lucky and his company and um andal Industries and open AI recently entered into an agreement with andil to develop AI with military applications now previously open AI had had a Prohibition against using its technology for weapon now with the caveat of course that you're concentrating on defensive systems at the moment the sorts of things that could you know guard us against attacks like drone swarms perhaps like what's happening in New Jersey right now we don't have time to talk about that what made you change your mind fundamentally about integrating your company's technology um into even a defensive Weaponry system yeah so we have a set of principles that we established and we approved this one for some use cases that comply with those but I think if the leading United States efforts do not help defend the United States and our allies against our adversaries we're going to be in a very bad place and so we need to figure out how to do that a year and a half ago when we were talking part of our conversation was whether or not we were like where the AI arms race with China was I think now it's like well and definitively clear that we are very much in that arms race with China um and you know I think even people who worry about the power of AI in this country feel like well if it's a choice between us and China it's got to be us we got to win spell out for us Sam in your mind because I'm sure you're thinking about this all the time like what it looks like if China wins the AI arms race like what what happens to America what happens to the world whatever China wants and do you think the possibility of that happening is a real one them winning uh I mean we intend to work our hardest to make sure they don't how do we know if they are winning given how much they lie and also steal stuff from us this is the hard thing right we we know what they publicly release we don't know what they don't publicly release um we have a lot of signals and we have a intelligence system but it's my own stance on this is we have got to try to be cooperative and uh arms races are bad for everybody involved we've learned that lesson again and again throughout history but we need to be able to win if we need to I am hopeful that this can be a great moment for world peace and I believe that if there's ever a time for Humanity to come together this seems like a good candidate and I want us to get there but we can't be naive about that President Trump is talks a lot about you know peace through strength is your is the Sam Alman open AI version of peace through strength we have to crush get ahead and win on AI so it's not even a question that China could do whatever it wants not crushes we have to be ahead and then we have to be as willing to work together as possible and I think that is somewhat similar to peace through strength it's like if there's an arms race we'll win it but we don't want to meaning if there's an arms race we want to win but we don't want the arms race period yeah but well it's not even that it's more like if there's any path towards doing this as a collaborative effort we should but we have to be C we can't control what other entities do you mean collaborate with our enemies we collaborate with China yeah actually I'll say that directly I I I think we collaborate with people we don't get along with all the time in areas where it's in our strategic interest to do so and this is one where I think the interests of the world and certainly the mission of our company would dictate that if it is possible to be truly collaborative we should do that are we doing that right now with China on AI like you know more than I do I was going to say you might know more than I like that that will be a big question for the new Administration but that's not going to happen at the company to company level that's going to happen like the presidents at the two countries level if Trump called you tomorrow and said hey Sam I want to make you like aiar AI regulation Chief you can do whatever you want in this position what's the first thing that you would do what's the most important thing that the person in that position would do us infrastructure and supply chain add a little bit more for people that don't know what that means build our own chips here build enough energy to run data centers here change what it takes to build data centers here but be able to like build the very expensive complex supply chain very expensive infrastructure in the United States bias and censorship in AI is a enormous topic and one that we think a lot about here at the Free Press and you know the most obvious example of this the one that trended for days and everyone was laughing at that was when Gemini generated those images of like black George Washington and like a trans naazi and it was hilarious but in a way it was really serious because it felt like only the most sort of like exaggerated hyperbolic obvious example of a much much deeper endemic problem which is the bias that is baked into these Technologies both because of the people programming those Technologies and because of the information that they're sort of scraping online talk to us about how you're thinking about it at chat GPT because obviously the system that is closest to reality it seems to me will will win in the end of the day if if a chat gbt is giving me images of you know he's telling me George Washington was trans I'm like I'm not going to rely on this we don't do that so okay fine but you understand my point how do you think about the problem of bias and how you're solving for it I think there are two things that matter uh one is what flexibility a user has to get the system to behave the way they want and I think or we think there should be very wide bounds like you know there are some things like you don't want a system to tell you how to create nuclear weapons fine we can all agree on that but if you want a system to be pretty offensive and you ask it to be I think part of alignment is doing what its user asks for for Within These broad bounds that Society agrees on the second thing that really matters is what the defaults are so if you don't do any of that which most users don't and you ask whatever controversial question you want how should the system respond and we put a ton of work into both of those things um we also try to write up how the model should behave we call this the model spec such that you can tell if it's a bug or you disagree with us on some stance is it possible to build a like chat GPT or any other technology in this Lane that we can't even conceive of yet that doesn't have a political point of view isn't that inevitable I think no matter how neutral you try to write the thing it will either be useless because it will just say I can't answer that because there's politics and everything or it will have some sort of point of view which is why what we think we can do is write down what we intend for our default people can debate that if there's bugs in there we can look at the bugs if there's problems with how we defined it we can change what the definition is and retrain the system but yeah I don't think any system can be per no two people are ever going to agree that one system is perfectly unbiased but that's another reason why personalization matters so much do you believe that AI or chat GPT has a responsibility to fight pernicious ideas let me give you an example of what I mean like if you knew that by putting your thumb on the scale in the teeniest tiniest way you might be able to usher in a world where there's less racism less anti-Semitism less misogyny and maybe would even be invisible to people because you know they wouldn't know you know at a certain point as we've just talked about this is going to be you know I don't know if this was Mark or somebody else the control layer of all of our information how do you think about that actually here's one thing I've been thinking about recently as a principal like open AI has not adopted this at all but this has just been an idea that I think gets at what you're saying like let's say let's say we discover some new thing where it's like if you do this people learn way better if chat GPT responds always with the Socratic method or whatever students using it learn way better um but let's say user preferences are not to get the socratic message users just say like I just want you to answer my question then like how should we decide what to do there as the default behavior and one idea that I have increasingly been thinking about is what if we're always just really clear when we make a change to the spec and so you'll never have our thumb the scale hiding behind an algorithm which I think Twitter does all the time for example and all sorts of weird things there like We'll always tell you what the behav what the intended behavior is and if we make a change to it we'll explain why but if we do discover something like what you just said uh or like what I just use as an example and we say okay when people are using it for Education we are going to use the Socratic method um because it does seem to have this measurable effect and here's why we're doing it we can debate that publicly maybe we change our default if you convince us otherwise um um anyone can of course change that in their user preferences because the AI is like a tool for you and should do what you want but I think the thing that would be wrong is if we changed that and didn't reflected in the spec and didn't tell people we were changing it um you know I think the like black box of the Twitter algorithm for example it's like doesn't feel good to me Sam you've donated a million dollars to Trump's inauguration and it turned some heads because in the past you've called him a racist a misogynist and a conspiracy theorist among other things you've been a prolific donor to democratic candidates and causes over the years but now you say that Trump is going to lead us into the age of AI and you're eager to support his efforts to ensure America stays ahead is this a change of heart a political Evolution A vibe shift inside of you what's going on all of those things and also I I hope I mean like he's our president and I wish him every bit of success and anyway we can you know work to support this part of what he wants to do we want to do what's the vibe shift inside of you we know that there's one going on inside Silicon Valley and one going on in the culture how have you changed in the past few years I mean a ton of ways but one one is that I uh you know I've watched for the last maybe 10 12 years as I think things have gotten off track things have been good in some ways but I think gotten really off track in terms of how we think about the importance of growth uh and economic success and a focus on the right things in in the country and in the world more broadly and I think it got it got very off track and I'd say the vibe shift is a hope that as we're facing down one of these most most important moments in technological history um that can help drive a VI A vibe shift back to what I believe in very deeply which is that growth is the only good way forward do you think growth and the growth of open Ai and the growth of AI more generally is a patriotic Duty yes I I actually wrote something like I someone just sent this back to I wrote something more than 10 years ago about how growth like I think it's my very first blog post ever about how growth was the central ingredient to democracy working well and I I think the world got badly confused about that and I'm happy to see it re recognized I'm going to use my 30 seconds on a lightning round Sam lightning round what are the Drone things what are the flying objects flying over New Jersey right now I have no idea I'm really interested in this question do you know um no we're reporting on it a lot I find it interesting that various electeds are saying it's the Iran Mothership or China do you think Twitter has become better or worse since Elon Musk took control worse you're having a baby will you will you let your kid have an AI friend yes will you let them go on social media at some point will you let them have screen time yes what's your favorite sports car you love sports cars there's a lot of good ones I can't pick one what's your favorite of yours no I can't pick a single favorite I'm mcar f one favorite movie The Dark Knight do you have any normal Hobbies I like have dinner with my friends I go hiking I like you know exercise I just like sit around my friends doing dumb stuff I I don't know yeah it feels pretty normal you built a treehouse recently why did you do that why' you do that um it was Thanksgiving and uh we looking activity for like the adults and the kids that we all thought everybody was at our Ranch and we want an activity we all thought would be fun and was not just sitting around drinking all day and it was great would you box Logan Paul no will we enter World War II in 2025 I hope not what's your New Year's resolution I know what it does Sam Alman thank you so much for coming on honestly thank you"}], "I played Pokemon, but with 50+ New Types": [{"content": "some of you may have heard but a while back Jacob and their team created a little something called Pokemon too many types it's just a normal game of Pok\u00e9mon Emerald but you might notice some things are just a little bit different everyone has talked about how chaotically fun this game is and I finally found the time to play it myself let me tell you everyone was right this was the most insane backwards chaotic playthrough of Pok\u00e9mon I've had in quite some time Professor Birch is being mauled by a dog in the grass right outside my house for the millionth time and after digging around in his stuff I helped myself to a poo but not just any poo for you see this one is silly obviously I blast the Angi poo to Smither and with that have now earned the freedom to explore the world on my own yep it's Dawning on me that I have no idea how anything works anymore trainers had all these new Pokemon they're pulling out moves I've never seen before types don't line up the way I'm familiar with it genuinely felt like I was playing Pokemon for the very first time again weasel is water fluffy snam is ice Bean Machop is fighting stinky Papio give that thing a shower it reachs up that's super effective I suppose that Mak makes a lot of sense going into this game I decided not to look at the type chart at all which by the way looks like this I'm going to have to unfortunately use my brain and logic to figure out how to win every single battle until I'm the Champion which may be a bit trickier than you would even guess for example this impidimp he has now been turned into a dark gamer Uno reverse type naturally I figured gamer might work similarly to the stinky type and be weak to water that makes sense right all right look I'm I didn't make the game all right guys I'm just figuring out the riddles however let's see what gamer has to say against water type take a shower what it's got what so so here's the logic you got to think about not only is it a gamer type it is an UNO reverse gamer type oh oh yeah of course yeah as much as I might think I know how things would work you're going to witness that it doesn't always pan out the way it seems I scooped myself up a krabby which as you can see is no longer water type and entered the rustboro forest only to be challenged by a te-a grunt with a single snow runt I wasn't worried until I realized the hard way that despite its silliness poo still doesn't like grass and crabs don't mix well with ice wiping this early in a Pok\u00e9mon game is genuinely so humbling and I don't like it at all honestly I didn't even want to tell you that it happened in the first place but we run it back because this isn't a Nuzlocke and my little pets are perfectly healthy after being dunked on this time we sent the grunt hight tailing it back into the bushes despite feeling dumb and stupid and pathetic for wiping to a level 9 Team Aqua grunt with one Pok\u00e9mon I waltzed into the first gym with my chest out like I earned being there as most of you know Rox San is typically a rock type trainer but she's now studied the ways of the ancient type Pok\u00e9mon which I didn't think would be much different until she completely steamrolled me oh I got doggy but doggy isn't going to do too much here God damn it waste of a turn no well her leip is crazy sus ancient grass type how was I supposed to predict that one what even is that now aware of the threat she had in her back pocket it I was able to navigate the rematch with Krabby the fossil killer earning us our very first gym badge also Geodude is boring ugly Rock I just wanted to share that one with the room we took a nice boat ride over to duford where we got to meet lots of new friends in the local cave like clink the prime steel guys and sabaly the gamer who has a little bit of an Easter egg attached to it someone just pointed something out okay will you trade yeah will you move yep yep yep yep yep yep after saying hi and bye to Steven doing who knows what all alone with his cave rocks we headed off to challenge Broly I opened the gym doors and was immediately hit with a wall of pure disgusting stench trying not to physically Decay we crawled through the Gym's Maze and were met by stink Master Broly and his smelly ass team Krabby knocked his Mankey out cold but sock came out and started overwhelming my Pok\u00e9mon one after the other get so much knowledge oh my God like why wouldn't it be so you can imagine I am not happy that this stupid thing is sweeping my team right now luckily the Vulpix I caught earlier was able to tank its hits with its new fluffy type and together with our own little stinker of a stunky we were able to finish the fight I snatched that badge from Broly's greasy hand and basically swam to slate Port myself to wash the fumes off my clothes to dissociate that disgusting experience away I went and caught myself a new friend a ground friend to be specific as well as a little fluffy Stuffle we also got to kick out Team Aqua who was holding the poor slate Port museum lady hostage with a gun thank God they were only armed with a harmless water gun horsey because I do not want to know what dealing with an actual threatening gun type Pok\u00e9mon would even look like battling more trainers on the route up to mville got got me back into the mood to take on the third gym so I shoved Wall-E out of the way and headed up to Watson things started off normal but quickly spiraled out of control because after Sab ey beat up his Porygon Watson immediately brought out his Ace you know his famous star Pokemon whimsicott and this thing just starts spamming its new move called hype train yep Watson specializes in Prime type Pok\u00e9mon which would definitely be a funny little hint hint nudge nudge if I was streaming this on Twitch but alas here we are unfortunately one cannot gift Prime Subs to a YouTube channel sadly all you can do is click the Subscribe button isn't that just a shame well whether you clicked the button or not I got wrecked by this cotton ball hype train works the same as roll out where each consecutive use gets stronger and stronger and this whimsicott must have had some sort of Aimbot on because it didn't miss a single one it literally demolished my team the second it stepped onto the battlefield I was also a bit unprepared and forgot to level everyone up so let's just forget that fight even happened like it wasn't even fair so it doesn't count round two was where the real action was this battle was much more neck and neck knowing what Watson's tactics were going into the fight I was able to play around it much more easily jayen doesn't fall for the same charade more than one time I'm like an AI learning machine all right I never lose the same fight TW I I don't stop no don't look at that with Watson defeated I was now one step closer to becoming the strongest trainer in all of this Topsy Turvy hoen I caught myself a hone Edge swablu and Skarmory while scaling the mountain and even had time to smack the Team Magma nerds around while heading to Lava Ridge to avoid another embarrassing underleveled situation I got everyone up to Flannery's level cap for a nice clean fair fight that's like I think the thing that is hardest for me wow oh God reading comprehension I think that's what I've decided I'm my god oh wow my crabs buddy holy what is the downside of this Mystic fire I'm just so weak to Fire and warm hugs do I have to wipe to every gym plannery she's mean I don't know what that Ninetails is eating but that thing is not normal after changing absolutely nothing about my strategy and just running back into the gym directly from the Pokemon Center I demanded a rematch like her team of fluffy Pokemon aren't that tough I just wasn't ready to be paralyzed and incinerated the whole fight by her puppies and kitties and that roed up monster of a Ninetails this time Kingler and sand slash were able to double team Flannery's fluffy team with much more ease earning us the heat badge with half the gyms now defeated it was finally time to deal with some long overdue Family Matters it's well known that our father Norman abandoned our home to be a gym leader in pelberg leaving me and mom back at the house alone little root has like five people living in it and one of them's a huge nerd that's like a social death sentence for a growing child and I am filled with a burning desire for justice after all this time all those days of having nothing to do but watch Birch go into the same stupid patch of grass and get mauled by the same stupid dog over and over and over I get to walk into Norman's gym and challenge him as an equal whatever reasoning he had to leave us is going to be revealed in our battle and it better be good good I walked through the doors the air was weird and tense each trainer I battled looked at me like they already knew exactly who I was and shifted their glance away out of embarrassment shame what is going on here not even the helpful gym guy had anything to say to me he wouldn't even tell me the type theme of the gym I burst through those final doors to find Norman looking out his windows at the horizon he's been waiting for me all right you ready to fight Norman and his very fun and normal gym have you not picked up on it yet I haven't picked up on anything he say just keep going what is he going to do what What Pokemon do do he have flil okay I don't get it I don't what is this riddle I'm just watching glump is it because he's only using attacks that are acute and family like no lony he can't be a fluffy trainer that was what flanner was cuddle slam no fluffy furry he said is he a furry trainer yes Norman can't a man have hobbies nor look there's nothing wrong with being a furry many of my friends are furries but to abandon your family to selfishly pursue your passion for lucariosklaw board if I was ever going to defeat a divorced man and his beloved furry I switched around some of my Pok\u00e9mon headed back in and again began the onslaught of devastating glumps and cuddle slams weaving through paralyzing warm hugs and even the occasional cute charm eventually it came down to our last Pokemon uh okay slash oh oh no sh sneak please you have a chance here please yes now that my furry father has been vanquished I was filled with an overwhelming energy and drive it was like I unlocked a version of myself that was capable of defeating anyone and everything in front of me I beat up all of Team Aqua that was infiltrating the weather Institute cleared Winona's song and dance gym without breaking a sweat Maxi stole the blue orb to awaken Groudon like an idiot so I had to teach him a lesson again you're going to use the wrong orb idiot why do you think the blue orb would be good for Groudon he hates Blue Team Aqua rats did the exact same thing so I had to do the exact same thing to them I was on a roll it felt like I was back in my element finally familiar with the types and was absolutely thriving we pulled up to tan Liza's gym ready to let nothing slow us down except it looks like they specialize in a type I hadn't seen up until this point space well time to slow down since I didn't have anything that could really handle space Pok\u00e9mon I went and caught myself a Balon because everyone knows ohot type is good against space I mean come on as well as prepared sand slash and stunky for the fight I wasn't too confident but made my way to the gym leader room to find clay what where's ton Liza aren't you supposed to be in you Nova I wasn't anticipating this but I guess I should just start expecting the unexpected from this game it's a double okay it's still a double battle 41 oh we lose we we definitely [Music] lose gun T this is in space wait what the is going on here I don't know what's good against gun how is song sure we'll go do that shoot what the he just shot my my my Goyle he shot my guy again that's so much damage for not very effective we'll do do that oh he's dead he's so dead bare arms oh my God what is this dude this guy's fighting me with the Constitution so this isn't actually a space type gym like I was originally led to believe this is in fact a gun gy and I am being blasted to Kingdom Come by Mr red white and blue over here I failed to expect this level of unexpected but how could I we switched around my team again this time for a high noon dual battle headed back in but honestly it wasn't looking that great on attempt to of fighting a man with assault weapons and air cutter again no no take it take it boy Bo take it stop how can you do this there's nothing I can do about it there's nothing this fight sucks [Music] balls whatever I genuinely think this clay fight was the most out of left field chaotic flabbergasting Pokemon battle I've gone through in my entire career as a Pok\u00e9mon player I don't think anything Pok\u00e9mon could create would ever elicit the kind of shock and despair I felt fighting clay the drift Veil gym leader in my Pokemon Emerald game okay I don't think this is enough yet I just oh he went again sorry that's so lucky oh is this it yes clay you you rooting tooting fing  I'm not talking to you I'm not talking to you get me out of here I basically crawl out the gym with my badge like I just got out of a fight with Wy coyote because I basically did and now I got to go deal with whatever commotion Team Magma is creating in the space station withered and tired I walk up the stairs to Maxi and Steven arguing about God knows what at this point girls girls I'm going to give it to you straight I'm having a bit of a day we all know we're just going to Hash this out in a battle so let's just cut the chitchat Steven get your ass over here and after all of what I just went through you guys are not going to believe what Steven put me through in that cursed Space Center yeah so the first fight I went into it unprepared because I didn't know the team Maxi and friend were packing so that was a bit of an unfortunate disadvantage it's all right we run it back but this is where things go drastically downhill hyper voice Steven you're just leaving me in the The Trenches why even try at this point Thunder oh my fuing God Steven you idiot why do they only go against me why do they only go against me Steven Steven you are theing Elite 4 champion of ho don't use Thunder on Agron it doesn't it in no world is it ever good I swear to God [Music] Stephen you're actually you're actually joking Stephen you're my guy I've always had your back I've been team Steven since day one but what in the world was that this is not the play style of the region Champion buddy get up don't talk to me I need some hair to blow off some much needed steam I infiltrated Team Aqua Hideout because Archie apparently didn't get the memo of my threat of a knuckle sandwich if he ever tried to use red on Blue Kyogre knuckle sandwiches delivered but unfortunately too late Kyogre is already halfway across the Pacific Ocean to go drown Groudon can any of you adults do anything right hello Earth to Archie's brain it's Hollow I scaled the sky Tower to wake up Rayquaza and rat on the siblings duking it out in the middle of suolis off he flew and after a bit of non- gentle parenting the two slink back in their rooms in shame yay Land and Sea across the globe are safe once again if I catch your asses playing with these fing orbs again I swear even though it was the eighth and final gym before taking on the Elite 4 Juan wasn't an issue for some competitors he could have been difficult because he actually ran a full-on crab t team very intimidating but I've also got a crab and my crab is stronger than his crabs so we won after all I've gone through this was the hardest I've had to claw my way to the Elite 4 in a long time but that just means Victory is going to taste oh so much sweeter I entered Victory Road anticipating an easy dungeon clear but from the Shadows emerged Wall-E I've beaten you before I can be you get holy mother okay maybe that one was a bit of a fluke I wasn't ready this time will turns out Wally's tough I didn't expect it but he really is this made me realize I'm not prepared for everything with my current roster of Pokemon and if I'm going to become the champion I need to make some big changes I've been swapping around my team pretty casually over the course of my adventure but after locking in I decided on this as my final roster primarina Kingler AIS slash beware and two new members of darmanitan the Angi fire monkey and duraladon the you guessed it gun look I've seen the power of being able to pull up with a gun I think I'm going to need that in the fights that are ahead of me with these changes I was able to rematch Wall-E and take home the win this time this is it these guys are my team and they're the ones I'm going to become the best with while doing some final training before the Elite 4 there was just a little tiny unexpected hiccup along the way what was that oh my Freddy you would never he would never have to teach it too I'll get rid of earthquake for a bite of 87 five nights what what what the it's Parish song Oh My Freddy what am I turning into you're not like this Freddy for those of you who are unaware five nights is basically an unhinged version of Parish song where after five turns both Pokemon on the battlefield are hit by a 250 base Power Attack and Bite of 87 is straight up a brand new on hit KO move where if you get bit you die instantly but there's only a 30% chance of it actually connecting highrisk High reward Type move equipped with a plethora of new threatening moves and mons my team was now prepared for the final Gauntlet I flashed my badges to the guards and took a step into Sydney's domain I like that look you're giving me let's have a good match as someone once taught me you got to be prepared for the gun Phoebe was up next with her gamer Pok\u00e9mon and even though I was able to take down her team with my loaded deroon and shower giving primarina the highlight of the fight was when she brought out a Freddy Fazbear of her own huge win beware oh it's Freddy V Freddy here it's got to be Freddy V Freddy and you know what Freddy [Music] does oh he got the first one he got it that's mying Freddy right there doesn't miss he hits that frontal lobe everying time I walked into glacia room Larry the third fight was against Larry who normally is a gym leader and Elite for member in Pala but looks like he also works for hoen jeez man three full-time jobs that cannot be legal you got to talk to HR he led with a Golem that only knew stealth rocks and explosion which is chaotically hilarious but right after that he sent out a W of a slacking that took out my duraludon primarina and AIS slash finally Kingler was able to knock it out after pulling off a few Dragon dances sorry crab Raves since I basically had a crab bazooka on my hands Kingler just swept him from there after the Larry jump scare I didn't even know what to expect for the final member it could genuinely be anyone Cynthia red clay butt again what no you're joking he's in theing vent no wait I F facing the wrong way I didn't know that's what happened when you click the VIN from that side I'll be honest Not only was I flashed for simply going about my E4 challenge but Elite 4 sussy Baka and his sus team went dummy mode on me I'm scared so I shoot oh no wait this isn't good this thing's got to go no he's faster he's dead what I thought no where is he oh nice crit no they all vent stop venting well now I guess you get another crab Rave I do no he he avoided it no Krabby I'm sorry a I was not anticipating a battle where their whole strategy was to hide in vents scattered all over the room and when they popped out they hit like trucks not even my five nights attack could hit them in the vents which meant I was just getting my own mons attacked by animatronics admittedly we were vaporized but shut up there's nothing in the rules about trying again it's not a Nuzlocke I refused to call it there because I will not let my legacy end with see that girl she was on her way to become the next hoen Champion but she couldn't get past Elite Four member sashy Boda poor thing the Second Battle went much better because not only was I able to play around all the venting but halfway through the fight Kingler finally learned a better crab move this whole time I was being forced to use 50 base power vice grip but now that we've got 100 base power crab hammer it was lights out for these imposters and with that it was time all that stood left in front of me was the champion Wallace which makes sense because Steven was definitely fired after that Maxi fight out came his first Pok\u00e9mon which was a simple why not now let me explain something here because this thing is far more threatening than you could ever believe this game has introduced so many new types into the world of Pok\u00e9mon many of them are extremely powerful but there's one type that Reigns amongst them all the absolute worst and that's baby type it's pretty self-explanatory which Pok\u00e9mon fall under the baby category Igglybuff cleffa Budu bonley literally the baby Pok\u00e9mon you know what this type is weak to literally like all of them think about it if you hit a baby with anything they're going to be taking damage it's a baby so now you're probably thinking okay so why does the final boss of hoen lead with why not the baby type it's also Uno reverse that's right every single type Effectiveness against this thing is now flipped it's a defensive monster just waiting to counter and mirror coat your whole team to death for simply breathing on it too hard I was genuinely so so scared of this thing I dragon tailed it out of there that's a nightmare for another time his lattos got dragged out which is crazy to say I was relieved to see compared to that masochist of a why not but of course it's still a lattos so it takes out my duraldon with a single Thunderbolt Kingler comes out to finish it off so next came syali which I'll just let you watch how this one played out I don't think I get past this thing what even is this type type Emerald he's a type type type type I don't even know what that is but it's got to be weak to Monkey so type type is more of a modifier than anything it just doubles all type interactions oh  so okay so I die here what so here's a little glitch sometimes uh let's say the max damage you can deal is 999 if the game register doing more it overflows into one HP so this is Dar manit tan died and came back to life basically pretty much yeah well that gives us enough time to Banana Blitz again yeah we take those all right nope I don't want to hear it we take those the next chunk of the battle plays out pretty normally Wallace did have some pretty scary Pok\u00e9mon including Steven's Metagross he very likely lost custody of until I was face to face with this stupid little bomb again it tried everything it could to bait my AIS slash into attacking it but we stayed patient I knew I had a single shot at this so AIS slash charged up as many swords dances as it could muster before slicing that thing to the Moon a final Beast entered the ring a through Abomination called Sans Shedinja this is the only Pokemon in the decks with the Sands type and it can only be touched by a very small selection of types A tried and true nightmare unfortunately for you Wallace I've played the genocide route of undertale I know exactly what it's going to take to bury this thing for good and he's right here it's a beautiful day Sans shinja but insects like you should be burning in [Music] hell I did it the strongest Pok\u00e9mon trainer in this Wacky World of hoen is me it took so much more than I thought it would to be here way more humiliating wipes than I'd like to admit I lost a lot of battles but shut up you try playing it then with the power of friendship logic determination and maybe just a little bit of love we've beaten Pokemon to many types and with that we're pretty much wrapping up on 2024 this was a big Jaden year for many personal and content related reasons and I just wanted to say thank you guys as always for watching after all this time I'm forever grateful for my team and friends who are always supporting me and I'm looking forward to working even harder in 2025 I still can't believe I really just love making videos this much even after 10 years I hope that you'll continue to support me no matter what projects I'm working on next year and I promise to do my absolute best until next time bye-bye"}], "25. Health Economics": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] JONATHAN GRUBER: So\ntoday, we're going to have sort of a\ndifferent kind of class since it's the last class. Today, I'm going to talk\nabout essentially how we bring to bear the set of\nissues we've talked about this semester to a\nreal-world topic, and actually, how it plays\nout in policy and practice. And I'll draw on some\nof my own experience, having applied the kind\nof tools we learned in 14.01 to the field of health\ncare economics for 25 years, and how that has led\nme to be able to help in the development of health\ncare policy in the US, and talk about sort of where\nhealth care policy stands at this point. So let's get a little\nbit of background about health care in the US. Basically, when we're talking\nabout health care in the US, we have to recognize that\nthe US spends, by far, the most money on health\ncare of any developed nation in the world. We spend about 17 and 1/2%\nof our gross domestic product on health care. That amounts to almost $10,000\nper man, woman, and child-- every man, woman,\nand child in America. That dwarfs the\nrest of the world. The typical European nation\nspends about 2/3 as much as a percent of\nGDP on health care. England spends less than\nhalf as much on health care. So basically, we spend\na lot on health care as a share of our economy. And what do we get for it?"}, {"content": "Well, the evidence here-- the first fact is clear."}, {"content": "The evidence that we get for\nit is a little bit mixed. So if you look at the\ntypical thing on the web, you know, US health\ncare is terrible. Our money's wasted. You'll see that on things\nlike infant mortality, we rate, like,\n20th in the world. Or life expectancy, we're,\nlike, 20th in the world. So by those metrics,\nwe don't do very well. But in fact, those metrics\nare misleading because we also have-- we have the most unequal health\ncare system in the world. So the right way\nto think about it is to think about the\nhaves and the have-nots. The haves, which is us and\nmost people in America, people who are\nwell-insured in the system, actually get probably\nthe best health care in the world, Now that might\nbe disputed by many people. But I think about\nthis like an economist would think about it,\nwhich is, how would you decide whether you would prefer\nproduct A versus product B, whether they buy product\nA versus product B? Every year, one million\npeople come to the US to get treated for their\nhealth care problems."}, {"content": "No one leaves. No one's going to\nEngland for surgery. No one's flying from the\nUS to England for surgery. They're coming here."}, {"content": "If you're in the system, we\nhave the best health care in the world. Unfortunately, if you're\nout of the system, we have some of the worst\nhealth care in the world. So a white baby born\nin America today, there's roughly a slightly\nmore than 0.5% chance the baby will die\nin their first year. That's comparable\nto northern Europe. If you look at a black\nbaby born in the US, the odds they die\nin the first year are about twice that, which\nis worse than Barbados. So the problem in the US is\nnot that our outcomes are bad. The problem is\nthey're very unequal-- that we're spending\nall this money. We're delivering good,\nbut not exceptional, outcomes for people\nin the system and bad outcomes for\npeople out of the system. So clearly, we're not\ngetting a lot of value-- it's not like we deliver\nexceptionally good outcomes to people in the system. We're slightly better,\ndespite spending a lot more, and we're worse for\nmany Americans who are left out of the system. So that's sort of the setup of\nwhere we are, which is really, you have two\nfundamental problems in health care in the US. Our spending is too high, and\nour access is too unequal. Now so I want to focus today's\nlecture on those two aspects and think about how can we\nbring the kind of lessons we've learned in this course\nto thinking about addressing those problems. So I'm going to focus on the\naccess problem and the cost problem."}, {"content": "Let's start with\nthe access problem. Now in America, before 2010,\nwe had about-- or before 2014, we had about 50 million\nuninsured Americans. 50 million people\nwho did not have health insurance in the US. We're the only\nnation in the world-- only developed\nnation in the world with a significant\nuninsured population. Now the fact that 50 million\npeople are uninsured, is that a problem? On its face, if I just\nsaid here's a fact. 50 million people in America\ndon't have health insurance. Based on that fact\nalone, can you tell me whether there's\na problem or not? You shook your head no."}, {"content": "Why not? AUDIENCE: Because it might be\nbetter for you not to have-- JONATHAN GRUBER: Yeah. You know, many more people than\nthat don't have flat-screen TVs and don't own homes. Why do we think\nthat we should care if people don't have something? The answer would be, we\nwould only care if what? Under what condition? When do we-- yeah-- AUDIENCE: [INAUDIBLE] JONATHAN GRUBER:\nIf-- well, they'd be better off if\nthey did have it. Now they could be better off\nbecause they could be richer, but that's not our problem. Given their budget,\nthey're not buying it. What-- under what condition\nis the market not-- under what type of conditions\nwould the market not deliver the best outcome? AUDIENCE: If there's\na failure, like-- JONATHAN GRUBER: If\nthere's a market failure. So the fact that\npeople aren't insured doesn't matter except A, if\nthere's a market failure, or B, for redistribution purposes. Remember, that's\nthe two reasons we want the government involved. So if health insurance markets\nwere perfectly functioning and people who were\nuninsured were roughly equally distributed in\nincome as everyone else, there'd be no cause for worry. But in fact, that's not true. We've talked in\nthis class about why markets like health insurance\nwon't function well, which is a problem\nof adverse selection. The problem is\ninformation failures which will lead health insurance\nmarkets not to function well. And the people who\nare uninsured tend to be much poorer than the\npeople who are insured. It's also\nredistributional concern. So the reason we care\nabout the uninsured are both because\nof market failures and for redistribution, that\nthey tend to be lower-income. What's interesting\nis the uninsured don't tend to be the\npoorest in society. They tend to be the near poor. So here's the way sort of\nhealth insurance coverage works in the US. For the vast majority\nof Americans-- 60% of American-- 60% of Americans\nhave what's called employer- sponsored insurance. So like your most\nof your parents, like me, they get health\ninsurance from their employer. The typical upper-income\nAmerican gets health insurance from their employer. The typical average-income\nAmerican does. About 60% of Americans. Then-- and I'm going to\ndo this sort of pre-ACA. So before 2014,\nbefore the big change that was put in place by\nthe Affordable Care Act, you had about another,\nmaybe, 6% that bought into what we call\nindividual or non-group health insurance. That is, they went out on\ntheir own and bought insurance. But that's a tiny\nmarket compared to ESI. And the reason is because of\nexactly the adverse selection problem we talked about. Think about yourself\nas an insurer. And you're worried about\nyourself as an insurer. And think about\nwhat your goal is. Your goal as an insurer\nis to essentially absorb risk in a way that allows\nyou to make a profit. So what you want is\nyou want to live off the law of large numbers. You know that with a\nlarge enough group, you could be able to predict\nwhat their costs will be. And therefore, you can\njust make a profit on top. So insurers love-- when\nMIT comes to an insurer, they're delighted. They're like, look, you got--\nbetween MIT and Lincoln Labs, you've got about\n10,000 employees. I, with great\ncertainty, can predict what the costs will be next\nyear for a group of 10,000 employees. And so I, as an\ninsurer, can know I can just charge that, plus\nX percent, and I'm golden. But when Jon Gruber\nwalks in the door, they're like, why are you\ncoming to me, individual? Maybe because you know\nyou're sick, maybe because you love skydiving. I don't know."}, {"content": "But I'm wary of you, so I'm\nto charge you a lot of money to get health insurance. As a result, most-- very few\npeople bought health insurance on their own. And in particular, the\nreason they didn't is because insurers would not\noffer health insurance to people if they were at all sick. They would do things\nlike having what we call pre-existing\nconditions exclusions. These were features of insurance\ncontracts which said, look, you walked in the door, Jon,\nand you want health insurance. But I know, in the past, you've\nhad cancer or asthma or knee surgery. I'm going to tell you,\nI'm going to insure you, but not for any expenses that\nmight arise from recurrence of those past injuries. So you had cancer in the past. Anything that comes up in the\nfuture because you had cancer, I'm not going to cover. Anything that comes\nup in the future because you had knee surgery,\nI'm not going to cover. Anything that comes up in the\nfuture because you had asthma, I'm not going to cover it. So I'm going to give you,\nessentially, partial insurance. So it's going to be\na market failure. I'm going to insure you, but\nonly for part of what you need. Alternatively, they could\nuse pre-existing condition solutions-- they could\nuse what is called medical underwriting,\nwhich was basically saying, OK, Jon, come in. I'm going to give you an\nexam, and if you look sick, I'm going to deny you insurance. Or if you look sick, I'm going\nto charge you 100 times more than someone else. So these were not\nillegal or even immoral. These were just ways\ninsurers came up with to try to deal with the\nadverse selection problem. As a result, this\nwas a market that did not function very well. Question about that? AUDIENCE: [INAUDIBLE] JONATHAN GRUBER: No, totally\nlegal in every state-- virtually every state,\ntotally legal and not immoral. I mean, this is just they're\nmaximizing their profits."}, {"content": "It's what companies do. And the point is that when\nthey did this, what this meant was if you didn't have\nemployer-sponsored insurance or insurance from the\ngovernment, which I'll come to next, then you\nwere subject to the fact that if you got\nsick, you might not be able to get insurance,\nwhich is sort of weird. Insurance is supposed\nto cover if you're sick. But in fact, if\nyou were sick, you might not be able to get it. So that was the fundamental\nmarket failure we had here through adverse selection. Now we also-- that was\nemployer-sponsored insurance, so that was about 2/3\nof the population. You also had on the order\nof 15% of the population had government-sponsored insurance-- probably more like 20%. 20% of the population\nhad government-sponsored. Insurance. The two big programs here are\ncalled Medicare and Medicaid. Now if you ever\ntake my 1441 class, I will only hold you\nresponsible for one thing if I ever meet you\n10 years later, which is remember the difference\nbetween these two programs. Medicare is health\ninsurance for the elderly. Medicaid is health\ninsurance for the poor. And those are our two big\npublic insurance programs. And about 20-- and if\nyou're in those programs, you're also set. They don't have any\nof these features. If you're in, you're\ncovered for everything. So about 20% of\npeople are there. And then finally, if you add up\nthe numbers, we had about 15-- the numbers don't quite add\nup, but you had about 15% of the population was uninsured. 15% uninsured. So you had about 2/3 private,\nabout one fifth public, and about one sixth uninsured. And those are individuals\nwho typically were not the poorest because the\npoorest people got Medicaid. The typical uninsured\nperson is, like, what we call the working\npoor, someone who's got a job, but it's a crappy job that\ndoesn't offer health insurance. But they make enough\nmoney that they can't qualify for being\nin the low-income program. So your family is struggling at,\nlike, $40,000, $50,000 a year, high enough income\nthat they're not qualifying for Medicaid but not\nin a good enough job they're getting health insurance. That's your typical\nuninsured family. 2/3 of the uninsured\nare in families that are headed by a\nfull-time, full-year worker. They're not typically the\nunemployed down-on-their luck people. They typically\nare the people who are trying to play by the\nrules, as they say in politics, but typically can't get a\njob with health insurance. So that's your basic landscape. And what we know\nfrom that landscape is that a lot of\nthe access problems were because of this\ngroup and this group because the people who couldn't\nget in this market, and as a result, were often uninsured. That was a lot of what\ndrove the access problems. So that was sort of the first-- one of the two big problems\nthat faced our system. And for many, many years,\nwe knew we had that problem. And for about 100\nyears, we've tried to reform health care in\nthe US to deal that problem. And probably about\nevery 17 years, on average, there was a big\nattempt to reform health care, and they always failed. And they always\nfailed because they failed between two extremes. There were two extreme\nviews that could never quite meet in the middle ground. And they come to what I\ntalked about last time, which is how do we solve the\nproblem of market failures in insurance markets? Well, one version of\nsolving that, I described, was subsidization. You could-- remember,\nwith my MIT program, if I paid the healthy guys\n$500, they'd all buy two, and I'd solve the problem. So one version\nwas subsidization. The problem is\nsubsidization only works if it's big enough to\novercome these problems. And no one ever proposed\nsubsidization big enough to overcome these problems. In my MIT example,\nI was going to give $400 to every\nhealthy-- first of all, it means giving money\nto healthy people, which is sort of\npolitically difficult. Like, hey, the healthier you\nare, the more money you get. It seems a bit weird. Also, it's just hard\nto solve these problems by just subsidizing people. Insurance companies\nare still too good at trying to get\nrid of the sick people. And even if you subsidize\npeople who come in, insurance companies will\nalways have an incentive. They'll say, great, healthy\npeople come, we'll subsidize. They'll still want\nto avoid the sick. So it doesn't solve the\nproblem in insurance companies. I didn't talk about\nthis last time, but as MIT's\ninsurance company, I should try to shed\nthe sick people. And that problem still\nexisted under this solution. The other extreme, which is\nsort of back in style again, is the single-payer model,\nwhich is saying, look, let's just have the government\nprovide health insurance to everyone. We have the government provide\nSocial Security to everyone. The government provides\nhealth insurers to every elderly in\nAmerica through Medicare. Everyone over 65\nin America, boom, gets government-provided\nhealth insurance. Talk about socialism. Every American gets that. In Canada, everybody gets\ngovernment-provided health insurance. Why not just do it here? Let's get rid of all the\ncrap with insurance companies we don't like. After all, insurance\ncompany administrative costs are about 15% of\nmedical spending. So, boom, we could lower\n15% of medical spending. That is, you know, that's\nlike $500 billion a year. Boom, it's gone. So basically, why not-- so\nsingle payer is something a lot of people\nhave advocated for. Let's just have one giant\nuniversal health insurance program. Now the problem with this-- the problem with the\nsingle-payer approach is largely-- there's pros and cons to\nthe economics perspective. But the problems here\nare largely political, which is that to make\nsingle payer happen, you have three enormous\npolitical barriers, which come back to economics. Everything comes\nback to economics, but they play their way out\nin the political system. The first problem\nis paying for it-- paying for it, which\nis that single payer-- to have the government give\neveryone health insurance means a massive expansion\nin the government, which means a big increase in taxes. And we know taxes\nhave deadweight loss."}, {"content": "We know taxes are\npolitically unpopular. Now here's what's\nmisleading about that."}, {"content": "Here's the fundamental thing. So I worked for the\nstate of Vermont. The state of Vermont wanted to\ndo their own single-payer plan. If any place can do\nit, it's Vermont. They're, like, super lefty. They essentially have\none insurance carrier, which is Blue Cross anyway. They're a small state. It seemed like if anyone\nwas going to do it, Vermont was going to do it. So I worked with them to\nput the numbers together, what it would cost them. And I had good\nnews and bad news. The good news was,\nI said to Vermont, if you do single payer you will\nlower the cost of health care in Vermont total by at\nleast 10%, at least. That was conservative. The bad news is to\npay for it, you're going to have to more than\ndouble the entire amount of taxes collected\nin state of Vermont. And that second sentence\njust killed everything. What's the problem? The problem is that right now\nhealth insurance in America is paid for by\nessentially a hidden tax. What's the hidden tax? It's the fact that when\nyour employer gives you health insurance, they pay\nyou less wages as a result. Remember our tax\nincidence discussion. And we said that essentially\ntaxing the employer falls on the\nemployer-employee depending on basically elasticities. Well, you can think of health\ninsurance the same way. When your employer gives\nyou health insurance, he doesn't just\neat the whole cost. He says, look, I'm paying you\na total set of compensation, part of which is\nhealth insurance. So I'm going to pass the\ncost of that health insurance on at least partially\nto your wages. That's essentially a hidden tax. So at MIT-- right now, I\nhave a health insurance plan through MIT, which costs about\n$18,000 a year for my family. I pay about $6,000 a\nyear out of my paycheck. MIT pays $12,000. But the truth is, MIT\npays me $12,000 less. They don't just give me\nthat health insurance out the goodness of their heart. They take it out of\nmy wages, or least partially out of my wages. That's essentially a hidden tax\nthat Americans pay every year to finance health insurance. If we went to single payer,\nthat hidden tax would go away. I would get a $12,000 raise. That's great. But I'd also face\na high new taxation to pay for the\ngovernment-sponsored plan. Now given that the total\ncost would fall-- we should be able to net this out\nin a way that most people win. The problem then\nbecomes the politics, which is you're tracing a hidden\ntax with a non-hidden tax. And that's very\nugly politically. So people don't believe their\nemployers will pay them more if you don't make the employers\nprovide health insurers, like, oh, the employers\nwill just pocket it. And I could teach them tax\nincidence till my face is blue, but they just won't believe it. They'll say employers\nwill just pocket it. But I have to pay this\nnew tax for single payer. So that's the first\nproblem single payer faces is that people don't\nreally understand that trade-off between\ngetting rid of the hidden tax and adding a new non-hidden tax. That's problem one. Problem two is the problem\nwe talked a little bit about, behavioral economics,\nand about loss aversion. There's a general feature,\nwhat we call status quo bias in human thinking. Status quo bias, which\nis, essentially, it is harder for me to\ngive up what I'm used to than to grab something new. We talked about the mug example."}, {"content": "Remember, I talked about mugs. So basically, you\nhad to pay me more to get the mug away from me than\nI was willing to pay to buy it. That once you have something,\nyou value it more than if you didn't have it yet. Well, right now,\n60% of Americans have employer-sponsored\ninsurance. And if we say to them, give\nthat up for Berniecare, they're going to be,\nlike, eh, I don't know. I kind of like my\nemployer-sponsored insurance. You know, yeah,\nyou might tell me Berniecare is\ngoing to be better, but that's just you talking. I know what I have\nright now, which I have employer-sponsored insurance. I don't want to move away\nfrom that status quo. So status quo bias makes\nit hard, in general, to do radical changes\non an economic system. And this is a perfect example. It's going to be hard\nto get people to give up what they have for something\nthat they don't really know about yet. That's the second problem. The third problem is,\nonce again about money, but really beyond the\nscope of this course, which is the problem of the insurance\ncompanies and lobbying, which is that the insurance business\nis big business in America. Health insurance companies\nmake about $900 billion a year. If you said to them, hey,\nhealth insurance companies, would you guys mind just\ngiving up your $900 billion to begin a single-payer\nhealth care, they'd actually say, yeah,\nit's been a good run. Go for it."}, {"content": "No. They're going to lobby and\nfight that because they want to keep their business. And that's going to be a\npretty hard force to overcome. So single payer has\nalways struggled with dealing with these\nkinds of political problems. And that's why we've been stuck. We've been stuck between\none alternative, which is subsidization, and the\nother alternative, which is single payer. And that's where\neconomists have come in-- came in the 2000s,\nfolks like myself, to talk about a\nnew alternative way to do it, which was\nessentially to try to bring in some of the\nbest features of these two approaches. And the solution we proposed-- so if you want to\nread more about this, I've actually written a\ncomic book to explain it."}, {"content": "It's a graphic\nnovel, technically. It's called Health Care Reform. It's, like, $9 on Amazon."}, {"content": "And so I like to think of\neverything in terms of images. Now I'm not going to draw one."}, {"content": "I'm not going to try\nto draw anything. But the way I like to think\nabout this is the solution we came up with, which we first\npioneered here in Massachusetts and then brought to\nthe whole country through the Affordable\nCare Act, is what we call a\nthree-legged-stool approach, three-legged-stool approach. Leg one is deal\nwith this problem. Deal with the insurance\ndiscrimination problem. And so leg one is ban\ninsurer discrimination. No more pre-existing conditions,\nno more medical underwriting. That is, if I walk in the door,\nand you have offered anyone-- you have to offer me health\ninsurance at the average price for my age. And you have to offer it to me. So any 40-year-old who walks\nin the door wanting insurance, you have to sell it to them,\nand you to sell it to them at a fixed 40-year-old price. You can't say, you're sick. I'm not going to sell it to you. So the first step is to\nban insurer discrimination, to try to solve that problem. Now the problem this\nraises is you have simply-- if you do this alone, you've\ncreated a new problem, which is if you tell insurers\nthey can't discriminate against the sick, you don't\nsolve the adverse selection problem. You're just making\ninsurers go bankrupt."}, {"content": "Now here's the way I\nlike to think of it. I'm sure none of you\never gambled on sports. But if you had\ngambled on sports, you might know the way\nsports gambling works is that there's a guy in the\nmiddle, called the bookie. And the bookie's\ngoal is to not-- is to get exactly the same\nnumber of bets on either team. So they take no risk, and just\nmake their profits off the top. So what bookies do is\nthey set point spreads. So the Patriots played the\nDolphins this past weekend. I am-- sadly, I'm\na Dolphins fan. The Patriots played\nthe Dolphins. The point spread was\nsomething like-- does anyone know what the spread\nwas in the Patriots' game? I think is was, like, 8 points. So that spread was chosen. The Patriots were favored by 8. What that meant was\nyour bet was either the Patriots win by either\nmore, or the Dolphins win, or the Patriots win by\n8, or by less than 8. So one side is Patriots\nwin by 8 or more. One side is Patriots win by\nless than 8, or Dolphins win. And the reason you\nhave that bias thing is because people think\nthe Patriots are better. They are better. And as a result,\nyou want to get-- if you set an even bet,\nPatriots win, Dolphins win, everyone would bet\non the Patriots. You'd lose money. So you want an equal\ndistribution of risks. So what you want is you\nwant to set the point spread so the distribution\nof risk is equal. Then having done that, you just\nmake your money off the top. Now imagine I passed a law\nwhich said all sports books have to reopen at halftime and make\nthe same bets available they made before the game started. Well, for those of you who\nwatched the exciting game this weekend, you\nrealized at halftime, it became pretty obvious\nthe Patriots weren't going to win by 8, that\nit was a lot closer game than people thought. So if they reopen\nthat, a bunch of people would suddenly bet\nagainst the Patriots. The Patriots ended up\nlosing, and the insurers would have gone bankrupt-- the\nbookie would've gone bankrupt. Insurers are just bookies. That's all they are. They just want a predictable\ndistribution of risks. So if you tell them, you have\nto offer health insurance to everyone for the\nsame price, but only the sick are going to buy,\nthey're going to lose money. So that's why we need the\nsecond leg of the stool, which I talked about last time, which\nwas the individual mandate. The individual mandate,\nwhich is to say, OK, insurers, if you offer\nhealth insurance to everyone at a fair price, we will,\nas our part of the deal, make sure everyone\nbuys health insurance. So when the 40-year-old walks\ninto your office wanting insurance, you can know it's\nnot because they're sick."}, {"content": "It's just because they have to. So we say to insurers, you\nprice insurance fairly, and in return, we'll\nmake sure you get the fair distribution of risks. So you say to me--\nmy MIT insurance, you price insurance\nat $1,500 and don't try to keep out the sick,\nI'll make sure everyone buys. And you'll make\nyour $100 profit. So that's-- the mandate was\nessentially trying to bring-- was trying to allow--\nget rid of discrimination by bringing in the\nentire pool of people so insurers could fairly price. The problem with that is you\ncan't mandate something people can't afford. So in Massachusetts,\nwhere we were creating this plan\nin the mid 2000s, the typical family\nhealth insurance policy was about $12,000 a year. The poverty line for a\nfamily was $22,000 a year. We couldn't exactly\nmandate people that they spend 55% percent\nof their income on health insurance. That was not really feasible. So the third leg of the\nstool we came up with is subsidies to make health\ninsurance affordable, saying, if you're\nlow-income, we will offset the cost of your insurance just\nlike the subsidy approach here. We'll offset the cost\nof your insurance to make it more affordable. We'll do it on an\nincome-related basis, so it doesn't cost so much. So we're not going to\nhave to pay for everyone's insurance like single payer. Remember, single payer,\nessentially taking someone like me, who's\nhappy with my insurance, swapping it out for new\ngovernment insurance. This is saying, no, if you're\nhappy with your insurance, stick with your insurance. But if you're low-income and\ncan't access the employer market, this gives\nyou a new place to go. And that was the idea\nthat became Romneycare, the plan here in Massachusetts,\nand eventually then became Obamacare, or the\nAffordable Care Act. So this is essentially\nthe idea of that plan. Now, did it work? Unambiguously, yes."}, {"content": "Now you won't find\nanyone more biased than me on this question. But I think what-- I think if I've tried to teach\nyou one thing in this class, it's that we need to rely on\nreal facts wherever possible. And if not, we could\nturn to theory. But here we have a set of real\nfacts that we can turn to, which is that\nessentially what we did in Massachusetts with this\nlaw is we covered about 2/3 of the uninsured population. At the federal level,\nwe covered about 45% of the uninsured population. It was a lower number because\nthe federal law did not apply to undocumented\nimmigrants, which are about a quarter\nof the uninsured. It's not an issue\nin Massachusetts, but a big issue in other places. That's about a quarter\nof the uninsured because the federal\nlaw did not apply to undocumented immigrants. So as a result, the\nshare cover was lower. But a large number\naren't covered."}, {"content": "Yeah. AUDIENCE: If there was\nan initial mandate, then how was there anyone\nwho was left uninsured? JONATHAN GRUBER: Great question. So there are three reasons why\npeople were left uninsured. The first reason was a\nquarter of the uninsured were undocumented\nimmigrants, and the law didn't apply to them. So right now the upper bound\nwas 75%, just to start. The second reason is that the\nindividual mandate contained exemptions to make it both a\nlittle more humane and, quite frankly, politically feasible. So if you could not\nget-- if your income was below the poverty\nline, you were not subject to the\nindividual mandate. And if you could not get\ninsurance for less than 8% of your income, you\nwere not subject to the individual mandate. So there were exemptions. And the third thing was\nthe individual mandate was not, like, we're going\nto throw you in jail. It was a tax penalty. And many people decided they'd\nrather just pay the penalty than buy health insurance. So for those three\nreasons, a number of people did not get health insurance\nunder the Affordable Care Act. Now there's a bunch of\ninteresting questions, like should the mandate\npenalty be bigger? How should we handle that?"}, {"content": "There's a lot of-- I could go for hours on this. But that's basically the\nstructure of what we had. So basically, that worked. It didn't get us to\nuniversal coverage. It wasn't as effective as\nsingle payer would have been, but it was the largest\nsingle insurance expansion in American history. And the evidence is clear. It brought many\npeople into insurance. It improved people's\nuse of health care. It improved health. So basically, that was kind\nof the step forward on access. Now the problem with\nthis is it's only a step. There's still many\nuninsured, and this has been politically really\nchallenging, because these two answers are quite simple. Just give people money or\njust have single payer. This is super complicated."}, {"content": "I can talk about these\nin about 15 seconds each. These took five\nminutes to go through. And people thought it\nwas just too complicated. It didn't make sense. Lots of reasons-- we could\ntalk lots reasons people didn't like it. So it's never really been\nas politically successful as people like myself,\nwho helped develop it, would have hoped. And it's left a lot\nof people uninsured. So we haven't solved\nthe access problem. We made a big step forward,\nbut we haven't solved it. And that's the ongoing debate\ntoday we see, particularly in the Democratic Party. The Republican Party\nreally doesn't focus much on insurance coverage. But the Democratic Party does. And they're-- that's why there's\na lot of energy behind single payer right now is like, look,\nyou tried the kind of halfway ground. That kind of worked, but\ndidn't work all the way. So let's just go all\nthe way to single payer. Yeah. AUDIENCE: The initial\nmandate, does that-- I guess, for the\nmore people living in poverty, does that work\ntogether with Medicaid or-- JONATHAN GRUBER: Yeah. Basically, a lot-- actually,\nit's quite interesting. It worked quite\nwell with Medicaid. A lot of people\nwho aren't insured, actually, are people\nwho are already eligible for free\nMedicaid coverage and just don't take it. Now we don't quite know why."}, {"content": "It could be language barriers. They don't understand. A lot of people-- a lot\nof even legal immigrants just don't understand\nthey're eligible. It could be people just don't\nwant a government handout. They're embarrassed taking\nhelp from the government. It could be people\nthink, I don't need it. I'm never going to be sick. We don't know why. So part of what\nthe mandate did was say, look, you already\nhave free health insurance. Just pay attention and take it. That's part of the effect it\nhad was bringing people in. So a large part of\nthe coverage increase is actually bringing in people\nwho were already eligible, just weren't taking it up before. So that's kind of where we are. So where we stand\nnow in coverage is we've taken a\ngiant step forward. We've covered probably\nabout now, probably, between a third and 40% of\nthe uninsured in America. But we're sort of right now\nkind of stuck at that point. And the question is, do we\njust sort of stick there, or do we try something\nmore aggressive? With the political\nproblems, I don't know."}, {"content": "But that's going to be the\nchallenge going forward. So that's-- questions\nabout that-- because that's where we\nare on problem number one, which is access in coverage. Now let's turn to problem\nnumber two, which is cost. Cost is way harder."}, {"content": "What I just did\nwas the easy part. It's way harder to get\nyour health care costs, and here's why. Two facts that are seemingly\ncontradicted if you think about it. Fact one. Since 1950, US\nspending on health care as a share of our\neconomy has quadrupled. We've gone from--\nmore than quadrupled. We've gone from 4% of our GDP\nbeing health care to over 17%. And it's been worth it. If you look at the\nimprovements in our health, and you value them in\nthe way economists do, which is we have statistical\nvalues of life we apply, or statistical values in\nimprovement in health, the improvement\nin our health has been worth the money\nspent on health care. You guys don't realize it. Health care totally\nsucked in 1950. Babies born in 1950 were\nfour times as likely to die before they reached\ntheir first birthday. If you had a heart\nattack in 1950, you were four times likelier\nto die within the first year. To put it in terms all young\nhealthy people care about, if you hurt your knee skiing\nin 1950, tore your ACL in 1950, or tore your cartilage, you\nwere in the hospital for a week. You were on crutches\nfor six weeks and had arthritis the\nrest of your life. Today, you go to an\noutpatient center. You get arthroscopic surgery. You're back on the slopes\na couple weeks later. Health care is just way better,\nand our health is way better. America is a much better off\nnation, spending 17% of GDP on health with how healthy\nwe are than we were in 1950. And once again, do\nthe economists tests. No one ever advertises, hey,\nwould you like 1950s health care at 1950s prices? No one out there is offering\nthat because it's worth it. That's fact one. Fact two is we waste a huge\namount of money on health care. By some estimates, about a third\nof what we spend on health care is totally wasteful, does\nnothing to improve our health. Now how can those two\nfacts be consistent? It's worth it,\nbut it's wasteful. Well, the answer is that the\nother 2/3 is super awesome, that basically the\nincrease in health care, where it's been productive,\nhas been amazing. But we dragged along all this\nunproductive spending too. So it's good news and bad news. So the good news is,\nwell, that's great. We just cut out the one\nthird that's unproductive, we've solved our problem. Literally, if we could\njust simply cut out the one third\nthat's unproductive, we'd spend the same amount as\nEurope does on health care. We'd solve our entire\nlong-run fiscal problem. The bad news is that it's\neasy to look back and see what the one third was. It's hard to look forward and\nsay what it's going to be, that health care comes with\na huge amount of uncertainty about what's going to work and\nwhat's going to be worth it. And as a result, it is\nvery hard to say, OK, fine. We'll cover this. We won't cover\nthat, because it's hard to know what's going\nto work and what's not. And so, essentially, you're\nin this very difficult spot. So what are the\nkind-- that's the sort of fundamental\ntrade-off that we face. So what are the potential\nsolutions to this problem? So essentially, there's a\ncouple of different solutions to the problem, two different\npaths we can follow. Path one is the regulatory\npath, which is basically the path that Europe follows. What Europe does is they\njust much, much more heavily regulate the delivery\nof health care. And they do that in two ways. One is they actually have\nregulations about what health care you can get. So for instance, England has\nthe euphemistically named NICE, the National Institute for\nHealth and Care Excellence, which actually tells people\nthey can't get some things. It literally rations. So for example, for many\nyears-- it's no longer true-- in England, if you're over 75,\nyou could not get a transplant. They said, look, we got a\nlimited number of kidneys. You're going to die soon anyway. Let's give the kidney\nto a young person. Actually, kind of makes sense. The idea is, look, we have\nsome limit on our kidneys. Why should it be determined\nby some random fact, like when you got on line? It should be\ndetermined by who gets the most value from the kidney. It's going to be someone who's\n30, not someone who's 75. So one regular route\nis to literally have regulations like that. That's actually pretty rare. Most countries don't actually\nregulate in that way. Most countries kind of let\nyou get what your doctor says you should get. There's three routes."}, {"content": "So one route is\nsort of regulatory. The other route of regulate--\nso one route is sort of what we call sort of\nregulating, you know-- I don't want to call\nit access-- sort of technological regulation,\nregulating which technology you can get. The second kind of regulation\nin Europe is supply regulation. So they basically don't\nlet there be many doctors. And there are not many\ndoctors and hospitals. So there are as many\nMRI machines in LA as there are in Canada. Basically, just not many place\nto go get an MRI in Canada. So if you' hurt\nyour knee in the US, you go, you get an MRI,\nlike, the next day. In Canada, you get\nit six weeks later. So the only way to control\nit is to actually regulate the supply of medical care. Just give people less\nstuff they can use. And the third way to control-- the third regulatory mechanism,\nand the most important, is price regulation. We are the only nation in\nthe world which essentially lets the free market determine\nthe price of health care services. Every other nation\nregulates the prices that people pay for their\nhealth care services. Now the question we\nhave to ask is why? Why does that make sense? Well, the answer would\nbe that we think-- it would make sense if we think\nthere's a fundamental market failure in the determination\nof health care prices. And in fact, it\nturns out there are numbers of market failures in\ndetermination of health care prices. So one market\nfailure, for example, is imperfect information. I don't know-- I can't shop\neffectively-- when I'm in the back of the ambulance\ndying from a heart attack, I can't be, like, you know\nthat hospital looks expensive."}, {"content": "Take me over there. I want to shop there. You can't really shop. It's a hard market to shop. And if you could,\nprices aren't posted. You don't really\nknow what it costs to get your heart attack\ntreated in different places. So imperfect information. There's also\nimperfect competition, which is if you have your\nheart attack on Cape Cod, there's, like, one-- or Nantucket, which is\nan island, with no way off but a ferry,\nthere's one place to go. There's one hospital. They have a perfect monopoly. You can't get off the island. You're going to die otherwise. So it's imperfect competition. There's even\nimperfect competition where you think the\ncompetition might be perfect. So take Boston. There are so many\nhospitals in Boston, you cannot literally fall down\nwithout hitting a hospital. Yet there is an\nenormous dispersion in the prices hospitals charge. In particular, the\nvery famous hospitals, like Mass General\nHospital, charge multiples of what less\nfamous hospitals charge, even though less famous\nhospitals are really nearby. Why? Well, because they\nhave essentially what we call a reputational\nmonopoly, that even though they don't have an actual physical\nmonopoly, people are like, I want to go to MGH. They're the best, even if\nthey're not necessarily the best. They just have this\nview of being the best. And they can charge\nhigher prices as a result, even if their outcomes\naren't necessarily better. In other markets, we\nthink perfect information would allow us to get rid of\nthese kinds of inefficiencies. It doesn't exist in health care. As a result, perfect\ncompetition simply does not work in\nhealth price setting. And as a result,\nall other countries regulate health care prices--\nand then not other countries-- even the US can\nregulate health prices. So the Medicare program\nhas regulated prices. That covers millions\nof Americans. It's just for the\nnon-government, private health insurance in the US, there's\nnon-regulated prices. Now I am not, despite my tone,\nsaying that regulating prices is the answer. It's not clear. Regulating prices comes\nwith a huge number of additional problems\nlike we talked about. We talked about\nregulated monopolies, which is the government may not\nknow the proper price to set. The government may\ndo a terrible job. They may get lobbied. They may be corrupt. Indeed, in the US, the\n1970s, virtually every state did regulate hospital prices. And every state\nwent away from that because they thought\nthe system was broken. So it's not like\nthere's any-- it's not like the European\nsolution's an easy answer. That's why the other route that\npeople have been pushing lately is a different route, which\nis the incentives route, which is basically to say,\nlook, we don't want to regulate supply or prices. What we're going to\ndo is we're going to say, doctors and\nhospitals, you get together and form these units we\ncall Accountable Care Organizations, ACOs. This is a big innovation\nof the Affordable Care Act of Obamacare, set up these ACOs. These are hospitals and\ndoctors all get together to be basically,\nlike, soup to nuts, all the health care\nyou need in one group. And we say to them, we are\ngoing to pay you one flat amount of money to care for Jon. And then within that,\nyou decide what he gets. You decide what prices\neverybody pays and makes. You figure all that out. But we're going to\ngive you a flat amount. In particular, that flat amount\nis not going to rise much. And that's going to bring\nthe costs of health care under control, where\nbasically every ACO will get an amount that's\na flat amount, and it just won't rise much. And that's how we'll\nbring health care costs under control. That has a number of\nwonderful features. First of all, it's\nmuch less evil sounding than things like\nnot letting [INAUDIBLE] rise or regulating what prices. Second of all, there's much\nfewer regulatory tools. We just say, here's a flat\namount we're giving you per person, and we're done."}, {"content": "So that sounds great."}, {"content": "The problem is we haven't\nbeen able to get it to work. And that's because it turns out\ndoctors and hospitals aren't very good at figuring out how\nto set prices and set supplies. They're just not--\nthey don't know how to really figure this out. And the ACOs so far have not\nactually performed very well. They've not saved much money. So really, we're stuck\nbetween a route which seems a lot easier but we\nhaven't really figured out how to make work,\nand a route which has worked all around the\nworld but seems politically nightmarish. And that's kind of\nwhere we are right now in terms of controlling costs. And that difficulty is\nwhat we find ourselves in. But let me be clear. This is not like, oh, that's\nvery interesting, Jon. I'll go home and\nforget about it now."}, {"content": "This is the entire future. Health care costs are\nthe key to determine the entire fiscal\nfuture of the US. As I mentioned last\nlecture, the US is currently estimated about\n$75 trillion in deficit over the long run. $70 trillion of\nthat is health care. Health care is the\nsingle determinant of the US fiscal\nbalance in the long run. Literally, it's the single most\nimportant government problem facing-- health care cost\nis the single most important government problem\nfacing your generation and the next generation. I like to say that all\nthat matters when we think about the future\nis health care cost and global warming because\neither way we're under water. Basically, those are\nthe two big issues we have to face going forward. So this is a serious issue\nthat your generation is going to have to struggle with-- sorry-- as you go on. So that's health care\nin the US in 40 minutes. So this class--\nyou know, there's a famous skit from\nSaturday Night Live, which is what you remember\nfive years after college."}, {"content": "And it's five minutes, and 3\nand 1/2 minutes of spring break. I don't expect you to remember\nthe formula for-- if you're not going on in economics,\nI don't expect you to remember the formula\nfor deriving cost function. What I expect you to\nget out of this class is A, an interest in economics. And I hope you'll go on. I sincerely hope that. And I'm available\nto anyone who wants to talk about the pros and\ncons of going on in economics. Obviously, I'm more pro."}, {"content": "But I'm happy to talk about it."}, {"content": "So always feel free to\nreach out about that. But B, even if you don't\ngo on in economics, I want this to make you\na more educated consumer of the newspaper. This is-- we are in an era, as\nI said in my very first lecture, where truth and facts\nand the scientific method are, themselves, under attack. And MIT is the last bastion\nof fighting this war. We are the place that explains\nthe scientific method, that uses the scientific method. And we need to use\nthe methods you've learned here to\nthink intelligently-- whatever your conclusions--\nbut to think intelligently about these economics topics. And fundamentally, that\nmeans being annoying. And to illustrate that,\nI'd like to end with a joke that some of you may have heard."}, {"content": "Sorry, I apologize if you have. So the joke is a doctor, a\npriest, and an economist go golfing. They get on the golf course-- and they hit the golf\ncourse, and they're behind someone going\nincredibly slowly. I don't know if there are\nany golfers among you, but the idea is if\nyou're very slow, you're supposed to allow\nthe people behind you to play through and\nget ahead of you. This person won't let\nanyone play through. And he's, like, 50 shots a hole. It's disgusting. And there's, like, 50 people\nlined up behind this guy. And these folks\nare so disgusted, they quit after nine holes. They go back to the clubhouse. They're pounding their\nbeers like, what an asshole. I can't believe he wouldn't\nlet us play through. It ruined our day. And someone comes up to\nthem and says, excuse me, are you new to this club? And they said, yes, we are. He said, well, I can tell\nyou're new to the club because if you weren't new, you\nwould have known the person you were playing behind is blind. And actually, it's\na miracle he can get the ball in the hole at all. And usually, it's an honor to\nbe on the same course as he is. And the person walks away. And there's, like,\na deadly silence. And the people at the\ntable are like, wow. I feel terrible. And the doctor goes, I can't-- I feel terrible. I can't believe I'm-- myself, a man of healing, would\nbe so insulting towards someone who's blind. I'm going to dedicate a wing\nof my hospital to the blind. And he turns to the priest. And the priest says, I\ncan't believe myself, a man of the cloth,\nand that I'm supposed to care for the less able\nin society, would do this. I'm going to set up a free\nsoup kitchen for the blind. And they turn to the economist. And the economist says, well, if\nhe's blind, why doesn't he just play at night? And-- makes sense, right? And basically, the point is\nthat the job of the economist is to sort of be\nannoying and look for the basic\nflaws in arguments, to understand them, to ask\nthe difficult questions, but to have responsible answers. And that's what I hope\nyou'll get out of this course that I hope you'll\ntake forward with you. So thank you very much\nfor sharing it with me. And good luck on the final. [APPLAUSE]"}], "Online Degree = Scam? | IIT Madras Seminar 2024": [{"content": "hi everyone and welcome to a new video today we have my online session with the folks at I Madras online bs degree let me set the context this is not the folks from the standard IIT offline degree this is the online degree which is a lot of them from non- Tech backgrounds a lot of them from a dual degree a lot of them only here for the name of an IIT so the discussion was around is this online degree similar to the offline degree what kind of differences exist U Can you call yourself you know a real graduate from it Madras if you're doing this degree um will the outcomes from both the programs be the same how can the outcomes from this online degree which is very easy to get in be compared with the offline degree eventually because right now there's a lot of iits coming out with online degrees U fairly easy barrier to entry how can you outshine and have similar outcomes as the offline degree U if you're from this batch a lot of discussion around online versus offline how it's very easy to get into these online degrees but the number of people who are actually able to graduate is really less so how difficult is it to get through these degrees some discussion around research whether or not you should get a job follow research do entrepreneurship and a lot of random doubts that we have on a day-to-day basis as Engineers it's a fairly raw talk a lot of raw questions from students and I've tried to answer them to the best of my abilities with that let's get into my online session at it Madras we do want to become someone who is worthy of the name iitm so we are kind of in a place where we don't know what to do I think the phone that you're feeling is probably no different than someone from a tier three college or a tier 2 College who probably feel similar how do you hold up to the it name I think one good thing that happens in this program is the number of people who get out is really less like I saw the numbers and you know it's very hard to pass out there's something there like some level of respect you will get you know you're able to finish the degree how do you see uh the BS program for the students that are pursuing it cently I would say one thing okay think of it like any other BSC or BS program um do not associate yourself you know at all to college in super 30 I've seen two people fail interviews because of DSA only they were very good at web 3 but let's say the company asked DSA and then they so we had to start DSA classes then we saw no one here ised in DSA they're all here for Dev we stop DSA classes and then whatever referals are happening right now are happening purely based on dev should you do it interview you will need it thank you for making time for us so to begin with let me ask you something though what would you like to be a trist sir kirat or by yeah right I'll k so uh all of the students here are to saing the itm BS degree a remote degree uh I'd like to start off by setting the agenda that uh this won't be a Q&A session at all as much as we would love to have one with you but we want to just have a discussion for now uh being someone who is so uh into remote jobs remote structure the entire idea of remote looking at this uh particular degree and the students in this degree what would you suggest them like like I mean networking to important of course we have a lot of uh essential factors with networking uh you you keep speaking that uh networking is very crucial for students to do because that is the way to grow so what do you think uh for people pursuing this degree what kind of uh outlooks to should these people have for networking yeah that's a great question by the way can you hear me well I'm sorry yeah it's all it's totally fine cool uh great question I think especially for you guys considering it's an online degree you probably have to do it more than other people I don't super suggest this in campuses because you know in campuses you have on-site companies and that's part of part is sort of sorted of course not for a remote job but most other jobs you'll at least get a campus placement so you don't have to aggressively uh Network even though it's a very overused term networking um I think what that means over here is just being in small technical groups lead CTO Founders sometimes very technical events meetings toward Asia things like these rather than you know um know what the other way to network is um but long story short U for you guys considering it's an online degree I'm un sure what kind of placements you know um you guys can sit for at the end um and if the answer is you don't have an official placement thingy then it definitely makes a lot of sense remote job or otherwise for you guys to look out H I mean uh the the entire curriculum does have a you know placement cell industrial uh cell that does bring opportunities to students uh but the entire idea of you know placements is totally different for the people following this curriculum right and uh when we look at your videos you know it's all oriented towards corporate the corporate world networking through the corporate world climbing the ladder in a smart way and building your knowledge in a smart way but uh this entire degree deals with data and AI data science in AI mostly uh and this opens up opportunities for research more than corporate in the current world looking at the way these are AI is moving forward now uh considering the remote aspect and also the fact that research is a huge area of uh moving forward what do you look at uh research or corporate because there's a lot of things for us to look at through this degree so that's a tough choice um I have struggled with it uh half of not half of my batch like 20% of my batch went for Masters or phds I'm assuming that's what you mean by uh research so like it's a tough choice it's you earn first or you learn first is the question generally the idea first ear later whoever whichever of my friends have gone for a PhD or a masters in machine learning or AI are very well positioned for this upcoming bull to you know um Sprint past everyone else when it comes to not just monetary outcomes but the network the places they're at the people they're meeting the alpha they'll have in the next 10 years um so specifically in machine learning and yeah probably five years ago was the best time to go for a PhD today also not the worst time um anything else like cyber security or if you're just going you know for uh for a job in the US or for an H1B then these are tricky times uh because a lot of H1B holders are not uh getting jobs have to come back so on and so forth for ML if you get up basically you should go for it like that's research is great research is great for ML I'm I'm myself I'm an ml researcher as of now uh I work in ml in biomed data and uh you know medical side of applications uh when I look at it you know looking at your videos you yourself being someone having such a large fan base and you yourself having a lot of followers uh the guidance is very less the kind of uh there's no structured way of going through research at all uh there's there's a lack of structure there's a lack of hierarchy and I'm a True Believer of this you know if there is no hierarchy it leads to Anarchy that is what I that is what I believe in and the entire research area is totally H so uh when you yourself being someone so structured when you look at your videos it's always structured there's a pathway there's a road map or there's a laid out uh brain map for you and your and you have peers that you suggest to so looking at research and also applying that entire structured concept to it what do you think uh we should should we like stick to the structured concept that exists that has proven to be right or is there any other way to go ahead accordingly I think there's some some structure in research like you have to publish a lot of papers you have to have great cgpa try to go for an internship early find a good professor get in touch with them eventually your professor is going to you know get you in if you're looking at a Stanford or or a UBC so there's some structure there um there is also competition um because you know the structure is very well defined for folks at it Bombay Folks at it Bombay are you know probably the on-site people uh because a lot of these people are getting picked for internships from their second year itself going for you know University internships rather than corporates but there's some level of structure U that said uh of course it's fairly ad hog like in the end it's very hard to tell who got in how they got in um there's no examination that you're giving yeah but I would say you know like there's some level of luck involved and everything but the basic things you should check off like your cgpa needs to be really good some paper if you have published that's great and be in touch with professors if you want to get into uh UBC then make sure you know you know the best professor over there and makes sense I mean okay uh research there is a particular structure now assume that some person goes through all of the structured road map the basic structure that exists does well uh and is in a good position right now would you as a you know would you as someone who's a senior developer right now or a senior software engineer right now who's in CS would you hire someone into corporate research and if you would what kind of criteria would you look at uh for this person assume it's me and I'm into research what kind of criteria are you looking at as of now to hire someone and to corpor interesting so I've talked to a few Founders when this ml Rush came I was talking to Founders understanding who they're hiring for and tldr was they were avoiding researchers of course open a will hire you an anthropic will hire you all phds eventually land here only from the best but if you look at you know General startups building on top of llms um one they can't afford you because you know as an ml researcher you're probably going to make a mill at the very least from open AI so how would a startup that's a starting afford you one two they also might not need your expertise because they're not building at the foundation level they're not building llms they're building on top of LMS so all the companies that I am sort of involved with if I think about it even in web 3 rarely does any of my companies hire a blockchain researcher we work with companies uh who hire blockchain researchers for example if we want to get our contracts audited we'll hire and consult they'll charge us very heavily and they're working with they're hiring or usually are group of phds who are doing cryptography so you know you don't need a job long story short if you're going for research you know you people will pay you for you have value people will find a way to reach you and compensate you and you don't really need to stuck to the stick to the 50 40 hour week right you can provide value other ways to many companies compared to one but if you are looking for one there'll be an open AI or you know someone working who be happy to at least interview you if not hire makes sense makes total sense but there's this one thing that you said you know about startups that you've talked to a lot of startup people and uh you ask them about their ml engineer hiring uh that is another issue now that is a like every company has a a next to them now I mean if you enter Bangalore you'll probably run into someone in the Metro and you ask them what they're doing they'll tell you that they're having a company with a next to them so what should we look out for because as someone who is there who who are studying this data and AI uh when the Bull Run is actually happening when there's a proper hike in Ai and unsure as to what is going to happen in the near future uh what what need what do we need to look at because there's a lot of options out there we don't know which business is going to stand Which business is not going to stand and uh um being researchers or being let just say people who are into corporate how do we look at a company and say okay you know what this looks good I can be here interesting I think that's true not just for AI but generally high growth startups okay you can't judge which one's going to do well until they reach a Tipping Point for example by now you know GTO is probably going to do well zato is public profitable they're going to do well everything else is a gamble um specifically for you know high growth startups but you can look at their funding run Runway things like these and and usually bet on the founders if there are solid Founders one business guy one Tech Guy you can learn from them your worst Cas is you learn a lot from the company U your medium cases the company survives you get a salary your best Cas is the company does really well your Equity grows a lot so specifically for a companies as youve said a lot of B companies in Bangalore not all of them would require or you know most of them wouldn't probably require an AI engineer as I said most of them have delegated all AI things to uh either libraries or to llms they're not doing this in house it's referred uh but I think generally companies are looking for you know whatever that product needs let's take an example uh a good example of an something on top of llm might be what Zoom recently added you know meeting summarizers so they if they're building on top of llms their existing fullstack Engineers can build that specific problem now if they want to fine tune the model they want to bring the model in house bring the pricing down they'll probably negotiate with openi but in the worst case if they do want to build it in house is when they will hire you know a COR ml person but again probably you know contractually things like this so I don't know that answers your question of you know find I it does answer to it does answer my question more or less but it brings up a question you know being someone who's in the tech World for for like a decade or over a decade now I would say um why haven't you gone into the AI bulletin because you've been analyzing the market you've been into the you know economic and financial status of the market and I'm pretty sure you were aware of the fact that AI is going to eek because your your your circle specifically was pretty good I would say you were you were having a one of the top bunch at I right so what made you take a step back and look into web web 3 and you know blockchain I think not everyone from it is following one specific R if I'm honest uh if I'm being honest most of them are following you know trying to get into Fang um rarely of you are following you know hype markets like these and you know making sure they're making their way there it's either you go for a m or a PhD cryptography information security machine learning and then you eventually join the company there hope that the market has survived by then um or you know the market is doing well U or there are very few people like me who are you know changing markets left right and Center U for me uh why have I not done this I followed these markets for a while now for example web RTC followed by web3 I'm not saying I'm not following AI in fact recently I've joined you know U one of these a Rappers that's doing really well as a consult so not necessarily shying away from it that said U since I'm not working at the model there right I don't know I can't I can't extract as much value as I can being a core let's say smart contract writer because I probably have more value as a core smart contract engineer during the bear of the web three than a full stack engineer in AI during the bull so that's a high the learning curve of ml is fairly High compared to you know um let's say something like web3 orc resources are less very limited there's a circle of you know researchers which is why it's really good if you get in like that's sort of a filtering Benchmark for a lot of companies if You' have done you know some sort of research in machine learning unless you've done done that very hard to or you know compete with those people I mean yeah you make a point but uh why is it that if it's if it's so obvious that we need to get into research and if you do get into research that the pay will be absolutely amazing and you have a great future ahead even though this fact is established why is it that the market or the majority of the students in India struggle to find out the fact that okay I need to get into research I need to build my knowledge first work on uh you know cases which are compet which like ask me questions that I need to think in a unique manual for why is that this this mindset is not inculcated and I've been a follower of your videos since you were posting you know uh those sequential videos lectures so Le you had a proper pink and violet layout if you remember that three years ago I guess I've been following you since then and uh even when I look at your videos there haven't been a lot of talks with how research is uh you know giving you a lot of value uh so this entire culture is not inculcated in students and even from your point of view haven't really you know that path I mean it's a given that you are not into AI but why why is this factor missing what do you think it's a personal choice for people right uh for example when I was going for my masters I Accord to Tamu NYU one more Inu I forgot all of them were charging fairly High there was I had to take a loan for sure plus there was covid so there were a bunch of factors that made me not go there U it's not necessary everyone has to do research people can do well without it like entrepreneurship is one part being a engineer C someone is good part being an employe is also a great part and one uh there are a lot of factors that come to the picture like you have to be willing to bet on a market for 5 years for example I was talking to my one of my friends recently who did a PhD in computer vision he was telling me the problem statement I was working on U for five years after you know graduating from it bomb so 9ine years almost that problem statement can now probably be solved by llms so we were looking at it the wrong way we probably should have solved it a different way there's some risk that comes with u you know unless you love the problem deeply uh and you know want to follow it through don't care about mon outcomes as well considering you know if you're giving 9 years as a medical practitioner if you give 9 years you know there's a lot of monetary outcome at the end like infinite money at the end but that's not true for you know most research there's some money and if you do very well then it's more than it but I don't think this needs to be forced on everyone uh people are smart enough to you know figure out U whether or not they want to go into research also there are family situations sometimes you can't afford it if you go for a PhD also you know you're barely subsidized U so you're not living a super Lish lifestyle of course you can save some money um but if you look at your counterparts with working in fan you know they're probably making more there's a lot of uh compromise that you have to do initially uh which is not for everyone that's probably one of the reasons I did not go for it uh as I said I applied never applied for PhD honestly did apply for Masters nothing too specific computer science U goal was to move to the US honestly there's no other research well there a little bit of ml like one of my seniors who went for ML research in NYU is doing really well I started by uh ni company they raised like 80 mil if I did go to NYU he' probably you know be guiding me I was would be doing that that would have been a great part what I'm doing right now was a great part it's very hard to judge thankfully life is very single threaded so you know you don't know what would have happened if you went down the other part maybe my flight would have crashed what knows yeah everyone has like a personal choice yeah I mean I remember watching a video of yours and you mentioning the senior who was like into ML and you looked at him you talk to him and then you realized okay you know what the next buun is V3 and I'll get into that but uh don't you think the ml buun is still going on because that video came came out one year ago I guess this EML bullrun thing that you had with your senior that video came out one year ago or N9 months ago more or less and U your talk was like two years prior that or three years prior that I'd assume so you had that talk four years ago and ml buun is still going on I'd say it's at its peak and I can for sure say that it's going to be at its peak till 2026 so uh how long do you think this is going to run oh I can't predict that would be nice if I could but I there's sentiment shifts though right initially there was a lot of euphoria everyone was getting funded left right and Center now the companies that are getting funded are people who have found real use cases on top of AI who have real Revenue so when move towards business of course open has a metric all llm companies will do really well my talking about they're also building their own llm for companies that's why they're raising at whatever valuation they want but other than that you know um now the next set of value is going to AC or Investments are going to ACR to real businesses will build on top U so will it continue it will honestly the whole problem is whether or not you can find real use spes on top of these things blockchain be AI or you know something else um if you do then you know companies will do well I don't see ml going anywhere honestly it's much better much more sticky what's come out via LMS compared to what you know web3 sols or web RTC sols say so we'll see but of course this is going to do well for the next few years makes sense totally makes sense now uh you being a webc andb web web3 and also blockchain person your content is totally I mean it it it of course deals with uh these Technologies these Landscapes when we when we put out our link you know the link for registration to this and we put a small category saying ask your questions all of these students enrolled in this I madas degree make uh by making sure that they're going to be involved in data and AI okay but all of the questions or not all I mean 40% of the questions said uh is is this a good time to get into web3 is a good time to get into blockchain now these students mind you these students are in the remote degree and half of them are pursuing like two degrees like I am I go to an offline College in Hyderabad and then I do this simultaneously so it is through interest that they they took this in but they're still considering web 3 and you know blockchain because they are thorough Watchers of your content now what there's this fine line you know that you tread when you're a content creator that you should not misguide people you know uh you should not uh you know give the wrong uh idea to people and guide them through to an interest which they which they shouldn't probably look at of course number games number game is huge in India 15 LPA they set uh so when you post videos what kind of uh you know logic runs in your mind that okay I shouldn't probably put out the wrong agenda because these students are data science students and they're still giving questions like these so it's it's kind of a personal concern to be honest I think generally it's not just for your degree any degree people are interested towards course yes if you go to an IIT look at mechanical engineering people 50% 60% are taking coding jobs so it's not just that your degree has data science and people are looking at other CS options every degree you look at most people are looking at CS options getting placed in CS companies rarely are people you know actually taking core jobs um when you join a degree you're fairly young you don't know what you're getting into honestly uh when I was getting in I was struggling between it Bombay mechanical and RI CS pretty randomly I took RI CS but I know eventually I had CS was a good option I have core interest in CS it's also had a decent monetary outcome which might not have been the case at mechanical so if I join mechanical day still a very high probability I would wouldn't have done Justice to my degree would have gone for a CS job so I don't think there's anything bad around uh choosing a different path in CS or otherwise a lot of people in CS eventually become engineering managers PMS so on and so forth though it's very you're fairly young to decide I've done a data science degree so I have to stick to data science U I think it depends on a lot of factors including you know where do you think jobs are where do you think uh how long does it take to get a job how hyping the job is so on and so forth which is why people from all degrees flock towards CS not just this one uh how do I decide whether or not I'm misguiding people on YouTube I thankfully do not think about it uh all the videos that are coming out are pure natural what is happening in my life right now what I'm trying to build right now and I'm putting that out what kind of let's say money I'm making and putting that out U two people get influenced probably uh would that lead to a bad thing for people at it Madras uh data science degree considering that took a data science degree I don't know maybe so you guys should think before you know you decide looking at any content creator H if he's getting into X should I get into X or not do your own research and then you know decide based on that makes sense makes sense and you know the journey for like getting into Cs and also like into and film filming videos putting them on YouTube uh it it it was an exciting one clearly because I've seen you since you're what 55k follow 55k subscribers or something and early subscriber it so uh I'm sure the journey was like amazing and throughout this process I've seen you change your stance a lot of course I mean opinions change especially in the Cs landscape that is totally understandable now one of the most controversial opinion of course considering the Indian market is the DSA one there were videos saying DSA okay no and then videos saying okay DSA you know what maybe and then there's a super 30 now uh in the middle there was a thing saying okay you need to so all the I guess we got like 60 to 70 questions on this just just address that one one thing for like for a minute what do we do for DSA uh in super 30 I've seen two people fail interviews because of DSA only they were very good at web 3 but let's say the company asked DSA and then they so we had to start DSA classes then we saw no one here ised in DSA they're all here for death we stop DSA classes and then whatever referrals are happening right now are happening based purely based on dev should you do it there were interview where you will need it for example for me my very first remote job they asked fairly solid BSA also you guys are in college so you have a lot of time to explore you can do a bunch of things two degrees like you are I don't know why you're doing that you know you're not able to manage DSA but personally I've seen for example you good colleges people do ICPC good sort you know your DSA sorted for a while you have to practice before your interviews U for most the common answer is can do it it's just another two hours every day you have to give U and should not avoid it uh for extremely you know for example you you said you want to go into research so does it make any sense for you to do DSA probably not because similarly there are people who know I want a remote job a very high growth remote job where I get selected based on my skills and nothing else but then you know you don't need H I mean okay coming to the fact that I'm puring two degrees I realize them into data and math a bit too late my original degree deals with blockchain cyber security and IOD and uh I I study blockchain and cyber security daily while I you know go to college but it doesn't involve data and math so I'm not enjoying it as much so I thought you know what I'll just try this out and it worked out for me so I thought okay fine and then it led to research so I'm glad I took this decision uh moving forward though uh when you look at you know DSA there are a lot of Landscapes to look at but uh as someone who is into tech for so long and uh you must know that there will be newer technologies that are coming up for sure I mean it it is an analy cycle at this point is it essential for us to stay in the loop especially with with llms man I mean like every week we have a new announcement from from open AI every week every month we have a new announcement from Gemini anthropic comes up with something insane and then suddenly the CEO changes his drama so is this like uh should we keep up with this or should we just leave it all alone work on our Concepts you know do our research or do are corporate and move forward what do you suggest so so when you say should we focus on this do you say should we focus on the standard DSA or should we focus on the funding anoun yeah should we like focus on standard DS I mean that is again of course a personal opinion for sure but the kind of Bull Run that AI is in the kind of announcement that you're getting on it on a weekly or monthly basis it's insane I mean the growth is insane and if you look at the Nobel prizes that the people won I'm not sure if you're aware of this or not all three in maths physics and chemistry dealt with AI there were AI applications in their respective fields that that shows the kind of influence AI is going at right now and should we like keep up with the pace that AI is moving at is it important to keep it up because when you are in your youngest ages I'm sure there were Technologies which were coming up even in web development or web 3 or blockchain and were you keeping up with the latest you know technologies that were kept that were like bringing forward or did you just mind your own business short answer no I wasn't um there in it as I said there's a very standard what everyone is doing which back then at least was everyone was going to Google us uh everyone was following the path of getting to Google us that's where your invion was limited right there was some people Bombay has a culture of research thean was focusing on Research over there I would doubt they were also looking at funding announcements they were looking at CV uh you know computer vision papers that are coming out so on and so forth so the fancy funding announcements or you know who's getting hired whereare or llm came out um I think more than that smart people focus on what research underlying research is coming out U that will eventually maybe lead to something a better you know 10x outcome like llms did chat GPT something new for sure like everyone tries it and gets allowed what is that next thing that is coming I think most people are focusing there so rather than looking at you know funding announcements and these things if you want to go for research you should focus there research paper for me never did that honestly was going through the but nothing outside that had friends who had to go forar fair enough as much I was allowed to like keep talking to you I think uh over to you all right uh I will come in in a bit again uh hello hello [Music] sorry uh so uh we were talking about our uh curriculum so can you please uh give your review on our curriculum uh yeah yeah yeah I haven't gone through it yet well a little bit I did um looks like a lot of it is your your videos are just on YouTube and also in your Erp is what I could tell I looked at some of your YouTube videos uh it's decent like it's much better than you know traditional College honestly uh or you know whatever TI three colleges U is IT industry oriented probably like Pro again this is fairly relative but compared to other colleges it's decent U also I haven't looked too much into it so you know I'm not the best judge right now we have foundational course which talks about I mean which teaches about mathematics and statistics a little bit in um English also yeah and do we have a little bit of programming python so tell me this what when you when you say little bit of programming in Python how deep are we going here uh this is the foundational course which means it is like stepping stone it is like a basement so this just deals with everything in uh in a very very basic level so from there we are taking to I mean we are taking us in a diploma level which deals with programming completely so here we have pdsa dbms mad projects Java system commands and then uh there is also another diploma degree here which is for specifically called data science where we have six courses and two projects and other diploma also had two projects and six courses as you can seen so it deals with MLF uh machine learning is split into three different courses here foundations techniques and practice we also have a project on it and there is BDM uh here we actually go and talk to a business and do a project analyze your data give them some suggestions that kind of thing happens that is the project and how to do it is the course and uh business analytics and tools and data science are related to the same thing so and then comes the BS degree so here we have two parts we have to choose from this one or this one which is related to uh deep learning and Ai and the other is related to software and software testing engineering and testing so there are some elective courses me sorry I was scrolling too fast these are some some of the elective courses we can [Music] choose is it all right uh I've seen this before uh it's very good uh I mean compared to a different colleg is pretty good uh is there scope for improvement there always is uh but you know love it and and uh I think the bigger problem is this not just proof for you guys like in any college people are rarely learning anything from you know the whatever classes you learn from the community and the problem with you guys might be you guys mean don't meet enough because most people if you ask so you know that might be missing U cabus wise of course it is much better than you know what you would find in a traditional College people are sleeping in a traditional College you guys have an Erp just studying one day before the examination um which is also fun so it seems like you know whatever you guys are paying for you're getting some value from it you have you can learn from it are there better resources maybe for learning the same things from you know maybe yeah that's that's a high level but you know happy to dive deeper uh one thing uh there's a better question that I wanted to ask why um how do you see the BS program like after the promotion that uh she did how do you see uh the BS program for the students that are pursuing it I would say one thing think of it like any other BC or BS program um do not associate yourself you know at all to a colleagues and I say that to everyone even from go to it offline okay you know your degree is your people who the people that you found around you and you know who are now doing really Val because usually colleges if you look at a lot of coding YouTubers which are they from they're all from D because start follow what you guys should really look for is this you know people possible this is having similar outcomes at the out of ID Delhi so what is that thing that you guys are doing like or you're going to do Consulting will probably be the first aliz from from this online program um that's something we'll figure out in a few years U but is that possible in an online degree uh yeah I've seen your stats lot lot of people go to level two there's less you know pressure on you guys to graduate everyone passes together everyone very Clos net I'm seeing you the age Gap is fairly big and you know some are very lower going to level two are going to level three so it's a good experiment and you guys are you know the first batch probably one of the first batches will come out the experiment so I'm excited to see what comes out of it but yeah very early to tell okay you know whether it will be better than let's say you know a real it col what a real this a real it college but onsite I or onsite tier three or onsite tier say better time will yeah I just like to but in here I mean really resonated with with the point on College like bomb is going to research that he's going to entrepreneur um so a couple of points with the online degree obviously because it is online you don't meet people obviously the guys at Chennai few of them do this full-time so they they have a community they have a desha they have a i and Research Park they have a couple of professors they work with they have the entrepreneurship and they have the library of ss right um but that's not there for the people online so that's number one uh number two harking back to a point previously about how personing two degrees might be stupid I don't think it is because with with this with the online degree you get the tag of the stamp of IIT on your resume you get like a tier three college and the I on your resume as well as you get I mean you get the content but then you can get the content from other YouTubers as well but I think the major thing is uh first of all the stamp secondly like this Society this entire meeting we're doing today is is a part of this huge Community Driven effort to get people together otherwise 174 people on this call wouldn't be together if not for the society so I I just wanted to share a few thoughts I mean no no particular question at this point great point I think there's no downside if you can manage two degrees you should do it U my yeah yeah I agree because not not the worst idea in the world if if you're on tier three college but does it really give you you know the credibility of an i is my question it's very easy to get in that is that is exactly so I talked to a professor from Colombia and I put IIT on my resume uh so he thought I was actually offline IIT uh and then I'm like no it's on BC degree and we're doing it and it's but it's official and all I have ID card and it's like oh no you should put online on it so I I think message for the other 1 170 people there on the call I put a bracket online on it you know but I share a story here when Yash came to the office for the first time he was wearing an IT madas degree sorry t-shirt I was like cool it madas then he said and from online I like degrees associate fake it till you make it I think is the vi it'll hurt you really bad if you use fake it make it if you you know eventually someone realizes agre High L advice for people here speaking of uh you did mention about offline iatm I and online I uh we are doing it in online so we do have this kind of foro because uh most of the people here are either working or they are having their own ENT uh they are entrepreneurs and they have their own companies or uh they have dual degrees and I I have come across so many people and I myself uh I'm doing it as a standalone degree so we really feel foral and I not even in Chen so I feel very left out and I don't know uh how we should come come over this thing and uh we do want to become someone who is worthy of the name iidm so we are kind of in place where we don't know what to do and we do have some people to look up to but we're not sure how we are going to make it or it's kind of what should I say maybe cat and a all kind of situation here interesting so I think the phone that you're feeling is probably no different than someone from a tier three college or a tier 2 college would probably feel similar um how do you hold up to the it name I think one good thing that happens in this program is you know um the number of people who get out is really less like I saw the numbers and you know it's very hard to pass out there's something there like some level of respect you'll get if you know you're able to finish the degree uh so I wouldn't say it's you know completely uh someone would deny can you go to it Madras an online degree if you finished the it Madras degree considering I've looked at the stats I would respect you it's a hard degree to go through you know they Grill you really bad I know anyone can join but not everyone can graduate so that's one and two it goes away with time and years you know uh I did not make it to whatever in xyc but you should you should you guys should meet offline just say 174 people this happens on steroids when you're on campus you're every day having you know meetings like these smaller groups yeah yeah that is super important nothing else onl but if you if you filter out the smart people and put them together they 100 times better than taking smart people but keeping them in their houses so one thing you guys can figure out somehow consider your society and you know um you guys are saving a lot on your fees also so why not spend a little on meeting I don't know Goa meet up Bangalore meet up and you everyone sort of reaches them yeah that is happening actually but uh it's not that everyone can go and meet on the specific time in so there are some uh drawbacks one more thing by which I wanted to ask is um um which I wanted to convey is that to all the people um one of my cousin was watching anime okay so I told him that oh you are watching cartoon so I I did that because I wanted to see the reaction so see U here's the agenda If he if he wants you know uh to prove that anime is not a cartoon he will be in the aggression or he will be in Lost Sensation that no no it's not a cartoon thing it's a anime or it's a different kind of class but he was not about that okay uh he said that okay no worries uh it's it's a cartoon for you it's a anime for me let's be Let's uh you know accept that so here's this thing for all the online people who are you know in the it Madras if you are know defending that I'm I'm in know online you are doing the wrong things on the on that step itself what's your call on this yeah I mean be Elling towards it bro like someone saying let them say I mean if someone is taking out the time and beting your degree or spending two minutes thinking it any ITB let them be people will say whatever want what difference will it make in your Liv arguing with them or agreeing with them we can do it as about that so um we cannot let like people openly ask because so guys like we got your questions We shortlisted Them Say set them into proper questions so we'll be asking soon since you have only like 12 more minutes we'll we'll get can I ask something not really please uh try to like you know keep it contained we have your questions here don't worry we'll cover everything which is which is repeated which was important so sh start so uh so the first question is there are two categories here so uh first category is people who are who are knowledgeable I mean they do have some coding uh knowledge but they don't have any formal degree in the coding aspect as not they not from the computers background so they want to get into Tech and the other situation is that there are people who don't have any work experience they are from uh Tire three college and they have a age Gap and they are doing this degree and they want to get into Tech so what advice will you give for these two category of people you're saying most people here are in these two categories madas this degree is not going to help you too much help you crack some prerequisits in a Google or somewhere else you need to work extremely hard on your skills you anything you work really hard and do DSA Dev and get really good at it and second choice is you get into a degree and chill you take the first one to that less paid or free thing of looking at a lot of videos and working really hard should be your goal that's 99% of the effort a degree will help you 1% here are some prerequisites and sure I'm sure there are placements and other things that you get from you this needs to be done even more for people are from nonch makes sense I mean yeah that totally makes sense I mean the next question though uh people most of the responses were were likey most of them are in the first year offline College Med dual degree people uh they're like okay there are multiple Pathways for me to look at they came into this thinking key half of them came into thinking madas well enough good enough for me but now they're like okay there are hackathons there's compet programming and then there is you know increasing my knowledge in data or AI should I like go into research as I asked and uh when you are already occupied with two degrees one offline one online and there's a lot of things laid out for you what is your suggestion like like is there any other option that you can suggest colle course have to manage a lot of things U yeah to drop out from one would be first advice U I don't think I mean unless you find something very good in your degree I don't know um but within a year figure out this one makes more sense for me and and you know probably because handling academics handing making sure you're passing through your examinations considering it's so hard you'll spend all of your time there only and what with what final outcome um is that really worth it maybe I don't know man I mean everyone has their own situation so think about it I I think you have to spend a lot of time working hard yourself on things that are happening in the industry which is most probably not being taught in your col makes sense now the next question though uh do you think decentralizing AI is possible from like a blockchain perspective out of honestly I mean this is no can try lot of people have tried it lot of somec money there but no one has been able to figure it out I think web AI exists very well on web2 traditional systems web3 is all something else merging them people have tried no sticky use case until now no stick use Cas until now I mean would you suggest people exploring though like your personal suggestion no makes sense now uh so many questions and I mean it so many questions asked about chok it is the Talk of the Town right now in CS for all the tech people and uh it is it goes without saying most of J is for web developers people with JS skills or like you know Java now dealing with data and AI most of the people like here what is your advice for people for G in data and specifically so many questions on yeah generally I would say don't stick too much to a degree as I said don't sck yourself you should look at standard things that you know lead to sometimes research outcomes sometimes ICPC sometimes D sometimes a Google job sometimes a startup job sometimes open source so said most of the companies uh do come in web def python JavaScript Java the three common stacks and this is look at college and judge it the best way to Jud iture um so you guys should do it you know you'll probably as I said be the first ones full pioneer when I was at it RI there used to be five people or six people who got into G by the time I graduated we did 42 we were the highest college you know doing G you should do that next madas online is 50 selection you have so many people but you know the real people you have to figure out what the bestes andus that makes that makes sense I mean conc on the standard stuff to while moving forward with your own with your own uh things so guys to a suggestion by the man himself make sure that you Explore More don't restrain yourself to data and AI sounds good anything else sounds good that's that's pretty much it yeah thank you thank you so much congratulations [Music] here"}], "Stanford CS236: Deep Generative Models I 2023 I Lecture 3 - Autoregressive Models": [{"content": "all right so let's get started the plan for today is to talk about Auto regressive models which is going to be the first uh type of first family of uh generative models uh that we're going to uh consider in the class this is the kind of technology behind large language models things like CH GPT um so yeah just as a recap uh remember sort of like this high level overview whenever you want to train a generative model you need data so samples from some IID unknown probability distribution P data and then uh you need to define a model family which is going to be a set of probability distributions uh over the same space over which you know your data is defined mind and uh these probability distributions are typically parameterized somehow um for example using uh it could be conditional probability tables in the case of a ban Network as we have seen in the in the last lecture for the most part we're going to be thinking about probability distributions that are defined in terms of neural networks so you can think of theta there in that picture as being kind of like the parameters of uh the neural network that you're going to use to define Define this probability distribution and then you're going to Define some sort of notion of similarity or Divergence between the data distribution and your model distribution and then we're going to try to optimize the parameters of the neural network to make your model distribution as close as possible to the data distribution uh the caveat being that you only have access to samples from the data distribution right so you don't know you can't evaluate the probability of an image under the data distribution the only thing you have access to a bunch of samples and uh once you have this probability distribution then you can do several things you can sample from it uh so you can choose a vector x with probability uh you know there's many different axes that you could choose from each one of them is assign a probability by your model and you can choose one uh with the the probability uh according to this probability distribution you samples from it uh and this is what you need to generate new data uh we're going to be interested in evaluating probabilities um for several reasons one is that evaluating probabilities is useful for training the models so if somehow you have a way of figuring out How likely is any particular image according to your model then that gives you a pretty natural way of training the model kind of like solving this optimization problem of trying to find the point that is close as possible to the data distribution and one way to do that is to just do maximum likelihood you can try to find the parameters of your model that maximize the probability of observing a particular data set the other thing you can do if you have access to probabilities is you can do things like anomaly detection so you can given an input you can see you know is this input likely or not so kind of like but we discussed in the last lecture one advantage of generative models compared to discriminative models is that you can reason about the possible inputs that you have that you might be given access to so you might for example try to detect adversarial examples uh because perhaps you know they they are different from the kind of like natural images that you've used for training your model and so if your generative model is good you might be able to identify that something is odd about a particular input maybe the likelihood is lower than it should be and so you can say okay this is this is perhaps an anomaly maybe I should I shouldn't I shouldn't be very confident about the kind of decisions uh or the kind of predictions that I make about this particular data point and as we discussed another thing you can do is potentially on supervised representation learning uh and so in order to do well uh at learning a good a good approximation of the data distribution you often need to understand the structure of the data and so in some cases uh it's going to be a little bit tricky for auto regressive models which is what we're going to talk about today but for other types of model models is going to be pretty natural there's going to be a pretty natural way of extracting features um as a byproduct basically of training a good generative model so the first question uh is kind of like how to represent this proability distributions uh so how do you define this set in a meaningful way and today we're going to talk about Auto regressive models right which are built on the idea of using chain rule essentially and uh next we're going to talk about how to learn it so recall that U there is this General result that you can take any probability distribution Define over a arbitrary large number of variables n and you can always Factor it as a product of conditionals so if you have four random variables X1 through X4 uh you can always write it down as the probability of X1 the probability of X2 given X1 and so forth and uh this is just fully General you don't to you don't need to make any assumptions on the on the distribution every distribution can be factorized this way exactly and in particular you can also use any ordering you want so in this case I'm factorizing it based on the ordering X1 X2 X3 and X4 but you could choose a different ordering so you could decide you could write it down as the probability of X4 times the probability of x3 given X4 and so forth and here you start to see that yeah in general you can always do it but perhaps some orderings might be better than others um so if there is some kind of like natural causal structure in the data then perhaps modeling the data along that direction is easier but chain rule doesn't care it works regardless of whatever ordering you you you're going to use uh baset essentially exploit this uh this idea and uh they make progress by basically simplifying these conditionals so we've seen that in general representing even when the random variables are discrete representing those conditionals as staes doesn't scale doesn't work and so B net ban networks essentially make some kind of conditional Independence assumption they assume the certain things are conditional independent from other things and uh and then that gives you potential simpler factors that you can represent as tables and the other way to go about it is to use a neural model well instead where instead uh you're going to give up on the tabular representations it's no longer a lookup table now it's going to be some kind of function parameterized by a neural network that you're going to use to uh map different kind of uh assignments to the variables you're conditioning on to parameters uh for the conditional distribution over the the the the next variable in this ordering that you're using so in this kind of neural models what we're going to do is we're going to start from chain Rule and then we're going to try to approximate the true conditionals uh using neural networks and this works to the extent that the neural network is sufficiently powerful that it can well approximate the conditional probabilities which could be potentially very complicated if you think about those as tables there could be really complicated relationships between the entries in the table and this kind of factorization using neural models Works to the extent that the neural network is sufficiently flexible that it can capture the structure of what you would get if you had a you know a fully General tabular representation and uh the good news is that uh efficiently deep neural network can in principle approximate any function and so that's kind of like where the magic of deep learning comes in if you can use very deep neural networks there's a good chance you might be able to actually come up with a decent approximation to these conditionals and that's why this these models tend to tend to work in practice so remember that you know the the Machinery we're going to use is going to be the same as the one you use using regular let's say classification so you want to predict a binary label give it a bunch of input features uh you just care about the conditional distribution of a single variable given a potentially large number of other variables but the important thing is that you're just trying to predict one thing at a time a single variable Y and so you can use things like logistic regression or Ral networks to do this kind of things and uh in particular we've seen that logistic regression is kind of like assuming a relatively simple dependency between the values of the covariates x or the features that you're conditioning on and the conditional probability of Y given X it's basically assuming that there is a linear dependency that then is fed through a sigmoid uh to get a a non- negative number that has the right kind of like normalization and uh you can make things more flexible by assuming some kind of nonlinear dependence and there that's where you use NE networks right so you can take your inputs act you can transform them by applying linear Transformations nonlinearities you can stack them in any way you want and then at the end of the day you still have some sort of transformation that gives you the parameters of this conditional distribution over what you're trying to predict given what you have access to and so maybe at the end you use a some kind of sigmoid function or a soft Max function to to basically normalize the the output to a probability distribution so it's more flexible you have more parameters which is good because the model you know you can capture a richer set of dependencies between the variables the price you pay is that you have more parameters to learn you need more memory and you might imagine that you might need more data uh cool so that's the building block and then basically the whole idea what Progressive models is that once you know how to predict one thing using a neural network you can kind of like combine them and you can always think of a high dimensional output let's say uh an image as a number of individual components and chain rule gives you a way of predicting individual components given the the previous ones and so then you can plug in your neural network to get a generative model and that's what neural Auto regressive models do right so for example uh let's say that you wanted to learn a generative model over images so just for Simplicity let's say that you wanted to work with a binarized mnist so mnist is kind of like a classic data set of handwritten digits um so that if you binarize them so that every pixel is either zero or one black or white um then they might look like this so you see that they kind of like look like handwritten digits and each image has uh 28x 28 pixels so you have 28 * 28 random variables to model and uh the variables are binary 0 1 Black or White and the goal is to basically learn a probability distribution over these 784 random variables uh such that uh you know when you sample from it they that you get hopefully look like the ones that you have in the training set or that in other words you're hoping that the distribution that you learn is a good approximation to the data distribution uh that generated these samples IID independent identically distributed samples that you have access to in the training set and again this is challenging because there's a lot of possible images you need to be able to assign a probability to each one of them and so uh recall the recipe is uh you define a family of probability distributions parameterized by Theta which we're going to see in this lecture and then you define some kind of learning objective to search over the parameter space to do some kind of optimization reduce the learning problem to optimization over Theta over the parameters that Define the distribution to try to find a good approximation of the data distribution which is going to be the next lecture uh so the way to use an auto regressive model to Define this probability distribution is you first need to pick an ordering so remember if you want to use chain rule you have to pick an ordering and for an image is not even obvious what the ordering should be um there is not an obvious kind of causal structure like you're not modeling a Time series where you might expect that you know there is some causal structure and maybe predicting the future the past is easier than going backwards but any ordering Works in principle and so for example you can take a raster scan ordering and so you can go from um top left to bottom right you can order the 784 pixels that way and then you can apply chain rule to this probability distribution and so you always you know that without loss of generality there's always a way to write down this distribution that way basically as the probability of choosing an arbitrary value for the first random variable then choosing a value for the second given the first and so forth and so that's how you break down a generative modeling problem that is tricky to a sequence a small number of classification regression something we know how to handle each one of these conditionals is only over a single random variable and that's the kind of setting you know how to deal with from or you typically consider when you think about classification regression those kind of problems and uh you know uh you cannot do tabular form so a ban network is is out of the question here and so instead we're going to try to basically model these conditionals using some kind of like neural model some kind of functional form that will allow us to map the different config figurations of the pixels we're conditioning on to a probability distribution or the next pixel that we need to to work with in this particular ordering that we've Chosen and uh so in particular I mean if you think about the first uh probability distribution you know you can represent it as a conditional probability table that's just a you know binary random variable you just need one parameter for that so that's why I'm saying pcpt here means that you can actually store that one set cly uh but the other ones become complicated and so you kind of have to make some sort of approximation and one simple thing you can do is to just lose logistic regression so you can try to use logistic regression to basically predict the next pixel given the previous pixels and that gives you a generative model basically and uh if you do that notice that you don't have a single classification problem you have a a sequence of classification problems like you need to be able to predict the second pixel given the first one you need to be able to predict the third pixel given the first two you need to be able to predict the last pixel the one in the bottom right given everything else so all these classification problems are basically different and separate do you even have a different number of covariates or or or Fe variables that you're conditioning on and so in general you're going to you can potentially use different parameters different models for each one of them and this is kind of like what I'm alluding here there is a different Vector of coefficients Alpha for your logistic regression model for each classification problem and uh so more explicitly for example you would have the first uh prior distribution over the first pixel which is just a single number it tells you how often do you choose the first pixel to be white versus black so if you think about the structure of these images you know the top this pixel here the top left is almost always black so you probably would want to choose this number to be to be close to zero assuming zero means black sort of like you want that pixel to be often black uh and then uh you know you need to be able to specify a way of predicting the first pix the second pixel again the first one and you can do it using a simple logistic regression model and and so forth right and uh that you know that's a modeling assumption whether or not this type of generative model works well depends on whether or not it's easy to predict the value of a pixel given the previous ones in this particular arbitrary order that I've chosen for the pixels and uh you know whether this works again depends on how how good this this how good this approximation is so it might work well or it might not work well because maybe these dependencies are too simple maybe regardless of how you choose this Alphas there is not a good way of figuring out how you should choose the the value whether or not a pixel is white or black in this case and uh but you can think of it as an AO regressive model and that's what because essentially what you're doing is you're trying to regress you're trying to predict the the data PA the structure of the data itself right so uh you're regressing on yourself like you're trying to predict parts of each of each data point given other parts of the data point and uh that's you know this kind of a modeling assumption has been tried before um this kind of model is called a fully visible sigmoid belief Network it's kind of like a relatively simple uh early type of generative model that as we will see is not going to work particularly well but it's kind of like useful to to work it through so that you get a certain level of understanding of exactly what it means to model a joint distribution in terms of a simple kind of like classification models so when you think about what we're doing here when you think about chain rule uh we have all these individual pixels that we're modeling conditionally and all the ones that come before it in the order and so when you model the probability of XI given all the variables that come before it in the ordering let's say using a logistic regression model uh you know you're basically outputting the conditional probability of the pixel being on or off given what you've given the values of the previous pixels and uh we're often going to denote this using this symbol here x minus I smaller than I uh which basically means given all the indexes I that are strictly smaller than than all the indexes J that are strictly smaller than I and uh which you know in the case of logistic regression that conditional probability is given by this relatively simple expression linear combination and then you pass it through a sigmoid now how would you evaluate you know if somebody gives you a data point and you want to know How likely is this data point according to my model which is the kind of computation you would have to do if you want to train a model by maximum likelihood how would you how would you evaluate that joint probability given that somehow you have all these values for for Alpha so what you would have to do is you would have go back to back to chain Ru so you will basically just multiply together all these factors and so more specifically you know the the first pixel X1 will have a value well I guess here I have an example with the let's say imagine that you only have four pixels uh there's four random variable and let's say that we are observing the value Z one one zero um then you basically need to multiply together uh all these values which are basically the predicted probability that a pixel takes a particular value given the others and these predicted probabilities depend on the values of the previous pixels in the ordering right and so they depend on so X hat I which is the predicted probability for the I pixel depends on all the pixels that come before it in the ordering so a little bit more explicitly it would look something like this um where you would have to compute the conditional probability of the second pixel when the first pixel is zero you would have to compute the conditional probability of the third pixel being let's say on in this case given that the previous two are zero and one and so forth and then you would basically replace that expression here for xat with the standard sigmoid logistic function thing and that would give you the the number how would you sample from this distribution so let's say that somehow you've trained a model and now you want to generate images according to this model the good thing about an autoregressive model is that you can basically it also gives you a recipe to sample from it like in general it might not be obvious how you do this like okay you have a recipe to evaluate how like different samples are but then how do you pick one with the right probability right so would you randomly generate one image probability and then do some sort of rejection sampling you could do things like that uh that seems you could use generic kind of like inference schemes if you have a way of evaluating probabilities you could try to you even brute force and kind of like invert the CDF and try to do something uh something like that that of course would never scale in to to the situation where you have hundreds of random variables the good news is that you can basically do it you can use chain rule again and kind of like decide the values of the pixels one by one so what you would do is we know what is the prior essentially probability that the first pixel is on or off and we can just pick a value for the first pixel now once we know the value of the first pixel we know how to figure out a value for probabilistically for the second pixel so we can plug it into the previous expression you could do you know something like this just to be very pedantic you have there's some prior probability and perhaps you always choose it to be black because all the images are like that but then you pick a value and then you basically sample the second random variable given the conditional distribution and this conditional distribution you can get the parameter by fitting it by using this expression so the the logistic regression model will try to predict the second pixel given the first one and uh you're going to get a number from this and then you can sample from it then you can pick you know you're generating two you have two pixels now that you've chosen values for then you can fit it to the next logistic regression model and you can keep generating the image one pixel at a time so that's the recipe and and it's good news because uh you know sampling is to some extent uh easy I mean it's uh not great because you have to sequentially go through every random variable that you're that you're working with but it's better than Alternatives like having to run out you know using Marco chain mon Carlo methods or other more complicated techniques that we might have to resort to for other classes of models the good news is that for these kind of models sampling is relatively is relatively easy conditional sampling might not be so if you wanted to sample pixel values uh based on you know if you wanted to do in painting because you have some you already have a piece of the image you want to generate the rest depending on what you know about the image it might be easy or it might be hard so it's not straightforward the fact that you can do this efficiently is a nice benefit of these type of models okay now how many parameters do we have so you know we have a bunch of alpha vectors these Alpha vectors have different lengths because there are different they are logistical regression models of different sizes basically any guess like for this model that's say two parameters and this one three and then four then five it's uh in n squ like it's n squ one plus roughly n squ right so you know potentially not great but maybe manageable cool now as as I kind of mentioned before this doesn't actually work particularly well so now I don't have the results on Mist but if you train it on this data set of uh the CCH 101 so the samples are on the left and you can see that they kind of have shapes like there is like objects of different types and then uh you know you can kind of train this simple model based on logistic regression classifiers then you can sample from it and you get this kind of blobs so not great and the reason is that basically the logistic aggression model is not sufficiently powerful to describe this potentially relatively complicated dependencies that you have on the pixel values so how can we make things more comp better let's use a deeper neural network right that's the that's the natural thing to do um when and if you do that you get a model that is called n Neo regressive density estimation and the simplest thing you can do is just use a single layer Neal Network to replace the logistic regression classifier and so what would it look like uh basically what you do is for every uh index I so for every pixel you take all the previous pixel values and you pass them through uh first a linear layer then some nonlinearity and then uh uh you pass the nonlinearity um what you get these features this vectors that you get through a logistic regression final output layer that would give you the the parameters of this B random variable so it will tell you how whether or not what is the probability that the I pixel is on or off and as you can see now we have a slightly more flexible model because uh you don't just have the alphas the parameters of the logistic regression classifier of the final layer of the network but now you also have the the first layer so you have a slightly more flexible model and uh and so it would look something like this so you would uh and again the issue here is that you you know you have if have n random variables you have n separate kind of classification problems and so in general you would you could use completely sort of like decoupled models and so the first model would have let say a single uh input X1 and so the the shape of this Matrix would be just a column Vector basically and then if you have two inputs X1 and X2 to predict the third pixel then this Matrix would have two columns essentially and and so forth and uh yeah do we have Sig like why do we have a Sig over H and then Sig over like the second Sigma makes sense but why do we have a sigma for H I don't think don't necessarily have it to have it it's just yeah here I'm having an external linearity there but yeah you don't necessarily need it yeah if you don't have that Sig wouldn't just lar layer yeah so it's better to have linearity yeah but you know this is just for illustration purposes you could imagine different architectures different doesn't have to be a sigmoid could be a Ru could be other things it's just yeah um so over here you have three rows in your a matrix like are we trying to predict three separate features for why I thought it was just one probility um I have oh I see what you mean so this is just like the there's basically a hidden Vector H which could have it's not necessarily a scalar that hidden Vector is then passed to a logistic regression classifier and so it's then mapped down to a scalar through this uh expression here which might be so there's a DOT product there right and so this you know in principle all works but you can kind of see the issue is that you are basically we're separately training different models for every pixel which doesn't seem great perhaps there is some common structure at the end of the day we're kind of like solving related problems we're kind of like trying to predict a pixel given part of an image given another given the previous part of the image and so there might be opportunity for doing something slightly better by tying the weights to reduce the number of parameters and as a by product speed up the computation and so what you can do here is you can basically tie together all these matrices A2 A3 A4 that you would have if you were to think of them as separate uh classification problems what you can do is you can basically just have a single Matrix and then you kind of like tie together uh all this uh the the weights that you use in the prediction Problems by basically selecting the corresponding slice of some bigger Matrix right so before we had this the first Matrix that we used to call A2 and then A3 and then A4 and they were completely you know decoupled you could choose any values you want for the entries of those matrices what you can do here is you can basically choose the first row the First Column to take some uh set of values and then you're going to use that for all the subsequent kind of like classification problems so you're equivalently kind of like trying to extract the same features about the first about X1 and then you're kind of like going to use them uh throughout all the classification problems that you have in the in the you know when you're trying to model the full image yeah um is reducing overfitting also motivation for this yeah so the question is reducing over over is you know overfitting also potentially a concern yeah reducing the number of parameters is also good uh for uh overfitting issues tying together the classification problems might be good uh you might learn a better solution that generalizes better and as we see it also makes it faster I'm curious like empirically it makes more sense to invert your X's you're saying like you always depend the same way based off the last thing you predict instead of like saying the n term should have the same weight for X1 for example uh what's the suggestion sorry I didn't quite so I guess over here we're always multiplying the first W1 X1 W1 X1 for every single x i we're predicting instead of that would it make more sense to invert your X's so that W1 looks at X IUS one W2 looks at X IUS 2 and so on and so forth you're just looking at one preceding entry two preceding entries and so on oh that could also work yeah that's a different kind of parameterization that is more like a convolutional kind of thing I would say that we're going to talk about that too this is what they did in this particular model a question about notation what is the w dot uh comma smaller than 9 mean what is the DOT it's just D Matrix yeah I don't think yeah probably didn't need to dot or I guess it means the piece of a bigger Matrix I think that was the intended notation but yeah you got the idea sure uh and the good news is that this can reduce the number of parameters so if you have size d uh for this hidden Vector H that you're using to uh make the predictions how many parameters do you need 2 * uh it's not longer quadratic in N that's the kind of big takeaway before we had something that was quadratic in N uh now it's basically linear because there's b a single Matrix that you have to store and then you canate reuse it all the time right um so that's good um now the other advantage that you have with this kind of model is that you can evaluate probabilities more efficiently uh because basically whenever you go remember if you want to evaluate the probability of a data point you have to evaluate all these conditionals so you have to go through every conditional and you basically have to evaluate the kind of computation if there is no structure on the matrices and you have to redo the computation because there is no nothing shared but if you have some sh shared structure and you can kind of like reuse the computation so if you've already computed this dot product this product here this Matrix Vector product here and then if you are adding an extra uh column then you you can reuse the computation that you've done before you can just add in an extra call is the is factor C also shared amongst all the hidden layers yeah I guess it could be or it doesn't have to be I think you could you could make it either way yeah I think I actually forgot to because it didn't fit but yeah you would have there should be a c and you could change it yeah are the um W columns like updated in each step so like in the fourth step here it also updates the first and and second column uh what do you mean update like minus setting was with the weight Matrix you basically you build it um column by column and but you try to learn right like over seeing like many examples so I was wondering like as a model learns it basically updates also in every step all the previous columns that it has learned right yeah yeah yeah so it's all tied together and then we haven't talked about how you would do learning but yeah so then you can see that kind of like the First Column matters for all the prediction tasks so you would be able to learn it you would get some signal from every sing learning problem yeah yeah yeah just to clarify um in this model you are sharing weights uh right yeah and does that uh imply any like assumptions you're making about the data you're looking at there is an assumption again you're kind of saying that these conditional probability tables we could could be arbitrary somehow can be captured by prediction models that have this sort of structure uh so somehow that there is some relationship between the way you would predict one pixel different pixels in an image whether or not it's reasonable it's it's it becomes an empirical question uh I think I have the results here and it tends to work significantly better than let's say uh the previous logistic regression model so it does seem like this kind of structure helps modeling natural images or toy kind of images like amist um and so here you can see some examples you have amist binarize the oh no actually I don't have I don't have the samples from here what you have here is samples from the model train on Mist on the left and the conditional probabilities corresponding to the samples on the right so remember that when you generate samples Auto regressively you actually get probabilities for each pixel given the previous ones and then you sample from them to generate to actually pick a value and so the images on the left are binary 01 the images on the right are kind of soft because for every pixel you got a number between 0o and one that then you sample from to generate a color in this case 01 and so you can see they kind of look a little bit better because they are a little bit more soft but that you can see that it's doing a reasonable job at capturing the the structure of these images what are the numbers on the like on right uh on the right a table look just almost exactly like that one why aren they why don't they just create some variation I mean some other kind of they are so the numbers are corresponding to the to the samples that you see so basically what this is saying is that what what you would actually do when you sample is you would take the first pixel you have a probability then you plot it on the right then you sample a value from that on the left then you go based on that value based on the actual binary value you come up with a probability for the second pixel which is just a number between Z and one you plot it on the Right image then you sample from it and you keep going so the right is notes doesn't come from like the things what factor learning yeah yeah it does it does so it's basically these numbers the predicted probabilities for every pixel which are the X at I so the probability that that pixel is on or off and then but they are matching so that's why look the same because the sample that you see on the left is what you get by by sampling from those distributions yeah I am noticing that like it is agnostic of what the label should be is that like the right call to make for Generation so the question is should we take advantage of the fact that maybe we have labels for the data set and so we know that you know there is different types of digits that there is maybe 10 digits and then we want to uh you know take advantage of that so here I'm assuming that we don't have access to the the label why if you had access to the label y you could imagine trying to learn a joint distribution between X and Y and perhaps you would get a better model or perhaps you can assume you don't have that kind of structure you just learn a model and you can kind of try to use the model to see whether it indeed figured out that there are 10 clusters of data points and that you know there's a bunch of data points that kind of have this shape of a that look like a c kind of like an oval and that's a zero and that's the kind of third point of how do you get features out of these models like presumably if you have a model that can generate digits that have the right structure and it generates them in the right proportions it has learned something about the structure of the images and what they have in common and so that was kind of like the third point of getting features and supervis learning we'll talk about how to do that but uh yeah there's two ways to see it you can either do it unsupervised or if you have access to the label then perhaps you can include it into into the model you can do conditional generation or you can jointly learn a distribution over X and Y yeah so in this case when you sample you can get any one of the 10 digits well if the model does well yes uh you know for example you to check whether the model is doing a good job you could try to see what is the proportion like if in the original training set all the images come they're uniformly you know you see an equal proportion of the different digits then you apply an Mist classifier to your samples and you can see does it generate uh digits in the right proportion if it doesn't then there's probably something wrong with the model if it does it's doing something right whether it's correct or not it's it's it's hard to say so like here it seems like you're injecting the stronger prior into the model so if you had an infinite data set would you expect the original approach to per better than this one meaning the that one's less structure imposed by us right so the representation it should learn should theoretically be richer that one is actually more structure like you're imposing like you have less parameters is less flexible uh if you had infinite data and infinite compute the best thing would be conditional probability tables ban Network that one would be able to in principle capture any relationship with infinite data you would be able to learn that table that would give you perfect module overfitting I mean but if you have infinite data you don't have to worry about that either uh something so on the left picture is the the actual samples generated from the model the right is we somehow code the conditional probabilities into a scale yeah just between zero one like the conditional probabilities would be numbers in between zero and one and it's just the gray scale yeah cool so that's the N um now you might wonder what do you do if you want to model uh color images let's say so if uh the B the variables are no longer binary but if they can take let's say k different values how do you maybe pixel intensi is ranging from 0 to 255 how do you do it now what you need to do is the output of the model has to be a categorical distribution over however many different values the random variables can take so you can basically do the same thing you first get this kind of hidden vector or latent representation H and then you instead of applying some kind of mapping it down to just the the parameters of a berol random variable you can use some kind of soft Max output layer to map it down to a vector of um if you have K different outputs that you care about a vector of K probabilities uh Pi i1 through p i k which basically would represent the probability that the I random variable should take one of the K different values that the random variable can take and uh that's the natural generalization of the sigmoid function we had before it's just one way to take K uh numbers which are not necessarily non- negative and they might not be normalized and it's just a way to normalize them so that they they become uh a valid probability distribution so specifically you just do something like this if you have a vector or arbitrary numbers you apply the soft Max operation it produces another Vector you apply an exponential to every component to make sure it's not negative and then you divide by the sum of these exponentials which is basically making sure that uh the entries are normalized so that it's if you sum the probabilities of all the possible things that can happen you get one and uh so natural generalization of what we had before now you might wonder what do you do if you want to model continuous data so maybe you have you're dealing with speech and it's more n it's not very natural to discretize the the I mean even for images perhaps you don't want to discretise the the random variables and you want to model them as continuous random variables so the solution is basically again use the same architecture but now the output of the neural network will be the parameters of some continuous distribution so it's no longer the parameter of a ber the parameters of a categorical it could be the parameters of a gaussian or a logistic or some U continuous probability density function that you think should work well for your data set and so for example one thing you could do is you could use a mixture of K Gauss so what you have to do is you need to make sure the output of your neural network gives you the parameters of K different GS uh which are then mixtured together let's say uniformly to obtain a relatively flexible kind of probability density function like you see here an example where there's three Gauss with different means and different standard deviations then you combine them together and you get a nice kind of GRE uh red curve where you're kind of allowed to move the probability mass and you're allowed to say maybe you know there is two different uh values that the random variable can take two modes one here and one here and you're allowed to move the probability Mass around by changing the mean and the standard deviation of the gut in this Cas have like 2 vales so I think I have the the the more precise thing here so you would say the conditional probability of XI given all the previous values is a mixture of K gos each one of them having a different mean and a different standard deviation and as usually you have to to basically use the neural network to get the parameters of this distribution so in this case as was suggested you could use the same trick and then as an output layer you can no longer use a soft Max or a sigmoid you have to use something else that gives you the parameters of these random variables and so you need 2K numbers you need K means and you need K standard deviations and you know the uh I guess you know you need to be careful about if you use depending on how you parameterize like if you parameterize a variance then has to be no negative but that's relatively easy to enforce okay now as a way to kind of like get a deeper understanding of what these kind of models do you might notice that they look a lot like out encoders like if you look at this kind of computation graph that I have here where you have the the data point X1 X2 and X3 and X4 that is been mapped to this predicted probability X1 hat X2 hat X3 hat and so forth it kind of looks a little bit like an out encoder where you take your input X and then you map it to some kind of predicted uh reconstruction of the input and so more specifically an out encoder is just a a model that is often used again in unsupervised learning it has two components it's an encoder takes a data point and Maps it to some kind of latent representation and then uh for example it could be again a simple neural networks a two layer net like this and then there is a decoder whose job is to try to invert this transformation and the job of the decoder is to take the output of the encoder and map it back to the original data point and uh you know in this case in this graph that I have here it could be another neural network that takes the output of the encoder and Maps it back to some reconstruction of the input and uh the loss function that you would use would be some kind of reconstruction loss so you would kind of like try to train the encoder and the decoder so that uh for every data point these kind of when you apply the decoder to the encoder you get back something close to the original data point so depending on whether the data is discreet or continues this could be something like a square loss where you try to make sure that at every coordinate your reconstructed I variable is close to the original one if you have discrete data it's more like does the model is the model doing a good job of predicting uh the value for the I uh let's say in this case it's binary here or the I random variable that I'm actually observing so if the I random variable is true is one is the model giving me a high probability for for the value one right not super important but kind of like this is how you would you would try to learn the decoder and the encoder so that they they they satisfy this condition and of course there is a trivial solution that is the identity mapping so if the uh encoder is just an identity function and the decoder is some identity function then you you do very well at this and it's not what you want typically so typically you would constrain the architecture somehow so that it cannot learn an identity function but that uh has kind of like the flavor of what we're doing uh with this sort of like Auto regressive models we're taking the data point and then we're trying to use parts of the data point to reconstruct itself or we fit it through these networks and then we output these predicted values and if you were to think about how you would train one of these models by let's say maximum likelihood you would get losses that are very similar to this you would want to you know if you were to train these logistic regression classifiers you would get something very similar to this where you would try to predict the value that you actually see in the in the data point I'm just trying to understand put it in coder decoder kind of mechanism is it uh is it the main point for encoder uh is just to kind of com uh compress all the previous informations into a very low dimensional kind of like is that the main yeah yeah so the question is why are what are out what are out encoders used for yes the the typical one typical use case would be to learn a compressed representation of the of the data somehow if you can do this you know maybe you force the output dimension of of the encoder to be small and then in order to do a good job at reconstruction it has to capture the key factors of variation in the data and so you can kind of think of it as some sort of like nonlinear PCA kind of thing that will try to discover uh structuring the data in an unsupervised way yeah can we do sampling when TR the the question is can we do sampling with an out encoder no an out encoder is not quite a generative model so these two things not quite the same but they are related and that's what we're going to see next um so yeah this was coming up you know typically you would train this to do representation learning try to find good representations uh what is exactly the you know if you think about kind of like what we just said now if you have an out encoder there is not it's not really a generative model like how do you generate data from an outter coder we just re but what's the input to the so the the suggestion is okay let's throw away the encoder let's just use the decoder what do you feed into the decoder to generate data some just handcrafted effect yeah that's the solution for a variational out encoder actually so the variational out encoder will be let's try to learn a simple generative model to feed inputs fake inputs to to your to your decoder uh and so you can kind of fake the the process and you can use it to generate so that's the variational out encoder solution I will talk about later but if you just have you know there's not an obvious way to generate the inputs to the decoder unless you have data but at that point you're not really sampling right could you like feable yeah that's the VA solution basically that we'll talk about yeah what if you like add a regularization term that for as your hidden representation to just look like a gausian or something like that yes so again that's the solution imposed by the that's basically a variational out encoder literally a variational out encoder is this plus what you suggested forcing the latent representations to be distributed according to a simple distribution a gausian and if that happens to work well then you can sample from that distribution fit the inputs to the to the decoder and that works but you know that requires a different kind of regularization the relationship here is that uh you know although this two things look similar it's not quite the same and the reason is that uh you know we cannot get a generative model from an out encoder because somehow we're not putting enough structure on this kind of computation graph and there is not an ordering remember that to get an auto regressive model we need an ordering mini chain rule so one way to actually get uh or to connect these two things is to enforce an ordering on the out encoder and if you do that you get back basically an auto regressive model and so basically if uh you're willing to put constraints on the weight matrices of these neural networks so that there is a corresponding basically evasion Network or or chain rule factorization then you can actually get an an outo regressive model from an out encoder and the idea is that basically if you think about it the issue is that we don't know what to fit to the decoder so somehow we need a way to generate the data sequentially to fit it into this decoder that we have access to and so one way to do it is to kind of like set up the computation graph so that the first reconstructed random variable does not depend on any of the inputs if that's the case then you can come up with the first output of this decoder yourself because you don't need any particular input to do that and then you can feed your predicted first random variable into then let's say that the you know at generation time then you don't need it now if you can it's fine if the predicted value for the second random variable depends on X1 that's fine because we can make up a value for X1 then we can fit it into the computation and we can predict a value for X2 then we can take this value we can take the first two fit them into the outter quar kind of thing and predict a value for X3 and we can keep going and it's the same thing as an auto regressive model so if you look at this kind of computation graph you can see that the predicted value for X1 depends on all the inputs in general and so you know if you look at the arrows all the inputs have an effect on the first predicted value and so that's a problem because we cannot get an auto regressive model if we do it that way but if we somehow mask the weights in the right way we can get an auto regressive model and then as a bonus then we have a single neural network that does the whole thing so it's not like before that we had the different classification models or that they were tied together somehow uh if uh we can do this then it's a single neural network that in a single forward pass can produce all the parameters that we need I was wondering in some tasks for example this digit task we earlier discussed um is there not a risk of the model learning just how to shift it by like one pixel or something uh not OB obvious that you can just shift because the I mean you're not you cannot cheat right so you cannot look at the next Pi they cannot you can only use there's gonna you have to pick an ordering and you have to predict yes but you can like begin with the L and then begin putting like the pixels to the left of it for example but what do you put you haven't seen them they haven't seen the right pixel so you don't know exactly what to copy right no no you do because like if we before order goes left right you will know what the uh pixel in the input image to the left of it is so you can just put that uh and you can draw like a black line on the left so like or I was wondering if or metric need to to like really prevent that from happening no you don't you don't need to prevent that from happening and partially it's because these B would then be trained by maximum likelihood so and that's a separate thing that we're going to talk about how to evaluate so that that solution might not actually give you a good score from the perspective of a learning algorithm even though maybe the samples would look fine uh but yeah I haven't seen that happening in practice so okay the bonus would be single pass you can get everything as opposed to and different passes and uh the way you do it is to basically mask right so what you have to enforce is some kind of ordering and so you basically have to take the general computation graph that you have from an out encoder and you have to mask out some connections so that there is some ordering that then you can use to generate data and the ordering can be anything uh so for example you can pick an ordering where we choose this X2 X3 and X1 which corresponds to the chain rule factorization of probability of X2 X3 given X2 and X1 given the other two and then what you can do is you can mask out some connections in this neural network so that X the Reconstruction for X2 does not depend on any of the inputs and then you can mask out the parameters of this neural network so that the parameter uh of x3 is only allowed to depend on x2 and uh uh the parameter of X1 is allowed to depend on everything just like according to the chain rule factorization and so one way to do it yeah so that's I think what I just said one way to do it is you can basically keep track for every hidden for every unit in your your hidden layers you can basically keep track of what inputs it depends on and so what you could do is you could pick for every unit you can pick an integer I and you can say I'm only going to allow this run this unit to depend on the inputs up to the I index I and so you can see here that uh you know there's this 2 one 2 two this B basically means it's only allowed to depend for example this unit is only allowed to depend on the unit one and two this unit here is labeled one so it's only allowed to depend on the first input according to the ordering which is X2 and then you basically um recursively ask add the masks to preserve this invariant so when you go to the next layer and you have a node that is labeled one then you are only allowing a connection to the nodes that are labeled uh up to one in the previous layer and the way you achieve it is by basically masking out and setting to zero basically some of the elements of the of the Matrix that you would use for that layer of the neural network and if you do that then you preserve this invariant and you can see that indeed uh the parameter of X the probability of X2 which is the output the second output of the neural network does not depend on any input which is what we want for a chain rule factorization and if you look at the parameter of x3 which is the third output you'll see that if you follow all these paths they should only uh depend on basically the second on x2 which is the variable that come before it in the ordering and so by maintaining this invariant you get out encoder which is actually an auto regressive model you are essentially forcing the model not to cheat by looking at Future outputs to predict uh and you can only use past output past inputs to predict future outputs essenti and this is one architecture that would enforce uh this kind of invariant yeah sorry is it something that's like done during training or do you like train an auto encoder and then mask certain generation this is done during training so you have to during train like you basically have to set up an architecture that is masked so that uh it's not allowed to cheat while you train because if you didn't mask then it could uh when trying to predict the X2 you just look at the actual value and you use it right and so this is very similar if you seen language models you also have to mask to basically not allow it to look into future uh tokens to to make a prediction if you're allowed to look into the future to predict uh tokens then it's going to cheat and you're not going to do the right thing and this is the same thing uh at the level of the comput different computation graph that basically achieves the same sort of result and the benefits of single passes during training time yes good question yeah yeah so the question is is the benefit only a training time or INF time so the benefit is only at training time because at inference time you still have the sequential thing that you would have to come up with a value for for the first variable and fit it in so it will still have to be sequential that's unavoidable every outo regressive model has that kind of annoying uh flavor basically how do you choose the so the recipe in this paper Is Random so you mean the the the the the value or the the ordering oh the ordering that's also very hard I think uh you know if you have something where you know the structure and you know again that there is some causal or there is time maybe there is a reasonable way of picking an ordering otherwise you would have to either choose many orderings if you have basically have a mixture uh choose one at random but there is not a good way of basically selecting an ordering there is actually research where people have been trying to learn how to regressive models and an ordering so you can like Define a family of models where you can search over possible orderings and search over factorizations that over that ordering but you can imagine there's like M factorial different orderings to search over and it's discrete so it's a very tough kind of optimization problem to find uh the right ordering if one is not dependent on anything how does the model output one there should output it should only Al two three right should be uh you would have to I mean depending on the loss fun it cannot depend on anything but you can still basically make a a guess based on no evidence so you would basically choose the prior right so if the let's say the second variable is always true then you would still depending on the training objective you would still try to choose an output here it's a constant but you would try to match basically the most likely value in the training set or if you have a proper scoring rule then would try to match the distribution that you see in the training set depending on the loss function you still try to choose a a value that makes sense but it's fixed so you can only choose one and so you can't do much but you're still you would still try to do your best to to to capture the data depending on the training loss yeah are there redundancies like in the second to last layer there's two uh nodes which just have one as an input so is it kind of redundant to have multiple nod just have one in uh I mean the weights are different so even though there is multiple nodes that have only one an input they might be extracting different features for that input so it's not necessarily predominant I would say so the objective of the auto is to deconstruct yes so how do you reconcile the loss function it's pring one thing at how do you like make the function reconstruction yeah so the function would be the ones that we have here uh which uh would be you know basically you would try to make the predictions close to what you have in the data so the loss function wouldn't change it's just that the way you make predictions is you're not allowed to cheat for example you're not allowed to look at XI when you predict XI and you're only allowed to predict it based on previous variables in some ordering and it turns out that that would be exactly the same loss that you would have if you were to train the AO regress model it depends on kind of the model family that you choose but if you have logistic regression models it would be exactly the same laws for example in your last layer like you said you pick each of the I guess the number of times it looks previously randomly so if you happen to pick 222 how would you predict the first entry after that yeah so you would basically be you're not allowed many connections and you would do a pretty bad job because you you would be less uh Flex ible that you could be it would still be a valid model uh it wouldn't be a good one I guess so that's why people often have kind of like an ensemble of these mods where you have multiple masks and you just do it that way yeah cool um let's see now an alternative way to to approach this is to um use uh RNN some kind of like recursive style Compu ation to basically predict uh the next uh random variable given the previous ones According to some ordering right at the end of the day this is what the key problem whenever you build an auto regressive model is solving a bunch of coupled kind of prediction problems where you predict a single variables single variable given the other variables that come before it in so moring and uh the issue is that this history kind of keeps getting longer so you're conditioning more and more things and uh rnns are pretty good at or or it's one way to kind of like handle this this uh kind of situation and uh kind of like try to keep a summary of all the information of all the things you've conditioned on so far and recursively update and so a computation graph would look something like this so there is a summary H let's say h of t or h of t + one which basically is a vector that summarizes all the inputs up to that time and you initialize it somehow based on some initialization and then you recursively update it by saying the new summary of the history is some transformation of the history you have seen so far and the new input for that times step XT + one and maybe you know this is one way to to kind of implement it you do some kind of linear transformation of HT XT + one you apply some nonlinearity and that gives you the new uh summary up to time t + one and then what you can do is just like what we've done so far is then you use H to basically or you transform it Ag and you map it to either let's say uh a category the parameters of a categorical random variable or a berol random variable or a mixture of gaussians whatever it is that you need to predict uh you do it through uh well I guess you probably also would need some nonlinearities here but there is some output which is the thing you use for prediction which is going to depend only on this uh history vector or the summary Vector of all the things you've seen so far and uh the good thing about this is that uh basically it has a very small number of parameters like regardless of how long the history is there is a fixed number of learnable parameters which are all these matrixes matrices that you use to recursively kind of like update your summary of all the information you've seen so far and so it's constant with respect to when remember we had the things that were linear in N we quadratic in N this thing is actually constant the mees are fixed and you just keep applying them exactly it's it's extreme weight sharing and that you try to do everything throughout a cion yes here we're imposing a mark assumption on the addition probabilities this is still not so the question is is this a mark of assumption there not a mark of assumption in the sense that if you think about XT is not just a function of the previous XT minus one right uh it still depends on all the past random variables in again not entirely General way so you can only capture the dependencies that you can write down in terms of this sort of recursion and so you know it's not uh it's definitely not a mark of assumption this is that if you think about the computation graph it does depend on all the previous inputs and uh so this is an example uh of how you would use this kind of model to model text so the idea is that in this simple example we have only let's say four different characters h e l and O and then uh you would basically encode them let's say using some kind of one hot encoding so H is one0 0 e is 0 1 0 0 and so forth and then as usual you would use some kind of Auto regressive factorization so you write it down this case from the ordering is the one from left to right so you you write the probability of choosing the first character in your piece of text and the probability of choosing the second character given the first one and so forth and uh what you would do is you would uh basically obtain these probabilities uh from the hidden layer of this recurrent neural network so you have these hidden layers that are updated according to that recursion that I show you before and then you would use the hidden layer you would uh transform it uh into an output layer which is just four numbers and then you can take a soft Max to basically map that to uh for non negative numbers between 0 and one the Su to one and so in this case for example uh we have a hidden layer and then we apply some linear transformation to get these four numbers and uh we're trying to basically choose the values such that the second entry of the vector is very large because that would put a lot of probability on the second sort of uh possible character which happens to be e which is the one we want for the second position and so then when you train these models the game is to choose values for these matrices so that you know let's say you maximize the probability of observing a particular data data point or data set um and yeah so again the the kind of like key thing here is that you have a very small number of parameters and then you use the hidden state of the neural of the of the RNN to get the conditional probabilities that you need in an AO regressive factorization and uh and then and then you can see kind of like the recursion then you would compute the next hidden state by taking the current history then every you know the new character that you have access to you update your recursion and you get a new hidden State you use that hidden state to come up with a vector of predicted probabilities for the next character and so forth it's the same Machinery as before but instead of having multiple kind of like linear reg or logistic regression classifiers we have a bunch of classifiers that are tied together by this recursion and uh the pro is that you can apply to sequences of arbitrary length and it's actually in theory at least rnns are pretty General in the sense that uh they are they can essentially represent any computable function at least in theory in practice uh they are tricky to learn and uh you know you still need to pick an ordering which is always a problem for AO regressive models the key thing the key issue with this sort of like rnns is that they requires they're very slow during training time uh because you have to unroll this recursion to compute the probabilities and uh that's a problem but I'll just show you some examples and then I think we can end here it actually works reasonably well like if you take a simple three layer RNN and you train it on the all the works of Shakespeare at the Character level so it's literally what I just showed you just a three layer RN um and then you sample from the model you can get things like this which has a little bit of the flavor of sh X I guess not I if you think about this is at the Character level you know it's this literally generating character by character it's actually pretty impressive like it learns it needs to learn which words are valid and which ones are not Grammar punctuation like it's pretty impressive that a relatively simple model like this working at the level of characters can do can do like this you could train it on Wikipedia and then you can sample and you can just you can make up fake Wikipedia Pages like this one on the Italy that conqu conquering India really interesting made up stuff but again you can see pretty interesting how it it's able to has the right markdown syntax and it's closing the brackets after opening them which has to remember through this single hidden state right that it's carrying over uh yeah so you know he even making up links to to for for this madeup facts that it generates and uh you know train it on baby names and then you can sample from the model you can get new new names so yeah it's a it's a pretty you know surprise works surprisingly well I guess the the main issue that hopefully then maybe I guess we'll go over it next time that the reason this is now used for state-of-the-art language models is that you have this bottl that you need to capture all the information up to time T in a single Vector which is a problem and the sequential evaluation that's the main bottleneck so it cannot take advantage of modern kind of gpus because in order to compute the probabilities you really have to unroll the computation and you have to go through it step by step and that's kind of like the the the main challenge"}], "The Paper that changed everything! The Science Behind ChatGPT Fully Explained": [{"content": "hello everyone okay today to be honest this is one of the episodes that will not get view I know from the get-go I will do all the work and this will not get viewed and I'm okay with it this is one of the episodes I actually do for the community so the reason I'm doing this episode is in one of my previous videos I mentioned the strawberry test and I was saying the reason that AI models struggle with the strawberry test and Counting how many RS in the word strawberry is because of the way it does the prediction and one of the community members who is mostly smarter than me when it comes to AI corrected me and said no it's more about how it does the embedding and the tokenization um at the early stages of the training of that model so I I said this is a good opportunity for me to dig deeper into understanding artificial intelligence as someone learning and sharing my journey with everyone and this brings me to this episode so I did some homework I looked at some references I read through it I'm going to do it all over again here and this is the type of video um if you're going on a long run Long Walk Drive it's something that you listen to I guarantee by the end of this video this is my value proposition to you that you will have definitely more knowledge of how AI models work than the average person now it might not be perfect but this will be giving you maybe keys and ideas and resources that could give you some inspiration to do more than I did with this knowledge so you can research it more understand it more and hopefully share that feedback with me so today we're going to start with some Basics I've already covered a video on the highlevel uh areas about artificial intelligence the different type of networks how they work and even I shared some resources on demoing such artificial neural networks how they work so at least you can imagine what goes behind it beyond the theoretical and today I'm going to do the same but I'm going to focus on a different area today we're going to focus on two things the Transformer architecture which is the thing that revolutionized everything we know today about artificial intelligence it brought us chat GPT Cloe all of these kind of models that we love today and then I'm going to look at the future you know what could be the next phase of evolution for artificial intelligence models and and finally if you wait till the end I'm going to give you three or four tools that you can play with that can help you understand better everything that we go through through throughout the episode and even you can share it with others and help you explain to them what is a Transformer and uh visually explain it to them rather than doing an hour probably um of uh sharing links and articles and reading through text and by the way you you feel free to jump till the end and just go to these resources see the demos but I guarantee you you will not capture the full value of this spend some time maybe you can skip between chapters but spend some time to go through the flow of the video and then go to these demos it will be much more valuable for you I will be repeating certain things I'm not an expert so I found myself when trying to learn things on YouTube that there's two two types either I go watch an expert doing things things overs simplistic or I watch an expert actually complicating things things that I I don't grasp or understand but I found a different type of video not so mainstream I'm going to do the same which is someone trying to learn learning real time uh the concept that they're talking about and I found that more relatable and in many cases help me grasp such Concepts much better than getting it from the expert so to speak so let's explore the together my name is Sam if you don't know me my channel is all about AI in Tech and helping people who are not technical like myself when I started my journey learn it use it in their personal life and their careers to improve it make it better take it to the next level and with this let's just get started subscribe to Daddy's channel the mic okay before I start everything I show you here it will be in the description all the links and resources these are things created by super smart amazing people that are giving out this information to the world I will link it in the description I've created as I mentioned before a video with the AI Basics networks how they work the types of networks at least the common ones I'll also include it in one of the cards um throughout the video and I'll include it in the description so you can have everything in this video in one place for you to do your own research or expand on it if you want to do so and with this let us start with quickly I will not spend lots of time with the fundamentals and then we C we can actually move to the important part which is the Transformer architecture and why it's special and closer to the end as I mentioned we're going to actually see why it gets the strawberry uh test wrong and we're going to demo that see why and how we can fix that maybe in the Transformer architecture but in general why it get set wrong for the most models okay so here you see this visual which I showed in the previous video and I'm sure you've seen it before the whole premise for someone who doesn't understand artificial intelligence yet maybe this will help you to follow along with the video is that someone somewhere decided to replicate uh the way we think the way our brain functions into a program can we do it artificially can we do it through machines basically and what they've done uh literally they were influenced by the way how our brain cells operate and work and how the anatomy of those cells is so you can see uh the cell how it looks I will not go over the scientific terms of the cell but basically it has branches as inputs going into the nucleus which is later on AI we call it a nod and then it has an output that goes probably to interact or uh connect to other nucleus uh cells in the brain and you can multiply that by billions and billions of cells and that what gives us what we perceive as humans as intelligence or IQ so this is how our brain works now they came and they tried to replicate that through um a program in mathematics now this idea is not new it's actually pretty old but we never had the computing power we never had the data available to actually uh start working with these things uh in real life um and as technology progressed we started doing it implementing it playing with it and we got along the the years certain breakthroughs obviously the Transformer was one of the most recent and the probably the most significant one um that we can recollect today and it it moved artificial intelligence from something that researchers used to work with to something for the open public to actually make use of uh in tools that we use today everyone probably is using artificial intelligence in one way or another so you can see here this is the nod which is basically the nucleus and it gets a bunch of inputs similar to the branches that we see uh here and uh again this is all mathematics so these are computer programs on top of machines but in the core of it all of this as you will see today it's all mathematical equations that make sense of data as it flows and by the way today as humans we are not able to them all of these calculation at once we know how it's built we know how it's calibrated and we judge based on the design of the model the input the output if it's a good one or not there's methods to to do that so we have all of these inputs which are X1 X2 until xn and then we have the weights now the weights is the end result the easiest way to to describe it it's the value we care about because this is the uh the value that is assigned to a model after it's trained and this is what gets a model to operate in the way we want it and for it for us to use it later as a trained model so this is the network for training that model and generating all of these weights that we will use later on in any model for operation for use now all of these inputs go to an activation function and the easiest way to describe the activation function it's a function that will decide if that node will activate or not so when we think about something in our brains not all our cells are working at the same time it's parts of our brains address certain areas or certain questions or certain topics that or or activities we it's taken care of so it's not every time we have a thought the whole brain lights up it's just parts of that brain and the easiest way for me at least in my in my mind to understand activation function it is exactly that it is the function that tells this node oh based on that input you you're going to fire up and continue to another node or you're not going to fire up you're not going to activate basically and things will stop here um and there's a sum which is a transfer activation function basically it takes all these inputs there's a function that runs over these inputs and it is what uh puts things together to go for the output so this is the First Fundamental idea um and again let me scroll down just to show you how these networks look again this is a very simp simplistic look of of networks it is again similar to the brain billions and billions of what they call parameters so you can these parameters are the weights but you can think of it when they train these uh neural networks they actually train them through billions of nods and eventually we have those weights that we'll use later on this is just a you know a view for you just to imagine how it looks so you'll have an input layer basically this is where you push the uh training data or whatever data you need to train that model and you have so many layers of hidden layers what they call Hidden layers and then you have an output layer where you get the output this is why they call it deep learning because you you have so many layers of hidden layers within that neural network that makes it really deep so the data has to go a long way from the input layer until it reaches the output layer and you can see at each stage there's that sum and activation function shown in the equations in the bottom so this is fundamentally what we are looking at when we talk about Ai and this idea again is old now something changed along the way in terms of the architecture of these things that made it much better in reasoning of some sort and uh but more importantly in having certain uh aspects which simulate um memory or context understanding because at the end of the day if I give you a sentence that sentence is highly linked in your brain to a context so for example if I mention um The cat went out to the field and it ate the mouse so once I say it it refers to the cat this is the context that your brain will start linking it to the cat computers can't do that and the the evolution that we have in the technology actually helped us to give it the ability to understand that this it this word is actually linked to to cat and that happened through the concept of attention what words in that sentence should the model or your brain for that matter give attention more or less what are the more related or less related words in a sentence that are important for you to comprehend and or important for the machine to comprehend so this is our Focus the attention part um when it comes to artificial intelligence models but at the back end of all of this it's all artificial neural networks that in simple terms look like this now let me move to another fundamental thing which maybe not so related like other things I'm going to show you here but I think it's important so I talked about it in my first video this is the convolutional neural network and this is a type of networks or CNN um it has to do more with image or other areas less text uh but these are very similar in in one way or another but they itely benefited as much as the conventional networks I just showed you from the Transformer architecture and artificial intelligence and uh the the way those networks operate so let me just take you down again you can see always there's this kind of view of how the brain works and then they show you how the network works uh it works more more with images and you can see it's that unique area that IT addresses and it's basically a network that cuts down an image to let's say say pixels or smaller parts they call them convolutions that's why it's called the convolutional neuronal network and each part uh becomes basically a matrix of numbers at the end of the day when we look at an image uh the colors in it uh the lights it's all it's it's just a number it's a it's a numeric value that the computer translates into an image when it's shown to us and when it handles that image as well it's numbers behind it so it takes that chunk of the image as a convolution turns it to these numbers and then does something called kernels into it basically does modifications those by the way could be as simple as increasing contrast um or doing other things like highlights it helps it break down that image to uh certain kind of aspects or a basic or simple uh way of looking at that image which might not be the same way we look at the image but it eventually will help the AI Network understand somehow what it is looking at so it does all of these convolutions again multiple layers and the kernels and at some point it it flattens all of that out and pushes it into a normal neural network or feed forward neural network and then it gets an output so let me show you uh in this uh again you can read this on your own pace this is not the topic of the episode but um this is one way of looking at it and by the way in the episode that I will link I give you a chance or a link or a tool where you can do this for yourself you can build the network you can actually see how it's predicting the input image versus the output so for example this is an image of the number two um and you can see that this design is taking this image breaking it through convolutions and then and you can see here convolution one convolution two and does all of these uh needed Kern and you can see it's multi-layered at each of them and then it's flattened here and then it goes through that feed forward Network and eventually you get an output the output here is 0 1 2 each of them will be assigned the probability and if the network is done right the probability for two will be the highest and then it will tell you I predict that what's written in that image is the number two so again I know this is just something for you to keep in mind that this definitely benefit Ed a lot this type of network from what we have when it comes to the Transformer architecture again just one more resource for you uh because this might come up and be mentioned as convolutional neural networks later on while we are reading um into the uh more detailed aspects of the Transformer architecture now let's spend a little while here on the activation function because those are very important when really understanding how neural networks uh are artificial neural networks work and again I am trying to learn as I go with you so if you find me struggling it's part of me thinking out loud with you and for us both to get to a place where we better understand all of this um and this will be the theme of the whole episode so I hope you enjoy it okay let's move on so what does an artificial neuron do simply put it calculates a weighted sum of its inputs adds a bias and then decides whether it should be fired or not so basically what I already explained so this is y is the output and then you have the sum of weight multiplied by the input so this is the W multiplied by the X uh adding to it the bias and again the bias is covered in the first video um it helps out in really fine-tuning that model as you train it uh in reducing the uh losses and basically the errors as it's being trained uh to the data it's fed again it's a different area of its own we're not going to focus on it today but just understand that this is the equation behind the activation function now the value of y uh can be anything ranging from uh minus infinity to Infinity um and then neuron really doesn't know the bounds of the value so how do we decide whether the neuron should fire or not why this firing pattern because we learned it from biology that's the way brain works the brain is working test is a working testimony of an awesome and intelligent system so again it's all the same theme it's it's the way our brain works and we're trying to replicate it into technology we decided to add an activation function for this purpose uh to check the Y value produced by a neuron and decide whether outside connections should consider this neuron as fired or not or rather let's say activated or not so the same thing I just um covered before again the activation functions are simple functions and there are so many types uh for different uses or sometimes the combinations of those types uh within the same network but here let's just go over it high level I will not go over each type of function and what it does it will just give you the idea of how that function works it gets something and it gets something out in a certain way and that could tell the network yeah this is activated or not activated and um the first thing that comes to our mind is how about a threshold based activation function if the value of y is above a certain value declare it activated if it is less than a threshold then say it's not so great okay this could work activation function a activated if Y is larger than threshold else not um alternatively a equals 1 if Y is higher than the threshold 0 Z otherwise so okay so this is called a step function so this is one type of activation function so you can see whatever inputs come if it's less than zero it will the out will be zero if it's more than zero the output will be flat one so here if the Y is negative the output will be zero and basically you can tell zero means it's not fired there's nothing that could happen with a zero of some sort but if the Y is posi then the output is one so that activation or that node carries on um and considered as activated or fired so let's just quickly look at if there's something more interesting here but I I I think you get the idea of the activation function now it goes here into you know the types of activation function so here we have a linear function so these are important and nonlinear function so the sigmo function is one of the most important and it's a nonlinear one so you can see here again it's the same concept so if we have something negative again you have to see where it falls uh into the chart here and then you can uh see what what the output will be right and the same goes if it's positive so this just gives a value on the curve based on the X's coming in the x's and the Y's basically and the sum of them coming in and it will give a y uh which will be somewhere on this curve depending on the sum that it is getting so at the highest range of it if the sum is equal to six or more the output will be will be one if the sum is smaller um of minus 6 it will be zero so again this is one way of one equation of deciding what nods fire and what's not and again all of these things beyond my expertise but it's it is um the way I think about it all of these things are levers for the people designing a model to put it within their Network to get certain performance out of that artificial intelligence Network that they're building or the model that they're building and training again here you can look at the link at your own pace there's so many types of activation functions this is a linear one so anything uh negative will be zero anything positive will will work against that linear um line here so if if it gets let's say a five it will be probably visually I'm looking at a five so this is one: one kind of linear function uh so it's it just anything positive will be the same value as the sum of the input anything negative is zero so it just removes the negatives uh this activation function so there's so many types so many things that you can look at but you get the idea the activation function fundamentally is a function that we design to decide which neurons continue carry on or fire basically or activate and which ones do not now let's jump to One More Concept this is called the back propagation algorithm and this is the way where actually models started getting trained and it is an algorithm that gave the models the ability to see what's happening going forward when the data is progressing into the network and the errors that are taking place see that errors in pre previous steps in in simple terms and try to correct them somehow or modify or by the way it's running so it will reduce those errors so we'll just go through it again it's a concept that helps a lot for you to understand later on as we progress through um the session towards what what we need to aim for which is Transformer architecture so let's just go quickly through the main parts of it so back propagation algorithm is probably the most fundamental building block in a neural network it was first introduced in the 1960s and almost 30 years later in 1989 popularized by raml Hart Hinton and Williams in a paper called learning representations by back propagation errors so again I I might have butchered their names I apologize for that but again it's it's the algorithm that helps us manage those errors and get the model to actually learn and train as it goes the algorithm is used to effectively train in neural network through a method called chain rule in simple terms after each each forward pass through a network back propagation performs a backward pass while adjusting the model's parameters weight and bias so we've seen the weight and bias so the bias if I didn't stress on it actually it goes into the nod by the way so these are some levers to tweak that model and how it will later on perform so what this does it allows not only feed forward kind of path for the information through the network but also a backward path which will allow that model again to modify weight and bias to perform better supposedly in the future at least this is the concept behind it and this is um happening or being used in neural networks since that time on obviously this have evolved a lot uh definitely it has evolved a lot um in the way it is being implemented or not okay so I'm learning as I go with you but it is definitely something as I learn uh or or read into artificial intelligence like it's one of the concepts that you need to grasp to a certain degree uh to really understand how the technology work so again here is just um um a look at the network so you have the inputs again these are going through the hidden layers that we talked about before and you you can see the nodes here and uh eventually it goes to an output and the input so this is just describing what we're looking at so you have an input layer and again this is the compilation of the inputs and weights uh basically the summation I guess you have the hidden layers uh again with their own uh equations um again this I'll give you a tool to do all of these calculations if you want to do so yourself this is I think the barrier of you know how deep you want to go in your understanding of the models you know my interest is to have good understanding of the concept and how that works um maybe touch the surface of the equations I'm an engineer I enjoy these things but this will be time consuming if it's your thing I will give you what will help you really tweak these things look at them as they work step by step later on at the end of the video but just understand that each layer each function each step has some numbers and modifications or manipulations to those numbers uh is maybe the the best term to use here and um okay so here activation a uh 2 okay and A3 are computed so here it's just talking about the type of activation function uh it is using so it's giving uh three examples we talked about the sigmo there's the reu and the tan each of them as we've seen does a certain uh function to manipulate the output based on the sum of the input and weights to activate or not activate um a nod let's go just to the important part of back propagation so this is going through all of the details of the equations what I'm interested in the back propagation and Computing gradients so according to the paper from 1989 back propagation repeatedly adjust the weights of the connections in the network so as to minimize a measure of the difference between the actual output Vector of the net and the desired output Vector so those talk by the way there's two types of data that they usually use uh in the things training data and validation data so training data is the data that you actually push through the network to train it validation data is the data you use to test the output of that Network and if it matches the training so basically back propagation um maybe in a simplistic term it does one run checks the output Compares it to a validation data sees the difference and by the way it does it compare to the training and validation data so you have what is called training loss and validation loss basic basically two types of errors and it looks at those errors and how wide they are or how big the error is or how small it is it will again be fed back to the network to modify or tweak the weights and biases so it will try again and try to reduce uh the error for the next run and so forth until a stage where it's satisfactory it is set as satisfactory where it holds and stops the training for the model in other words back propagation aims to minim minimize the cost function by adjusting Network weights and biases so the cost function is mentioned in this article you can read about it the level of adjustment is determined by the gradient of the cost function with respect to those parameters one question may arise why Computing gradients so again it is part of the math of doing back propagation and uh managing these artificial neural networks I will not go through it today you will have the link for this article um for you to dig as deep as you want um though now this is just a video I wanted to show before we move on it basically looks like this so you can have the forward feed type of movement within the network but also you have the um the Red Arrows which is the back propagation so you can see that goes back feeding to these nodes and then the nodes will modify or tweak the weights and biases and again go back to feed forward and see what output that actually generates within that neural network okay so let's move to the next part here okay so now we are getting into the interesting stuff ahead of the Transformer architecture the most prevalent type of networks that were used are the recurrent neural networks and long short-term memory uh networks lstm so it I think it's very important for us to understand what was the basically the height of of the technology before the Transformer architecture um and what was the issues within that uh architecture or that technology at that time and later on we will find out what actually the the Transformer um architecture solved compared to what we we had and again by the way the Transformer architecture did not replace fully these type of networks these are networks that are still powerful tools that are just enabled to much better perform in terms of quality of output compared to just working alone through these Technologies so still uh recurrent neural networks are a very important part of the technology of artificial intelligence and how it's designed trained and delivered um to the consumers or the users of that technology but at that stage the main thing was for developing artificial intelligence Concepts was the rnns which is the current neural networks and the long shortterm memory Network which is lstm and those are variants sort of speak um of the same type of network so we'll go through that just to see what was there ahead of Transformers and later on we'll start getting to the important stuff when it comes to the version of artificial intelligence in concept basic concept that we are enjoying today in everyday life so let's go through the introduction in recent years recurrent neural network and their specialized variant so it's a variant of the uh RNN long shortterm memory lstm Network have emerged as powerful tools in the realm of sequential data processing and here I would focus on the word sequential so this is one of the areas or the limiters in this technology at that stage that things went into sequence tokens or data went into sequence and uh the context was not there because it's going into sequence from natural language processing to time series forecasting these neural architectures have shown remarkable capabilities in capturing temporal dependencies and patterns so the basics of rnns Imagine a traditional neural network it receives inputs processes them through hidden layers and generates an output however so this is what we already covered the the normal neural network however rnns add a crucial twist memory they incorporate their previous output back into the network allowing them to remember past information and influence their current processing so this is not ideally back propagation but it sounds just like it it just retains for some time the uh information or for a longer period the information within the network so um that could be for back propagation for error this could be for context but it's again limited so the the output of of one node goes back to the previous node so it can somehow return that kind of loop um uh which runs for some time I think and we'll get the details a little bit as we go through this article the architecture of rnns rnns are a type of neural network that has hidden States and allows past outputs to be used as inputs so past outputs are used as inputs so I'm just imagining with you so it runs and it takes the output at each layer as an input again for the same layer maybe we we'll look at it now and this will will get the network as it's being trained to know what happened last time basically what happened the last time the data went through that Network okay this was the outputs now it might modify differently either for certain quality parameters or to reduce the um errors that we talked into the back propagation I think this is different in that sense from back propagation so back propagation just takes the those errors back through the backward feed um and provides uh them for tweaking the weight and the bias this one just literally is recurrent so it takes the output feeds it back back as an input so we have the inputs which is the X if you remember x i or x 0 X1 until xn and then we have the weights and this network will have one more input which is the output that the same not generated pre previously so uh the next time it runs it has the previous output as one more input to consider okay so this is just a high level architecture so let's just read quickly the basic building blocks so the basic building block of RNN is a recurrent unit this unit takes two inputs the current input X which is here so this is the current input and the hidden state from the previous time step the hidden State a acts as the memory carrying information about what the network has seen so far okay so it's not as simple as the same uh output of the not so actually it's the output from the previous um um the previous state of what the network has seen so far we we hopefully maybe we can see more details around that later but basically here if you're looking this is the a so this is the memory part of it and this is the output so we have inputs we have outputs this is one hidden layer I assume and this hidden layer is getting the previous state of what the network has seen so far when it comes to the perspective of this layer so I assume this layer has much previous layers and layers to follow it so it only sees what went through the last time or the last state um of previous layers okay let's carry on so um example of RNN machine translation okay sentence I'm going to eat lunch an RNN translating the this sentence to French might initially translate it to okay I will not even try to pronounce French I'm going to definitely butcher it um but okay this is the French word of eat I assume however or one variant of eat in French however if the preceding sentence uh in the conversation was would you like to join me for dinner the RN should understand that eat refers to lunch in this context and translate it to something else in French instead this shows how rnns can use context of surrounding sentences to improve the accuracy of translation so they have context but again I think it's limited context but this is the the value that rnns brought to the technology it give the network some memory and some context based on the data fed into that Network so let's go through the quickly the different types of rnns one to1 RNN processes single input and generates a single output useful for tasks like predicting the next word in a sequence one to many RNN processes a single input and generates multiple outputs used in music generation where one Melody becomes a sequence of nodes many to one rnns processes multiple inputs I think this is the typical one we understand and generates a single output common to sentiment analysis where multiple reviews lead to a single single positive or negative sentiment many to many okay so this is just types of uh the the network that you can build challenges with okay this is this is where the money is this is what we need to I think understand before we start moving to what happened later on in the evolution of this technology while rnns are effective in capturing short-term dependencies in sequential data they often struggle to learn long-term dependencies this is due to the vanishing gradient problem where gradients diminish exponentially as they are back propagated through time leading to difficulties in training the network to remember distant information okay so um The Vanishing gradient problem the easiest way I'll describe it I don't know if it will be explained later on I forgot honestly remember you're dealing with numbers and fractions of numbers so um in the recurrent neural network back propagation I assume from reading this happens if these uh gradients or basically the values that are uh moving layer to layer in the network are reducing at some point these gradients will vanish it will go down to zero so it will lose the information that it had uh so that will limit its ability to maintain that context for a long time and I think the opposite Could Happen um so the opposite of the vanishing gradient problem so it can actually grow until a high value or maybe one Limited at one I'm not sure but the problem of how you handle those numbers within the network as you train it is is a challenge one of them here is the vanishing or the main one here is the vanishing gradient problem again as it moves through the nods if these values of the gradients are just reducing and all of this is happening through in many cases multiplications and some so if you keep multiplying by a smaller number obviously that number will keep on diminishing and it will go to a too small value maybe close to this zero where the state of the training or the model that you have vanishes it goes away I think this is um what is meant here so let's look at the back propagation through time so this is the network okay so we have here inputs these are the nods these are the outputs and uh we we'll see what L is um but again so we get uh the this is the feed forward this is the back propagation and as it goes back this is where the gradient could go down to zero okay so somehow here it operates as the the network that we know but it just has the element of um the uh recurrent fact which is as I said in the uh which I suspected in the beginning it is actually um the same or some kind of um modified back propagation algorithm that makes it recurrent as a network so yeah okay so it's good they're talking about Vanishing gradient when back propagating errors through through many time steps in in an RNN gradients tend to diminish exponentially as they propagate backwards through time this phenomena can occur due to the repeated multiplication of gradient values during back propagation leading to a very small gradient consequently early time steps receive negligible updates during training hindering long-term dependencies learning so I think it is the same idea I had because when it goes in the back propagation path or the backward path or the back backward feed path it's being multiplied by smaller and smaller gradients and that leads to the values to diminish down to zero um more or less so it will lose its state as a model okay so standard RNN gradient flow Vanishing gradients so this is just a depiction of you know what happens so Vanishing gradients uh many values are less than one so you have the activation function weight initialization Network architecture okay when the weights are very small they get smaller quickly by multiplying in the back propagation process dropping down to zero making the model unstable that's why it's called Vanishing because the gradients vanish okay exploding gradient so this is the opposite of it which I mentioned a conversely exploding gradient refers to the situation where gradients exponentially grow during back propagation the this often happens when the Network's parameters are initialized poorly or when the network architecture is not properly designed causing gradients to increase uncontrollably exploding gradients can lead to numerical instability during training causing the model to diverge okay so again this is the other scenario where many values are higher than one exploding gradients gradient clipping to scale big gradients okay again it's all fundamentally means there's a big problem with recurring neural networks of L of state so it has a memory which is good was a big development but they remained with the issue of not being able to keep that Network stable for longer times now they made variant of that which was called the long shortterm memory Network so let's read about that and see also what's the issues with this one and what was able to solve and what it couldn't solve uh when it comes to this technology to surmount the limitations of conventional rnns uh lstm networks emerged as a breakthrough Innovation armed with a sophisticated memory mechanism long short-term memory networks excel in capturing long-term dependencies with finesse so it's an RNN that could hold memory um for long term peering into the architecture of lstm networks okay in addition to the inputs recurrent and output layers lstm networks Harbor memory cells designed to store information over extended periods governed by gate mechanisms these memory cells regulate the retention for getting and updating of information at each time step circumventing The Vanishing gradient problem and adaptly modeling long range dependence so basically what's different is that they have a memory cell we'll see what that actually is that will solve the vanishing gradient issue and it holds memory for a longer time so let's look at the key Concepts okay maintain a cell state so the state of that cell is maintained for uh in some way or another use gates to control the flow of information forget Gates um gets rid of ir relevant information store a Gates relevant information from current input selectively update cell State output gate returns a filtered version of the C State back propagation through time with partially uninterrupted grad gradient flow okay so that's interesting so it has some kind of gates and I understand Gates as rules basically equations functions um some of them will get rid of ir relevant information probably information out of the bound of certain limitations it's able to store some of that in certain Gates and then update the state of that um cell and then return filtered version of the cell State okay so again you can see here um it's a complex cell so this is the architecture within the nod so you have the input you have the output and this is what's happening between all of these uh let's call them uh sub noes okay maybe this is the best way to to um describe it it's uh certain functions that either retain modify eliminate certain values from the input uh going to the output the best way I would put it it's a more complex more sophisticated activation function at least this is how I understand it so far so this is the architecture and there's a legend for it so it will help us understand so X is the input so let's see the first um uh okay the the red bubbles here those are the biases okay that's good the plus this is elementwise summation and concentration so this is a function that adds the um again this is the let's say the ideal Activation so adds all these inputs and I assume um okay so this is the recurrent element into this network so you have the output of the previous block coming here in the orange so we have inputs biases we have uh the output of the previous um uh block all of them going into the summation so okay we understand this part now all of these sums are going into these yellow things which is the sigmoid U sigmoid activation function so again this is the activation function here okay so you can see there's two types of activation functions in the this uh kind of node so you have the tan H I don't know if you call it the tan H or just the tan and you have the sigmo so all of them uh all of the summations will hit those activation functions and then okay they will go to these icons which is elementwise multiplication okay so uh this will do some multiplication and again goes to the tan H this one here it goes to a summation here goes to a mult multiplication all of that will move to um a memory from current block so it's stored at a state so this is the storage this is the output of the current block so this probably goes to the next blocks so this is the output and this one is the memory from the previous block so we have input from previous block and the inputs and the biases coming in and we have the uh memory from the previous block um and we have the output going out and the memory out of this block going out as well so this is two outputs going out from the current block and this is the memory from the current block so all of this multiplication and summation again this is the complex part you want to dig deep into this feel free but what these calculations are doing are generating values that are either eliminating something or put in a the way they put it as a block for keeping the memory or giving the the output of the current run um and so forth so it's just complex calculations that will enable the architecture to operate in the way that um it is designed which is not only taking inputs and giving outputs actually taking inputs and like recurrent networks taking the output of at the state of previous uh um layers or nods but here also it's giving an output and it's giving an output of the memory State uh of this uh layer or this node this is the storage and it's also taking as an input the memory from a previous block so it's much more complex inputs and outputs managed for uh this architecture so this is again more details around the input gate controls the flow of information into the memory cell utilizes sigmoid activation function to determine which information from the current input should be stored so this is this is this part here that it's just deciding what it needs to actually store and this is goes to the storage here so this is why it goes straight to the storage uh forget gate regulates the retention or forgetting of information from the previous time step employs again a sigo activation function to decide which information is IR relevant okay I will not go into these things fundamentally we've evolved the rnns into the lstm networks those were equipped more with a memory and the ability to um eliminate certain information retain certain information um within the architecture so it gave it longer term memory uh sort of speak to retain its state for longer time which helped again the context part of uh training those models but you know up to this point it wasn't I I guess good enough um that it went to the public it wasn't good enough that it's something that you can um use um um in models that are uh scaled in the way we see today so you can see the challenge I think even with with these limitations or even with this capabilities that uh the lstms got it wasn't good enough in terms of context maybe it was good enough to do um very short translations but nothing more than that so the conclusion let's just read that I think always these are helpful in summary recurrent neural networks and long short-term memory lstm networks represent powerful architectures for process sequential data so we keep going to sequential data this is a very uh important one as before we progress while rnns are effective in capturing short-term dependencies lstm networks excel in modeling long-term dependencies by incorporating sophisticated memory mechanisms understanding the principles underlying these architectures is essential for leveraging their capabilities in various applications from natural language processing to time series forecasting and as research in this field continues to advance rnns and lstm networks are expected to play an increasingly important role in shaping the future of AI okay so again as I mentioned in the beginning uh rnns are still an important part of the architecture so that didn't go away so what we're going to cover next is not like something that replaced them I think it's the way to describe transformal architecture is one more technology that enables artificial intelligence so these two architectures that we just covered gave us a lot so the lstm gave us that longer dependency retention within the network but still it's I think the problem that remains with them is that um they have this kind of sequential limitation of the how the data flows through them um and um that that's a problem that we will look at later on and how it's solved as of now I think we have all the fundamentals to start looking at um basic concepts that take us towards the uh Transformer architecture and what that brought to the artificial intelligence technology okay so if you're watching so far honestly you could be considered the saint to watch so far and um at this point you know I feel ashamed to ask you to subscribe uh bearing that much I hope you're getting value if you're watching so far so hey if you like it do not forget to subscribe I would definitely appreciate that so now before we go to the Transformer architecture let's talk about tokenization embedding I think these are two concepts that um at some level we must understand not only for the case here of this video but really for anything when it comes to understanding AI models and how they operate so let's progress here and start with tokenization so tokenization is the process of taking the input text and partitioning it into small secure manageable units called tokens this uh these units can be words phrases subwords punctuation marks or characters according to open AI one token is about four characters and uh three quarters words in English Okay three quarter of word in English this indicates that 100 tokens are approximately equal to 75 words tokenization is the crucial step in natural language processing during this process you are preparing your input text in a format that makes more sense to AI models without losing its context once tokenized your AI systems can analyze and interpret human language efficiently let's take a look at the key steps to perform tokenization okay so it's basically uh turning text into tokens tokens as it mentions it could be words or part of words or even punctuations and it's just a way for the model to be able to understand the context or the the text that you are entering uh basically when when it says that turning text into numbers this is usually the idea so uh the step one of tokenization is something called normalization an initial step in which you need to convert the input text to lower case using NLP tools to ensure uniformity so everything is lower case so this is new to me so when you push something into um the the normalization process you don't have Caps or anything everything is lowercase you can then strip out unnecessary punctuation marks and uh replace or remove special characters like emojis or hashtags if you're prompting with um hashtag or if you're training maybe more accurately with um emojis or these kind of special characters those have have no value or bear no value to the model then you go to the splitting you can break down your text into tokens using any of the following approaches word tokenization the word tokenization method suitable for traditional language models like engram it allows you to split the input text into individual words consider the sentence the chatbots are beneficial H in the word tokenization approach this sentence would be tokenized as the word the chatbot are so each word in the sentence becomes its own token subword tokenization so this is a different way modern language models like GPT 3.5 GPT 4 and bir and by the way if you go to open AI um uh website they have a page dedicated to understanding how they do their tokenization use subword tokenization approach this approach breaks down text into smaller units Than Words which helps handle a broader range of vocabulary and complex paragraphs consider the sentence generative AI assistants are beneficial in the subword tokenization approach the sentence can be split as okay gener ative AI assistant and are benef so it breaks the actual word into part so it's not per word the character tokenization so character tokenization is commonly used for systems like spell Checkers that require fine grained analysis it enables you to partition the whole text into an array of single characters consider the sentence like I like cats the character based tokenization would split it to basically each letter and even spaces as you can see here um its own token now this is interesting if you remember at the beginning I told you uh the strawberry test someone mentioned to me it's about the tokenization part of it and the embedding so this is we might have part of the answer here I do not think that the character tokenization is the mainstream so for example if you go to open AI they use the subboard tokenization they do not use the character tokenization so the token as far as the model is concerned is not a letter it's a part of a word so it doesn't see letters so step three so after we actually tokenized so we've normalized tokenized now we're going to mapping in this step you must assign each token a unique identifier and add it to a predefined vocabulary adding special tokens you can add following special tokens during tokenization to help the model understand the structure and context of the input data so we'll do mapping and I think mapping will come in later and then we'll do um the special tokens and these will allow again as uh the tokenization to help the model basically understand the structure better maybe it's not really explained here but let's take it as it is okay so CLS CLS is a classification token added to at the beginning of every input sequence after the text passes through the model the output Vector corresponding to this token can be used to predict the entire input okay sep a separator token that helps you distinguish different segments of the text within the same it is useful uh in task like question answering or sentence pair classification so I think these are part of the special tokens they just give more context for the model as it runs through the uh input okay now embedding so that's the really important part embedding is a process of representing the tokens as continuous vectors in a high dimensional space where similar tokens have similar Vector representations these vector ctors are also known as embeddings help Ai and machine learning models capture the semantic meaning of the tokens and the relationships in the input text to create these embeddings you can use machine learning algorithms such as word to VC or gloy the resulting embeddings are organized in Matrix where each row corresponds to the vector representation of a specific token from a predefined vocabulary for instance if a Vo consists of 10,000 tokens and each embedding has 300 Dimension the embedding Matrix will be 10,000 multiplied by 200 matrix by 300 Matrix sorry the way I understand embedding and you can see we're talking about a huge number of dimensions and this is something that your brain can't even imagine um but the way if you want to think of it in our human context so imagine you are in a VR kind of um situation so you look at things in 3D and you have all the words in the vocabulary in that space and these are grouped obviously here we're talking about the tokens so could be parts of words and these are grouped in a way where it reflects the association of these words together and this is why I think like when when you do embedding if you ever went that deep um I did it in doing uh working with flow wise uh for example opening I have has its own embedding so uh all of these tokens or words for easier terms are grouped um where semantically they are similar so let's say the words that have similar meaning or are correlated to each other are within similar chunks or groups within that huge space so if you look at space for example you can find uh let's say door and knob so the word door and the word knob are in one group because these are related uh you can look at you know another group you can probably find cat and dog something like that this is how you imagine it and um each of them is represented with a matrix of numbers it's data basically and that data the way I which is the embedding uh the way I would describe it it is the GPS it is the coordinates of that word in that 3D space so if I give the navigator that number it will identify that word but if I give it the embedding of another word it can tell is that word close to the original word that or the initial word or is it far away from it if it's close that means those are within context those are similar in meaning or related in some sense to each other if they're not well there's not really high importance of the relationship between these two words together so just imagine it this way this is your uh this is your navigation to the relationship between words or tokens among each other in that kind of multi-dimensional space which is here they're mentioning 300 I think uh the open AI embedding it goes to 512 Dimensions but just the concept you want to grasp out of this that embedding is our way of going to that you know multi-dimensional dictionary seeing where all of these tokens are placed and how they are placed and in which groups and uh um in terms of numbers and are they related or unrelated to each other so let's look at this um example here so we have the mouse run up the clock and then the mouse run down so um we have all of these words here and this is will come later in the Transformer model we have here the sequence of these words so you know some of them are repeated so only here it's done once so we have the sequence of these word from 1 to six and you can see again the sequence of these words depending on the input so here you have the mouse run up the clock it has all the words one to5 here it has 1 to 3 and six all of those go to embedding layer output Dimension is four and these are the numbers so this is the embedding um representation of and this is multi-dimensional again of these of this input here and this input here and then you can build context just comparing all of these words and their embeddings to each other we'll go into that later but just remember remember it's a way for us to see where those word words fall into that space and how related or unrelated they are to each other okay I think so if you want to spend more time reading about this and going to the detail you can look it up on this uh link here all the links will be provided in the description but for us this is what we wanted to really understand we know what tokenization we have an idea of embedding now we'll go to the really important stuff which which is the Transformer architecture and everything that we've covered so far will play a role in understanding what that did and what it changed and where we're at today because of it so moving on let's go to this amazing article by Dr Ernesto Lee so thank you Dr Ernesto Lee you know I care of putting these resources again because of the people behind them so Dr Ernesto made this blog post to explain intuitively in an easy way uh the uh the the Transformer architecture um and the paper that basically broke that technology out to the world which is attention is all you need we're going to go to the paper itself later on but I thought the first run through this is through someone trying to explain it in layman terms to someone like me someone like you and later on we go to the paper because it's very important even if you understand the idea here I recommend to everyone to go to the original paper attention is all you need and read through it it's an amazing amazing paper to read um and even if you're not technical person you're going to grasp I would say at least 60 to 80% just by going through it at it different and whole new level of understanding it elsewhere so the intuitive explanation of attention is all un need the paper that revolutionized Ai and created generative AI like chat GPT like this title says it all this is the technology that brought us generative AI that we know today at least at a scale at you know consumer scale consumer level something like chat gbt is just started with this technology which came in 2017 so this is the technology that makes chat GPT works this is the architecture now we're going to go step by step to understand this the way I'm going to um try to explain it I'll try to go through the architecture in my own understanding today and then we'll go to break it down into bits and pieces to understand it further and further and further and hopefully uh um by the end of it we'll have a much commonly me and you a much better understanding of this architecture and what it means again I'm not a technical person I'm like you trying to learn so if you see me struggling this is my way of making and putting things together this is my brain you know my human intelligence now there's a name for our intelligence called human intelligence works and I'm training my brain to really learn artificial intelligence so I'm running my own um um Transformer architecture in my brain to make sure at the end of this I'll have an updated fine-tuned model that understands AI better so here um this is the architecture in general and the the main thing about it that you have this what they call the encoder block you have here the uh decoder block and you have inputs and you have outputs going out and eventually you'll have a final output which is a probability and the way it works is you push an input so imagine the input as a text similar to the examples went through sentence I ate the apple for example or uh let's make it a part of a sentence so um the Apple dropped from so what's the word after that so imagine you put only this sentence and you end it at from so we take that input we go through the embedding which we covered so what the embedding will do it will take all of these words give them that kind of uh Matrix that position them in that you know embedding dictionary that 3D space where each word Falls and then we're going to do positional encoding if you remember uh just now we looked at it so we're going to give them the easiest term a number that gives them the sequence so what's the pos position of each word this is word one two 3 four and once we have that we push it to the encoder now the encoder what it will do it will go through what's called a multi-head attention and this is where the money is when when it comes to the the Transformer architecture this is really the the the brains of it and what it does here and what what it brought to the technology that wasn't there before it was able to give context real context and in a parallel manner so this is where things are not happening sequentially so what it does it takes all of these inputs and positional encoding sums them together and what it does is push them through some kind of algorithm that will look at the embedding of each word in relation to the other words and it will create that kind of you the easiest way I describe it a heat map so which words are more related to the other words and this is from the perspective of each token that is going in and this is why it's called multi-head attention it all happens in parallel so all of these kind of matrices or heat Maps happen together and you can the the model will see each word and how it Stacks against all the other words in terms of of attention what is the when we say attention what are the other words that are the highest importance to that um uh to those other words in the input so for example we said the um the Apple fell from right this is what we said so um is the related more to the apple or fell or from and so forth it will do it for each of these words and through this multi head attention uh calculation and after that it will do a um adding and normalizing of that data so it can process it further and it will push it through a feed forward Network this is your normal Network here again it will do an add in norm and then the output of the encoder which has by this stage all the input information with its uh embedding and positional uh encoding so it has the meaning it has the positions of the words but also because it went through the multi-head attention it has that context ual contextual knowledge of that input of which words matter more to which other words so it understands the relationship between words the easiest way to put it and all of that goes into the decoder now again the decoder is um remember this is part of the bigger way of how this operates so here you we want to um predict the from so this is it says shifted to the right so we said the Apple fell from what's after that so that output prediction or the expected output goes into the same process so let's say at at the first word nothing happens here it's blank I would assume is my understanding because we have one input still it didn't generate the next word uh but eventually let's say after from it will put the that Apple F fell from the and later on three will come for example so once the is generated when it comes to running for the word after that uh to to um put the probability of three the will be the input here uh towards the output decoder part and it will go through the same things it will embed that word it will give it a positional encoding it could be a couple of words and then or tokens it will go through the um masked multi-head attention so it will put the context of the output and here it will do it again but here it is linking it to the input okay so it it has previous words the input plus previous words it will give it like that longer context so the Apple fell from the tree now maybe it will continue after that and then it will normalize at each stage obviously push it through a feed forward then it will make it kind of a linear softmax is a certain special type of function that will give probability for all the possible outcomes so for example at at this output it will say the Apple fell from the and if so all of these are possible outputs the softmax will give probability let's say the is 60% if is 3% you know so each possible output will get its own percentage eventually um the highest probability or the highest percentage will be the output of this in our example the Apple fell from the tree it will be most probably that the entry will be the highest probable next tokens to fall after the input this is is in the shortest sense of the form how I understand today the uh Transformer architecture the thing that it did which wasn't there before is that M multi-head attention getting the context so it understands words in the very similar way that we do so when when you hear someone saying the Apple fell from the you have the context of that statement and you know because of these words probably after that will come there and then maybe most probably a three there's a context of the Apple foring from somewhere to somewhere I don't know if I complicated more for you or made it simple I hope I made it simple but this is in a nutshell the um the transform architecture if you don't really want to know more about the details of it you can uh jump off the video here but now we're going to go into really really interesting stuff believe me it's intriguing and really interesting to learn how all of these blocks work we're going to go for it I will not uh uh go for like deep deep understanding of the equation and the math behind it I just want you to have that knowledge that will make you above 99% of people around you who understand artificial intelligence which will enable you to do much more if you ask me with AI even with chat gbt once you understand how this thing works obviously this happened in 2017 there are developments happening around it so I don't think today the way they train the models it's exact exactly like this but this is definitely is the DNA of it so 90% of what they use is the Transformer architecture that you're looking at and we're going to look after that at what's happening out there that could take us to the next level of the transform Transformer architecture what what is next there that could really even make AI models much much better okay so let's let's carry on so this is I gave you my understanding maybe you liked it maybe not but let's go and um this is just an intro to the to the concept and you can see it was this paper was published in 20 2017 it was uh the introduction of the transform architecture okay and and you can see here before I move forward um uh prior to the Inception of recurrent neural networks RN ends and their variation of lstm and Gru I don't know honestly what gru is write me a comment in the comment section if you know what this is were the go-to solutions for sequential data processing while effective these models had the itation particularly in terms of training efficiency and handling long range dependencies with data so it's less about the sequence here it's more about still the dependencies okay Enter the concept of attention this is why it's a brilliant title you know it's like a YouTube video If you give it a wrong title it will not work so they gave it a really good title attention is um is all you need so this is why this paper focused on attention so rather than processing data sequentially well I'm right so it's more about doing things in parallel so rather than processing data sequentially the attention mechanism allows the model to focus on different parts of the input data providing it with the kind of shortterm memory to discern what's essential this Innovation enabled models to capture intricate patterns and relationships in data with remarkable accuracy so why is the paper of monumental importance basis of subsequent Innovations the Transformer architecture forms the foundation for models like Bert I think this is the early name of Google GPT and T5 which have dominated NLP task ranging from translation to text generation so this is the translation which was the thing they everyone played with before to text generation this is the generative AI part elevated AI capabilities with the power of attention AI models can now generate more coherent and contextually relevant content this led to enhanced chat Bots improved search engines and more relat language translation tools again just to pause here for a second I think at this level you also in your mind you can imagine why the model hallucinates like the way it works the way the Transformer works of predicting the next word based on relationship it can easily get things wrong so Hallucination is part of um uh this kind of idea of how it works so the understanding of the details of how models operate I think it will help you even navigating your your interaction interfaces with AI models anyways democratization of AI the rise of pre-train models which owe their Genesis to the Transformer means businesses and developers without vast resources can now access state-of-the-art AI capabilities now doing things in parallel means and I'm assuming here that you need less computational power to train certain models um obviously with a specific number of parameters I think the more than parameters the more computational power you're going to need but and and this is one of the biggest problems in AI today we know that's totally expensive like the one of the most expensive technology uh to to perform today is training an AI model and um that's affecting things in so many ways so it's limiting certain Societies or areas or countries to have access to the technology so by doing these Innovations which were're not there yet I think in the future people are still working towards things that will require less computational power to get higher quality models you will give access to more people to benefit from this technology and that creates value you know I know that's different topic of AI taking jobs y yada these kind of Technologies they create lots of value that maybe one of the scenarios they remove the threat of that technology to people losing their jobs because lots of money lots of value will be created in the market so you want to make it also um as one aspect of looking at this techn ology of how do you make it accessible for more people again just a you know stop in the in the middle of all of this so let's carry on but these are some of the main importance and what this technology or the Transformer architecture brought to the world of artificial intelligence the attention mechanism explained imagine you're reading a lengthy novel and every time you come across a pronoun like he or she you instantly recall who it refers to from the previous paragraph or chapters instead of reading the novel linear from uh start to finish and understand every sentences context your brain intuitively attends to the relevant part that helps make sense of the current sentence I think this is a better way of putting what I try to explain but so these kind of pronouns when we read something we just keep relating them to the right character or the right thing basically so this is what the attention mechanism uh did for artificial intelligence this ability to refer back or pay attention to specific parts of the text for comprehens for comprehension is exactly how attention mechanism in neural networks like chat gbt okay let's take an simplified example let's do that I think the is like what's if it's simplified I want to work with it so the sentence Dr Lee who loves his dog Daisy often takes her to the park and gives her several good boys okay I think this is how you pronounce it or how you say it if you want to know who her refers to your brain would likely attend more to the world Dr Lee and dog Daisy to drive the context in essence you assign different weights to different words based on their relevance so the weights are basically what we get out of these um attention heads okay so let's go to the attention mechanism so but you understand the stage we want we want to get um want to give a Mark or grade or weight for certain parts of the context to to really understand it at least for the machine to understand it and this is what takes us to this mechanism words in a sentence are assigned different weights these weights determine how much Focus or attention each word gets when trying to predict or comprehend another word connecting to CH okay CH like other Transformer based models leverages this attention mechanism when you pae a question the model doesn't just look at your current message in isolation it attends to various parts of entire conversation context assigning weights to different parts based on relevance this ability helps the model to generate relevant and contextually appropriate responses so just as your brain attends to specific words in our example sentence to understand the reference to of her chib attends to different parts of the conversation to provide a coherent reply so it's not only looking at the input today it's looking at the input and the context of the conversation or the thread that you're having with chat GPT so imagine all of that amount of data is assigned weights and the model is able to tell what is more important uh to all the other words in the context for each word so it will predict the next one I hope I made that clear so again we go to the uh same architecture how it looks I went in my words of how that should be explained I'll just go to Snippets of the things Dr Lee is highlighting here and then we'll move to different sections of really digging deep into the sub areas of that architecture so the first one is embedding and Source sentence so here for example you get the catat on the mat so you input sentence the catat on the mat the model First turns these words into numerical vectors through a process called embedding we looked at embedding we're not going to dig deeper but again we turn text into vectors of numbers which will help the model understand in the space like where that word Falls okay and then we have POS positional encoding so this is the step we talked about and this is the one that assigns a sequence number for each word so the cat sat on the mat so this is a matrix single layer Matrix of um uh which has the numbers of each word so you you know the sequence of the words so we have 1 2 3 4 one again which is that and then five since Transformers don't inherently understand the order of words this step adds information about the position of each word in the sentence so the word cat might get some positional information indicating it's the second word so simply it's a number just to tell the model this is where the word Falls within that context in terms of sequence not attention multi-head attention or multi-headed attention so so this is the left side because we said we have the encoder and the decoder side left and right so cat and sat are important and related in the sentence so this is what happens it runs through each of the words against all other words in a matrix um based on the sum of the embeddings and the position and it will you'll see why I keep using the term heat map it will look at the numbers and let's say the higher the number the higher the weight the higher the attention it should give to that word and that context so this is the magic step where the model figures out which words in the sentence are important and relevant to each other here it might recognize the cat is closely related to sat because the cat is the one doing the sitting adding and Norm so we talked about normalization in in previous um networks when we talked about the RNN it was at that time making everything lower case let's see if this is the same one here after attention is applied the model normalizes the data ensuring it is in a format that is easy for the model to work with Okay I think this is is more around numbers nothing to do with the normalization we talked about full understanding of the input sentence and what words are important and what words are related so again this is pushing the data out of the attention multi-head attention so the attention data pushing it in the network it will get the network to understand okay so I need to focus on this and this and this fur further these TOS are linked these TOS have nothing to do with each other it's not that important of a connection so that's the the the actual Network that does this understanding based on the multi-head attention so this is just a simple neural network that does further Transformations on the data output embedding and output sentence so start assembling the translation and look at preer translations so this is basically an example showing a translation of this sentence um that does with the cat sitting on the mat so the decoder starts its process by looking at any prior translations initially it might just be the starting token indicating the beginning of the translation if you remember we had those kind of special tokens in the tokenization so the first token because there's no like the first word to be translated that doesn't exist yet so you'll have to start with it so there will be a special token that will um highlight or flag to the model that this is we're going to predict now the first word it will not take any real um uh output input basically maybe that will confuse you but it will not have anything coming in here um other than later on the output from the encoder so that will be the first word after that first word is out I think uh that will be the input uh for the uh second word to be predicted the decoder starts is processed by looking at any prayer translation initially it might okay so we just mentioned that U masked multi-head attention so uh on the right side the decoder we have two steps of the multi-head attention one of them is mask and one of them is un mask and when we say mask if if you ever dealt with images or Instagram if you do these things masking an image is just highlighting an area you want to keep and the area that you don't want to keep so this is the mass multihead basically do a little bit more to uh just mask out certain parts and keep certain parts this is the way I am understanding it if you think I'm wrong write a comment in the comment section so what are the best words to include in the translation based on what's already been translated but don't look ahead so basically this is all happening without considering um what's happening later on so not looking ahead and based on the words being translated focused only on the output this is how I understand it again um this will uh decide you know what to include and what not to include later on it will get mixed with what you're getting from the input embedding and or the the other output or the previous output that will change but uh for some reason we have to do it purely without masking it purely to the uh output itself and to the full context maybe doing both will give us higher quality kind of translation or generative um um context of the words that the AI is predicting the decoder pays attention to the previously translated words this is masked to ensure the model doesn't look ahead at Future Words which it shouldn't no yet okay so as I mentioned before the output will be multiple options and predictions so you don't want it to look at those future possibilities just focusing on the uh previously translated words only and later on the the output will be all of these multiple options with probabilities that to use to select the next word I know you know this can get more complex again the more you dig deep into the science behind it or the math behind it maybe more accurately you'll understand it further I will give you the tool to do that if you want to do that I didn't do it myself but I'll give you that tool um but just here I hope you're getting the flow of what what this is doing for us we do the first MTH multi-ad attention then we do the next one again each of them comes with the ADD and Norm or normalization so the second one is using the preer translation plus the new text that was input remember it is the it is represented as a number okay identify the best words Poss probabilities okay so here we mix both we take the prior translation the new text that was the input so we give it the first input and then it will start predicting the input so the first word will go to the input here maybe this is the part where I get confused when I look at the Transformer architecture if you have the answer correct me so let me read it one more time time using the preer translation plus the new text that was input the word here is new it's new text that was the input okay so maybe this is at the first run still this is the input that we were looking at so the cat sat on the mat it's the same one remember it is represented as numbers okay identify the best words probability okay so I'll take it as I understand it I'll not complicated basically it will take the um previous word it will take the input and it will start giving the probabilities of the next word once the probability of the next word comes that word will again go here to the input shifted right and this is the loop here this will keep looping I think so it will not go to the input the input is standard the loop will happen here in the decoder part this is why sometimes they call it the encoder decoder so I'm just presuming here now the decoder also pays attention to the encoder's output trying to figure out the best words to trans late next so it might look at cat and decide the next French word should be Shia I think or Shia I don't know I not try to translate here to French add a norm important from a tech perspective but not so much for an intuition perspective so okay we need to put numbers in a certain way um for us to put the probability and the words uh going forward and then again the data is normalized feed for the neural network does its Transformations and then we go to the linear and soft Max convert numbers toward so this is the opposite of embedding so this reverses the embedding taking the numbers putting them as words and I assume this is again going to something similar to the embedding where takes the numbers goes to the word in that kind of 3D space we talked about picks the words and drops it out this is the function that does that I assume um these steps convert the decoders internal data back into actual words after going uh through this the model might output the word sha or shat um as the translation for cat this process continues for each word until the full sentence I will not read it in French is generated remember this is a very simplified example in reality the model considers many possibility translations at once and uses complex math to choose the best words so this is what I I keep telling you about the output will be so many words with probabilities and the model usually selects the highest probability as the word that should come next okay but this should give you a basic idea of how data flows through Transformer when translating a sentence okay so again here is giving one more example I'll will not go through it you can read it but this is the the highest level or broadest level of understanding how the Transformer works now let's understand one concept before actually going to the multi head attention which I said the most important part of about the Transformer and then I'm going to look with you at the paper we will be repeating some Concepts when we look at the actual paper but I think it's very important after that it will be the fun part where we look at things we can have or the future what it will bring um I keep reminding you of the U because this is a long video of what's coming so let's move to the next concept before we move to the um uh the multi-head attention concept and then the paper of attention is all you need okay so we're going to go to look at something um these are efficients or coefficients or factors that are very important to understanding how the multi-head attention works the qk and V which is the query key and value um we're going to go briefly at them I don't expect you to really understand them 100% I don't understand them 100% but at least this helped me um grasp the idea of of how important it is to the calculation that goes behind the multi-head attention and based on that it helped me understand the multi-head attention more so that's the whole um reason I'm covering this here later on we'll go to the multi-ad attention it will be uh these kind of three the query the key and the value will keep coming up at least when that happens we'll have the understanding and will not be lost in in that explanation of the multihead ention so that's the whole that's the whole um idea of me covering this quickly as as quickly as I can um okay so let me read the introduction to this um article on LinkedIn uh by this Chief digital and Technology officer at constellar okay in the realm of natural language processing large language models llms like gpt3 and birth have revolutionized how machines understand and generate a human language at the heart of these model mod lies the concept of the qkv and the multi-head attention are the key it sounds cryptic to me at the very beginning and it takes me a few weeks to figure it out so imagine someone like that is saying you know it sounds something complex for me to to grasp took them took him um weeks to understand it but again so if if if so that's very humble to mention in such an article very welcoming for someone like me to read um so if you don't fully grasp it yeah the person telling us about it didn't get it from the first time but we just want to get the idea behind it so um the following is what has been explained in the paper so this is the scale do product attention and multi-head attention so so these are two types of attention mechanisms I assume but forget about these details let's look at the multihead attention this is what we want to really uh focus on you can see the way it receives the information if you remember in the original architecture when we looked at it once the embedding and the positional sequence happens we put them together and then we uh push them to the multi-head attention the way it goes in it goes in through these variables let's call them variables for simple terms which happen on a multi-layer so in parallel we have V which is the value key K which is the key and then Q which is the query and so let's let's try to understand them and see what what is the multi-head attention is getting as an input for it to be able to do some calculations to give us the map of where attention should go before it push pushes that to the feed forward Network so the query represents the current item that the model is focusing on in this in a sequence the query is like asking a question about a particular element okay so let's say we have the the cat sat on the mat let's let's work with the previous example when we are looking at cat cat is the query this is how I understand it so cat is the element um in the sequence that we are focusing on key represents all items in the sequence that the model could focus on the keys are what the query is compared against to determine how much attention should be paid to them so the key I would say is the other words so if we are if the query is cut uh the the key would be the sat on the mat so without the cat so it's all the other values that the query is measured against to see where attention is going the value each key associate uh is associated with a value once the model determines which keys are important based on the query the corresponding values are used to construct the output so each key is associated with value so I I think this is the value it could be an input but at the same time it is the main output out of the multi-ad attention I think so let's read on but this is the value that we have now we know what's the key we know what's the query so the query is the word the key is everything else the context around that word the value is what gives that weight let's let's use the original term of each of the key parts of where attention should go more or less when it compares to the query which is cat so let's read this part maybe this explains it a little bit more a simple sentence like Tom is going to fish at the river bank is easy for us to understand to let computers understand it we need to encode every word into numbers which is called word embedding that's we understand assuming in a simple six-dimensional space the word River can be represented as a word embedding of okay he gives it just numbers just to show an example of the embedding of the word River those words with a higher similarity will uh be close to each other for example Group One River fish and uh fish Fishman group two Hospital post office and restaurant it becomes interesting when we try to figure out where to put the word bank it is a policyi that can be interpreted differently based on the context of the sentence in which it is okay so again this is just about the embedding still and we we talked about it that 3D space and imagining how these groups of embeddings are um put together so different tokens are more relatable to each other so he's just explaining it in simpler terms the same way but he he he brings um um an interesting point so Bank the word bank it could be here closer to this group or closer to this group so river bank so how does it differentiate or the bank itself so how does it differentiate where this should be associated with I think this is his question here when we read it we know a bank cannot be the place where you draw money why well the presence of the words river and fish contribute more to our understanding of the context compared to the rest therefore they should have high attention scores and be closer to bank okay so let's go back to the important part where we're going through this article which is the query key and value how does a computer determine uh that it should pay more attention to River and fish and not others this is where query and key comes in they are two linear Transformations that help answer the question within this sentence what are the similarity scores among the words first okay so here we have all these linear matrices so we have each of them as a linear Matrix and you can see these are a bunch of numbers some of them when you do a certain calculation on it be closer or farther away from each other so I think river is the query so the river is the query we're looking at the key is everything else so the multi-dimension basically when you put them together um Matrix of the other words so this is just um visual depicting the uh key and um the query here so we have the bank and we have the river similarity okay so this is just uh showing you how all of these come together you can see the value which is um kind of putting together the query and the key so we have the width of the Matrix the dimensions based on the query I assume here here you have the rest of the keys um I think this is like inverted The Matrix is inverted here so all of this is mathematical operations that happen to the embedding and positional data that comes in to make sense of it the easiest way to put it and then you get the value this is the value that tells us okay this token is more important to this token and this token is less important to these token the output goes through the steps match mule scale mask and soft Max all of these are operations mathematical operations that are needed to prep the data to go into the multi-head attention and even later on to be pushed into the feed forward Network and even to be pushed as words that we get from the model now in the previous um article if you remember Dr Lee didn't want to go through that because he wanted to keep what's important to understand the context of the Transformer here it's going a little bit through that I want us just to grasp the concept of how the query key and value work so um just just uh understand that Matt mule scale mask and soft Max so we looked at mask like the mask multi multi-ad attention and the unmasked one so just understand that these are mathematical operations that happen to to manipulate the data this is the easiest way to put it we are manipulating the data to be able to get really the output that we want and there's lots of computing behind it and lots of Genius kind of mathematics people created to really get us to that so we're not trying to fully understand that today so let's carry on we then have the final output a weighed sum of these values where the weights are determined by how well each key matches the query so we're just matching that those keys to the queries we're giving it values the V and that's it we're good to go and uh use that information so the new embedding compared to the original one captures more contextual relationships I I think this is what happens in the multi-ad this is the mult like this is a single head of the multi-head um attention so it's all functions that the query and the key goes through eventually uh the value is added which we'll have to really uh grasp later on is the value just the input embedding or it's an outcome of the whole thing so but what I understand at least from what is being said and the graphic here is that the input is one which is the sequence and the input embedding we take it through certain functions that based on the query and the key will tell us what's attention should be given to which Keys compared to the query eventually that output will be different from the input embedding goes in with the value which go into that mat mule here and really give a matrix that contains the information of attention for the key and the queries and this will happen for each query within the all the possibilities of the keys in parallel uh in the multi-layers OR multi-heads of that attention calculation or manipulation of our data hopefully that makes sense so this is just a look at how maybe the possibilities are looking when you match each uh query with the keys and it generates numbers the higher the number the more attention is given to that key um I think this is interesting so um this just uh uh this part is just saying that is one set linear projection representing so-called attention head okay where okay yeah so so here it mentions that this is also um applicable to images somehow so you can use it for images to understand the objects in this image if you remember we covered the convolutional networks and I told you Transformers didn't only re revolutionized the neural networks the general ones it also affected the convolutional neural networks which has to do with images anyways so we understand the concept of q k and V those are the embedding now the query is the part of the embedding that handles the word that we're looking at the key is the input embedding that handles everything else that is in relation to the query and the value is in theory the weight that is given that could give us the the understanding of attention for these words they go through certain functions at the end we have um a big Matrix multi-dimensional Matrix complex one that contains all of these information it has the sequence it has the uh attention uh relationships between the words it has the queries and the keys and the values all of it is put in one huge Matrix that we later on if you remember normalize and push to the feed forward Network so that's just the concept that you need to grasp now we can actually go and look just at the Transformer um U when it comes to the multi-ad attention um and go a deep dive on that and then we'll go to the paper want to give more time for the part of the Transformer architecture that really gave it its its superpowers and the importance that it got and everything it brought to us from 2017 so far so this is a paper by kitan DOI around the multi-head attention particularly so let's scroll down okay so how attention is used in the Transformer attention is used in the transformer in three places self attention in the encoder uh the input sequence pays attention to itself so this is the self attention again this is the encoder this is the decoder if you remember and you can see that now I think all of you should if you paid attention you should understand what is happening position encoding embedding Target um this is yeah input and Target Target so this is the target word so I was correct so you understand how these thing work uh these things work so you you now have you're more Savvy when you look at the architecture you get it um we want to just dig deeper into this these parts of attention the encoder decoder attention self attention self attention we want to dig deeper in that and really try to understand it because this is where the money is when it comes to these um to this architecture so the first one is self attention in the encoder um the input sequence pays attention to itself self attention the decoder the target sequence pays attention to itself and encoder decoder attention in the decoder the target sequence pays attention to the input sequence okay this might have been very broad or not articulated in the detail but this is the beginning of this article but for us we understand is here this is the self attention for the input I'm just um simplifying it here this is the self attention of the uh expected output or the projected output this is the encoder decoder attention which is the attention for the expected output plus the what we get from the input and then this goes to the output probabilities in in layman terms okay let's go to the more details within those self attention mechanism the input sequence is fed to the input embeddings and position encoding which produces and encoded representations for each word in the input sequence that captures the meaning and position of each word okay so this we get which is the embedding again and the sequence position sequence um now let's carry on this is fed to all three parameters query key and value in the self attention in the first encoder which then also produces an encoded representation of each word in the input sequence that now incorporates the attention scores for each word as well so now see it's easier to understand because we already looked at the query key and value so we take the embedding and the positional encoding we um there's some manipulation that happened and out of that manipulation we take the query which is the word we're looking at we take the keys which is other words and the values we push them in a way that will give us let's say a body of information or Matrix that contains uh the attention relationships of the input uh keys uh that we have within our tokens okay so we now we have the input or the encoder attention figured out in a data block let's let's simplify the term to this okay so U so as this passes through the encoders in the stack each self attention module is also adds its own attention scores into each words representation okay so this is uh just one graphic to look at so we have input embedding and position encoding it goes to you have a m matx here okay there's a sequence and there's an embedding obviously this looks as a single layer I don't think so this will be um multi-layered even at this stage here and then some manipulations that we've seen before happen uh that breaks it to a value key and query these are again functional manipulation I want to remind you things that we play with the Matrix to get parts of the Matrix modified mat matrices with the same size or different size that we need to have to have the value key and query which each of them as we know now gives different uh piece of information all go to the multi head self attention which is again a different level of functions that run through these M different matrices and then we get the uh um uh the encoder output we go and feed it back to the second layer here but before we do that uh remember there's normalization here because the way the output comes out of the encoder has to be normalized before it goes to the encoder decoder attention in the decoder but here it's clear because here they're showing the normalization so here the same happened output embedding and position encoding this happened for the next sequence word this is the Matrix that we have then we manipulate it again for Value key and query it goes to the self attention manipulations of its own so different type of functions it will give us all of the information we have so far in this one big Matrix that we normalize and that Matrix that we normalized goes as the query for the encoder decoder attention this is like the interesting part here what we get here is from the input is the value and key so the only thing we're getting from the input is the attention of the query and it's a relationship to all the other Keys um while the query becomes the expected next output word in the decoder okay so decoder self attention now I explained it let's just read it quick coming to the decoder stack the target sequence is fed to the output embedding and position encoding which produces an encoded representation of each word in the Target sequence that captures the meaning and position of each word this is fed to all three parameters query key and value and self attention in the first decoder which then also produces an encoded representation of each word in the Target sequence which now incorporates the attention scores for each word as well so this is the same what happens in the encoder we understand it now we'll go to the encoder decoder attention which is the interesting one along with that the output of the final encoder in the stack is passed to the value and key parameters in the encoder decoder attention the encoder decoder attention is therefore getting the representation of both the target sequence from the decoder self attention and a representation of the input sequence from the encoder stack therefore produces a representation with the attention score for each Target sequence word that captures the influence of the attention scores from the input sequence as well as this passes through the decoders in the stack each self attention and each encoder decoder attention also add their own attention scores into each words representation so that's a mouthful the way I will simplify it to you so so and and this is why it's important to understand the the query key and value so when we do the encoder we break down the um inputs into the key value and query we look at the query versus all the other Keys We assign values to them we get the output as a matrix now the decoder part the output part as we are producing the um next token or next word and the probabilities we are doing that number one in relation to the words and that were generated and are being generated also we're keeping that as a query as a whole in the second layer we take it only as a query the output of the first um um decoder uh uh self attention phase on the right we take it as a query to the second uh encoder decoder so we look at the word that is being predicted in context as well so we have the information of the attention with the input itself so it's linking everything to each other so not only we do it once looking at the words uh uh where the input is how the input keys are related to each other we actually do it to the output also in relation to itself and in relation to the input so if you want to think about it all the words in the input and the output going through the Transformer are mapped in terms of attention of these words to each other all of them input the previous words in the output and the possible words in the output coming out so this is how we decide the next word so the more we generate output in relation to um a certain query we are looking at the input the previous outputs that were generated at high probability and the next word is decided at the attention based on all of these Keys together um uh uh put together in that complete context so we're not only looking at the input we're not looking only at the output we're actually looking at the whole the model is looking at the whole thing when it's predicting the next word this is the power that made generative AI be able to give us words it still hallucinates we know that but for many ways it gives us the next word which is highly probable unexpected um term or word within the model that is generating that makes sense even to us as humans because it's looking at complete con context now we're doing it with a very small examples like the cat at on the mat imagine that at paragraphs this is what you do with chbt and C today so the whole context is part of it and I assume today from what we've read so far even the thread the whole context of the chat the Open chat is part of that context and now in open AI they actually gave it memory abilities so everything that you interact with when it comes to chat GPT potentially is also part of that attention calculation um in the Transformer so this is like the the whole idea that was generated in the Transformer architecture gave that open door for doing all of these manipulations where you can actually generate real context in the data that you provide the model and you gave the model the ability to see that context that in the past it wasn't able to see at um in parallel which helped the Computing and where in the past as well it couldn't see it at longer context or longer sequences of dependencies okay before we move on to the paper let's just look at this the multi- attention head in the Transformer the attention module repeats its computations multiple times in parallel so this is why they call it um multi-ad attention so or multiple attention heads because it does it multiple times in parallel each of these is called attention head the attention module splits its query key and value parameters n ways and passes each split independently through a separate head all of these similar attention calculations are then combined together to produce a final attention score now the way I understand even the splitting of the query keys and the the values is done in different way I'm assuming if my understanding is correct correct me if you know more in the um um in the in the uh comment section is that it will do it for each query so each word in that context and the other keys so if we're looking at cat we look at the other keys if we're looking at Matt we're looking at cat as a key not a query um and so forth so we have that multi-ad calcul happening at all then all of it is merged and we have a matrix eventually that encompasses all of that attention relationships within it okay attention hyper parameters again the embedding size so here you know if you want to carry on with this part on your own this is interesting I did a quick read for this it just again explains simple to uh similarly to what we did already it shows you the way these uh matrices are being um manipulated changed modified masked whatever you call it for us to get the end result that we get so splitting of these matrices masking these matrices reshaping them you can see all of it here again for me I want to understand that this is happening you can see Swap and three shape I want to understand that this is happening to get to the result um maybe at a later stage I will go more into the actual calculation it happens for these matrices to get what we get um if you're interested I'm going to give you this um link as well as everything else you can see masking here and yeah so just understand that this is part of the manipulation now I think even if you stop here you understand the Transformer architecture for the most part um I want to spend little while on the paper itself I will not go through everything because at this stage I think we covered it and then I want to go to the Future and the cherry on the top me giving you certain tools that took me some time to find that are amazing for understanding this at a whole new level even more than what you can get out of this video so let's go to the um actual paper so this is the paper again I'll not go over the names of the great people that gave us the Transformer architecture the name which I said it's an awesome name so whatever whoever is doing this actually could be really good in doing YouTube videos attention is all you need okay I will read the abstract quickly the dominant sequence transduction models are based on complex recurrent or convolutional networks neural networks that include an encoder and decoder the best performing models also connect the encoder and decoder through an attention mechanism we propose a new simple Network architecture the Transformer based solely on attention mechanisms dispensing with recurrence and convolutions entirely so basically they're removing the whole concept of recurrence and convolutions and they're solving so many of the problems that we covered in those kind of attention heads that we talked about in the architecture where it encompasses all of the information the model needs really to be able to predict the next word our model achieves again this is these you'll see all of these kind of blus um these are what I read about online these are kind of metrics related to translation accuracy so don't worry about it so because the example or the testing they did the training for preparing this paper they did it for a translation kind of job so our model achieves 28.4 blus on the WMT 2014 English to German translation task improving over the existing best results including uh embl by over two Blu on the WMT y yada so just saying how well the job did or was done uh when using or when deploy deploying the Transformer architecture um so again I'll just go to certain things that I think are interesting uh to read everything else you can read it for yourself it is definitely something everyone should read um but we already I think covered the important parts of the Transformer architecture so let me go to the model architecture most competitive neural sequence transduction models have encoder decoder structure here the encoder Maps an input sequence of symbol represent representing X so these are the inputs to a sequence of continuous representation Zed given Z the decoder then generates the output sequence of symbols so these are the Y's the output um one element at a time at each step the model is auto regressive consuming the previously generated symbols as additional input when generating the the next so as we already explained it takes the input and the output that it predicted as an input as it predicts the next word and the one after and the one after and this goes through the encoder decoder stack so this is the original you can see even it looks cleaner the orig original architecture that was created um by this team okay so um attention I just want to read again lots of repetition here I know but it will just help so I want to to read you attention in their words an attention function can be described as mapping a query and a set of key value pairs to an output where the query Keys values and output are all vectors the output is computed as a weighted sum of the values where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key we already discussed that keys and uh queries relation and values scale do product attention Okay so these this is what again here here um uh what we discussed before but again these are the functions just to make it Crystal Clear if I didn't yet do that these are the functions that you have here so in the multi-head attention in each head in each layer you go through each of these manipulations or modifications that we talked about you can look any of them up and see the calculation behind them so just to make this crystal clear so we covered that we have the Q K and V we get everything that we concate later on basically put together group make it linear so it goes to the feed forward everything has to go linear to go to the feed forward neural network okay you can get the soft Max and equations related to it here and they talk about the multihead attention that we already covered again the equations are all mentioned here I I think it gets more complex than this they just put it in a paper for um for peer evaluation I would assume so people who are evaluating this paper probably know these concept cepts they're just giving them the high level modification of the architecture that they've done like what's they're bringing as a change all the other you know sub calculations that you need to figure out for you to be able to just look at these kind of seemingly simple calculations you must already have knowledge of um so don't think it's as simple I don't think it's as simple um and I'll show you something that will help in that sense later on applications of attention in our model again how the attention is used and positive wise feed forward Network embedding and softmax again how you embed something and how you turn it back to a word uh positional encoding again some details around how that works it's not simply one two and three there's um some some more details around that so in all the Articles we looked through it it was only simple sequential numbering which is um as you might have expected is not the way to do it or probably not the way to do it and then why self attention this is an important part I want to read in the section We compare various aspects of self attention layers to the recurrent and convolutional layers commonly used out for mapping variable length sequence of symbol representations again the inputs to another sequence of equal length which is the the the Zeds here with the um the this is actually the function that um compounds all of the uh summations of the inputs and the weights together such as hidden layer in a typical sequence transduction encoder or decoder motivating our use of self attention we consider three deata I think this is how it's pronounced one is the total computational comp complexity per layer another is the amount of computation that can be parallelized so done in parallel as measured by the minimum number of sequential operations required the third is the path length between long range dependencies in the network learning long range dependenc is a key challenge in many sequence transction tasks one key factor affecting the ability to learn such dependencies is the length of the path forward and the backward signals have to Traverse in the network the shorter these paths uh between any combination of positions in the input and the output sequence the easier it is to learn long range range dependencies hence we also compare the maximum path length between any two inputs and output positions in network composed of the different uh layer types so basically what they're saying here as I understand it is one of the the amazing things about the Transformer architecture is doing this multi- attention heads in parallel will reduce the length between input and the output and in simple terms it will allow it to contain or maintain more context or um more dependencies Within that range compared to doing things in sequence and this is was one of the problems that we had when it came to the uh recurrent neural networks if you remember and the convolutional ones which they refer to in the beginning of this paper as noted in taper one the self attention layer connects connects all positions with a constant number of sequentially executed operations whereas a recurrent layer requires o n okay this is the the sequential operation in terms of computational complexity self attention layers are faster than recurrent layers when the sequence length n is smaller than representation Dimension okay so this is again some of the equation context of this paper which is most often the case with s sentence representations used by state-of-the-art models in machine translations such as word piece um uh and bite pair representations to improve computational performance for tasks involving very long sequences self attention could be restricted to considering only a neighborhood of size in the input sequence uh centered around the respective output position this would increase a maxim okay we plan to investigate this approach further so at that time when they did it it wasn't you know figuring out everything they need to figure out but I think here what they're talking about is how this architecture would support reducing the computational requirements I assume a single convolutional layer with a kernel so if you remember when you looked at convolutional layers there's convolutions and kernels and again this is why I I touched on it in the beginning while I didn't dig deep on it um the Transformer was a big shift and big change for even the convolution neural networks so here they're just saying a single convolutional layer with a kernel width of so and so does not connect all pairs of inputs and outputs positions doing so require a stack of convolutional layers in the case of uh contiguous kernels or in the case of delated convolutions increasing the length of the longest path between the two positions again this is the path sequential aspect of the neural network but for convolutional networks convolutional layers are generally more expensive than recurrent layers by a factor of K separable convolutions however decrease the complexity of considerably even with k equal n however the complexity of a separable convolution is equal to the combination of self attention layer and the pointwise Fe feed forward layer um the approach we take in our model OKAY long story short even for the convolutional networks this optimizes the Computing requirement for training these models here they talk about the training with some equations numbers and results and then they conclude their um uh their their uh their paper here you can read it even you have a link to the original GitHub repository for the architecture if you want to go there I will have the link for this paper as well in the description if you want to go and see the actual code for this architecture as the same team that created the paper put forward the link is here so it's an interesting to look at now I'll spend short short amount of time to give you an idea of what coming in the future when it comes comes to um future architecture to expect and uh I'll give you at the end the amazing things that will help you understand this at a deep level if you want to do that now here this is um one more uh article that I'll give you the link I'll not go through it it will focus on you know what's what did the Transformer architecture change where it was um uh solving a problem what it's the downside like what are the gaps in the Transformer architecture and maybe what's the future to solve that uh it's a very interesting one just go read it it's it's interesting I I went through it quickly now there's the main architecture people are talking about today on the internet that could be um the future and the next uh stage of evolution after Transformer architecture is something called the Mamba large language model architecture and this is what they say you know this is the new paradigm in machine learning this is the new thing it's not fully cooked I think it's um as an architecture it's there I I'll give you the link to that architecture it's not stable yet it has its problem but it's deploying a technology that we'll touch on quickly that has high potential of taking you know this to the next level when it comes to Transformer architecture today and um going to the next level of contextual understanding of the um the the inputs that we have and the outputs within the L language model training but I think the the the main main aspect of the mumum is the comp the reduction of comput computational needs for training these models which will become something very important if not the most important things because at some point um training these models might become so expensive that it will be also so expensive to fail at these trainings because you expect that companies when they train the models they're taking a chance on the design it might not work it might work if it's super expensive not to mention that it will limit the accessibility to certain demographics but also it will deter corporates and organizations from actually training more and more models and it will slow down the technology we don't want that so there will be a big focus on reducing the computational requirement for these models so let's go to the important part of the Mamba to understand what the hell is the Mamba and then we'll move forward to the interesting stuff of the tools and the visuals that we can play with okay so this is as recent as 2023 so inate 2023 researchers from Carnegie milon and Princeton University published a research paper that revealed a new architecture for large language models called mamba mamba is a new state space model architecture so this is the technology I am talking about State space model architecture you can read about it more concerned with sequence modeling it was developed to address some limitations of Transformer models especially in processing long sequences and has been showing promising performance okay what is the mamba mamba is a new large language model architecture that integrates the structured State space sequence s for model to manage lengthy data sequences and I think this is much more in terms of sequence to what we have with a Transformer even today in 2024 so combining the best features of the recurrent convolutional and continuous time model so you see those are still alive the recurrent and the uh convolution S4 can effectively and efficiently simulate long-term dependencies this allows it to handle irregularity sample data have unbounded context and maintain computational efficiency throughout the training and testing so three main things it will allow it to handle irregularity uh in the sample data it will have unbounded context that's a big claim to make and it will U maintain competitional efficiency throughout training and testing so each of them is a breakthrough by itself now the architecture is promising all three expanding above the S3 uh Paradigm Mamba brings about several noteworthy improvements especially in handling time variant operations its architecture revolves around special selection mechanisms that modifies the structured State space model uh parameters according to the input as a result Mamba May successfully filter out less important data by focusing only on crucial information within sequence according to Wikipedia the model translations from a time uh invariant to a Time varying framework which impacts both the computation and efficiency of the system so it has I think this uh State space model is a different mechanism for uh capturing the context and the attention information within the model so the features the main features Again The Selective State spaces this is something to read about particularly spend time on it if you're interested all of it is something that is happening through the research remember I think at a point of time um we viewed the transformer in the same way people just improved it with time it became mainstream thing the same goes here so what we are looking at here could be in the future the state-ofthe-art technology when it comes to artificial intelligence that everyone talks about and we people will refer to 2023 when this paper came out from Princeton and Carnegie um whatever um the amazing people behind this kind of research in AI simplified architecture so it's simple in AR architecture Hardware aware parallelism so again um you know doing things in parallel will reduce the hardware requirement will make the barrier lower for computing and you know doing more with training these models so so again the link will be there you can go through the architecture but the most thing to to uh understand it's definitely an improvement um over the Transformer uh in theory they're saying it allows for unbounded context and it will reduce the computational power and it will handle irregularities in data so that's I think a big thing I don't know what goes behind the statement I'm sure it's more complex than just the statement itself so read through it it's very uh impressive and interesting I did some reading there now one interesting part that I'll give you another link where you can actually uh read it in a similar intuitive manner um some kind of simpler conversation around what it means how it's done but um also the architecture for the Mamba is on GitHub so so okay let's go just jump to the interesting part before we close this video if you're watching so far I mean I don't know you should write your your name in the comment if you really watched this far I'm not joking if you actually watched this far you should be a Super Fan um you know super friend maybe write a comment in the comment section definitely that tells a lot about your interest in artificial intelligence to encourage me even if there's one person who writes a comment with their name that they watched this video end to end one person for me made all of the effort of creating this video worthwhile um you know I helped someone this is the whole concept behind this um Channel helping people so if I helped one person perfectly fine I spend hours working on this if you're here you're that one person don't forget to subscribe to my channel channel and write a comment engage with me so I'm going to give you three things that you can use to build things on your own or play with with with these architectures on your own and one that you can use it to visualize everything we talked about and even show it to others so the first one is this uh GitHub created by this amazing uh person I found on X this is his handle here he has his oh his Tom is Tom y so he created uh this repository where you can download the the code base here and what you interact with is actually an Excel file so you don't need to be a coder at all just go to this repository which I'll have in the description download the code so you can click at the code here and download the zip unzip the folder and you can look for example at the Transformer open it you will see stepbystep calculation from the input until the output going through the encoder um self attention decoder and then the uh the the um unmasked um uh self attention of the encoder decoder and then you know the flattening and everything we talked about until the output in Excel you can see the equations you can see how it works it's an amazing thing if you want to dig really really deep using a tool that is intuitive for most of us uh as Excel please download it and if you go to his account here you'll find his all his um social media handles follow him again I'm sure someone like him not only he helped People Like Us who know uh or want to learn more around AI but also he might put forward things in the future that you know might interest you you can see I'm already starting his repository the second one is basically the mom repository so we talked about the Mamba architecture which has its issues but still it's on the Forefront of things this is the repository if this is your thing if you can if you know how to handle these type of code maybe you know with AI I never tried to do this myself to train a model usually doing like serious training of this will need um really super uh comput computational availability or a budget that you can do to do it on the cloud so if this is your thing actually the actual architecture Is An Open Source on GitHub for everyone to play with it um by the people who created it again uh under this account here so I'll give you the link let me start this one as well just in case so go and check that out if this is your thing the third one is an amazing GitHub repository that someone created that's the person here um let me start this one as well I already followed this account after I've seen the work that they've done this is basically an application once you run it it will create an amazing visual that will showcase to you um how the whole cycle of the Transformer work and really it will help you understand everything we talked about visually I think it's very important to go through the whole context to read these articles to have a robust understanding the visual will be a cherry on the top but even if you want to skip and just look at the visuals that's your thing that's also nice um the great thing this same repository if you don't want to you know download it or Fork it and run your own code I'll put the link they are already hosting it on a website which is this one and here you can actually see step by step the Transformer working so it's called the Transformer explained um and this is based off the deployment of the GitHub code and you can see here I already played with it a lot and you can see what I've done here as the input um in the word strawberry the count of R is and I'm getting one now the interesting thing here when you play with the temperature the probability if you see here on the right you have all the output probabilities that we talked about in the Transformer architecture uh is here so the as you play with the temperature and this is why you can tell the temperature is a very important variable um or hyper parameter in AI models it will change what the next word is okay so it's now the so at at I think this is one at one it becomes the next word is be becomes the and then and then zero so you can crank this up you know 16 10 you know I think one of them should be three at you know at some point at certain um modifications you can even change the input and see when you will get the actual correct number but now that we understand how embedding works and again when you play with this you can actually click on it see some details so you can see this is the token embedding happening here it's added to the positional encoding that we talked about all of that is pushed through the let's go to the actual multihead self attention so what do you see here these are the qk andv so all of them are done in different heads in different ways and you can see here uh in real time when you run it so let me just hit generate here so you can see how it it runs and you can see in real time if you hover I think over um so you can see here even the this is the heat map what I kept referring to as the heat map um is shown here if you click on this at one point I think you can see uh how the keys and yeah you have to hover carefully at one area yeah so now I got it to uh appear so here you can see the um qkv calculations and you can see it's happening for each of the qu Series against all other keys and it's doing it and it's generating this big Matrix this is the Q um QV KV weights all in one big Matrix and then it's adding the bias and then it's getting all of these again um different outputs uh for the multi um for the multi-ad attention um that we have here in the visual based on the this is the visual depiction of what you've seen here and you can see like how it links so you get the query in you get the key in you get the value if you remember directly to the output all of that goes out of the multi-head self attention box here where we do the normalization and then you have the feed forward Network this is the feed forward Network and then we start getting the 11 more identical Transformer blocks okay these are the outputs and all the probable out um um next word so all the probabilities for the next token or output and us ually you get here what is um the most probable uh next output and you can by the way you can just highlight this write something else so my name is let's say see what this generates you hit generate it will run the whole network for you and it will give you um the next probable word again this is based on point6 temperature so it is predicting that my my name is a so which doesn't make sense let's push it to point8 it's giving something else so you can put for example I put my name my name is samur run again and see what I get as next so the whole concept of this amazing work by this group is to predict the next word and through the Transformer architecture but also view it in real time how it works look at the calculations of the qk V how it happens look at you know what goes into the normalization look how that's pushed after flattening into feed forward Network and how you have all the probabilities as outputs so I know it has been a really long one um I hope you did you got more value than you suffered of me talking and reading all the time and just explaining things over and over and over again it took me really a similar effort um to do these things to go through these things to really grasp them well I'm not an expert yet but I'm on that way where I think I have a much better understanding than the average person when it comes to not only how neural networks and AI works but also going at a deeper level of really understanding how the um Transformer architecture Works what's coming in the future how the calculation in theory happen and why it works as it works and basically answering um or understanding or learning from one of the people of this community who told me well that's why doesn't get the strawberry test now I get it so thank you for triggering this whole boring movie and I know it might not get more than 10 views I'm good with that if I get one person to comment in the comment section if you enjoyed it even if you got like from one of the chapters like through one of the minutes in this long video I assume value please consider subscribing to my channel and with this I'll keep it short thank you and goodbye subscribe to the Daddy's Channel give me the mic"}], "Multi-headed attention": [{"content": "[Music] hi uh welcome back so this is where we stopped yesterday where we were talking about the self attention block within the Transformer architecture and uh we saw that the entire self attention can be uh done in parallel for all the capital T tokens uh and uh it all happens through these Matrix multiplications right so in effect what is happening is the following right so this is what is known as a scaled dot product self attention and this is called one head and soon we'll see multiple such heads but we'll get there when we get there but for now just remember this is called sell scaled dot product based self attention so what exactly is happening here so this purple box here right this is the scale do product unit right so this is what is lying inside this purple block Here and Now what is the input to the Box let's see uh so you get the key uh query and the value matrices how are these constructed originally remember at the input all you had were these H1 to HT right so you had these word representations for the t-word and we were calling them as H1 H2 and so on right now from the H1 H2 what happens uh you pass them through the linear projection right through the WQ W K and W V matrices to get the Q K and V matrices right so this is just multiplying WQ by these vectors and you just stack up these vectors into a matrix so that you can do just do WQ multiplied by that H Matrix right let's just call it h then you get the Q Matrix similarly WK m mped by this gives you the K Matrix and WV multiplied by this gives you the V Matrix right all of this happening in parallel as uh three Matrix operations then you get the qkv and then this is what happens inside the uh self attention head and at the output what do you get you get uh uh zed1 you get Z1 Z2 all the way up to ZT right so this is what we had seen uh when we ended the last lecture now this is called one head so what what do I mean by a head here so this is one such unit which takes the inputs H1 to H2 and gives you the elements zed1 to Z2 right or the refined representation Z1 to ZT which also take care of the contextual information because they depend on the key they depend on the value and they depend on the query right so they take care of the contextual information uh now you could have one more such block right so you could have the same block repeated so let me just call this Z1 1 Z2 1 and z uh 1 T right so this is the output of the first attention head similarly you could have the same block repeated where you have another set of parameters right so let me just call these uh W1 right these are the first set of weight matrices you have similarly you could have another repeated block right and let me just show it on the next slide we just repeat these two blocks right and now you have head 1 head 2 and head 1 is giving you uh representations zed1 and this is giving you representations Z2 now there are several questions here right why would you have two heads and then if you had getting these two representations which one do you consider right so we'll answer those two questions but first let us motivate right why would you need multiple heads and we have already seen this in a different context before right so we want to motivate multi multiple heads in attention right so one head is uh one uh one one scale do product unit which gives use Z1 to ZT right the representation Z1 to ZT and I'm making a case for many such hits so why why is why am I doing this so we have already seen this in the context of convolutional neural networks right so where we had multiple filters right so these are three different filters uh operating on the same image right and each filter essentially does the same thing it has parameters say W1 W2 W3 it just goes over the image and gives you an output feature map right and the reason we wanted to capture have multiple filters is that we were hoping that each filter May capture a different characteristic from the image right some may detect edges some may detect blurs and so on right so that's why you had multiple filters right and more the filters the more abstract representations you could compute right the same argument holds here if you have one self attention then it will capture it'll learn one way of capturing the contextual information right but there might be more than one way of capturing this contextual information right so you might also want to have a situation where it focuses on animal with a very high attention and you might also want it to focus on some ver with a very high attention right and both of these might be important because one is indicating that it is a pronoun for animal and the other might be indicating that it is the object of this work right and so in both both of these you might want to capture so one head could learn to give more attention to animal the other head could learn to give more attention to this work right so just as you had multiple filters to capture multiple characteristics from the image you could have these multiple attention heads right and let's just look at it a bit more uh carefully right so here's an example so the animal didn't cross the street because it was too tired right and I have the same copy of the sentence here and now I'm trying to learn a contextual representation for it and now I want to focus more on was right because I want to know was what is the subject of it right so it is the subject here so I want to know that so I want to capture that information by paying more attention to was right but I also earlier made a case so what does that mean if I'm learning the alphas right so if I'm learning say let's this is 1 2 3 4 5 6 7 8 9 10 this is a 10th word so if I'm learning Alpha 10 then this is Alpha 10 1 Alpha 10 2 right and this is Alpha 10 11 right so this is the uh attention that should be paid on the 11th word when you're Computing a refined representation for the 10th word right and I want this to be high right but I had also earlier made the case that I want the attention on animal to be high because uh animal is the I mean it is referring animal animal is the word for which it is the pronoun in this case right so that means if I were to compute again the weights Alpha 10 and so on then I want this to be high so I also have a case for this to be high I also have a case for this to be high so so one way of dealing with this would be have two separate attention heads right and compute two Alphas one from one block of self attention another from the other block of self attention and this block could learn to give more importance to this Alpha and the other block could learn to give more importance to this Alpha right now of course uh this is slightly make believe right we understand that because we already visited this in the case of recurrent neural networks that there is no signal right we are not telling the model that hey you need to pay more attention to V or hey you need to pay more attention to animal we just hope that when we looking at the final loss function and if it indeed is beneficial to focus more on V right that means have a higher weight for Alpha which in turn will uh contribute uh accordingly when we try to compute the refined representation for uh say uh the 10th word right uh and that effectively reduces the loss so it would then learn to have a higher weight for Voss right similarly if it helps so this is is z 110 similarly if you had Zed coming out from the other attention head and this will also participate in the fuel computation and then participate in the loss so if it helps that now this set of Alphas should be such that it should focus more on the word animal and if the loss dictates that then the machine would learn that or the model would learn that right so that we're not giving it an explicit signal we're just hoping that by Trying to minimize the loss it has more freedom now in some cases it can learn to put a high alpha here in some cases it can put a learn to put a high alpha here right so you're making a better design Choice by allowing it more uh uh choices right or allowing it more parameters in terms of the W's the projection matrices which in turn result in different Alphas right so just making it a more flexible model uh which has more choices or more options to how to adjust the alpha in different cases so it might choose to have Alpha was high for one case Alpha animal high in the other case and then do something something different in the third head and so on right so that's the motivation for having multiple heads I just already explained this I'll just skip over this the same thing whatever I explained that in one case it would want to focus on V the other case it might want to focus on animal and this is actually from a actual train transformer right so we looked at the uh attention weights there were two heads and we looked at what the attention weights were and we found that in one case it is giving higher in one of the heads it is giving higher attention to animal and the other head it is giving higher attention to WS right so it does learn to do such things right so this is what the two-headed attention would look like you would have the Q uh uh query uh sorry you have the query key and value vectors right which are coming from your projections sorry this should have been this is the H Matrix right which is H1 H2 all the way up to HT and you get out here is qk V right so this is again the H Matrix and what you get out here is q k v right so you just have these two copies now this as I said would release zed1 Z2 all the way up to ZT and I'll just call it Z1 one and so on and this would give you Zed 1 Z2 all the way up to ZT and I'll call it z2s right now what do I do with this I have two representations now computed for this word H1 to T right so how now what do I do with these two Zeds simple I just concatenate them so that's all I'm going to do so you concatenate it so you get a larger representation and then you pass it through a linear transformation right so we'll uh see that uh soon and then what you get is the final output right so what let's just look at this carefully right what is happening here so uh again let me just look at some uh okay this important that I get get rid of this right so this is the H here okay and let's just focus on H1 right now H1 suppose H1 was a a 512 dimensional Vector right so now what I could do is uh I will choose W to be 512 cross 256 okay I'm just giving you some example so that means the U projection which comes out right my Q KV would be 256 dimensional right because it's 512 multiplied by a 512 cross 256 Matrix right or rather actually this would be um yeah so you get it it's I'll get I'll just project it down so this will be 256 dimensional right so at the output again I'll get 256 dimensional Zs in both the cases now when they concatenate I again get a five1 two dimensional output right and this I could again pass it through whatever uh transformation I want right for example I could choose a 512 cross 1 1224 I could choose a 512 cross 256 or I could choose a 512 cross 512 right and depending on that I will know what my output Dimension would be if I choose this then my Z final Zs coming out of here would be 5 and two dimensional right so let's just understand it correctly so this H1 gave me a 256 dimensional zed1 this through this network or through this self attention it I got another 256 dimensional H1 and then I got five and two dimensional uh output here which then again I pass it through a linear transformation right so it's because you're going to concatenate it makes sense that you the output of each of these is small right because if each of these is five and two dimensional then you concatenate you'll keep growing larger right and typically use eight heads so now if each of this is 5 and two dimensional and then you concatenate them then you'll get a 4096 dimensional output here which is too large right because it increases the size of the parameters that will go through a linear transformation and so on right so typically what you do is if you want 5 and2 dimensional size here right then you make sure that your each of your eight heads gives you a 64 dimensional output so when you concatenate them you get a five and2 dimensional output so you start with a five and2 dimensional output you adjust these Dimensions such that you get a 64 dimensional output at each of these heads you have eight such heads so when you concatenate them you'll again get a 5 and two dimensional output then you do an appropriate linear transformation you could choose this one so that your final Zs are also five and two dimensional right so that's what you could U do right so this is what a two-headed attention would look like and I've already told you how to extend it to multi heads you'll just have the same U block repeated as many times as you want and then finally you would just adjust all these Transformations right so as I said I could uh let's just look at it again if my hes are five and two dimensional these are hes then I pass them through I multiply them by a 64 cross 512 Matrix so I get 64 dimensional outputs here 64 dimensional outputs here same happens in all the eight heads so when I concatenate them I get a five and two dimensional output right so whatever I started with I get the same so I can just adjust the parameters accordingly and then I do a linear transformation to get my final uh Z1 to ZT right so remember this concatenation is happening per word right that means uh the Z1 representations coming out of each of these are getting concatenated here then the Z2 representations coming out of each of these are getting concatenated here right uh so it's per word so the input is a set of words you have capital t word embeddings and the output at this layer or at every layer right here here here at all these layers the output is again uh capital T embeddings right so that you should remember that okay so we are done so we have the uh multi-headed attention Okay so we are back to the basic block that we had so this is what we had we had these uh uh inputs coming in here right and then now we have seen this self attention in detail which could be a multi-headed self attention and I give it inputs H1 H2 HT and then through all the uh processing that happens inside I get outputs I think I was calling these as S1 S2 all the way up to St right so once I have got this now I need to understand what happens in the feed forward neural network right so let's focus on that now right and this encoder is typically a stacked encoder so you'll have six such blocks that's why I'm calling this a basic building block this is one layer right so you passed in H1 to HT you got out Z1 to ZT now this Z1 to ZT becomes input to another such layer and again you get a new set of representations out from your capital t representations out right this we have seen that the output of one layer actess the input to the next layer right so all of this looks identical in all these blocks and there could be 6 8 12 such blocks depending on the Transformer architecture that you're looking at now let's see what happens in the feed forward Network so now uh you had uh uh you so these are what the final output is of the feed forward network is Zed this intermediate output coming out of the self attention I should have called it s and this is the input H1 right so now what exactly happens in the feed forward neural network nothing it's quite simple so remember that each of these guys here is a 51 two dimensional representation or some D dimensional representation it is going to pass through a feed forward neutral Network and again give you a d dimensional representation at the output right that's all that is happening here so feed forward neutral network is only acting as a uh projection uh layer here right so um yeah so this is the input S1 okay there's some intermediate being computed let me just call it uh say m okay right and then you get Z1 at the output right so this could again be 5 and two dimensional input one2 four dimensional projection and then again five and two dimensional output and of course there would be a nonlinearity here you could use uh any nonlinearity that you want right uh and typically it is um one of the G based either G or one of those Nom uh nonlinearities okay and the same set of parameters right so this here would have some parameters right so you'll have some W's here and then some another set of W's here right so let me just call them W feet forward Network and let me call this W1 because it's layer one and W2 Layer Two right so the same set of parameters will be used everywhere right so each of these s1's or Si will pass through the same transition and give you the corresponding zi right so that's what I'm going to show with the animation that the same network is essentially being used everywhere right so you get this same output everywhere right so this uh uh yeah so you have the same network for each position and uh uh you use uh this uh as the this is the nonlinearity that you're going to uh use right uh so nothing great happening within the feed forward neural network whatever output the multi-headed attention gives it just uh projects it and then gives you back a final output right so that's all we are done uh with the uh yeah so that's all we are done with the uh uh encoder layer right so this is one layer of the encoder and now I could stack many sets layers but each layer the internal working would remain the same just the output of the previous layer will be the input to this layer right so nothing else changes right so we are done with the encoder part of the Transformer so the encoder is composed of n such identical layers and each layer is composed of these two sub layers one is the multi-headed attention and the other is the feed forward neural network uh and uh so the computer is computation is paralled in the horizontal direction right so what do I mean by that is that you of course so if you have these n layers right of course you cannot compute all the layers in parall right because Layer Two will take the output of layer one as input right so unless you have done the layer one computation you cannot do the layer two computation right so when I say it's parallelized it's only within each layer right so for a given uh set of U yeah input samples right within that layer all the self attentions all the alphas all the Zeds they'll all get computed in parall right unless I mean earlier when uh again I'll just repeat this because this is important in the case of an RNN when you were given H1 to HT and you had to compute Z1 to ZT right you first had to compute Z1 then Z2 then ZT and so on right and here we saw that using this large Matrix multiplications we get Z1 to ZT in parallel right you don't have to wait for the previous time step for the next time step to be computed right so this parallelism you see in every layer but of course across layers the computation is still sequential right because you need the previous layers output to do the next layer's computation you have the input then the layer one outputs get computed then it feeds to Layer Two and so on till the end and each of these T cross 512 outputs get computed in parallel right and now this final output of the uh encoder right which is the output from the last layer we are going to denote it as e right so we'll refer to it as E1 to E capital T because there are t such tokens in the input and for each token you get this final refined representation which is contextual as well as gone through several layers of abstraction or several uh deep players right"}], "Unreal Engine 5 BP Tutorial | 2.4 String Datatype | 2. Variables | Aditya Burgula": [{"content": " Hello friends, welcome back to another brand new video. I am Alithya and in this video we will be taking a look at a new data type and share Unreal Engine such a string. So this data type is very commonly used in various programming languages and even in Unreal Engine. So with our machine, let us get into the video. So friends first let us understand the data type of string. The string is simply a data type which can store a sequence of characters. So now what do I mean by characters? It can be pretty much anything from letters to different symbols to numbers. But one main thing that differentiates between a string and an integer data type or a flow data type is that you cannot perform calculations because it is not a number. A string can have pretty much anything and if you take A and B you can't add, you can't multiply A and B, you can't do any kind of mathematical operations on these. So that was the base concept of it."}, {"content": "So now let us see how we can create it. So here we have the plus button and here I will just create it to use a person's username inside the game and let us change it to string. So once it is changed we can drag and click get username and same way we can also set it to name. So this is about getting and setting username. So if I click on this and we go on the details tab you can see that is almost the same properties as with other data types. So I will just compile and here you can see username. Now here we can give a value. So I will give like something like this or random value which includes all the characters add the rate.com like something like mail maybe. So it's just random string value. Now we're using the same print string we can actually print it to the screen. So we can do a big and play. So it is already connected over here. So I'll just drag this and using this node you do a print string and do this. Now we can also reset the value and here we'll set it to hello. So you can also show a simple text. So this is what is actually taking as an input as you can see over here when in the print function. So it takes input as string data type. So we'll be taking a look at that more detail later. We can do print once again. So here it is printing both the values. So that was about kind of basic overview of the string data type. I hope you have got an idea of how string data type works in Unreal Engine. We're taking a look at some of the operations which we can do with strings that is concatenation or addition operator. But for now we'll just keep it to the introduction level. And we come to the operator section that time we'll take a deep look at how we can do operations or strings. So thanks for watching nice."}, {"content": "I hope you liked this video today. Please don't forget to hit that like button, share button, subscribe button. So see you in the next video. Bye."}, {"content": "I hope you liked this video today. Please don't forget to hit that like button, share button, subscribe button. So see you in the next video. Bye. "}, {"content": " Hello friends, welcome back to another brand new video. I am Alithya and in this video we will be taking a look at a new data type and share Unreal Engine such a string. So this data type is very commonly used in various programming languages and even in Unreal Engine. So with our machine, let us get into the video. So friends first let us understand the data type of string. The string is simply a data type which can store a sequence of characters. So now what do I mean by characters? It can be pretty much anything from letters to different symbols to numbers. But one main thing that differentiates between a string and an integer data type or a flow data type is that you cannot perform calculations because it is not a number. A string can have pretty much anything and if you take A and B you can't add, you can't multiply A and B. you can't do any kind of mathematical operations on these. So that was the base concept of it."}, {"content": "So now let us see how we can create it. So here we have the plus button and here I'll just create it to use a person's username inside the game and let us change it to string. So once it is changed we can drag and click get username and same way we can also set username. So this is about getting and setting username. So if I click on this and we go on the details tab you can see that's almost the same properties as with other data types. So I'll just compile and here you can see a username. Now here we can give a value. So I'll give like something like this or random value which includes all the characters at array.com like something like that. mail maybe so it says random string value. Now we're using the same print string we can actually print it to the screen so we can do a big and big so it is already connected over here so I'll just drag this and using this node we do a print string and do this. Now we can also reset the value and here we'll set it to hello so you can also show a simple text so this is what is actually taking as an input as you can see over here when in the print function so it takes input as string data type so we'll be taking a look at that more detail later we can do print once again so here it is printing both the values so  That was a basic overview of the string data type. I hope you have got an idea of how string data type works in Unreal Engine. We will be taking a look at some of the operations which we can do with strings that is concatenation or addition operator. But for now, we will just keep it to the introduction level. When we come to the operator section, that time we will take a deep look at how we can do operations or strings. So thanks for watching nice."}, {"content": "I hope you liked this video today. Please don't forget to hit that like button, share button and subscribe button. See you in the next video. Bye."}, {"content": "So now let us see how we can create it. here we have the plus button and here I'll just create it to use a person's username inside the game and let us change it to stu. So once it is changed we can drag and click get username and same way we can also set username. So this is about getting and setting username. So if I click on this and we go on the details tab you can see that's almost the same properties as with other data types. So I'll just compile and here you can see username. Now here we can give a value. So I'll give like something like this or random value which includes all the characters, add the rate.com like something like mail maybe. So it's just random string value. Now we're using the same print string we can actually print it to the screen so we can do a big and big so it is already connected over here. So I'll just drag this. and using this node, we'll do a Princeton and do this. Now we can also reset the value and here we'll set it to hello. So you can also show a simple text. So this is what is actually taking as an input. As you can see over here, we have an end-to-print function. So it takes input as string data type. So we'll be taking a look at that in more detail later. We can do print once again. So here we see it is printing both the values. So that was what kind of basic overview of the string data type. I hope you have got an idea of how string data type works in Unreal Engine. We'll be taking a look at some of the operations which we can do with strings that is concatenation or addition operator. But for now, we'll just keep it to the introduction level. When we come to the operator section, that time we'll take a deep look at how we can do operations or strings. So thanks for watching nice."}, {"content": "I hope you liked this video today. Please don't forget to hit that like button, share button, subscribe button. So see you in the next video."}, {"content": "So now let us see how we can create it. here we have the plus button and here I'll just create it to use a person's username inside the game and let us change it to stu. So once it is changed we can drag and click get username and same way we can also set username. So this is about getting and setting username. So if I click on this and we go on the details tab you can see that's almost the same properties as with other data types. So I'll just compile and here you can see username. Now here we can give a value. So I'll give like something like this or random value which includes all the characters, add the rate.com like something like mail maybe. So it's just random string value. Now we're using the same print string we can actually print it to the screen so we can do a big and big so it is already connected over here. So I'll just drag this. and using this node, we'll do a print string and do this. Now we can also reset the value and here we'll set it to hello. So you can also show a simple text. So this is what is actually taking as an input. As you can see over here, even in the print function. So it takes input as string data type. So we'll be taking a look at that more detail later. We can do print once again. So here we see it is printing both the values. So that was what kind of basic overview of the string data type. I hope you have got an idea of how string data type works in Unreal Engine. We'll be taking a look at some of the operations which we can do with strings. That is concatenation or addition operator. But for now, we'll just keep it to the introduction level."}, {"content": "When we come to the operator section, that time we'll take a deep look at how we can do operations or strings. So thanks for watching nice. I hope you liked this video today. Please don't forget to hit that like button, share button, subscribe button. So see you in the next video."}, {"content": "So now let us see how we can create it. So here we have the plus button and here I will just create it to use a person's user  the game and let us change it to string. So once it is changed we can drag and click get username and same way we can also set username. So this was about getting and setting username. So if I click on this and we go on the details tab you can see that is almost the same properties as with other data types. So I'll just compile and here you can see a username. Now here we can give a value. So I'll give like something like this or random value which includes all the characters, add the rate dot com like something like mail maybe. So it's just random string value. Now we're using the same print string we can actually print it to the screen. So we can do a big and play. So it is already connected over here. So I'll just drag this and using this node we'll do a print string and do this. Now we can also reset the value and here we'll set it to hello. So you can also store a simple text. So this is what is actually taking as an input as you can see over here even in the print function. So it takes input as string data type. So we'll be taking a look at that more detail later. We can do print once again. So here it is printing both the values. So that was about kind of basic overview of the string data type. I hope you have got an idea of how string data type works in Unreal Engine. We're taking a look at some of the operations which we can do with strings that is concatenation or addition operator. But for now we'll just keep it to the introduction level. And we come to the operator section that time we'll take a deep look at how we can do operations on strings. So thanks for watching nice."}, {"content": "I hope you liked this video today. Please don't forget to hit that like button share button subscribe button. So see you in the next video."}, {"content": "So now let us see how we can create it. So here we have the plus button and here I will just create it to use a person's username inside the game and let us change it to string. So once it is changed we can drag and click get username and same way we can also set it to name. So this is about getting and setting username. So if I click on this and we go on the details tab you can see that is almost the same properties as with other data types. So I will just compile and here you can see username. Now here we can give a value. So I will give like something like this or random value which includes all the characters and create.com like something like that. mail maybe so it says random string value. Now we're using the same print string we can actually print it to the screen so we can do a big and big so it is already connected over here so I'll just drag this and using this node we do a print string and do this. Now we can also reset the value and here we'll set it to hello so you can also show a simple text so this is what is actually taking as an input as you can see over here even in the print function so it takes input as string data type so we'll be taking a look at that more detail later we can do print once again so here it is printing both the values so that was about kind of basic overview of the string data type I hope you have got an idea of how string data type works in Unreal Engine we're taking a look at some of the operations which we can do with strings that is concatenation or addition operator but for now we'll just keep it to the introduction level and we come to the operator section that time we'll take a deep look at how we can do operations on strings so thanks for watching nice I hope you like this video today please don't forget to hit that like button share button subscribe button so see you in the next video"}, {"content": "So now let us see how we can create it. So here we have the plus button and here I will just create it to use a person's user name inside the game. let us change it to string. So once it is changed we can drag and click get username and same way we can also set username. So this was about getting and setting username. So if I click on this and we go on the details tab you can see that has almost the same properties as with other data types. So I'll just compile and here you can see username. Now here we can give a value. So I'll give like something like this or random value which includes all the characters, add the dot com like something like mail maybe. So it says random string value. Now we're using the same print string we can actually print it to the screen. So we can do a big and play. So it is already connected over here. So I'll just drag this and using this node we do a print string and do this. Now we can also reset the value and here we'll set it to hello. So you can also just simple text. So this is what is actually taking as an input as you can see over here. and the print function. So it takes input as string data type. So we'll be taking a look at that more detail later. We can do print once again. So here it is printing both the values. So that was what kind of basic overview of the string data type. I hope you have got an idea of how string data type works in Unreal Engine. We're taking a look at some of the operations which we can do with strings that is concatenation or addition operator. But for now we'll just keep it to the introduction level. When we come to the operator section that time we'll take a deep look at how we can do operations on strings. So thanks for watching nice."}, {"content": "I hope you like this video today. Please don't forget to hit that like button, share button, subscribe button. So see you in the next video."}, {"content": "So now let us see how we can create it. So here we have the plus button and here I will just create it to use a person's user name inside the game and let us change it to string. So once it has changed, we can drag and click get username and same way we can also set it's a name. So this is about getting and setting username. So if I click on this and we go on the details tab, you can see that's almost the same properties as with other data types. So I'll just compile and here you can see username. Now here we can give a value. So I'll give like something like this or random value, which includes all the characters at the rate.com like something like mail maybe. So it says random string value. Now we're using the same print string. We can actually print it to the screen."}, {"content": "So we can do a big and play. So it is already connected over here. So I'll just drag this and using this node, we'll do a print string and do this. Now we can also reset the value and here we'll set it to hello. So you can also show a simple text. So this is what is actually taking as an input. As you can see over here. and the print function. So it takes input as string data type. So we'll be taking a look at that more detail later. We can do print once again. So here it is printing both the values. So that was what kind of basic overview of the string data type. I hope you have got an idea of how string data type works in Unreal Engine. We're taking a look at some of the operations which we can do with strings that is concatenation or addition operator. But for now we'll just keep it to the introduction level. When we come to the operator section that time we'll take a deep look at how we can do operations on strings. So thanks for watching nice."}], "#1 Installing and Setting up .NET Core and VS Code | C# Programming Tutorial | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video of the dot net and c sharp tutorial series i am aditya and in this video we'll be installing and setting up our computer for dotnet and c-sharp development so guys first let's open a browser and for running any dotnet application or c-sharp application you need the.net framework installed in mostly windows applications you get it already but we are going to use a.net core as it is cross platform and even if you're a mac user the process will be almost the same so i can just write dot net core download and after that you get an official link from microsoft that is net core linux mac os and windows so the process will be almost the same so guys after you open the website as you can see dotnet.microsoft.com i'll be keeping the links in the description below also so after you open this you are going to get like this like all the versions of netco and you must just choose the recommended version right now it is 3.1.net core 3.1 so click on that and it will start downloading and after that the setup is also very simple uh you must just go to the default options just like okay okay install and it will do the thing it may take a little while and after that we'll be installing vs code which is an ide and guys i hope that right now we have installed.net core and guys now we need an ide so an ide is something like a development environment where you actually write your code in and makes it much easier for us to write code because it has some features like intellisense or code completion and then it provides you with some tools extra tools for faster coding so like that visual studio is also one of them for actually.net there's even an id called professional id called as visual studio it is has it has versions depending on the er like visual studio 2017 2019 the latest one is 2019 we'll be not installing that because that's a heavy software kind of that and it takes a lot of time to download all this stuff and it's actually a very huge process and this virtual studio code it's a lightweight editor supports multiple languages so that's where we'll be using this so here i'll give the link in the description for this site also and here you can see for windows depending on your operating system you can download it the installation process is very easy and after you install i'll see you in the visual studio code page so guys right now after you open the visuals through your code after installing it successfully you might get a screen like this i actually have a different theme for you it might be a little much more darker and the first thing which we are going to do is use the terminal and check out.net installation i could actually have using the normal terminal or command prompt in windows but we'll be learning about how we can use the terminal inside vs code so here you go to the terminals tab and open terminal where and you can even see a shortcut over here you can use that so i'll be going like this and here you can see here it has opened a panel for this this is nothing but a command prompt and even you can choose what kind of comment prompt you want to use like there's windows command prompt powershell and git bash for this video we'll be just using the cmd normal command prompt and guys to check the dotnet installation you can just write dotnet dash dash version and press enter and if it was successful it will show you all these things so here we can see dotnet version 3.1.2 so now this installation was successful and now let's configure vs code for dot net on c shop development for that we must go over here which is called as extensions tab and click on that and here you must search for c sharp so i actually have already installed so if it won't be installed for you so you must search here for vs code c sharp and after you get that and you'll get a window like this somewhat like this and here you will get an install button here as you can see i have options like disable uninstall and set color theme whereas you will get an option like install and you must install that after installing you're done with setting up an extension or all the required plugins for c sharp and now we must just open a folder to work with c sharp so guys first uh here you can go over here you can see file and here we have options such as new file new window new open file open folder so here we'll choose of open folder and here i'll go to c-sharp and here again i have a folder and i'll be opening this and here you can see we have a c-sharp folder opened over here you can see the name of the folder and i'll just close this welcome screen and here we must open terminal and click new terminal and write dotnet new console so press enter and it will create the kind of a template basic template for writing c sharp code so guys right now you can see it has successfully completed as you can see here we got the message as restore success succeeded and here in the folder you can see there are more items like we have an object folder and here we have the main that is program.cs file and here after we open that you can see here we have some c sharp code so after you create this i recommend that you kind of restart your visual studio code ide close it and restart it and you must always check whenever you create like this file using the terminal check that this starts running so here we can see start omnishop server starting omnishop server so this will initiate all the required tools for actually developing in c-sharp and it will give us intellisense everything if this doesn't start or you have any problem with that you just close the visual studio code restart it again and still you're facing some problems and this is not running you can keep the problems in the comments down below i'll be always ready to answer your queries or you can even search it on google or stack overflow for solutions so guys now you can see it has started all the tools starting up all the tools so see you after all this thing is finished so guys now as you can see it has completed and now we even have another new folder called as bin now we must create all the required files to actually run and debug the program so guys now here we should open the command prompt of this vs code or you can just call it the command line or anything so to open it you must just use a shortcut key called as control shift p and for mac i guess it is command shift p and here you can see we got from dot net like generate assets for build and debug so just press enter on this and it will create all the required files for us to run the program and debug it and here if you see we got two files called as launch.json and tasks.json so if you go through over here you can see all the configurations for this so first we are going to launch.json and here we should just change we'll just change it to external terminal so external terminal and make sure that you follow the casing e should be small and t should be capital and other keyword all the letters are small and the task.json is you can just leave it same way and guys now we can just go to program.cs and just add a small line like console dot read line and here you can see we even got some intellisense and after that we can just go over here run and select run without debugging so here we got a new kind of bar over here and first it will start building the c-sharp file so here you can see executing task so guys right now here you can see after the build process you can see that we have got a terminal open for us and it says dot exe and it has run the program for us and it's just a simple hello world program and here if we can see i'll just minimize it you can see all the process is done it has opened the debug console and here you can see that terminal will be used reused by task and you must get something like this and if you have any error you can please comment on below and i'll be always ready to answer your doubts or queries so i'll just friends enter over here and it will close it and it will even close this bar over here and stop the terminal so i can just press enter over here as well and it will remove everything so guys that was about how we can use vscode.net core to actually run c-sharp programs in our system and guys i hope you like this video please be sure to subscribe to my channel and hit the bell icon so that you never miss any updates so see you in the next video you"}], "Unreal Engine 5 BP Tutorial | 2.3 Boolean Datatype | 2. Variables | Aditya Burgula": [{"content": "hello friends welcome back to another brand new video i'm aditya and in this video we'll be learning a new data type inside unreal engine that is boolean or shortly known as bool so without wasting the time guys let us get into the video so friends boolean data type is very simple and most widely and commonly used in unreal engine and in any other programming language so what is a boolean data type so a boolean data type is used to store two values either two values that is true or false and in programming sense you can also represent them numerically using zero and one where zero refers to false and one rep refers to true so now let us see a practical implementation of this data type inside the blueprint so here on the variables tab i'm going to press the plus button now once you press the plus button it's going to ask for a name now i would like to point you a comment kind of a practice that is done by most of the unreal engineers is to add prefix of small b before the variable name so what i mean by that let me just show you so whenever i name a boolean variable what you what i do is that i keep a small b before it and then i give the name so this is kind of helpful when you want to uniquely identify the boolean variable and it is done by most of the professionals or the unreal engine defs i prefer that you also do the same now once we add the b then we are going to give the name so practical example where we can use a boolean data type is where we want to check or acknowledge whether the player is alive or dead or we can use it when we want to see if the player is in match or is in the lobby or if the player is male or if the player is female so based on that you can give so for now i'll just give like is a life so if the player is alive or dead so we can just use this uh variable same like other variables we have used so far so i'll just drag this on to the screen and here we get the same options like get and set so here we'll just do a set so here we have the node now so what you can see is that we have this kind of box over here black box same like other variable sets so now actually we we can't give any value like type true or false like in programming languages we type true or type false rather here in unreal engine blueprints what we do is we just have a check box actually and we can press on it to give it the value so if the check mark is there that means the value is true if there is no check marks inside the box that means the value is false now to illustrate a better example what we can do is we'll just use the begin play i'll just copy the note the thing is begin play cannot be called more than once so here so here i just pasted the begin play and now we'll be using a new note that is called as branch and it is mostly dependent on this bool data type so here you can see we have a branch and it is asking for a condition so don't worry about what this condition is it's quite simple so and when we come to the conditional statements that time will look at all these branches and other condition based uh nodes in unreal engine very detail so don't worry about that so even begin play and then we have set so i'm going to set is alive to false and then i'm going to attach this pin to the branch node condition pin then we have these two execution pins so if this value is alive is true then whatever is connected to this true node it will be run so here i am going to do a print string and here i'm going to say player is alive now if the player is if the value is false that the player is dead then i'm going to print clear is dead so i guess now you're able to see the code much more clearly so first we are setting the value to true and then we are running a branch i'll just hit compile and now if the if i play the game so you can see it showing player is alive so this is running successfully because the value is this alive is set to true now if i uh remove the check mark and i compile it again and play you can see it is showing player is dead because the value is showing as false so the player is not alive and one more thing i think you might have noticed by now is that when the variable is be created with the prefix of b and when we do a set statement or when we do a get statement also what you can see is that it is not showing the bx you can see right it's not showing b is alive rather it is just showing b is alive so unreal engine is kind of intelligent enough to remove that so that was about it guys a boolean data type i hope it is very easy and simple for you guys to understand it so please don't forget to hit that like button subscribe button and bell icon so that you never miss any updates on my channel thanks for watching guys see you in the next video you"}], "Unreal Engine 5 BP Tutorial | 2.1 What are Variables ? & Integers | 2. Variables | Aditya Burgula": [{"content": "hello friends welcome back to another brand new video i am aditya and in this video we'll be talking about and understanding the concept of variables and data types then we'll be taking a look at very commonly used data type that is interior so without wasting any time guys let us get into the video so friends first let us understand the concept of variable and data type so a variable can be assumed to be like a box which is like acting as a container in which you can store anything like a data or for example now we'll take and keep some cubes so a box with cubes so that box is nothing but a variable and the cubes are nothing but the data now let us take another box and put inside that some spheres so now that is also a variable but it has a different shape or different type of data nothing but spheres so box one has cubes and box two has peers so that defines the type of data and the type of data is nothing but data type so what type of data is inside that variable so commonly in most programming languages you have data types like strings integers booleans so in unreal engine we have vectors rotators so we'll take a look at a very commonly used data type that is integer across all programming languages if it is unity or c plus this java it is very common in them so in unreal engine specifically we have three kinds of data types to store numbers so the first one being byte second one being integer and third one being integer 64 according to their sizes so now what do i mean by sizes so size refers to the amount of data that that particular data type can hold so suppose first let us take the example of byte so byte can only store values from 0 to 255 so it cannot store neither negative values nor numbers above 255 if you want to throw 256 you cannot inside buy it so this data type can be useful if you want to store rgb values like 0 to 255 right so that can be helpful in that byte data type and when it comes to integer and integer 64. so integer is kind of it has a range which is negative 2 billion to positive 2 billion i i guess so i'll just put up on the screen the limit for integer and integer 64."}, {"content": "integer 64 is pretty huge i don't even know what to call that number it is very huge so depending on the usage you can choose between all these three uh if you want very huge number two if you want to store very huge number and do calculations on those then you can use integer 64. for normal use cases you can just use integer data type so now let us take a look and see how we can create these variables assign them a particular data type and bring them to the screen and see how it works so previously we have worked on blueprint classes right we have created them and seen how we can use them but for now from now on we'll be actually using level blueprint which is actually quite easy to use so it doesn't have much complicated things and it's very simple to open a level blueprint we will go to the blueprints tab on the top as you can see over here so i'll just click on this and here we can see level blueprint so we can click open level blueprint and it will open it so once it opens you're going to be presented with the screen like this here it shows my blueprint even graph and details so what i'll do is i'll drag this details tab and i'll put it down over here so to create a variable first as you can see over here there's a variables and here we have a plus icon right so you can just click on that and you can also do add and here from here also you can add a variable so adds a new variable so you can use any of these so i'll just click on this and here you can see new it is asking for name of the variable so here we'll just uh set ammo so a bullets guns ammo so how many bullets does it have left so here by default it is on integer so we can also if we just click on this so if we just click on this current type integer if i just click here you can see all the different data types that unreal engine provides so almost the boolean byte integer float double and string these are kind of common in all the other programming languages and game engines so even vector rotator transform these are specific to 3d game engines so for now let us just keep it to integer and now if i just select this variable as you can see in the details panel it pops up everything so i'll just drag this over here and let us see this in more detail so here we can see the detail step so when i select a variable it is showing all the details of the variable so here it has the variable name and here it is showing us the integer so it is showing the data type so if i again click over here we can change it from here itself and here on the right side you can see the showing array set map so these are collections we'll see that later now we have instance editable we'll go on through all these properties through the course of time so for now uh we'll just focus on this the default value so the default value is given 30 usually it is 0 i don't know why it is showing 30 maybe because i have used the variable somewhere i don't know so let us just uh set the variable to sum like 90. so now the variable holds the data of integer of value 90. so i'll just drag it back over here again and now to use the variable what we can do is we can just select it and drag it into the graph like this so once you release your mouse you're going to get this options like get and set ammo so get is nothing but getting the value and set is nothing but setting the value so we can if we if i use the get node what i can do is i can use the value inside that variable so a basic example would be we'll just do an event begin play and then even begin play we'll just do print string as we have done previously and once here as you can see the print string it takes a string data type whereas we have an integer data type right so usually for all the common data types unreal engine automatically converts it so if i drag this over here integer and put it on string here you can see it is showing us convert integer to string so i'll press this and you can see a conversion node so this is how we use the get node and printed to the screen so let us see this in action so i'll just compile this and let us hit play so here you can see it is printing 90. now let us see how we can use the set node so to use a set node we can just drag it like this over here and select set and here we'll just drag the execution flow over here so now after printing the string we are going to set the value and we'll set the value to 30 so the previous thing i think and once we set it to 30 we'll again call print string and here you can see here it already gives us another node so here we can use this so after setting the value it is giving us the same variable value so retrieve the value of the variable can use instead of a separate get node so i can just use like this instead of dragging this and copying this and pasting it over here like this we can just use the same thing over here which already prove is provided by the set node so let us run this and now if you run this you might not notice the set node in action because it will just print both of these values that is 90 and 30 at the same time so i'll just hit play and here you can see 30 and 90 are displayed at the same time to actually see it working what we can do is we can add a delay node i think we have used this node before so i'll just call delay so delay node will actually wait for some time so whatever duration video usually it is in seconds so it will wait for that time after it waits then it will run whatever it's there on its right side so whatever it's there after this completed node execution flow it will run it so after it completes two seconds then it will go and set the value to 30 the ammo variables value then it will do the printing so let us see this in action i will compile this once again and let us hit play so here 90 and then you can see 30. so i hope you have understood the basic concept of variable data type and how we can create a variable how we can set get a variable and how we can print it to the screen obviously we have seen that before so i hope you have understood this concept and if you like this video hit that like button and also don't forget to hit that subscribe button and hit the bell icon and select all notifications to never miss any updates on my channel thank you for watching guys see you in the next video you"}], "Unreal Engine 5 BP Tutorial | 2.5 Name Datatype | 2. Variables | Aditya Burgula": [{"content": " Hello friends, welcome back to the brand new video. I'm Adithya and in this video guys will be learning about a new data type inside Unreal Engine that is, name. So without wasting time guys, let's get into the video. So friends, the name data type is very similar to the string data type which we have learned previously. So as a string data type can hold characters, numbers and special symbols, a text data type can also hold the same kind of data. Now we might wonder what makes the difference between these two data types then. The main difference is that the name data type is used to store or uniquely identify object names or asset names inside Unreal Engine like materials, levels and lot more. So let us see a kind of a simple example as to how we use this data type. So by default, Unreal actually provides a very commonly used node that is kind of called as open level. So by chance if you don't know what a level is, so a level is nothing much like this world which you can see over here which comprises of all the 3D objects, camera and the player itself. So this is kind of nothing what called as level and there is also an alternative name to this which is called as a map also. So if I go to the content drawer and here you can see by default I am in the starter contents and maps here you can see that kind of defaultly provided levels which is starter map and minimal default advanced lighting. So we will go to the starter map through coding and blueprint. So we will start with this map but through blueprint logic we will transition to another map. So how do we do that is using this open level. So if you clearly notice this, the open level has means accepts a data type of name. So this specifically used for these purposes and assets and all those things also use that same, so same data type. So what you can do is instead of pressing this press button, compiling it and giving it a new name. Instead of you can use you can just drag off this node like this and then choose promote to variable on the top. So once you click like that it is going to ask for a name. So I just name it as transition level name. So I will just compile it once more and once I press this and I go to details tab here you can see it is by default it is showing starter map. So we will just change to something else I guess I think I have selected it previously maybe I don't know."}, {"content": "So we will go to the minimal default. And one more thing about this data type is that they are case sensitive. So starter map so whatever you see the value right now, s is capital and m is capital. If the m is small, it represents a completely different asset if you provide it like this. And there is nothing called a starter map with small m. So the in real in general fail to find such an asset and you may be thrown up with an error."}, {"content": "So it is very important for you to check if they are spelling and the case is actually perfect or is correct. This is called as case sensitive even a string data type is also case sensitive. So here we will go to minimal underscore default. So let me just check the spelling once. So here minimal default. So I guess the spelling is perfectly fine."}, {"content": "Now we must write the logic for it. So I will take the begin play node over here and I will disconnect it by holding alt. We will just drag this down a little bit over here. Now after begin play what I am going to do is I am going to call a print string. So here I just said loading a level. So once it says that I will give a delay of two seconds. So once the delay is completed, we will do another print string and say loaded level loaded and immediately after that we will just call this open load function. And we can just keep the variable over here. So we will compile this program and it play. So here it is showing loading a level and level is loaded. So this is the minimal default level. So as you can see this is a quick transition. So this is a kind of a simple usage of this name baritite. So that was it for this video guys and I hope you liked this video. So thanks for watching guys. Please don't forget to hit that like button share button subscribe button and press it bell icon and select all notifications to never miss any updates on my channel. Thanks for watching guys. See you in the next video."}, {"content": " Hello friends, welcome back to the brand new video. I'm Adithya and in this video guys will be learning about a new data type inside Unreal Engine that is, name. So without wasting time guys, let's get into the video. So friends, the name data type is very similar to the string data type which we have learned previously. So as a string data type can hold characters, numbers and special symbols, a text data type can also hold the same kind of data. Now we might wonder what makes the difference between these two data types then. The main difference is that the name data type is used to store or uniquely identify object names or asset names inside Unreal Engine like materials, levels and lot more. So let us see a kind of a simple example as to how we use this data type. So by default, Unreal actually provides a very commonly used node that is kind of called as open level. So by chance if you don't know what a level is, so a level is nothing much like this world which you can see over here which comprises of all the 3D objects, camera and the player itself. So this kind of nothing. called as level and there's also an alternative name to this which is called as a map also. So if I go to the content drawer and here you can see by default I'm in the starter contents and maps here you can see that kind of defaultly provided levels which is starter map and minimal default advanced lighting. So we'll go to the starter map and through coding and blueprint. So we'll start with this map but through blueprint logic we'll transition to another map. So how we do that is using this open level. So if you clearly notice this the open level has uh means accepts a data type of name. So this specifically used for these purposes and assets and all those things also use that same."}, {"content": "So same data type. So what you can do is instead of compressing this press button, compiling it and giving it a new name. Instead of what you can use you can just drag off this node pin like this and then choose promote to variable on the top. So once you click like that it is going to ask for a name. So I just named it as transition level name. So I'll just compile it once more and once I press this and I go to details tab here you can see it is uh by default it is showing starter map. So we'll just change to something else I guess I think I have selected it previously maybe I don't know. So we'll go to the minimal default and one more thing about this data type is that they are case sensitive. So starter maps so whatever you see the value right now s is capital and m is capital. If the m is small it represents a completely different asset if you provide it like this and there's nothing called a starter map with small m. So the in real engine will fail to find such an asset and you may be thrown up with an error. So it is very important for you to check if they are spelling and the case is actually perfect or is correct. This is called as case sensitive even a string data type is also case sensitive. So here we'll go to minimal underscore default. So let me just check the spelling once so here minimal default."}, {"content": "So I guess the spelling is perfectly fine now we must write the logic for it. So I'll take the begin play node over here and I'll disconnect it by holding Alt. We'll just drag this down a little bit over here. Now after begin play what I'm going to do is I'm going to call a print string. So here I just said loading a level. So once it says that I'll give a delay of two seconds. So once the delay is completed, we'll do another print string and say load it, level load it. And immediately after that we'll just call this open load function. We can just keep the variable over here. So we'll compile this program and it play. So here it is showing loading a level and level is loaded. So there's the minimal default level. So as you can see, there's a quick transition. So this is a kind of a simple usage of this name baritite. So that was it for this video guys and I hope you liked this video."}, {"content": "So thanks for watching guys. Please don't forget to hit that like button, share button, subscribe button and press it bell icon and select all notifications to never miss any updates on my channel. Thanks for watching guys. See you in the next video."}, {"content": " Hello friends, welcome back to the brand new video. I'm Adithya and in this video guys will be learning about a new data type inside Unreal Engine that is, name. So without wasting time guys, let's get into the video. So friends, the name data type is very similar to the string data type which we have learned previously. So as a string data type can hold characters, numbers and special symbols, a text data type can also hold the same kind of data. Now we might wonder what makes the difference between these two data types then. The main difference is that the name data type is used to store or uniquely identify object names or asset names inside Unreal Engine like materials, levels and lot more. So let us see a kind of a simple example as to how we use this data type. So by default, Unreal actually provides a very commonly used node that is kind of called as open level. So by chance if you don't know what a level is, so a level is nothing much like this world which you can see over here which comprises of all the 3D objects, camera and the player itself. So this is kind of nothing what called as level and there is also an alternative name to this which is called as a map also. So if I go to the content drawer and here you can see by default I am in the starter contents and maps here you can see that kind of defaultly provided levels which is starter map and minimal default advanced lighting. So we will go to the starter map through coding and blueprint. So we will start with this map but through blueprint logic we will transition to another map. So how do we do that is using this open level. So if you clearly notice this, the open level has, means accepts a data type of name. So this specifically used for these purposes and assets and all those things also use that same, so same data type. So what you can do is instead of cup pressing this press button, compiling it and giving it a new name, instead of what you can use, you can just drag off this node, pin like this and then choose promote to variable on the top. So once you click like that, it is going to ask for a name. So I just named it as transition level name. So I'll just compile it once more and once I press this and I go to detail staff here, you can see it is by default at the showing starter map. So we'll just change to something else."}, {"content": "I guess I think I have selected it previously. Maybe I don't know. So we'll go to the minimal default and one more thing about this data type is that they are case sensitive. So starter map. So whatever you see the value right now, s is capital and m is capital. If the m is small, it represents a completely different asset if you provide it like this. And there's nothing called a starter map with small m. So the in real engine will fail to find such an asset and you may be thrown up with some error. So it is very important for you to check if the spelling and the case is actually perfect or is correct. This is called as case sensitive. Even a string data type is also case sensitive. So here we'll go to minimal underscore default. So let me just check the spelling ones. So here minimal default. So I guess the spelling is perfectly fine."}, {"content": "Now we might write the logic for it. So I'll take the begin play node over here and I'll disconnect it by holding Alt. We'll just drag this down a little bit over here. Now after begin play what I'm going to do is I'm going to call a print string. So here I just said loading a level. So once it says that I'll give a delay of two seconds. So once the delay is completed, we'll do another print string and say load it, level load it. And immediately after that we'll just call this open load function. We can just keep the variable over here. So we'll compile this program and it play. So here it is showing loading a level and level is loaded. So there's the minimal default level. So as you can see, there's a quick transition. So this is a kind of a simple usage of this name baritite. So that was it for this video guys and I hope you liked this video."}, {"content": " Hello friends, welcome back to the brand new video. I'm Adithya and in this video guys will be learning about a new data type inside Unreal Engine that is, name. So without wasting time guys, let's get into the video. So friends, the name data type is very similar to the string data type which we have learned previously. So as a string data type can hold characters, numbers and special symbols, a text data type can also hold the same kind of data. Now we might wonder what makes the difference between these two data types then. The main difference is that the name data type is used to store or uniquely identify object names or asset names inside Unreal Engine like materials, levels and lot more. So let us see a kind of a simple example as to how we use this data type. So by default, Unreal actually provides a very commonly used node that is kind of called as open level. So by chance if you don't know what a level is, so a level is nothing much like this world which you can see over here which comprises of all the 3D objects, camera and the player itself. So this is kind of nothing what called as level and there is also an alternative name for this which is called as a map. also. So if I go to the content drawer and here you can see by default I am in the starter contents and maps here you can see that kind of defaultly provided levels which is starter map and minimal default advanced lighting. So we will go to the starter map in through coding and blueprint. So we will start with this map but through blueprint logic we will transition to another map. So how we do that is using this open level. So if you clearly notice this the open level has means accepts a data type of name. So this specifically used for these purposes and assets and all those things also use that same. So same data type."}, {"content": "So what you can do is instead of pressing this press button come by and giving it a new name. Instead of what you can do is you can just drag off this node pin like this and then choose promote to variable on the top. So once you click like that it is going to ask for a name. So I just named it as transition level name. So I will just compile it once more and once I press this and I go to details tab here you can see it is by default at the  showing starter map. So we'll just change to something else I guess."}, {"content": "I think I have selected it previously maybe I don't know. So we'll go to the minimal default and one more thing about this data type is that they're case sensitive. So starter map. So whatever you see the value right now, s is capital and m is capital. If the m is small, it represents a completely different asset if you provide it like this. And there's nothing called a starter map with small m. So the in real engine will fail to find such an asset and you may be thrown up in a certain error. So it is very important for you to check if they are spelling and the case is actually perfect or is correct. This is called as case sensitive even a string data type is also case sensitive. So here we'll go to minimal underscore default. So let me just check the spelling once. So here minimal default. So I guess this spelling is perfectly fine. Now we must write the logic for it. So I'll take the begin play note over here and I'll disconnect it by holding alt. We'll just drag this down a little bit over here. Now after begin play what I'm going to do is I'm going to call a print string. here I just said loading a level. So once it says that I'll give a deal of two seconds. So once the delay is completed, we'll do another print string and say loaded level loaded. And immediately after that, we'll just call this open load function. And we can just keep the variable over here. So we'll compile this program and it play. So it is showing loading a level and level is loaded. So there's a minimal default level. So as you can see, there's a quick transition. So this is a kind of a simple usage of this name baritite. So that was it for this video guys."}, {"content": "And I hope you liked this video. So thanks for watching guys. Please don't forget to hit that like button share button subscribe button and press it bell icon and select all notifications to never miss any updates on my channel. Thanks for watching guys. See you in the next video."}, {"content": " Hello friends, welcome back to the brand new video. I'm Adithya and in this video guys will be learning about a new data type inside Unreal Engine that is, name. So without wasting time guys, let's get into the video. So friends, the name data type is very similar to the string data type which we have learned previously. So as a string data type can hold characters, numbers and special symbols, a text data type can also hold the same kind of data. Now we might wonder what makes the difference between these two data types then. The main difference is that the name data type is used to store or uniquely identify object names or asset names inside Unreal Engine like materials, levels and lot more. So let us see a kind of a simple example as to how we use this data type. So by default, Unreal actually provides a very commonly used node that is kind of called as open level. So by chance if you don't know what a level is, so a level is nothing much like this world which you can see over here which comprises of all the 3D objects, camera and the player itself. So this is kind of nothing what called as level and there is also an alternative name to this which is called as a map also. So if I go to the content drawer and here you can see by default I am in the starter contents and maps here you can see that kind of defaultly provided levels which is starter map and minimal default advanced lighting. So we will go to the starter map through coding and blueprint. So we will start with this map but through blueprint logic we will transition to another map. So how do we do that is using this open level. So if you clearly notice this, the open level has means accepts a data type of name. So this specifically used for these purposes and assets and all those things also use that same, so same data type. So what you can do is instead of pressing this press button, compiling it and giving it a new name. Instead of using it you can just drag off this node like this and then choose promote to variable on the top. So once you click like that it is going to ask for a name."}, {"content": "So I just named it as transition level name. So I will just compile it once more and once I press this and I go to detail tab here you can see it is by default it is showing starter map. So we will just change to some..."}, {"content": "thing I'll try is I think I have selected it previously maybe I don't know so we'll go to the minimal default and one more thing about this data type is that they are case sensitive. So starter map so whatever you see the value right now s is capital and m is capital if the m is small it represents a completely different asset if you provide it like this and there's nothing called a starter map with small m so the in real engine will fail to find such an asset and you may be thrown up with an error so it is very important for you to check if the spelling and the case is actually perfect or is correct this is called as case sensitive even a string data type is also case sensitive so here we'll go to minimal underscore default so let me just check the spelling once so here minimal default so I guess the spelling is perfectly fine now we must write the logic for it so I'll take the begin play node over here and I'll disconnect it by holding alt we'll just drag this down a little bit over here now after begin play what I'm going to do is I'm going to call a print string so here I just said loading a level so once it says that I'll give a delay of two seconds so once the delay is completed we'll do another print string and say load it level loaded and immediately after that will just call us open load function and we can just keep the variable over here so we'll compile this program and it play so here it is showing loading a level and level is loaded so there's the minimal default level so as you can see there's a quick transition so this is a kind of a simple usage of this name baritite so that was it for this video guys and I hope you liked this video so thanks for watching guys please don't forget to hit that like button share button subscribe button and press it bell icon and select all notifications to never miss any updates on my channel thanks for watching guys see you in the next video"}, {"content": " Hello friends, welcome back to the brand new video. I'm Adithya and in this video guys will be learning about a new data type inside Unreal Engine that is, name. So without wasting time guys, let's get into the video. So friends, the name data type is very similar to the string data type which we have learned previously. So as a string data type can hold characters, numbers and special symbols, a text data type can also hold the same kind of data. Now we might wonder what makes the difference between these two data types then. The main difference is that the name data type is used to store or uniquely identify object names or asset names inside Unreal Engine like materials, levels and lot more. So let us see a kind of a simple example as to how we use this data type. So by default, Unreal actually provides a very commonly used node that is kind of called as open level. So by chance if you don't know what a level is, so a level is nothing much like this world which you can see over here which comprises of all the 3D objects, camera and the player itself. So this is kind of nothing what called as level and there is also an alternative name to this which is called as a map also. So if I go to the content drawer and here you can see by default I am in the starter contents and maps here you can see that kind of defaultly provided levels which is starter map and minimal default advanced lighting. So we will go to the starter map through coding and blueprint. So we will start with this map but through blueprint logic we will transition to  another map. So how we do that is using this open level. So if you clearly notice this, the open level has, I mean, accepts a data type of name. So this specifically used for these purposes and assets and all those things also use that same."}, {"content": "So same data type. So what you can do is instead of cup pressing this press button, compiling it and giving it a new name, instead of what you can do is you can just drag off this node pin like this and then choose promote to variable on the top. So once you click like that, it is going to ask for a name. So I just named it as transition level name. So I'll just compile it once more and once I press this and I go to detail staff here, you can see it is by default it is showing starter map. So we'll just change to something else."}, {"content": "I guess I think I have selected it previously, maybe I don't know. So we'll go to the minimal default and one more thing about this data type is that they're case sensitive. So starter map. So whatever you see the value right now, s is capital and m is capital. If the m is small, it represents a completely different asset if you provide it like this. And there's nothing called a starter map with small m. So the in real engine will fail to find such an asset and you may be thrown up with an error. So it is very important for you to check if they are spelling and the case is actually perfect or is correct. This is called as case sensitive even a string data type is also case sensitive. So here we'll go to minimal underscore default. So let me just check the spelling once. So here minimal default. So I guess this spelling is perfectly fine. Now we must write the logic for it. So I'll take the begin play node over here and I'll disconnect it by holding Alt. We'll just drag this down a little bit over here. Now after begin play, what I'm going to do is I'm going to call a print string. So here I just said loading a level. So once it says that I'll give a delay of two seconds. So once the delay is completed, we'll do another print string and say load it, level load it and immediately after that we'll just call this open load function. And we can just keep the variable over here. So we'll compile this program and it play. So here it is showing loading a level and level is loaded. So this is the minimal default level. So as you can see, this is a quick transition. So this is a kind of a simple usage of this name baritite. So that was it for this video guys and I hope you liked this video."}, {"content": " Hello friends, welcome back to the brand new video. I'm Adithya and in this video guys will be learning about a new data type inside Unreal Engine that is, name. So without wasting time guys, let's get into the video. So friends, the name data type is very similar to the string data type which we have learned previously. So as a string data type can hold characters, numbers and special symbols, a text data type can also hold the same kind of data. Now we might wonder what makes the difference between these two data types then. The main difference is that the name data type is used to store or uniquely identify object names or asset names inside Unreal Engine like materials, levels and lot more. So let us see a kind of a simple example as to how we use this data type. So by default, Unreal actually provides a very commonly used node that is kind of called as open level. So by chance if you don't know what a level is, so a level is nothing much like this world which you can see over here which comprises of all the 3D objects, camera and the player itself. So this is kind of nothing what called as level and there is also an alternative name to this which is called as a map also. So if I go to the content drawer and here you can see by default I am in the starter contents and maps here you can see that kind of defaultly provided levels which is starter map and minimal default advanced lighting. So we will go to the starter map through coding and blueprint. So we will start with this map but through blueprint logic we will transition to another map. So how we do that is using this open level. So if you clearly notice this the open level has means accepts a data type of name. So this specifically used for these purposes and assets and all those things also use that same. So same data type. So what you can do is instead of cup pressing this press button, compiling it and giving it a new name. Instead of what you can do is you can just drag off this node pin like this and then choose promote to variable on the top. So once you click like that it is going to ask for a name."}, {"content": "So I just named it as transition level name. So I will just compile it once more and once I press this and I go to detail staff here you can see it is by default that is showing starter map. So we will just change to some."}, {"content": "thing I'll try is I think I have selected it previously maybe I don't know so we'll go to the minimal default and one more thing about this data type is that they are case sensitive. So starter map so whatever you see the value right now s is capital and m is capital if the m is small it represents a completely different asset if you provide it like this and there's nothing called a starter map with small m so the in real engine will fail to find such an asset and you may be thrown up with an error so it is very important for you to check if the spelling and the case is actually perfect or is correct this is called as case sensitive even a string data type is also case sensitive so here we'll go to minimal underscore default so let me just check the spelling once so here minimal default so I guess the spelling is perfectly fine now we must write the logic for it so I'll take the begin play node over here and I'll disconnect it by holding alt we'll just drag this down a little bit over here now after begin play what I'm going to do is I'm going to call a print string so here I just said loading a level so once it says that I'll give it  or dlee of two seconds. So once the delay is completed, we'll do another print string and say loaded, level loaded. And immediately after that, we'll just call this open load function. And we can just keep the variable over here. So we'll compile this program and it play. So it is showing loading a level and level is loaded. So this is the minimal default level. So as you can see, this is a quick transition. So this is a kind of a simple usage of this name paradigm. So that was it for this video guys and I hope you liked this video. So thanks for watching guys. Please don't forget to hit that like button, share button, subscribe button and press it bell icon and select all notifications to never miss any updates on my channel. Thanks for watching guys. See you in the next video."}], "Unreal Engine 5 BP Tutorial | 2.2 Float Datatype | 2. Variables | Aditya Burgula": [{"content": " Hello friends welcome back to another brand new video. I'm Aditya and in this video we will be learning about float data type inside of V5. Without wasting any time guys, let us get into the video. So friends, we have covered about indeed data type. And that data type is very simple. We have seen how we can use it to store numbers. Now when it comes to float data type, it is pretty much the same. We can use it to store numbers. So then what makes the difference between integer and flow? It's very simple. Intitator type is used to store integers. And whereas float data type is used to store rational numbers. So let us have a quick overview of what integers and rational numbers are. In mathematics, we have very popular sets like national numbers, which are a set of numbers starting from 1 to infinity. Then we have whole number set, which starts from 0 to infinity. Then we have integer set and that set has all numbers, all the positive numbers, and all the negative numbers till infinity and then 0. Then we have on top of that, we have rational numbers. So in rational numbers, we have all these fractions. So that fractions are nothing but decimals. And those fractions we can store in the form of float data. On top of rational numbers, we have rational numbers. So that is all the topic right now here. Let us just discuss about rational numbers. So let us see the practical implementation of it by creating a new variable."}, {"content": "So I'll just click on this. And as you can see, it is asking for a variable name. And I'll just give it a help. So usually health is stored as a float data data because it can have fractions in all the states. And we give percent to say it's like 100 percent has 37 percent health. And that time you need fractions. So health. And I created the variable health. Now I'm just going to drag it into the screen and just get it. So this is how you get the value. And now in the details tab, I think you can see once you've selected, it is showing please compile the product. So we'll compile it now. And you can see we can set the value. And you can see 0.00. So notice the difference. We got the point over here. 0.00. Whereas if I click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimals, it's the float. So let us just create a simple program."}, {"content": "I'll just call the event tick. And we'll do a princess. So now what is event tick? So event tick has nothing but just like event begin play. As event begin play is called when the game starts, exactly when the game starts and only once it is just called once, the event tick is called every frame. It is called every frame. So if your game is running at 60 FPS, that time it will call whatever is connected to this node. 60 times is second. So if I attach it to the string, and it has already created the conversion node, just like for the integer, now let us compile this and let us run. So it's going to show like whole this top number. So it's going to continuously printed. So if I hit play, you can see 0.00. Just continuous printing. I don't know what my frame rate is, maybe 60 I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. It can also select it over here than node also. And let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it."}, {"content": "It's quite simple. There's nothing much to complex in it. There's nothing but a derivative which can just store rational values or decimal values. So I hope you like this video."}, {"content": "If you did it, please hit that like button. And also hit the subscribe button and press the bell icon. So that you never miss any updates on my channel. Thanks for watching. I see you in the next video."}, {"content": "So I'll just click on this. And as you can see, it is asking for a variable name. And I'll just give it a help. So usually health is stored as a float data data because it can have fractions in all the states. And we give percent to say that 100 percent has 37 percent health. And that time you need fractions. So health. And I created the variable help. Now I'm just going to drag it into the screen and just get. So this is how you get the value. And now in the details tab, I think you can see once you've selected, it is showing please compile the program. So we'll compile it now. And you can see we can set the value. And you can see 0.00. So notice the difference. We got the point over here, 0.00. Whereas if I click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimals, it's the float. Let us just create a simple program."}, {"content": "I'll just call the event tick. And we'll do a printed. So now what is event tick? So event tick has nothing but just like event begin play. As event begin play is called when the game starts exactly when the game starts and only once it is just called once, the event tick is called every frame. It is called every frame. So if your game is running at 60 FPS, that time, it will call whatever is connected to this node 60 times is second. So if I attach it to the string, and it has already created the conversion node just like for the integer. Now let us compile this and let us run. So it's going to show like whole this stuff numbers. It's going to continuously printed. So if I hit play, you can see 0.00. It just continues printing. I don't know what my frame rate is, maybe 60, I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. You can also select it over here the node also. And let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it."}, {"content": "It's quite simple. There's nothing much to complex in it. There's nothing but a derivative. This can just store rational values or decimal values. So I hope you liked this video."}, {"content": "If you did, please hit that like button. And also hit the subscribe button and press the bell icon so that you never miss any updates on my channel. Thanks for watching. I'll see you in the next video."}, {"content": "So I'll just click on this. And as you can see, it is asking for a variable name. And I'll just give it a help. So usually health is stored as a float data data because it can have fractions in all the states. And we give percent to say that 100 percent has 37 percent health. And that time you need fractions. So health. And I created the variable health. Now I'm just going to drag it into the screen and just get. So this is how you get the value. And now in the details tab, I think you can see once you've selected, it is showing please compile the tokens. So we'll compile it now and you can see we can set the value and you can see 0.00. So notice the difference. We got the point over here 0.00. Whereas if I click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimals, you need to float. Let us just create a simple program."}, {"content": "I'll just call it a event tick and we'll do a printed. So now what is event tick? So event tick has nothing but just like event begin play. As event begin play is called when the game starts exactly when the game starts and only once it is just called once. The event tick is called every frame. It is called every frame. So if your game is running at 60 FPS, that time it will call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node just like for the integer. Now let us compile this and let us run. So it's going to show like whole this stuff numbers. It's going to continuously printed. So if I hit play, you can see 0.00 is just continuous printing. I don't know what my frame rate is maybe 60 I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. You can also select it over here the node also. And let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it."}, {"content": "It's quite simple. There's nothing much to complex in it. There's nothing but a derivative which can just store rational value. So I hope you liked this video."}, {"content": "If you did, please hit that like button and also hit the subscribe button and press the bell icon so that you never miss any updates on my channel. Thanks for watching. I see you in the next video."}, {"content": "So I'll just click on this. And as you can see, it is asking for a variable name. And I'll just give it a help. So usually health is stored as a float data data because it can have fractions in all the states. And we give percent to say that 100 percent has 37 percent health. And that time you need fractions. So health. And I created the variable health. Now I'm just going to drag it into the screen. and just fit get. So this is how you get the value and now in the details tab I think you can see once you've selected it is showing please compile the program so we'll compile it now and you can see we can set the value and you can see 0.00. So notice the difference we got the point over here 0.00. Whereas if I click on the integer variable and if we scroll to the value we can see we do not have any point we can just we can just store a number that's it we can't store the fractions or decimals. So when you want to store any fraction or decimals you need to float. So let us just create a simple program."}, {"content": "I'll just call the event tick and we'll do a princess. So now what is event tick? So event tick is nothing but just like event begin play as event begin play is called when the game starts exactly when the game starts and only once it is just called once the event tick is called every frame it is called every frame. So if your game is running at 60 FPS that time it will call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node just like for the integer now let us compile this and let us run. So it's going to show like whole this stuff numbers it's going to continuously printed. So if I hit play you can see 0 it is just continuous printing I don't know what my frame rate is maybe 60 I guess so 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here can also select it over here the node also and let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate I hope you have understood it. It's quite simple there's nothing much too complex in it. There's nothing but a derivative which can just store rational values or decimal values. So I hope you like this video you protect please hit that like button and also hit the subscribe button and press the bell icon so that you never miss any updates on my channel."}, {"content": "Thanks for watching and see you in the next video."}, {"content": "So I'll just click on this. And as you can see, it is asking for a variable name. And I'll just give it a help. So usually health is stored as a float data data because it can have fractions in all the states. And we give percent to say it's like 100 percent has 37 percent health. And that time you need fractions. So health. And I created the variable health. Now I'm just going to drag it into the screen and just get it. So this is how you get the value. And now in the details tab, I think you can see once you've selected, it is showing please compile the product. So we'll compile it now. And you can see we can set the value. And you can see 0.00. So notice the difference. We got the point over here. 0.00. Whereas if I click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimals, you need to float. Let us just create a simple program. I'll just call it EventTick and we'll do a printed. So now what is EventTick? So EventTick is nothing but just like EventPigantPlay. As EventPigantPlay is called when the game starts, exactly when the game starts and only once it is just called once, the EventTick is called every frame. It is called every frame. So if your game is running at 60 FPS, that time it will call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node, just like for the integer. Now let us compile this and let us run."}, {"content": "So it's going to show like whole this stuff numbers. It's going to continuously printed. So if I hit play, you can see zero. It is just continuous printing. I don't know what my frame rate is maybe 60 I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. You can also select it over here the node also. And let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it."}, {"content": "It's quite simple. There's nothing much to complex in it. There's nothing but a derivative which can just store rational values or decimal values. So I hope you liked this video."}, {"content": "If you did it, please hit that like button and also hit the subscribe button and press the bell icon so that you never miss any updates on my channel. Thanks for watching. I see you in the next video. Bye."}, {"content": "So I'll just click on this. And as you can see, it is asking for a variable name. And I'll just give it a help. So usually health is stored as a float data data because it can have fractions in all the states. And we give percent to say it's like 100 percent has 37 percent health. And that time you need fractions. So health. And I created the variable health. Now I'm just going to drag it into the screen and just get it. So this is how you get the value. And now in the details tab, I think you can see once you've selected, it is showing please compile the product. So we'll compile it now. And you can see we can set the value. And you can see 0.00. So notice the difference we got. the point over here 0.00. Whereas if I click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimals, you need to float. Let us just create a simple program."}, {"content": "I'll just call it a event tick and we'll do a princess. So now what is event tick? So event tick is nothing but just like event begin play. As event begin play is called when the game starts, exactly when the game starts and only once it is just called once, the event tick is called every frame. It is called every frame. So if your game is running at 60 FPS, that time it will call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node just like for the integer. Now let us compile this and let us run. So it's going to show like whole this stuff numbers. It's going to continuously printed. So if I hit play, you can see 0. It is just continuous printing. I don't know what my frame rate is maybe 60 I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. You can also select it over here the node also and let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it."}, {"content": "It's quite simple. There's nothing much too complex in it. There's nothing but a derivative which can just store rational values or decimal values. So I hope you like this video."}, {"content": "If you did it, please hit that like button and also hit the subscribe button and press the bell icon so that you never miss any updates on my channel. Thanks for watching and see you in the next video."}, {"content": " Hello friends welcome back to another brand new video. I'm Aditya and in this video we will be learning about float data type inside of V5. Without wasting any time guys, let us get into the video. So friends, we have covered about indeed data type. And that data type is very simple. We have seen how we can use it to store numbers. Now when it comes to float data type, it is pretty much the same. We can use it to store numbers. So then what makes the difference between integer and flow? It's very simple. Intitator type is used to store integers. And whereas float data type is used to store rational numbers. So let us have a quick overview of what integers and rational numbers are. In mathematics, we have very popular sets like national numbers, which are a set of numbers starting from 1 to infinity. Then we have whole number set, which starts from 0 to infinity. Then we have integer set and that set has all numbers, all the positive numbers, and all the negative numbers till infinity and then 0. Then we have on top of that we have rational numbers. So in rational numbers,  numbers we have all these fractions right so that fractions are nothing but decimals and those fractions we can store in the form of flow data. So and on top of fraction numbers we have a ration numbers so that is of the copy right now here let us just discuss about fraction numbers. So let us see the practical implementation of it by creating a new variable."}, {"content": "So I'll just click on this and as you can see it is asking for a variable name and I'll just give it a help. So usually health is stored as a flow data data because it can have fractions in all those things and we give percent to say like 100 percent has 37 percent health and that time you need fractions. So health and I created the variable health now I'm just going to drag it into the screen and just get. So this is how you get the value and now in the details tab I think you can see once you've selected it is showing please compile the product so we'll compile it now and you can see we can set the value and you can see 0.00. So notice the difference we got the point over here 0.00. zero. Whereas if I click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimal. So when you want to store any fraction or decimal, you need to float. Let us just create a simple program. I'll just call it a event tick and we'll do a princess. So now what is event tick? So event tick is nothing but just like event tick and begin play. As event begin play is called when the game starts exactly when the game starts and only once it is just called once, the event tick is called every frame. It is called every frame. So if your game is running at 60 FPS, that time it will call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node just like for the integer. Now let us compile this and let us run. So it's going to show like whole this stuff numbers. It's  You can see 0 it is just continuous printing. I don't know what my frame rate is maybe 60 I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. You can also select it over here the node also. And let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it."}, {"content": "It's quite simple. There's nothing much to complex in it. There's nothing but a dilatant which can just store rational values or decimal values. So I hope you liked this video."}, {"content": "If you did, please hit that like button. And also hit the subscribe button and press the bell icon so that you never miss any updates on my channel. Thanks for watching. I see you in the next video."}, {"content": "So I'll just click on this. And as you can see, it is asking for a variable name. And I'll just give it a help. So usually health is stored as a float data data because it can have fractions in all the states. And we give percent to say it's like 100 percent has 37 percent health. And that time you need fractions. So health. And I created the variable health. Now I'm just going to drag it into the screen and just get it. So this is how you get the value. And now in the details tab, I think you can see once you've selected, it is showing please compile the product. So we'll compile it now. And you can see we can set the value. And you can see 0.00. So notice the difference. We got the point over here. 0.00. Where are I see? click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimals, you need to float. Let us just create a simple program."}, {"content": "I'll just call it a event tick and we'll do a princess. So now what is event tick? So event tick is nothing but just like event begin play. As event begin play is called when the game starts, exactly when the game starts and only once it is just called once, the event tick is called every frame. It is called every frame. So if your game is running at 60 of years, that time it will call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node just like for the integer. Now let us compile this and let us run. So it's going to show like whole this stuff. Numbers it's going to continuously print it. So if I hit play, you can see zero. It is just continuous printing. I don't know what my frame rate is maybe 60 I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. You can also select it over here the node also and let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it."}, {"content": "It's quite simple. There's nothing much too complex in it. There's nothing but a derivative. This can just store rational values or decimal values. So I hope you liked this video."}, {"content": "So I'll just click on this."}, {"content": "And as you can see, it is asking for a variable name and I'll just give it a hell. So usually health is stored as a flow data because it can have fractions in all those things. And we give percent is like 100 percent has 37 percent health and that time you need fractions. So health and I created the variable health. Now I'm just going to drag it into the screen and just get. So this is how you get the value. And now in the details tab, I think you can see once you've selected, it is showing please compile the tokens. So we'll compile it now and you can see we can set the value and you can see 0.00. So notice the difference. We got the point over here 0.00. Whereas if I click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just we can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimal units to float, let us just create a simple program. I'll just call the event tick."}, {"content": "And we'll do a printed. So now what is event tick? So event tick has nothing but just like event begin play. As event begin play is called when the game starts exactly when the game starts and only once it is just called once. The event tick is called every frame. It is called every frame. So if your game is running at 60 FPS that time,  call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node just like for the integer. Now let us compile this and let us run. So it's going to show like whole this stuff numbers. It's going to continuously printed. So if I hit play you can see zero it is just continuous printing. I don't know what my frame rate is maybe 60 I guess. So 60 or 70 maybe. So now let us just give a value to it. So I'll just select the health over here. You can also select it over here the node also. And let us scroll and give it some value and compile and play. Here you can see it is just printing it. So that was about float rate. I hope you have understood it. It's quite simple. There's nothing much too complex in it. There's nothing but a derivative which can just store rational values or decimal values. So I hope you like this video."}, {"content": "If you did it please hit that like button and also hit the subscribe button and press the bell icon so that you never miss any updates on my channel. Thanks for watching and see you in the next video."}, {"content": " Hello friends welcome back to another brand new video. I'm Aditya and in this video we will be learning about float data type inside of V5. Without wasting any time guys, let us get into the video. So friends, we have covered about indeed data type. And that data type is very simple. We have seen how we can use it to store numbers. Now when it comes to float data type, it is pretty much the same. We can use it to store numbers. So then what makes the difference between integer and flow? It's very simple. Intitator type is used to store integers. And whereas float data type is used to store rational numbers. So let us have a quick overview of what integers and rational numbers are. In mathematics, we have very popular sets like national numbers, which are a set of numbers starting from 1 to infinity. Then we have whole number set, which starts from 0 to infinity. Then we have integer set and that set has all numbers, all the positive numbers, and all the negative numbers till infinity and then 0. Then we have on top of that we have rational numbers."}, {"content": "So in rational numbers, we have all the positive numbers. fractions right so that fractions are nothing but decimals and those fractions we can store in the form of flow data so and on top of fraction numbers we have a ration numbers so that is of the copy right now here let us just discuss about fraction numbers so let us see the practical implementation of it by creating a new variable so I'll just click on this and as you can see it is asking for a variable name and I'll just give it a help so usually health is stored as a flow data because it can have fractions in all those things and we give percent percent like 100 percent has 37 percent health and that time you need fractions so health and I created the variable health now I'm just going to drag it into the screen and just get so this is how you get the value and now in the details tab I think you can see once you've selected it is showing please compile the tokens so we'll compile it now and you can see we can set the value and you can see 0.00 so notice the difference we got the point over here 0.00 where I see  click on the integer variable and if we scroll to the value, we can see we do not have any point. We can just store a number. That's it. We can't store the fractions or decimals. So when you want to store any fraction or decimals, you need to float. Let us just create a simple program. I'll just call it a event tick and we'll do a princess. So now what is event tick? So event tick is nothing but just like event begin play. As event begin play is called when the game starts, exactly when the game starts and only once it is just called once, the event tick is called every frame. It is called every frame. So if your game is running at 60 of years, that time it will call whatever is connected to this node 60 times a second. So if I attach it to the string and it has already created the conversion node just like for the integer. Now let us compile this and let us write. So it's going to show like whole this stuff. The numbers it's going to continuously print it. So if I hit play, you can see zero. It is just continuously printing. I don't know what my."}, {"content": "So, now let us just give a value to it. So, I will just select the health over here. You can also select it over here, the node also. And let us scroll and give it some value and compile and play. Here you can see it is just printing it. So, that was about float prototype. I hope you have understood it. It's quite simple. There's nothing much too complex in it. There's nothing but a derivative which can just store rational values or decimal values. So, I hope you liked this video."}, {"content": "If you did, please hit that like button and also hit the subscribe button and press the bell icon so that you never miss any updates on my channel. Thanks for watching and see you in the next video. You"}], "Doctor explains CO-CODAMOL (Paracetamol/Codeine) | Doses, side effects, interactions and more!": [{"content": "hi I'm Dr James Donovan and today we're going to cover key things that you need to know about codol a combination painkiller made up of paracetamol and Codine now it's typically used to treat types of pain including headaches muscle pain migraines and tooth AE and it's especially helpful when common painkillers like ipren or aspirin aren't effective or they're not working now in this video we're going to cover several key important things that I think you need to know about codal including who can and can't take codol how and when to take it side effects potential interactions with other medications that you might be taking as well as common questions that I'm often asked and additional resources but before we start what exactly is codol and how does it work well codol contains two medicines paracetamol and Codine these two painkillers work in different ways to relieve pain paracetamol seems to work by blocking chemical messages in the brain that tell us that we've got pain pain it also helps by reducing high temperatures by affecting the chemical messenges in an area of your brain that controls body temperature on the other hand Codine belongs to a group of medicines called opioids now these medicines include things like morphine it affects pain receptors and helps the brain to block pain signals to the rest of the body now when Codine blocks the pain receptors there can be other unwanted effects like slow and shallow breathing and it can also cause slowing of digestion which is why Codine tends to cause constipation so firstly who can and can't take codol well most adults and young people age 12 and 17 can take it but it's not suitable for everyone that it's really important that you talk to your doctor if you have any lung or breathing problems a head injury adrenal gland issues which are the glands that sit on top of your kidneys seizure disorders or if you drink more than 14 units of alcohol a week it's also important that you tell your doctor if you're pregnant trying to get pregnant or if you're breastfeeding so now let's talk about how and when to take codal well codal comes in three different strengths and while you can buy the lowest strength over the calter from the pharmacist the highest strength need a prescription from your doctor now it can sometimes be a little bit tricky to understand the strength of the tablet and how much of each medicine is in each tablet but in general codal tablets and capsules come in three different strengths containing 8 milligrams 15 milligram or 30 milligram of Codine now all three strengths of tablets contain 500 milligrams of paracetamol the same as in a standard paracetamol tablet or capule now the strength of codol appears as two numbers on the packet for example 8 500 means that each tablet or capsule contains 8 migs of Codine and 500 milligrams of paracetamol now the key is to follow your doctor's instructions carefully because codal can can be addictive adults shouldn't exceed eight tablets in 24 hours and should leave at least 4 to 6 hours between doses in terms of practical tips for taking them swallow the tablets or capsules whole with water and if you're using soluble tablets this means you can dissolve them in water first and codol can be taken with or without food now it's important to know how long to take codol for and your doctor should be guiding you but if you bought it to Pharmacy don't use it for more than 3 days without Consulting a healthc care professional if it doesn't seem to be working after this period of time it's also important to know that taking too much codol can be very dangerous and that's because the paraset molinet can cause liver damage don't increase the dose of codol or take more than two tablets at once even if your pain is very bad and talk to your pharmacist or a doctor if you think the dose is not enough to help your pain and they might be able to recommend other alternatives to help you it's also important that you don't take paracetamol at the same time because obviously codal contains paracetamol and remember that it can be addictive so now let's talk about potential side effects whil as many people experience no or mild side effects common issues can include constipation nausea dizziness sleepiness and headaches now if these persist or they become problematic it's important again to speak to your doctor or pharmacist now for serious side effects like breathing difficulties seizures or severe allergic reactions it's really important that you seek medical help immediately it's also important to be aware of possib interactions with other medications that you might be taking and that's because codol can affect how other medications work including sleeping pills anti-depressants and medicines for blood clots or infections now it's generally safe to take with ibuprofen and aspirin but you should always avoid other medications containing paracetamol to prevent overdose it's also important that you read the information leaflet inside the pack fully before you start taking it finally let's cover some common questions that people often have about this medication so first people often ask how long does it take to work well generally codol starts to relieve pain about an hour but this can vary from person to person other people ask can I drive or operate Machinery well it's important that you don't drive a car ride a bike or use tools on Machinery if codal makes you sleepy gives you blurred vision or makes you feel dizzy clumsy or unable to concentrate or make decisions now this might be more likely when you first start taking code code all but it could happen at any time so for example when you use another medication it's really important to remember that here in the UK it's an offense to drive a car if your ability to drive safely is affected it's your responsibility to decide if it's safe to drive and if you in any doubt don't drive even if your ability to drive is not affected the police have got the right to request a saliva sample to check how much codol is in your body some people also ask can I drink alcohol with it well it's best to avoid alcohol especially when you first start taking coco demol or if it makes you sleepy other people ask can I become addicted well if you start taking Coco deol regularly for a long time you can become addicted to the coding in it you're likely to become addicted if you follow your doctor's advice carefully about how long to take it for and if you've bought Coco monitor Pharmacy always follow the instructions that come with the medicine and remember only take it for a maximum of 3 days at a time if your pain is not better after 3 days it's important to speak to your doctor for advice about further pain relief it's also really important only take codal for the shortest amount of time possible now remember these are not all of the side effects or interactions and remember for a full list always check the information leaflet inside your medication packet I've also included useful links in the description box of this video with more information from the NHS website if you're pregnant breastfeeding or trying to get pregnant or if you want to learn more about codol this video was just intended as a general guide and educational resource I am by no means promoting codal use but it can be a useful pain relief in certain circumstances now if you do have any questions please post them in the comments section once again thanks for watching I hope you learn something new and until next time bye"}], "Justice: What's The Right Thing To Do? Episode 04: \"THIS LAND IS MY LAND\"": [{"content": "funding for this program is provided by additional funding provided by today we turn to John Locke on the face of it Locke is a powerful ally of the libertarian first he believes, as libertarians today maintain that there are certain fundamental individual\nrights that are so important that no government even a representative government even a\ndemocratically elected government can override them. not only that he believes that those fundamental rights include a natural right to life liberty and property and furthermore he argues that the right to property is not just the creation of government or of law the right to property is a natural right in the sense that it is pre-political it is a right that attaches  to individuals as human beings even before government comes on the scene even before parliaments and legislatures enact\nlaws to define rights and to enforce them Locke says in order to think about what it means to have a natural right we have to imagine the way things are before government before law and that's what Locke means by the state of nature. he says the state of nature is the state of\nliberty human beings are free and equal beings there is no natural hierarchy it's not the case that some people are born\nto be kings and others were born to be serfs we're free and equal in the state of nature and yet he makes the point but there's a difference between a state of\nliberty and the state of license and the reason is that even in the state of\nnature there is a kind of the law it's not the kind of law the legislatures enact it's the law of nature and this law of nature constrains what we can do even though we're free even though we're in the state of nature well what are the constraints? the only constraint given by the laws of nature is that the rights we have the national rights we have we can't give up nor can we take them from somebody else under the law of nature I'm not free take somebody else's life or liberty or property nor am I free to take my own life liberty or property even though I'm free, I'm not free to violate the laws of nature, I'm not free\nto take my own life or to sell myself into slavery or to give to somebody else arbitrary absolute power over me so where does this constraint you may think it's a fairly minimal constraint,\nbut where does it come from? Well Locke tells us where it comes from and he gives two answers  here's the first answer for men being all the workmanship of one omnipotent and infinitely wise maker,\nnamely God, they're his property whose workmanship they are, made to last during his, not one another's pleasure. so one answer the question is why can't I\ngive up my natural rights to life liberty and property well they're not strictly speaking yours after all you are the creature of God. God has a  bigger property right in us a prior priority right now you might say that an unsatisfying unconvincing answer at least\nfor those who don't believe in God what did Locke have to say to them well here's where Locke appeals to the idea of reason and this is the idea that if we properly reflect on what it means to be free we will be lead to the conclusion that freedom can't just be a matter of doing\nwhatever we want I think this is what Locke means when he says the state of nature has a law of nature to govern it\nwhich obliges everyone and reason which is that law teaches all mankind, who will but consult it, that\nbeing all equal and independent no one ought to harm another in his life health\nliberty for possessions this leads to a puzzling paradoxical feature to Locke's account of rights familiar in one sense but strange in another it's the idea that out natural rights are inalienable what does unalienable mean? it's not for us to alienate them or to get them\nup to give them a way to trade them the way to sell them consider an airline ticket airline tickets are nontransferable or tickets to the patriots or to the red\nsox nontransferable tickets are unalienable I own them in the limited sense that I can use them for myself but I can't\ntrade them away so in one sense an unalienable right,\na  nontransferable right makes something I own less fully mine but in another sense of unalienable rights especially where we're thinking about life liberty\nand property for a right to be unalienable, makes it\nmore deeply more profoundly mine and that's Locke's sense of unalienable we see it in the American declaration of independence\nThomas Jefferson drew on this idea of Locke unalienable rights to life liberty and as Jefferson amended Locke, to the pursuit of happiness. unalienable rights rights that are so essentially mine that even I can't trade them away or give\nthem up so these are the rights we have in the state of \nnature before there is any government in the case of life and liberty I can't take\nmy own life I can't sell myself into slavery anymore than I can take somebody else's life\nor take someone else as a slave by force but how does that work in the case of property? because it's essential to Locke's case that private property can arise even before there is any government how can there be a right to private property even before there is any government? Locke's famous answer comes in section twenty seven every man has a property in his own person this nobody has any right to but himself the labor of his body the work of his hands we may say are properly his so he moves as the libertarians later of would move from the idea that we own ourselves that we have property in our persons to the closely connected idea that we own\nour own labor and from that to the further claim that whatever we mix our labor with is unowned becomes our property whatsoever then he removes out of the state that nature \nhas provided, and left it in, he has mixed his labor with, and joined to it  \nsomething that is his own, and thereby makes it his property why? because the labor is the questionable property of the laborer and therefore  no one but the laborer can have a right to what is joined to or mixed with his labor and then he adds this important provision at least where there is enough and as good\nleft in common for others. but we not only acquire our property in the fruits of the\nearth in the deer that we hunt in the fish that we catch but also if we till and plow and enclose the land \nand grow potatoes we own not only the potatoes but the land the earth as much land as a man tills, plants, improves,\ncultivates, and can use the product of, so much is his property. he by his labor encloses it from the commons. so the idea is that rights are unalienable seems to\ndistance Locke from a libertarian libertarian wants to say we have an absolute property rate in our selves and therefore we can do with ourselves whatever\nwe want Locke is not a sturdy ally for that view in fact he says if you take  natural rights seriously you'll be led to the\nidea that there are certain constraints on what we can do with our natural\nrights, constraints given either by God or by reason reflecting on what it means\nreally to be free and really to be free means recognizing that our rights are unalienable so here's the difference between Locke and\nthe libertarians but when it comes the Locke's account of private property he begins to look again like a pretty good ally because he's argument for private property begins with the idea that we are the proprietors\nof our own person and therefore of our labor and there of the\nfruits of our labor including not only the things we gather and hunt in the state of nature but also we acquire a property right in the\nland that we enclosed and cultivate and improve there are some examples that can bring out\nthe the moral intuition that our labor can take something that is unowned and make it ours though sometimes there are disputes about this there's a debate among rich countries and developing countries about trade related intellectual property\nrights it came to a head recently over drug patent laws western countries and especially the united states\nsay we have a big pharmaceutical industry that develops  new drugs we want all countries in the world to agree to respect the patents then there came along the aids crisis\nin south Africa and the American aids drugs were hugely expensive far more than could be afforded by most Africans so the south African government said we're going to begin to buy a generic version of the AIDS antiretroviral drug at a tiny fraction of the cost because we can find an Indian manufacturing company that figures out how the thing is made and produces it and for a tiny fraction of the cost we can\nsave lives if we don't respect that patent and then the American government said no here's a company that invested research and created this drug you can just start mass-producing  these drugs without paying the licensing fee so there was a dispute the US and the pharmaceutical companies sued the\nsouth African government to try to prevent their buying the cheap generic this they saw it, pirated version of an aids drug and eventually the pharmaceutical industry gave in and said all right you can do that but this dispute\nabout what the rules of property should be of intellectual property of drug patenting in a way is the last frontier of the state of\nnature because among nations where there is no uniform\nlaw of patent rights and property rights it's up for grabs until by some act of consent some international agreement people enter into some settled rules. what about Locke's account of private property and how it can arise before government and before law comes on\nthe scene is it successful?"}, {"content": "how many think it's pretty persuasive? how many don't find it persuasive? now let's hear from some critics what is wrong with Locke's account of how private property can arise without consent I think it's justifies European cultural norms as far as you look at how native Americans may not cultivated American\nland by their arrival in the America's  that that contributed to the development of America\nwhich would have otherwise necessarily happened then or by that specific group so you think that this defense this\ndefense of private property in land yes because it complicate original acquisitions\nif you only site the arrival of foreigners that cultivated the land I see, and what's your name? Rachelle Rachelle? Rachelle says this account of how property arises would fit what was going on in north America during the time of the settlement, the European settlement do you think Rochelle, that it's  it's a way of defending the appropriation of the land indeed, because he is  also you know, justifying the glorious revolution, so\nI don't think it's inconceivable that he's also justifying colonization as well well that's an interesting historical suggestion and I think there's a lot to be said for it what do you think of the validity of his argument though? because if you're right that this would justify the taking of land\nin north America from native Americans who didn't enclose it, if it's a good argument then Locke's given us a justification for that\nif it's a bad argument then Locke's given us a mere rationalization it is morally indefensible I'm leaning to the second one. You're leaning \nto the second one, but that's my opinion as well alright let's hear if there's a defender of  Locke\u2019s account\nof private property and it would be interesting if they could\naddress Rachelle's worried that this is just a way of defending\nthe the appropriation of land by the American colonists from the native Americans who didn't \nenclose it is there someone who will defend Locke on that point? you're ready are you going to defend Locke? but you're you're accusing him of justifying\nthe European basically massacre of the native Americans but who says he's defending it maybe the European\ncolonization isn't right you know maybe it's the state of war that\nhe talked about in his second treatise, you know so the war is between the native Americans and the colonists, the settlers that might have been a state of war that we can only emerged from by an agreement or an act of consent and that's what would have been required yeah and both sides would have to agree to\nand carry out and everything but what about and what's your name? Dan. Dan, what about Rachelle's says this argument in section twenty seven and then in thirty\ntwo about appropriating land that argument if it's valid would justify the settlers appropriating that land and excluding others from it you think that argument\u2019s a good argument? well does it kind of imply that the native\nAmericans hadn't already done that? well the native Americans as hunter gatherers\ndidn't actually enclose enclose land so I think Rochelle is on to something there what I wanted I go ahead Dan. At the same time he's saying that just by\npicking an acorn or taking a apple or maybe killing of buffalo on a certain amount\nof land that makes it yours because it's your labor and\nthat's your labor would enclose that land so by that definition maybe they didn't have fences around little plots of land but didn't they were using it so by Locke's definitions, so maybe by Locke's\ndefinition the native Americans could have claimed a property\nrights in the land itself but they just didn't\nhave Locke on their side as she points out. good okay that's good One more defender of Locke well I mean just to defend Locke, he does say \nthere are some times in which you can't take another person's\nland for example you can't acquire land that is common property to people and in terms of \nAmerican Indians I feel like they already have civilizations themselves and they were using land in common so it's kind \nof like an analogy to what he was talking about\nwith like the  common English property you can't take land that everyone has in common. That's very interesting and you can't take land unless you make sure that there's as much\nland as possible enough for other people take as well so if you're taking common,  so you have to make sure whenever you take land or that there's enough let for other people to use that's just as good as the land that you took That's true, Locke says there has to be this right to private property in the earth is\nsubject to the provision that there be as much and as good \nleft for others what's your name. I'm Fang So Fang in a way agrees with Dan that maybe\nthere is a claim within Locke's framework that could be developed on behalf of the native Americans here's the further question, if the right to private property is natural\nnot conventional, if it's something that we acquire even before we agree to\ngovernment how does that right constrain what the legitimate\ngovernment can do in order for finally to see, whether Locke is an ally or potentially a critic of the libertarian idea of the state we have to ask what becomes of our natural\nrights once we enter into society we know that the way we enter into society\nis by consent by agreement to leave the state of nature and to be governed\nby the majority and by a system of laws, human laws but those human laws our only legitimate if they respect our natural rights if they respect our inalienable rights to life liberty\nand property No parliament no legislature however democratic its credentials can legitimately violate our natural rights. this idea that no law can violate our right to life liberty and property would seem to support the idea of a government so limited that it would gladden the heart of the libertarian after all but those hearts should not be so quickly gladdened because even though for Locke the law of nature persists once government arrived even though Locke insists on limited government government limited by the end for which it was created namely the preservation of property even so there's an important sense in which what counts as my property what counts as respecting my life and liberty are for the government to define that there be property that there be respect for life and liberty is what limits government but what counts as respecting my life and respecting my property that is for governments to decide and define how can that be is Locke contradicting himself or is there an important distinction here in order to answer that question which will\ndecide Locke's fit with the libertarian view we need to look closely at what legitimate government looks like for Locke, and we turn to that next time. Nikola, if you didn't think you'd get caught would you pay your taxes umm, I don't think so I would rather have a system personally that I could give money to exactly those sections of the government that I support and\nnot just blanket support everything. you'd rather be in the state of nature at least \non April fifteenth last time we began to discuss Locke's state of nature his account of private property his theory of legitimate government which is government based on consent and also\nlimited government Locke believes in certain fundamental rights\nthat constrain what government can do and he believes that those rights are natural\nrights not rights that flow from law or from government and so Locke's great philosophical experiment is to see if he can\ngive an account of how there could be  aright of private property without consent, before government and legislators arrive on the scene to define\nproperty that's his question that's his claim. there is a way, Locke argues, to create property, not just in the things we gather and hunt but in the land itself provided there is enough and it's good enough for others today I want to turn to the question of consent which is Locke\u2019s second big idea, private\nproperty is one consent is the other what is the work of consent people here have been invoking the idea of consent since we began since the first week you remember when we\nwere talking about pushing the fat man off the bridge someone said\nbut he didn't agree to sacrifice himself it would be different if he consented or when we were talking about the cabin\nboy killing and eating the cabin boy some people said well if they had consented\nto a lottery it would be different then it would be all right so consent has come up a lot and here in John Locke we have one of the great philosophers of consent consent is an obvious, familiar idea in moral\nand political philosophy Locke says that legitimate government is government founded\non consent and who nowadays would disagree with him? sometimes when ideas of political philosophies\nare as familiar as Locke\u2019s ideas about consent it's hard to make sense of them or at\nleast to find them very interesting but there are some puzzles some strange features of Locke\u2019s account of consent as the basis of\nlegitimate government and that's what I\u2019d like to take up today one way of testing the possibility of Locke's idea of consent and also probing some of its perplexities, is to ask just what a legitimate government founded and consent can do what are its powers according to Locke, well in order to answer that question it helps to remember what the state of nature is like. remember the state of nature is the condition that we decide to leave and that's what gives rise to consent why not stay there why bother with government\nat all? well, what's Locke's to answer to that question he says there's some inconveniences in the state of nature but what are those\ninconveniences? the main inconveniences is that everyone can enforce the law of nature everyone is an enforcer or what Locke calls the\nexecutor of the state of nature and he means executor literally if someone violates the law of nature he's an aggressor he's beyond reason and you can punish him and you don't have to be too careful or fine about gradations of punishment in the state of nature you can kill him you can certainly kill someone who comes after\nyou tries to murder you that's self-defense but the enforcement power the right to punish\neveryone can do the punishing in the state of nature and not only can you punish with death people\nwho come after you seeking to take your life you can also punish a thief who tries to steal\nyour goods because that also counts as aggression against the law of nature if someone has stolen from a third party you can go after him why is this well violations of the law of nature are an\nact of aggression there's no police force there are no judges, no juries so everyone is the judge in his or\nher own case and Locke observes that when people are\nthe judges of their own cases they tend to get carried away and this gives rise to the inconvenience in the\nstate of nature people over shoot the mark there's aggression there's\npunishment and before you know it everybody is insecure in their enjoyment of his or her unalienable rights to life liberty and property now he describes in pretty harsh and even grim terms what you can do to people who violate the law of nature one may destroy a man who makes war upon him for the same reason that he may kill a wolf or a lion  such men have no other rule, but that of force and \nviolence, listen to this and so may be treated as beasts of prey those dangerous and noxious creatures that would be sure to destroy you if you fall\ninto their power so kill them first so what starts out as a seemingly benign state of nature where everyone's free and\nyet where there is a law and the law respects people's rights and those rights are so powerful that they're \nunalienable what starts out looking very benign once you look closer is pretty fierce and filled with violence and that's why people want to leave how do they leave well here's where consent comes in the only way to escape from the state of nature is to undertake an active of consent where you agree to give up the enforcement power and to create a government or a community where there will be a legislature to make law and where everyone agrees in advance everyone who enters agrees in advance to abide by whatever the majority decides but then the question and this is our question\nand here's where I want to get your views then the question is what powers what can the majority decide now here it gets tricky for Locke because you remember alongside the whole story about consent and majority rule there are these natural rights,\nthe law of nature these unalienable rights and you remember they don't disappear when people join together to create a civil society so even once the majority is in charge the majority can't violate you' re inalienable rights can't violate your fundamental right to life\nliberty and property so here's the puzzle, how much power does the majority have how limited is the government created by consent? it's limited by the obligation on the part of the majority to respect and to enforce the fundamental natural rights of the citizens they don't give those up we don't give those\nup when we enter government that's this powerful idea taken over from Locke by Jefferson in the Declaration unalienable rights so let's go to our two cases remember Michael Jordan, Bill Gates libertarian\nobjection to taxation for redistribution well what about\nLocke\u2019s limited government is there anyone who thinks that Locke does give grounds for opposing taxation for redistribution anybody?"}, {"content": "if you, if the majority rules that there should\nbe taxation even if the minority should still not have to be taxed\nbecause that's taking away property which is one of the rights of nature so and what's your name? Ben so if the majority taxes the minority without the consent of the minority to that\nparticular tax law it does amount to the taking of their property\nwithout their consent and it would seem that Locke should object to that you want some  textual support for your  reading of Locke, Ben I brought some along just in case you raised it if you've got, if you have your text look at\none thirty eight passage one thirty eight the supreme power by which Locke means legislature, cannot take\nfrom any man any part of his property without his own consent for the preservation of property being the\nend of government and that for which men enter into society it necessarily supposes and requires that people should have property that was the whole reason for entering a society\nin the first place to protect the right to property and when Locke speaks about the right to property he\noften uses that as a kind of global term for the whole category, the right to life liberty\nand property so that part of Locke at the beginning of one thirty eight seems to\nsupport Ben's reading but what about the part of one thirty eight if you keep reading Men therefore in society having property they have such a right to the goods which by the law of the community are theirs, look at this, and that no one can take from them without\ntheir consent and then at the end of this passage we see he said so it's a mistake\nto think that the legislative power can do what it will to dispose to the estates of the subject arbitrarily or take any part\nof them at pleasure here's what's elusive on the one hand he says the government can't take your property without\nyour consent he's clear about that but then he goes on to say and that's the\nnatural right to property but then it seems that property, what counts\nas property is not natural but conventional defined by the government the goods which by the law of the community are theirs and the plot thickens if you look ahead to section one forty in one forty he says governments can't be\nsupported without great charge. Government is expensive and it's fit that everyone who enjoys his\nshare of the protection should pay out of his estate and then here's a crucial line but still it must be with his own consent i.e. the consent of the majority giving it either by themselves or through their\nrepresentatives so what is Locke actually saying property is natural in one sense but conventional in another it's natural in the sense that we have a fundamental unalienable right that their be property that the institution of property exist and\nbe respected by the government so an arbitrary taking property would be a violation of the law of nature and would be illegitimate but it's a further question here's the conventional aspect of property, it's\na further question what counts as property, how it's defined and what counts as taking property, and that's up to the government so the consent here we're kind of back to our question what is the work of consent what it takes for taxation to be legitimate is that it be by consent not the consent of Bill Gates himself that he's\nthe one who has to pays the tax but by the content that he and we, all of us\nwithin the society gave when we emerged from the state of nature and \ncreated the government in the first place it's the collective consent and by that reading it looks like consent is doing a whole lot and the limited government consent creates\nisn't all that limited does anyone want to respond that or have\na question about that? go ahead, stand up well I'm just wondering what Locke's view is on  once you have a government that's already\nin place whether it is possible for people who are born into that\ngovernment to then leave and return to the state of nature I mean, I don't think that Locke mentioned that at all. what do you think? well I think as the convention it would be very\ndifficult to leave the government because you were no longer there's because nobody else is just living in the \nstate of nature, everybody else is now governed by this legislature what would it mean today, you're asking and what's your name? Nicola to leave the state, suppose you\nwanted to leave civil society today, you want to withdraw your consent and return to the state of nature. Well because you \ndidn't actually consent to it,  you were just born into it,  it was your ancestors who joined you didn't sign the social contract I didn't sign all right so what does Locke say there I don't think Locke says that you have to sign anything\nI think he says that it's kind of implied consent by willingly taking government services you\nare implying you're consenting to the government taking things from you all right so implied consent, that's a partial\nanswer to this challenge now you may not think that implied consent is\nas good as the real thing is that what you're shaking your head about Nicola? speak up stand up and I don't think that necessarily just by utilizing the government's  you know various resources that we are necessarily implying that we agree with the way that this government was formed or that we have consented to actually join into the\nsocial contract so you don't think the idea of implied consent\nis strong enough to generate any obligation at all to obey  government not necessarily no, Nicola if you didn't think you'd get caught would you pay your taxes umm I don't think so I would rather have a system, personally, that I could give money to exactly those sections of the government that I support and not just blanket support everything. you'd rather be in the state of\nnature of at least on April fifteenth but what I'm trying to get at is you consider\nthat you're under no obligation since you haven't actually entered into an active\nconsent but for prudential reasons you do what you're\nsupposed to do according to the law. exactly. if you look at it that way then you're violating another\none of Locke's treatises which is that you can't take anything from anyone else like\nyou can't you can't take the government's services and then not give them anything in return if you if you want to go live in a state of nature that's\nfine but you can't take anything from the government\nbecause by the government's terms which are the only terms under which you can enter\nthe agreement say that you have to pay taxes to take those things. so you're saying that Nicola can go on back to the state of\nnature if she wants to but you can't drive on Mass Ave. Exactly I want to raise the stakes beyond using Mass Ave,  and even beyond taxation what about life what about military conscription yes, what do you think, stand up first of all we have to remember that sending people to war is not necessarily implying that they'll die, I mean obviously you're not raising their chances here, it's not a death penalty so if you're going to discuss whether or not\nmilitary conscriptions is equivalent to you know suppressing people's right to life you shouldn't approach it that way secondly the real problem here is Locke has\nthis view about consent and natural rights but you're not allowed to give up your natural\nrights either so the real question is how does he himself figure it out between I agree to give up my life give up my property when he talks about taxes or military conscription for the fact, but I guess Locke would be against suicide and that's still you know my own consent\nI mean. Good."}, {"content": "What's your name?"}, {"content": "Eric. so I Eric brings us back to the puzzle we've been wrestling\nwith since we started reading Locke on the one hand we have these unalienable rights to life liberty and property which means that\neven we don't have the power to give them up and that's what creates the limits on legitimate government it's not what we\nconsent to that limits government it's what we lack the power to give away when we consent that limits government that's the that's the point at the heart of Locke's whole account of legitimate government but now you say well if we can't give up our own life, if we can't commit suicide if we can't give up our rights to property how\ncan we then agree to be bound by a majority that will force us to sacrifice our lives or give up our property does Locke have a way out of this or \nis he basically sanctioning an all-powerful government despite everything he says about unalienable rights does he have a way out of it? who would speak here\nin defense of Locke or make sense find a way out of this predicament all right go ahead. I feel like there's a general distinction\nto be made between the right to life that individuals possess and the the fact that the government cannot take away\nan individual's right to life I think if you look at conscription as the government picking out certain individuals\nto go fight in war then that would be a violation of the rights\ntheir  national right to life on the other hand if you have conscription\nof let's say a lottery for example then in that case I would view that as the population picking their representatives\ndefend them in the case of war the idea being that since the whole population\ncannot go out there to defend its own right of property it picks its own representatives\nthrough a process that's essentially random and the these these sort of elected representatives go out\nand fight for the rights of the people it looks very similar, it works just like\nan elected government in my opinion  alright so an elected government can conscript citizens\nto go out and defend the way of life the community that makes the enjoyment of rights possible. I think I think it can because  to me it seems that it's very similar\nto the process of electing representatives the legislature although here it's as if the government it's electing by conscription certain citizens to go die for the sake of the whole is that consistent with respect for a natural right\nto liberty well what I would say is there's a distinction\nbetween picking out individuals  and having a random choice of individuals. between let me make sure, between picking out \nindividuals,  well I don't, let me what's your name? Gogol. Gogol says there's a difference between\npicking out individuals to lay down their lives and having a general law I think this is on I think this is the answer Locke would give, \nactually Locke is against arbitrary government he's\nagainst the arbitrary taking the singling out of Bill Gates to finance the war in Iraq he's against singling out a particular citizen or group of people to go off and fight but if there's a general law such that the the government's choice the majority's action\nis non arbitrary, it doesn't really amount to a violation of people's basic rights what does count as a violation is an arbitrary taking because that would\nessentially say not only to Bill Gates, but to everyone there is no rule of law there is no institution\nof property because at the whim of the king or for that matter of the parliament we can name you or you to give up your property or to give up your life but so long as there is a no arbitrary\nrule of law then it's permissive now you may say this doesn't amount to a very limited government and the libertarian may complain that Locke is not such a terrific ally after\nall the libertarian has two grounds for disappointment in Locke first that the rights are unalienable and therefore I\ndon't really own myself after all I can't dispose of my life or my liberty or my property in a way that violates my rights that's disappointment number one, disappointment number two once there is a legitimate government based\non consent the only limits for Locke are limits on arbitrary the takings of life or of liberty or of property but if the majority decides or if the majority\npromulgates a generally applicable law and if it votes duly according to fare procedures then there is no violation whether it's a system of taxation or system of conscription so it's clear that Locke is worried about the absolute arbitrary power of kings but it's also true and here's a darker side of Locke that this is great theorist of consent came up\nwith a theory of private property that didn't require consent that may and this goes back to the point Rochelle\nmade last time, may have had something to do with Locke's second concern which was America you remember when he talks about the state of nature he's\nnot talking about an imaginary place in the beginning he says all the world was\nAmerica and what was going on in America the settlers we're enclosing land and engaged in wars with the native Americans Locke who was an administrator of one of the colonies may have been as interested in providing a justification for private property through enclosure\nwithout consent through enclosure and cultivation as he was with developing a theory of government based on consent that would reign in kings and arbitrary rulers the question we're left with the fundamental question we still haven't\nanswered is what then becomes of consent what work can it do what is its moral force what are the limits of consent consent matters  not only for governments but also from markets and beginning next time we're going to take up questions of the limits of consent in the buying and selling of goods don't miss the chance to interact online with other\nviewers of Justice join the conversation, take a pop quiz watch lectures you've missed, and a lot more. Visit justiceharvard.org it's the right thing to do funding for this program is provided by additional funding provided by"}], "Justice: What's The Right Thing To Do? Episode 02: \"PUTTING A PRICE TAG ON LIFE\"": [{"content": "Funding for this program provided by Additional funding provided by last time we argued about the case of the Queen verses Dudley and Stephens the lifeboat case, the case of cannibalism\nat sea and with the arguments about the lifeboat in mind the arguments for and against \nwhat Dudley and Stephens did in mind, let's turn back to the philosophy the utilitarian philosophy of Jeremy Bentham Bentham was born in England in 1748,\nat the age of twelve he went to Oxford, at fifteen he went to law\nschool he was admitted to the bar at age nineteen \nbut he never practiced law, instead he devoted his life to jurisprudence and moral philosophy. last time we began to consider Bentham's version\nof utilitarianism the main idea is simply stated and it's this, the highest principle of morality whether personal or political morality is to maximize the general welfare or the collective happiness or the overall balance of pleasure over\npain in a phrase maximize utility Bentham arrives at this principle by the following\nline of reasoning we're all governed by pain and pleasure they are our sovereign masters and so any\nmoral system has to take account of them. How best to take account? By maximizing and this leads to the principle of the greatest good for the greatest\nnumber what exactly should we maximize? Bentham tells us happiness or more precisely utility. Maximizing utility is a principal not only\nfor individuals but also for communities and for legislators what after all is a community Bentham asks, it's the sum of the individuals who comprise it and that's why in deciding the best policy, in deciding what the\nlaw should be, in deciding what's just, citizens and legislators should ask themselves\nthe question if we add up, all of the benefits of this policy and subtract all of the costs, the right thing to do is the one that maximizes the balance of happiness over suffering. that's what it means to maximize utility now, today I want to see  whether you agree or disagree with it, and it often goes, this utilitarian logic, under\nthe name of cost-benefit analysis which is used by companies and by governments all the time and what it involves is placing a value usually a dollar value\nto stand for utility on the costs and the benefits of various proposals. recently in the Czech Republic there was a proposal to increases the excise\ntax on smoking Philip Morris, the tobacco company, does huge business in the Czech Republic. They commissioned a study of cost-benefit analysis of smoking in the Czech Republic and what their cost benefit analysis found was the government gains by having Czech citizens smoke. Now, how do they gain? It's true that there are negative effects to the public finance of the Czech government because there are increased health care costs\nfor people who develop smoking-related diseases on the other hand there were positive \neffects and those were added up on the other side of the ledger the positive effects included, for the most\npart, various tax revenues that the government derives from the sale of cigarette products\nbut it also included health care savings to the government when people die early pensions savings, you don't have to pay pensions\nfor as long, and also savings in housing costs for the elderly and when all of the costs and benefits were added\nup the Philip Morris study found that there is a net public finance gain\nin the Czech Republic of a hundred and forty seven million dollars and given the savings in housing and health care and pension costs the government enjoys the saving of savings\nof over twelve hundred dollars for each person who dies prematurely due to\nsmoking. cost-benefit analysis now, those among you who are defenders utilitarianism \nmay think that this is a unfair test Philip Morris was pilloried in the press and\nthey issued an apology for this heartless calculation you may say that what's missing here is something that\nthe utilitarian can be easily incorporate mainly the value to the person and to the families\nof those who die from lung cancer. what about the value of life? Some cost-benefit analyses incorporate a measure for the value of life. One of the most famous of these involved the\nFord Pinto case did any of you read about that? this was back\nin the 1970's, you remember that the Ford Pinto was, a kind of car? anybody? it was a small car, subcompact car,\nvery popular but it had one problem which is the fuel tank was at the\nback of the car and in rear collisions the fuel tank exploded and some people were killed and some severely injured. victims of these injuries took Ford to court\nto sue and in the court case it turned out that Ford had long since known about the vulnerable fuel tank and had done a cost-benefit analysis to determine\nwhether it would be worth it to put in a special shield that would protect the fuel tank and prevent it\nfrom exploding. They did a cost benefit analysis the cost per part to increase the safety of the Pinto, they calculated at eleven dollars per part and here's, this was the cost benefit analysis that emerged in the trial, eleven dollars per part at 12.5 million cars and trucks came to a total cost of  137 million dollars to improve the safety but then they calculated the benefits of spending all this money on a  safer car and they counted 180 deaths and they assigned a dollar value 200 thousand dollars per death 180 injuries 67 thousand and then the cost to repair the replacement cost for two thousand\nvehicles that would be destroyed without the safety device 700 dollars per vehicle, so the benefits turned out to be only 49.5 million, and so they didn't install the device needless to say when this memo of the Ford Motor Company's cost-benefit analysis came\nout in the trial it appalled the jurors who awarded a huge settlement is this a counter example to the utilitarian\nidea of calculating because Ford included a measure of the value life. Now who here wants to defend cost-benefit analysis from this apparent counter example who has a defense? or do you think it's completely destroys the whole utilitarian calculus? I think that once again they've made the same mistake the previous case\ndid that they've assigned a dollar value to human life and once again they failed to take into\naccount things like suffering and emotional losses of families, I mean families\nlost earnings but they also lost a loved one and that is more value than 200 thousand dollars. Good, and wait wait wait, what's you're name? Julie Roto. so if two hundred thousand, Julie, is too too low a figure because it doesn't include\nthe loss of a loved one, and the loss of those years of life, what would be, what do you think would be a more accurate number? I don't believe I could give a number I think\nthat this sort of analysis shouldn't be applied to issues of human life. I think it can't be used monetarily so they didn't just put to low a number, Julie says, they were wrong to try to\nput any number at all. all right let's hear someone who you have to adjust for inflation all right fair enough so what would the number of being now? this is was thirty five years ago two million dollars you would put two million and what's your name Voicheck Voicheck says we have to allow for inflation we should be more generous then would you be satisfied that this is the\nright way of thinking about the question? I guess unfortunately it is for there's needs to be of number put somewhere I'm not sure what number would be but I do\nagree that there could possibly be a number put on a human life. all right so Voicheck says and here he disagrees with Julie Julie says we can't put a number of human\nlife for the purpose of a cost-benefit analysis,\nVoicheck says we have to because we have to make decisions somehow what do other people think about this? Is there anyone prepared to defend cost-benefit analysis here as accurate, as desirable? I think that if ford and other car companies didn't use\ncost-benefit analysis they'd eventually go out of business because they wouldn't be able\nto be profitable and millions of people wouldn't be able to use\ntheir cars to get to jobs, to put food on the table to feed their children so I think that if cost-benefit\nanalysis isn't employed the greater good is sacrificed in this case. Alright let me ask, what's your name?"}, {"content": "Raul."}, {"content": "Raul. there was recently a study done about cell\nphone use by drivers, when people are driving a car, and there's a debate about whether that should be\nbanned and  the figure was that some two thousand people die as a result of accidents each year using cell phones and yet the cost benefit analysis which was done by\nthe center for risk analysis at Harvard found that if you look at the benefits of the cell phone use and you put some value on the life, it comes out about\nthe same because of the enormous economic benefit\nof enabling people to take advantage of their time, not waste time, be able to make deals\nand talk to friends and so on while they're driving doesn't that suggest that it's a mistake to try to put monetary figures\non questions of human life? well I think that if the great majority of people tried to derive maximum utility out of a service\nlike using cell phones and the convenience that cell phones provide that sacrifice is necessary for satisfaction to occur. You're an outright utilitarian. In, yes okay. all right then, one last question Raul and I put this to Voicheck, what dollar figure should be put on human life to decide whether to ban the\nuse of cell phones well I don't want to  arbitrarily calculate a figure, I mean right now I think that you want to take it under advisement. yeah I'll take it under advisement. but what roughly speaking would it be? you've\ngot 23 hundred deaths you've got to assign a  dollar value to know\nwhether you want to prevent those deaths by banning the use of cell phones in cars so what would you're hunch be? how much? million two million two million was Voitech's figure is that about right? maybe a million. a million.?! Alright that's good,  thank you So these are some of the controversies that arise\nthese days from cost-benefit analysis especially those that involve placing a dollar value on everything to be\nadded up. well now I want to turn to your objections, to your objections not necessarily\nto cost benefit analysis specifically, because that's just one version of the utilitarian logic in practice today, but to the theory as a whole, to the idea that the right thing to do, the just basis for policy and law, is to maximize utility. How many disagree with the utilitarian approach to law and to the common good? How many bring with it? so more agree than disagree. so let's hear from the critics my main issue with it is that I feel like you can't say that just because someone's\nin the minority what they want and need is less valuable than\nsomeone who's in the majority so I guess I have an issue with the idea that the greatest good for the greatest number is okay because there is still what about people who are in  the lesser number, like it's not fair to them\nthey didn't have a say in where they wanted to be. alright now that's an interesting objection, you're\nworried about the effect on minority. yes."}, {"content": "what's your name by the way. Anna. alright who has an answer to Anna's worry about\nthe effect on the minority What do you say to Anna? she said that the minorities value less, I don't think that's\nthe case because individually the minorities value is just the same as the individual in the majority\nit's just that the numbers outweigh the  minority and I mean at a certain point you have to make a\ndecision and I'm sorry for the minority but sometimes it's for the general for the greater good. For the greater good, Anna what do you\nsay?"}, {"content": "what's your name? Youngda."}, {"content": "What do you say to Youngda? Youngda says you just have to add up people's\npreferences and those in the minority do have their preferences\nweighed. can you give an example of the kind of thing\nyou're worried about when you say you're worried about utilitarianism violating the concern or respect due the minority? can you give an example. so well with any of the cases that we've talked\nabout, like with the shipwreck one, I think that the boy who was eaten still had just as much of a right to live as the other people\nand  just because he was the minority in that case the one who maybe had less of a chance to keep living that doesn't mean that the others automatically have a right\nto eat him just because it would give a greater amount of people the chance to live. so there may be a certain rights that the minority members have that the individual has that\nshouldn't be traded off for the sake of utility? yes Anna? Now this would be a test for you, back in ancient Rome they threw Christians to the lions in the\ncoliseum for sport if you think how the utilitarian calculus\nwould go  yes, the Christian thrown to the lion suffers enormous\nexcruciating pain, but look at the collective ecstasy of the Romans. Youngda. Well in that time I don't think in the modern-day of time to value the, um, to given \na number to the happiness given to the people watching I don't think any policy maker would say the pain of one person, the suffering of one person is\nmuch much, in comparison to the happiness gained no but you have to admit that if there were\nenough Romans delirious with happiness, it would outweigh even the most excruciating\npain of a handful of Christians thrown to the lion. so we really have here two different objections\nto utilitarianism one has to do with whether utilitarianism adequately respects individual rights or minority rights and the other has to do with the whole idea of aggregating utility for preferences or values is it possible to aggregate all values to translate them into dollar terms? there was in the  1930's a psychologist who tried to address the second question. He tried to prove what utilitarianism assumes, that it is possible to translate all goods, all values, all human concerns into a single uniform measure and he did this by conducting a survey of the young recipients of relief, this was\nin the 1930's and he asked them, he gave them a list of\nunpleasant experiences and he asked them how much would you have to\nbe paid to undergo the following experiences and he kept track for example how much would you have to be paid to have\none upper front tooth pulled out or how much would you have to be paid to have one little\none tow cut off? or eat a live earth worm, six inches long or to live the rest of your life on a farm in\nKansas or to choke a stray cat to death with your bare hands now what do you suppose what do you suppose was the most expensive\nitem on that list Kansas?"}, {"content": "You're right it was Kansas for a Kansas people said they'd have to pay them they have to be paid three hundred\nthousand dollars what do you think what do you think was the next most expensive? not the cat not the tooth not the toe the worm! people said you'd have to pay them a hundred\nthousand dollars to eat the worm what do you think was the least expensive\nitem? not the cat the tooth during the depression people were willing\nto have their tooth pulled  for only forty five hundred dollars now here's what Thorndike concluded from his study any want or satisfaction which exists, exists in some amount and is therefore measurable the life of a dog or a cat or a chicken consists of appetites cravings desires and their gratifications so does the life of human beings though the appetites and desires are more complicated but what about Thorndike's study? does it support Bentham's idea that all goods all values can be captured according\nto a single uniform measure of value or does the preposterous character of those\ndifferent items on the list suggest the opposite conclusion that may be whether we're talking about life or Kansas or the worm maybe the things we value and cherish can't be captured according to a single uniform measure of value and if they can't what are the consequences for the utilitarian theory of morality that's a question we'll continue with next\ntime alright now let's take the other part of the poll which is the the highest experience or pleasure? how many say  Shakespeare how many say fear Factor no you can't be serious really? last time last time we began to consider some objections to Jeremy Bentham's version of utilitarianism people raised two objections in the discussion we had the first was the objection, the claim that utilitarianism, by concerning itself with the greatest good for the greatest number fails adequately to respect individual rights. today we have debates about torture and terrorism suppose a suspected terrorists was apprehended\non September tenth and you had reason to believe that the suspect had crucial information about an impending\nterrorist attack that would kill over three thousand people and you couldn't extract the information would it be just to torture the suspect to get the information or do you say no there is a categorical moral duty of \nrespect for individual rights in a way we're back to the questions we started\nwith t about trolley cars and organ transplants so that's\nthe first issue and you remember we considered some examples of\ncost-benefit analysis but a lot of people were unhappy with cost-benefit\nanalysis when it came to placing a dollar value on\nhuman life and so that led us to the second objection, it questioned whether it's possible to translate\nall values into a single uniform measure of value it asks in other words whether all values\nare commensurable let me give you one other example of an experience, this actually is a true\nstory, it comes from personal experience that raises a question at least about whether\nall values can be translated without loss into utilitarian terms some years ago when I was a graduate student I was at Oxford\nin England and they had men\u2019s and women's colleges they weren't yet mixed and the women's colleges had rules against overnight male guests by the nineteen seventies these rules were rarely enforced and easily violated, or so I was told, by the late nineteen seventies when I was there,\npressure grew to relax these rules and it became the subject of debate among the faculty at St. Anne's College which was one of these all women colleges the older women on the faculty we're traditionalists they were opposed to\nchange on conventional moral grounds but times had changed and they were embarrassed to give the true grounds of their objection and so the translated their arguments into utilitarian terms if men stay overnight, they argued, the costs to the college will increase. how you might wonder well they'll want to take baths, and that\nwill use up hot water they said furthermore they argued we'll have to replace the mattresses more often the reformers met these arguments by adopting the following\ncompromise each woman could have a maximum of three overnight male\nguest each week they didn't say whether it had to be the same\none, or three different provided and this is the compromise provided the guest paid fifty pence to defray the cost to the college the next day the national headline in the national newspaper\nread St. Anne's girls, fifty pence a night another illustration of the difficulty of translating all values in this case a certain idea of virtue into utilitarian terms so that's all to illustrate the second objection to utilitarianism, at least the\npart of that objection that questions rather the utilitarianism is right to assume that we can assume the uniformity of value, the commensurability of values\nand translate all moral considerations into dollars or money. But there is a second aspect to this worry about aggregating values\nand preferences why should we weigh  all preferences that people have without assessing whether they're good preferences\nor bad preferences shouldn't we distinguish between higher pleasures and lower pleasures. Now, part of the appeal of  not making any qualitative distinctions about\nthe worth of people's preferences, part of the appeal is that it is non-judgmental and egalitarian the Benthamite utilitarian says everybody's preferences count and they count regardless of what people want regardless of what makes it different people happy. For Bentham, all that matters you'll remember are the intensity and the duration of a pleasure or pain the so-called higher pleasures or nobler\nvirtues are simply those, according to Bentham that produce stronger, longer, pleasure yet a famous phrase to express this idea the quantity of pleasure being equal pushpin is as good as poetry. What was pushpin? It was some kind of a child's game like to tidily winks\npushpin is as good as poetry Bentham said and lying behind this idea I think is the claim the intuition that it's a presumption to judge whose pleasures are intrinsically higher or worthier or better and there is something attractive in this refusal to judge, after all some people like Mozart, others Madonna some people like ballet others bowling, who's to say a Benthamite might argue, who's to say which \nof these pleasures whose pleasures are higher worthier nobler than others? But, is that right? this refusal to make qualitative distinctions can we altogether dispense with the idea that certain things we take pleasure in are better or worthier than others think back to the case of the Romans in the coliseum,\none thing that troubled people about that practice is that it seemed to violate the rights of the Christian another way of objecting to what's going\non there is that the pleasure that the Romans\ntake in this bloody spectacle should that pleasure which is a base, kind of corrupt degrading pleasure, should that even be valorized or weighed in deciding what\nthe the general welfare is? so here are the objections to Bentham's\nutilitarianism and now we turn to someone who tried to respond to those objections, a later day utilitarian John Stuart Mill so what we need to examine now is whether John Stuart Mill had a convincing\nreply to these objections to utilitarianism. John Stuart Mill was born in 1806 his father James  Mill was a disciple of Bentham\u2019s and James Mills set about giving his son John Stuart Mill a model education he was a child prodigy John Stuart Mill the knew Latin, sorry, Greek at the age of three, \nLatin at eight and at age ten he wrote a history of Roman law. At age twenty he had a nervous breakdown this left him in a depression for five years but at age twenty five what helped lift him\nout of this depression is that he met Harriet Taylor she in no doubt married him, they lived happily ever after and it was under her influence the John Stuart Mill try to humanize utilitarianism what Mill tried to do was to see whether the utilitarian calculus could be enlarged and modified to accommodate humanitarian concerns like the concern to respect individual rights and also to address the distinction between\nhigher and lower pleasures. In 1859 Mill wrote a famous book\non liberty the main point of which was the importance\nof defending individual rights and minority rights and in 1861 toward the end of his life he wrote the book we read is part of this course Utilitarianism. It makes it clear that utility is the only standard of morality in his view so he's not challenging Bentham's premise, he's affirming it. he says very explicitly the sole evidence, it is possible to produce that anything is\ndesirable is that people actually do desire it. so he stays with the idea that our de facto\nactual empirical desires are the only basis for moral judgment. but then page eight also in chapter two, he argues that it is possible\nfor a utilitarian to distinguish higher from lower pleasures. now, those of you who've read Mill already how according to him is it possible to draw that\ndistinction? How can a utilitarian distinguish qualitatively higher pleasures from lesser ones, base ones, unworthy ones? If you tried both of them and you'll prefer the higher one naturally\nalways that's great, that's right. What's your name?"}, {"content": "John. so as John points out Mill says here's the test, since we can't step outside actual desires, actual preferences that would violate utilitarian premises, the only test of whether a pleasure is higher or lower is whether someone who has experienced\nboth would prefer it. And here, in chapter two we see the passage where Mill makes the point that John just described of two pleasures, if there be one to which all\nare almost all who have experience of both give a decided preference, irrespective of any feeling of moral obligation to\nprefer it, in other words no outside, no independent standard, then that is the more desirable pleasure. what do people think about that argument."}, {"content": "does that does it succeeded? how many think that it does succeed? of arguing within utilitarian terms for a\ndistinction between higher and lower pleasures. how many think it doesn't succeed? I want to hear your reasons. but before we give the reasons let's do an experiment of Mills' claim. In order to do this experiment we're going to look that three short excerpts of popular entertainment the first one is a Hamlet soliloquy it'll be followed by two other experiences see what you think. 'what a piece of work is a man how noble in reason how infinite in faculties in form and moving, how express and admirable in action how like an angel. In apprehension, how like a god the beauty of the world the paragon of animals and yet, to me what is this quintessence of dust? man delights not me. Imagine a world where your greatest fears become reality each show, six contestants from around the country battle\neach other in three extreme stunts. these stunts are designed to challenge \nthese contestants both physically and mentally six contestants, three stunts, one winner. Fear factor. The Simpsons. Well hi diddly-o peddle to the metal o-philes! Flanders- since when do you like anything cool. well, I don't care for the speed, but I can't get enough of that \nsafety gear  helmets, roll bars, caution flags. I like the fresh\nair and looking at the poor people in the infield. Dang Cletus, why you got to park by my parents. Now hunny, it's my parents too. I don't even have to ask which one you like\nmost the Simpsons? How many like the Simpson's most? How many Shakespeare? What about fear factor? how many preferred fear factor? really? people overwhelmingly like the Simpsons better than Shakespeare. alright, now let's take the other part of the poll which is the highest experience or pleasure? how many say Shakespeare? how many say fear factor? no you can't be serious really?"}, {"content": "alright go ahead you can say it. I found that one  the most entertaining I know but which do you think was the worthiest, \nthe noblest experience, I know you find it the most anything if something is good just because it is pleasurable\nwhat is the matter if you have some kind of  abstract idea of whether it is good by someone else's\nsense or not. Alright so you come down on the straight Benthamite's side whose to judge and why should we judge apart from just registering and aggregating\nde facto preferences, alright fair enough. what's your name?"}, {"content": "Nate? okay fair enough Alright so how many think that the Simpson's is actually apart from liking is actually the higher experience higher than Shakespeare. Alright let's see the vote for Shakespeare again how many think Shakespeare is higher? alright so why is it ideally I'd like to hear from someone is there\nsomeone think Shakespeare is highest but who preferred watching the Simpsons Like I guess just sitting and watching the Simpsons, it's entertaining\nbecause the make jokes, they make us laugh but someone has to tell us that Shakespeare was this great writer\nwe had to be taught how to read him, how to understand him, we had to be taught how to take in Rembrandt, how to analyze a painting. well how do, what's your name? Aneesha. Aneesha, when you say someone told you that Shakespeare's better are you accepting it on blind faith you voted that\nShakespeare's higher only because the culture tells you that our teachers tell you that\nor do you actually agree with that yourself well in the sense that Shakespeare, no, but earlier you made an example of Rembrandt I feel like I would enjoy a reading a comic book\nmore than I would enjoy a kind of analyzing Rembrandt because someone told me it was\ngreat, you know. Right so of some this seems  to be, you're suggesting a kind of cultural convention and pressure. We're told what books, what works of art are great. who else? although I enjoyed watching the Simpsons more\nin this particular moment in Justice, if I were to spend the rest of my life\nconsidering the three different video clips shown I would not want to spend that remainder of my life considering the latter two clips. I think I would derive more pleasure from being able to branch out in my own mind sort of considering more deep pleasures, more\ndeep thoughts. and tell me your name Joe. Joe, so if you had to spend the rest of your life\non  on a farm in Kansas with only with only Shakespeare or the collected episodes of the Simpsons you would prefer Shakespeare what do you conclude from that about John Stuart Mill's test but the test of a higher pleasure is whether people who have experienced both prefer it. can I cite another example briefly? in biology in neuro biology last year we were told of a rat who was\ntested a  particular center in the brain where the rat was able to stimulate its\nbrain and cause itself intense pleasure repeatedly the rat did not eat or drink until it died so the rat was clearly experiencing intense\npleasure now if you asked me right now if I'd rather\nexperience intense pleasure or have a full lifetime of higher pleasure, I would consider\nintense pleasure to be lower pleasure, right  now enjoy intense pleasure yes I would but over a lifetime I think I would think almost a complete majority here would agree that they would rather be a human\nwith higher pleasure that rat with intense pleasure for a momentary period of time so now in answer to your question, right, I think this proves that, or I won't say proves I think the conclusion is that Mill's theory that when a majority people are\nasked what they would rather do, they will answer that they would rather engage in a higher pleasure. So you think that this\nsupports Mills, that Mills was on to something here I do. all right is there anyone who disagrees with Joe who thinks that\nour experiment disproves Mills' test shows that that's not an adequate way that you can't distinguish higher pleasures within\nthe utilitarian framework. If whatever is good is truly just whatever\npeople prefer it's truly relative and there's no objective definition then there will be some society where people prefer\nSimpsons more anyone can appreciate the Simpsons, but I think\nit does take education to appreciate Shakespeare Alright, you're saying it takes education to appreciate\nhigher true thing Mill's point is that the higher pleasures do require cultivation and appreciation and education he doesn't dispute that but once having been cultivated and educated people will see not only see the difference between higher\nlower  pleasures but will it actually prefer the higher to the lower. you find this famous passage from John Stuart\nMill- it is better to be a human being dissatisfied then a pig satisfied. Better to the Socrates dissatisfied than\na fool satisfied and if the fool or the pig are of a different opinion it is because they only know their side of the question. so here you have an attempt to distinguish higher from lower pleasures so going to an art museum or being a couch\npotato, swilling beer watching television at home sometimes Mill agrees we might succumb to the temptation to do the latter, to be couch potatoes, but even when we do that out of indolence and sloth, we know that the pleasure we get gazing at Rembrandts in the museum is actually higher, because we've experienced both. And is a higher pressure gazing at Rembrandts because of engages our higher human faculties what about Mill's attempt to reply to the objection about individual rights? In a way he uses the same kind of argument and this comes out in chapter five he says while I dispute the pretensions of any\ntheory which sets up an imaginary standard of justice not grounded on utility, but still he considers justice grounded on utility to be what he calls the\nchief part and incomparably the most sacred and binding\npart of all morality. so justice is higher individual rights are privileged but not for reasons that depart from utilitarian assumptions. Justice is a name for certain moral requirements which, regarded collectively stand higher in the scale of social utility and are therefore of more paramount obligation  than any others so justice is sacred, it's prior, it's privileged,\nit isn't something that can easily be traded off against lesser things but the reason is ultimately Mills Claims a utilitarian reason once you consider the long run interests of humankind, of all of us, as progressive beings. If we do justice and if we respect rights society as a whole will be better off in the long run. Well is that convincing? Or is Mill actually, without admitting it, stepping\noutside utilitarian considerations in arguing for qualitatively higher pleasures and for sacred or specially important individual rights? we haven't fully answered that question because to answer that question in the case of rights and justice will require that we explore other ways, non utilitarian ways of accounting for the basis or rights and then asking whether they succeed as for Jeremy Bentham, who launched utilitarianism as a doctrine in moral and legal philosophy Bentham died in 1832 at the\nage of eighty five but if you go to London you can visit him\ntoday literally. he provided in his will that his body be preserved, embalmed and displayed in the university of London where he still presides in a glass case with a wax head dressed in his actual clothing. you see before he died, Bentham addressed himself to a question consistent\nwith his philosophy, of what use could a dead man be to the living one use, he said, would be to make one's corpse\navailable for the study of anatomy in the case of great philosophers, however, better yet to preserve one's physical presence in order\nto inspire future generations of thinkers. You want to see what Bentham looks like stuffed? Here's what he looks like There he is now, if you look closely you'll notice that the embalming up his actual had was not a\nsuccess so they substituted a waxed head and at the bottom for verisimilitude you can actually see his actual had on a plate you see it? right there so, what's the moral of the story? the moral of the story by the way they bring him out during meetings\nof the board at university college London and the minutes record him as present but\nnot voting. here is a philosopher in life and in death who adhered to the principles of his philosophy. we'll continue with rights next time. Don't miss the chance to interact online with other viewers of Justice join the conversation, take a pop quiz, watch lectures you've missed, and a lot more. Visit Justiceharvard.org It's the right thing to do. funding for this program is provided by additional funding provided by"}], "Justice: What's The Right Thing To Do? Episode 07: \"A LESSON IN LYING\"": [{"content": "funding for this program is provided by additional funding provided by last time we began and trying to we began by trying to navigate our way through K moral theory now fully to make sense of K moral theory in the groundwork requires that we be able to answer three questions how can Duty and autonomy go together what's the Great dignity and answering to duty it would seem that these two ideas are opposed Duty and autonomy what's kant's answer to that need someone here to speak up on kant's behalf does he have an answer yes go ahead stand up K believes that you only act autonomously when you are when you're pursuing something only in the name of Duty and not because of your own circumstances such as like you're only doing something good and moral if you're doing it because of Duty not because something of your own personal gain now why is that acting what's your name mine is Matt Matt why is that acting out of freedom I I hear what you're saying you choose to accept those moral laws in yourself and they're not brought on from outside upon on okay good because acting out of Duty yeah is following a moral law that you impose on yourself that you impose on yourself that's what makes Duty compatible with freedom yeah okay that's good Matt that is K answer that's great thank you so K's answer is it is not in so far as I am subject to the law that I have dignity but rather in so far as with regard to that very same law I'm the author and I'm subordinated to that law on that grounds that I took it as Matt just said I took it upon myself I will that law so that's why for Kant acting according to duty and acting freely in the sense of autonomously are one and the same but that raises the question how many moral laws are there because if dignity consists in being governed by a law that I give myself what's to guarantee that that my conscience will be the same as your conscience who has count answer to that yes because a moral law trans is not contingent upon subjective conditions it would transcend all particular differences between people and so would be a universal law and in this respect there would only be one moral law because it would be Supreme that's exactly right what's your name Kelly Kelly so Kelly can't believes that if we choose freely out of our own consciences the moral law we're guaranteed to come up with one and the same moral law yes and that's because when I choose it's not me Michael sandal choosing it's not you Kelly choosing for yourself what is it exactly who's doing the choosing who's the subject who's the agent who's doing the choosing reason well reason pure reason pure reason and what you mean by pure reason is what exactly well pure reason is like we were saying before not subject to any external um conditions that may be imposed on it so that's great so the reason that does the Willing the reason that governs my will when I will the moral law is the same reason that operates when you choose the moral law for yourself yes and that's why it's possible to act autonomously to choose for myself for each of us to choose for ourselves as autonomous beings and for all of us to wind up willing the same moral law the categorical imperative but then there is one big and very difficult question left even if you accept everything that Matt and Kelly have said so far how is a categorical imperative possible how is morality possible to answer that question Kant says we need to make a distinction we need to make a distinction between two standpoints two standpoints from which we can and make sense of our experience let me try to explain what he means by these two standpoints as an object of experience I belong to the sensible World there my actions are determined by the laws of nature and by the regularities of cause and effect but as a subject of experience I inhabit an intelligible world he here being independent of the laws of nature I am capable of autonomy capable of acting according to a law I give myself now Kant says that only from this second standpoint can I regard myself as free for to be independent of determination by causes in the sensible world is to be free if I were wholly an empirical being as the utilitarians assume if I were a being holy and only subject to the deliverances of my senses to pain and pleasure and hunger and thirst and appetite if that's all there were to humanity we wouldn't be capable of Freedom K reasons because in that case every exercise of will would be conditioned by the desire for some object in that case all choice would be heteronomous Choice governed by the pursuit of some external end when we think of ourselves as free count rights we transfer ourselves into the intelligible world as members and recognize the autonomy of the will that's the idea of the two standpoints so how are categorical imperatives Possible only because the idea of freedom makes me a member of an intelligible world now Kant admits we aren't only rational beings we don't only inhabit the intelligible world the realm of freedom if we did if we did then all of our actions would invariably Accord with the autonomy of the will but precisely because we inhabit simultaneously the two standpoints the two Realms the realm of freedom and the realm of necessity precisely because we inhabit both Realms there is always potentially a gap between what we do and what we ought to do between is and ought another way of putting this point and this is the point with which Kant concludes the groundwork morality is not empirical whatever you see in the world whatever you discover through science can't decide moral questions morality stands at a certain distance from the world from the empirical world and that's why no science could deliver moral truth now I want to test kant's moral theory with the hardest possible case a case that he raises the case of the murderer at the door Kant says that lying is wrong we all know that we've discussed why lying is at odds with the categorical imperative a French philosopher Benjamin Kon wrote an article responding to the groundwork where he said this absolute prohibition on lying is wrong it can't be right what if a murderer came to your door looking for your friend who was hiding in your house and the murderer asked you point blank is your friend in your house conston says it would be crazy to say that the moral thing to do in that case is to tell the truth kstone says the murderer certainly doesn't deserve the truth and K Ro a reply and Kant stuck by his principle that lying even to the murderer at the door is wrong and the reason it's wrong he said is once you start taking consequences into account to carat accept I to the categorical imperative you've given up the whole moral framework you've become a consequentialist or maybe a rule utilitarian but most of you and most of K's readers think there's something odd and implausible about this answer I would like to try to defend Kant on this point and then I want to see whether you think that my defense is plausible and I would want to defend him within the spirit of his own account of morality imagine that someone comes to your door you were asked the question by this murder you're hiding your friend is there a way that you could avoid telling a lie without selling out your friend does anyone have an idea of how you might be able to do that yes stand up I was just going to say if I were to let my friend in my house to hide in the first place I'd probably make a plan with them so I'd be like hey I'll tell the murderer you're here but escape and that's one of the options mentioned so but I'm not sure that's aan an option H you're still lying though no because he's in the house but he won't be oh I see all right good enough one more try if you just say you don't know where he is because he might not be locked in the closet he might have left the closet you have no clue where he could be so you would say I don't know which wouldn't actually be a lie be because you weren't at that very moment looking in the closet exactly so it would be strictly speaking true yes and yet possibly deceiving misleading but still true what's your name John John all right John has uh now John may be on to something John you're really offering us the option of a clever evasion that is strictly speaking true this raises the question whether there is a moral difference between an outright lie and a misleading truth from K point of view there actually is a world of difference between a lie and a misleading truth why is that even though both might have the same consequences but then remember Kant doesn't base morality on consequences he bases it on formal adherence to the moral law now sometimes in ordinary life we make exceptions for the general rule against lying with a white lie what is a white lie it's it's a lie to make well to avoid hurting someone feelings for example it's a lie that we think of as justified by the consequences now Kant could not endorse a white lie but perhaps he could endorse a misleading truth suppose someone gives you a tie as a gift and you open the box and it's just awful what do you say thank you thank you you could say thank you but they're waiting to see what you think of it or they ask you what do you think of it you could tell a white Li and say it's beautiful but that wouldn't be permissible from K's point of view could you say not a white lie but a misleading truth you open the box and you say I've never seen a tie like that before thank you you shouldn't have that's good can you think of a contemporary political leader who engaged you can what are you thinking of remember the whole carefully worded denials in the Monica Lewinsky Affair of Bill Clinton now those denials actually became the subject of very explicit debate and argument during the impeachment hearings take a look at the following excerpts from Bill Clinton is there something do you think morally at stake in the distinction between a lie and a misleading carefully couched truth I want to say one thing to the American people I want you to listen to me I'm going to say this again I did not have sexual relations with that woman Miss Linsky I never told anybody to lie not a single time never these allegations are false did he lie to the American people when he said I never had sex with that woman you know he doesn't believe he did and because of the let me explain may I explain Congressman what he said was to the American people that he did not have sexual relations and I understand you're not going to like this Congressman because it you will see it as a a hair splitting evasive answer but in his own mind his definition was not okay I understand that argument okay all right so there you have the exchange now at the time you may have thought this was just a legalistic hair spitting exchange between a republican who wanted to impeach Clinton and the lawyer who was trying to defend him but now in the light of Kant do you think there is something morally at stake in the distinction between a lie and an evasion a true but misleading statement I'd like to hear from Defenders of K people who think there is a distinction are you are you ready to defend Kant well I think when you try to say that lying and misleading truths are the same thing you're basing it on a consequentialist argument which is that they achieve the same thing but the fact of the matter is you told the truth and you intended that people would believe what you were saying which was the truth which means it is not more the same as telling a lie and intending that they believe it is the truth even though it's not true good what's your name Diana so Diana says there that KH has a point here and it's a point that might even come to the aid of Bill Clinton and that is well what about that someone over here for C motivation is key so if you give to someone because primarily you want to feel good about yourself com with that has no moral worth well with this the motivation is the same it's to sort of mislead someone it's to lie it's to sort of throw them off the track and the motivation is the same so there should be no difference okay good so here isn't the motiv motive the same Diana what what do you say to this argument that well the motive is the same in both cases there is the attempt or at least the hope that one's pursuer will be misled uh well that you could look at it that way but I think that the fact is that your immediate motive is that they should believe you the ultimate consequence of that is that they might be deceived and not find out what was going on but your immediate motive is that they should believe you because you're telling the truth may I help a little sure you and K why don't you say and what's your name I'm sorry Wesley why don't you say to Wesley it's not exactly the case that the motive in both cases is to mislead they're hoping they're hoping that the person will be misled by the statement I don't know where they are or I never had sexual relations you're hoping that they will be misled but in the case where you're telling the truth your motive is to mislead while at the same time telling the truth and honoring the moral law and staying within the bounds of the categorical imp N I think K's answer would be Diana yes yes you like that I do okay so I think K's answer would be unlike a falsehood unlike a lie a misleading truth pays a certain homage to duty and the homage it pays to duty is what justifies that the work of even the work of evasion Diana yes you like okay and so there is something some element of respect for the Dignity of the moral law in the careful evasion because Clinton could have told an outright lie but he didn't and so I think kant's K's Insight here is in the carefully couched but true evasion there is a kind of homage to the Dignity of the moral law that is not present in the outright lie and that Wesley is part of the motive it's part of the motive yes I hope he will be misled I hope the murderer will run down the road or go to the mall looking for my friend instead of the closet I hope that will be the effect I can't control that I can't control the consequences but what I can control is standing by and honoring however I pursue the ends I hope will unfold to do so in a way that is consistent with respect for the moral law Wesley I don't think is entirely persuaded but at least this brings out this discussion brings out some of what's at stake what's morally at stake in con notion of the categorical imperative as long as any uh effort is involved I would say that the contract is valid and it should take effect but why what was what morally can you point to for example two people agree to be married and one suddenly calls the other in two minutes say I changed my mind does the uh contract have obligation on both sides well I'm tempted to say no fine last time we talked about Khan's categorical imperative and we considered the way he applied the idea of the categorical imperative to the case of lying I want to turn briefly to one other application of K's moral theory and that's his political Theory now comp says that just laws arise from a certain kind of social contract but this contract he tells us is of an exceptional nature what makes the contract exceptional is that it's not an actual contract that happens when people come together and try to figure out what the Constitution should be Kant points out that the contract that generates Justice is what he calls an idea of reason it's not an actual contract among actual men and women gathered in a constitutional convention why not I think K's reason is that actual men and women gathered in a real con tional convention would have different interests values aims and there would also be differences of bargaining power and differences of knowledge among them and so the laws that would result from their deliberations wouldn't necessarily be just wouldn't necessarily conform to principles of right but would simply reflect the differences of bargaining power the special interests the fact that some might know more than others about law or about politics so Kant says a contract that generates principles of right is merely an idea of reason but it has undoubted practical reality because it can oblige every legislator to frame his laws in such a way that they could have been produced by the United will of the whole nation so Kant is a contractarian but he doesn't trace the origin or the rightness of law to any actual social contract this gives rise to an obvious question what is the moral force of a hypothetical contract a contract that never happened that's the question we take up today but in order to investigate it we need to turn to a modern philosopher John RS who worked out in his book a theory of Justice in great detail an account of a hypothetical agreement as the basis for justice R's theory of Justice in Broad outline is parallel to K in two important respects like Kant r was a Critic of utilitarianism each person possesses an inviability founded on Justice R's rights that even the welfare of society as a whole cannot override the rights secured by Justice are not subject to political bargaining or to the calculus of social interests the second respect in which rs's Theory follows cons is on the idea that principles of Justice properly understood can be derived from a hypothetical social contract not an actual one and rals works this out in fascinating detail with the device of what he calls the veil of ignorance the way to arrive at the rights the basic rights that we must respect the basic framework of Rights and duties is to imagine that we were gathered together trying to choose the principles to govern our Collective lives without knowing certain important particular facts about ourselves that's the idea of the veil of ignorance now what would happen if we gathered together just as we are here and try to come up with principles of Justice to govern our Collective life there would be a cacaphony of proposals of suggestions reflecting people's different interests some are strong some are weak some are rich some are poor so R says imagine instead that we are gathered in an original position of equality and what assures the equality is the veil of ignorance imagine that we are all behind a veil of ignorance which temporarily abstracts from or brackets hides from us who in particular we are our race our class our place in society our strengths our weaknesses whether we're healthy or unhealthy then and only then R says the principles we would agree to would be principles of Justice that's how the hypothetical contract Works what is the moral force of this kind of hypothetical agreement is it stronger or weaker than a real agreement an actual social contract in order to answer that question we have to look hard at the moral force of actual contract there are really two questions here one one of them is how do actual contracts bind me or obligate me question number one and question number two how do actual real life contracts justify the terms that they produce if you think about it this is in line with walls and K the answer to the second question how do actual contracts justify the terms that they produce the answer is they don't at least not on their own actual contracts are not self-sufficient moral instruments of any actual contract or agreement it can always be asked is it fair what they agreed to the fact of the agreement never guarantees the fairness of the agreement and we know this by looking at our own Constitutional Convention It produced a constitution that permitted slavery to persist it was agreed to it was an actual contract but that doesn't establish that the laws agreed to all of them were just well then what is the moral force of actual contracts to the extent that they bind us they obligated in two ways suppose maybe here it would help to take an example we make an agreement a commercial agreement I promise to pay you $100 if you will go Harvest and bring to me a 100 lobsters we make a deal you go out and harvest them and bring them to me I eat the lobsters serve them to my friends and then I don't pay and you say but you're obligated and I say why what do you say well we had a deal and you benefited you ate all those lobsters well that's a pretty strong argument it's an argument that depends though on the fact that I benefited from your labor so contracts sometimes bind us in so far as they are instruments of mutual benefit I ate the lobsters I owe you the $100 for having gathered them but suppose now take a second case we make this deal I'll pay you $100 for 100 lobsters and 2 minutes later before you've gone to any work I call you back and say I've changed my mind now there's no benefit there's no work on your part so there's no element of reciprocal exchange what about in that case do I still owe you merely in virtue of the fact that we had an agreement who says those of you who say yes I still owe you why okay stand up why do I owe you I call you back after two minutes you haven't done any work um I think I spent a time and effort in uh drafting this contract with you and also have emotional expectation that I'll go through the work so you took time to draft the contract but we did it very quickly we just chatted on the phone that wouldn't be a for form of contract though well I faxed it to you it only took a minute as long as any uh effort is involved I would say that the contract is valid and it should take effect but why what was what morally can you point to that obligates me I admit that I agreed but you didn't go to any work I didn't enjoy any benefit because one my mentally go through all the work of harvesting the lobsters you mentally went through the work of harvesting the lobsters that's nothing is it it's not much is it worth $100 that you were imagining yourself going and collecting up it may not worth $100 but it may worth something to some people all right I'll give you a buck for it for that but what what I so you're still pointing what's interesting you're still pointing to the re reciprocal dimension of contracts you did or imagined that you did or looked forward to doing something on my behalf for example two people agree to be married and one suddenly calls the other in two minutes say I changed my mind does the uh contract have obligation on both sides nobody has paid any um work or nobody has benefited yet well I'm tempted to say no fine J all right what's your name Julian thank you Julian all right that was good now is there anyone who has who agrees with Julian that I still owe the money for any other reason now I have go ahead stand up I think if you back out it sort of cheapens the institution of contracts good but why why does it well I think this is kind of content but there's you know almost there's a certain intrinsic value in being able to make contracts and having you knowing that people will expect that you'll go through with that good there is some it would cheapen the whole idea of contracts which has to do with taking an obligation on myself is that is that the idea yeah I think so what's your name Adam so Adam points instead not to any reciprocal benefit or Mutual exchange but to the mere fact of the agreement itself we see here there are really two different ways in which actual contracts generate obligations one has to do with the act of consent as a voluntary act and it points Adam said this was a conent idea and I think he's right because it points to the ideal of autonomy when I make a contract the obligation is one that is self-imposed and that carries a certain moral weight independent of other considerations and then there's a second element of the moral force of contract arguments which has to do with the sense in which actual contracts are instruments of mutual benefit and this points toward the ideal of reciprocity that obligation can arise I can have an obligation to you in so far as you do something for me now we're investigating the moral force and also the moral limits of actual contracts and here I would like to advance an argument about the moral limits of actual contracts now that we know what moral ingredients do the work when people come together and say I will do this if you do that I would like to argue first that the fact that two people agree to some exchange does not mean that the terms of their agreement are fair when my two sons were young they collected baseball cards and traded them and one was there was a 2-year age there is a 2-year age difference between them and so I had to Institute a rule about the trades that no trade was complete until I had approved it and the reason is obvious the older one knew more about the value of these cards and so would take advantage of the younger one so that's why I had to review it to make sure that the agreement that the agreements were Fair now you may say well this is paternalism of course it was that's what paternalism is for that kind of thing so what what does this show what does the baseball card example show the fact of an agreement is not sufficient to establish the fairness of the terms I read some years ago of a case in Chicago there was an elderly Widow an 84 year-old Widow named Rose who had a problem in her apartment with a leaky toilet and she signed a contract with an unscrupulous contractor who offered to repair her leaky toilet in exchange for $50,000 but she had agreed she was of sound mind maybe terribly naive and unfamiliar with the price of Plumbing she had made this agreement luckily it was discovered she went to the bank and asked to withdraw $25,000 and the teller said what do you need need all of that money for and she said well I have a leaky toilet and the teller called authorities and they discovered this unscrupulous contractor now I suspect that even the most Ardent contractarians in the in the room will agree that the fact of This Woman's agreement is not a sufficient condition of the agreement being fair is there anyone who will dispute that no one am I missing anyone Alex where are you where are you so um maybe there's no dispute then to my first claim that the that an actual agreement is not necessary to their it's not a efficient condition of there being an obligation I want to now make a a stronger maybe more controversial Claim about the moral limits of actual contracts that a contract or an act of consent is not only not sufficient but it's not even a necessary condition of there being an obligation and the idea here is that if there is reciprocity if there is an exchange then a receipt of benefits there can be an obligation even without an act of consent one great example of this involves the 18th century philosopher the Scottish moral philosopher David Hume when he was young Hume wrote a book arguing against loide aidea of an original social contract Hume Heap scorned on this contractarian idea he said it was a philosophical fiction one of the most mysterious and incomprehensible operations that can possibly Be Imagined this idea of the social contract many years later when he was 62 years old Hume had an experience that put to the test his rejection of consent as the basis of obligation Hume had a house in Edinburgh he rented it to his friend James Boswell who in turn subl it to a subtenant the subtenant decided that the house needed some repairs and a paint job he hired a contractor to do the work the painter did the work and sent the bill to Hume Hume refused to pay on the grounds that he hadn't consented he hadn't hired the painter the case went to court the contractor said it's true Hume didn't agree but the house needed a painting and I gave it a very good one Hume thought this was a bad argument the only argument this painter makes is that the work was necessary to be done but this is no good answer because by the same rule this painter may go through every house in Edinburgh and do what he thinks proper to be done without the landlord's consent and give the same reason that the work was necessary and that the house was the better for it so Hume didn't like the theory that there could be obligation to repay a benefit without consent but the defense failed and he had to pay let me give you one other example of the distinction between the consent based aspect of obligations and the benefit-based aspect and how they sometimes run together this is based on a personal experience some years ago I was driving across the country with some friends and we found ourselves in the middle of nowhere in Hammond Indiana we stopped at a rest stop and got out of the car and when we came back our car wouldn't start none of us knew much about cars we didn't really know what to do until we noticed that in the parking lot driving up next to us was a van and on the side it said Sam's mobile repair van and out of the van came a man presumably Sam and he came up to us us and he said can I help you here's how I work I work by the hour for $50 an hour if I fix your car in five minutes you owe me the $50 and if I work on your car for an hour and can't fix it you'll still owe me the $50 so I said well what is the likelihood that you'll be able toix taks the car in he didn't answer but he did start looking under the poking around under the steering column short time passed he emerged from under the steering column and said there's nothing wrong with the ignition system but you still have 45 minutes left should I look under the hood I said wait a minute I haven't hired you we haven't made any agreement and then he became very angry and he said do you mean to say that if I had fixed your car while I was working under the steering column that you wouldn't have paid me and I said that's a different question I didn't I didn't go into the distinction between consent-based and benefit-based obligations but I think he had the intuition that if he had fixed it while he was poking around that I would have owed him the 50 bucks I shared that intuition I would have but he inferred from that this was the fallacy and the reasoning that I think lay behind his anger he inferred from that fact that therefore implicitly we had an agreement but that it seems to me is a mistake it's a mistake that fails to recognize the distinction between these two different aspects of contract arguments yes I agree I would have owed him $50 if he had repaired my car during that time not because we had made any agreement we hadn't but simply because if he had fixed my car he would have conferred on me a benefit for which I would have Ed him in the name of reciprocity and fairness so here's another example of the distinction between these two different kinds of arguments these two different aspects of the morality of contract now I want to hear how many think I was in the right in that case that's reassuring is there anyone who thinks I was in the wrong anyone you do why go ahead isn't the problem with this is that any benefit is inherently subjectively defined I mean what if you wanted your car broken and he had fixed it I mean no I didn't want it broken yeah in this case who would who would who would I don't know someone I mean what if what if Hume you know what if the painter had painted his house blue but he hated the color blue I mean you have to sort of Define what your benefit is before the person does it well all right so what would you conclude from that though for the larger issue here would you conclude that therefore consent is a necessary condition of there being an obligation absolutely you would what's your name Nate because otherwise how can we know Nate says whether there has been an exchange of equivalent or Fair benefits unless we have the sub valuation which may vary one person to the next of the situation all right that's a fair challenge let me put to you one other example in order to test the relation between these two aspects of the morality of contract suppose I get married and suppose I discover that after 20 years of faithfulness on my part every year on our trip across the country my wife has has been seeing another man a man with a van on the Indiana troll Road this part is completely made up by the way wouldn't I have two different reasons for moral outrage one reason could be we had an agreement she broke her promise referring to the fact of her consent but I would also have a second ground for moral outrage having nothing to do with the contract as such but I've been so faithful for my part surely I deserve better than this is this what I'm do in return and so on so that would point to the element of reciprocity each reason has an independent moral Force that's the general point and you can see this if you imagine a slight variation on the marriage case suppose we hadn't been married for 20 years suppose we were just married and that the Betrayal occurred on the way to our honeymoon in Hammond Indiana after the contract has been made but before there is any history of performance on my part performance of the contract I mean I would still oh come on come on I would still with with Julian I'd be able to say but you promised you promised that would isolate the Pure Element of consent right where where there were no benefit never mind you get the idea here's the main idea actual contracts have their moral force in virtue of two distinguishable ideals autonomy and reciprocity but in real life every actual contract may fall short may fail to realize the ideals that give contracts their moral force in the first place the ideal of autonomy May not be realized because there may be a difference in the bargaining power of the parties the ideal of reciprocity may not be realized because there may be a difference of knowledge between the parties and so they may misidentify what really counts as having having equivalent value now suppose you were to imagine imagine a contract where the ideals of autonomy and of reciprocity were not subject to contingency but were guaranteed to be realized what kind of contract would that have to be imagine a contract among parties who were equal in power and knowledge rather than unequal who were identically situated rather than differently situated that is the idea behind rs's claim that the way to think about Justice is from the standpoint of a hypothetical contract behind a veil of ignorance that creates a condition of equality by ruling out or enabling us to forget for the moment the differences in power and knowledge that would that could even in principle lead to unfair results this is why for content for RS a hypothetical contract among equals is the only way to think about principles of Justice what will those principles be that's the question we'll turn to next time don't miss the chance to interact online with other viewers of Justice join the conversation take a pop quiz watch lectures you've missed and learn a lot more visit justiceharvard.org it's the right thing to do funding for this program is provided by additional funding provided by"}], "Justice: What's The Right Thing To Do? Episode 08: \"WHATS A FAIR START?\"": [{"content": "funding for this program is provided by additional funding provided by today we turn to the question of distributive justice how should income and wealth and power and opportunities be distributed according to what principles John Rawls offers a detailed answer to that question and we're going to examine and assess his answer to that question today we put ourselves in a position to do so last time by trying to make sense of why he thinks that principles of justice our best derived from a hypothetical contract and what matters is that the hypothetical contract be carried out in an original position of equality behind what Rawls calls the veil of ignorance so that much is clear all right then let's turn to the principles that Rawls says would be chosen behind the veil of ignorance first you consider some of the major alternatives what about utilitarianism would the people in the original position choose to govern their collective lives utilitarian principles the greatest good for the greatest number no they wouldn't all sense and the reason is that behind the veil of ignorance everyone knows that once the veil goes up and real life begins we will each want to be respected with dignity even if we turn out to be a member of a minority we don't want to be oppressed and so we would agree to reject utilitarianism and instead to adopt as our first principle equal basic liberties fundamental rights to freedom of speech freedom of assembly religious liberty freedom of conscience and the like we wouldn't want to take the chance that we would wind up as members of an oppressed or despised minority with the majority tyrannize anova us and so it all says utilitarianism would be rejected utilitarianism makes the mistake of all its rights of forgetting or at least not taking seriously the distinction between persons and in the original position behind the veil of ignorance we would recognize that and reject utilitarianism we wouldn't trade off our fundamental rights and liberties for any economic advantages that's the first principle second principle has to do with social and economic inequalities what would we agree to remember we don't know whether we're going to wind up being rich or poor healthy or unhealthy we don't know what kind of family we're going to come from whether we're going to inherit millions or whether we will come from an impoverished family so we might at first thought say well let's require an equal distribution of income and wealth just to be on the safe side but then we would realize that we could do better than that even if we're unlucky and wind up at the bottom we could do better if we agree to a qualified principle of equality Rawls calls it the difference principle a principle that says only those social and economic inequalities will be permitted that work to the benefit of the least well-off so we wouldn't reject all inequality of income and wealth we would allow some but the test would be do they work to the benefit of everyone including those or as he specifies the principle especially those at the bottom only those inequalities would be accepted behind the veil of ignorance and so Rawls argues only those inequalities that work to the benefit of the least well-off are just we talked about the examples of Michael Jordan making 31 million dollars a year of Bill Gates having a fortune in the tens of billions with those inequalities be permitted under the difference principle only if they were part of a system those wage differentials that actually worked to the advantage of the least well-off well what would that system be maybe it turns out that as a practical matter you have to provide incentives to attract the right people to certain jobs and when you do having those people in those jobs will actually help those at the bottom strictly speaking Rawls is argument for the difference principle is that it would be chosen behind the veil of ignorance let me hear what you think about Rawls's claim that these two principles would be chosen behind the veil of ignorance is there anyone who disagrees that they would be chosen all right let's start up in the balcony if that's all right go ahead okay your argument depends upon us believing that we would argue and set policy or justice from a bottom that for the disadvantaged and I just don't see from a proof standpoint where where we've proven that why not the top right and what's your name Mike Mike all right good question put yourself behind the veil of ignorance enter into the thought experiment what principles would you choose how would you think it through well I would say things like even Harvard's existence is an example of preaching toward the top because Harvard takes the top academics and I didn't know when I was born how smart I would be but I worked my life to get to a place of this caliber now if you'd said Harvard's gonna randomly take 1600 people of absolutely no qualification we'd all be saying well there's nothing much not much to work for and so what principle would you choose in that situation I would say a merit-based one where one where I don't ously know what I have a brother have a system that rewards me based on my efforts so you but Mike behind the veil of ignorance would choose a merit-based system where people are rewarded according to their efforts alright fair enough what would you say go ahead my question is if the merit-based argument is based on um when everyone is at a level of equality where from that position you be you're rewarded to where you get or is it regardless of of what advantages you may have when you began your education to get where you are here I think what we do the question you're asking is saying it you know if you want to look at whatever utilitarianism policy is do we want to maximize world wealth and I think of system that rewards merit is the one that we've pretty much all established is what is best for all of us this by the fact that some of us may be in the second percentile and some may be in the 98th percentile and the end of the day it lifts that lowest that lowest base level a community that rewards effort as opposed to innate differences I don't understand how how you're rewarding someone's efforts who clearly has had not you but maybe myself advantages throughout to get where I am here I mean I can't say that that somebody else who maybe it worked as hard as I did would have had the same opportunity to come to a school like this alright let's let's look at that point what's your name Kate Kate you suspect that the ability to get into top schools may largely depend on coming from an affluent family having a favorable back family background social cultural economic advantages and so on I mean economic but your social cultural all of those advantages for sure someone did a study of the hundred and forty six selective colleges and universities in the United States and they looked at the students in those colleges and universities to try to find out what their background was their economic background what percentage do you think come from the bottom quarter of the income scale you know the figure is only three percent of students at the most selective colleges and universities come from poor backgrounds over 70 percent come from affluent families let's go one step further then and try to address Mike's challenge Rawls actually has two arguments not one in favor of his principles of justice and in particular of the difference principle one argument is the official argument what would be chosen behind the veil of ignorance some people challenge that argument saying maybe people would want to take their chances maybe people would be gamblers behind the veil of ignorance hoping that they would wind up on top that's one challenge that has been put to Rawls but backing up the argument from the original position is a second argument and that is a straightforwardly moral argument and it goes like this it says the distribution of income and wealth and opportunities should not be based on factors for which people can claim no credit it shouldn't be based on factors that are arbitrary from a moral point of view Rawls illustrates this by considering several rival theories of justice he begins with the theory of justice that most everyone these days would reject a feudal aristocracy what's wrong with the allocation of life prospects in a feudal aristocracy Rawls says well the thing that's obviously wrong about it is that people's life prospects are determined by the accident of birth are you born to a noble family or to the family of peasants and serfs and that's it you can't rise it's not your doing where you wind up or what opportunities you have but that's arbitrary from a moral point of view and so that objection to a feudal aristocracy leads and historically has led people to say careers should be open to talents there should be formal equality of opportunity regardless of the accident of birth every person should be free to strive to work to apply for any job in the society and then if you open up jobs and you allow people to apply and if we work as hard as they can then the results are just so it's more or less the libertarian system that we've discussed in earlier weeks what does Rawls think about this he says it's an improvement it's an improvement because it doesn't take as fixed the accident of birth but even with formal equality of opportunity the libertarian conception doesn't extend that doesn't extend its insight far enough because if you let everybody run the race everybody can enter the race but some people start at different starting points that race isn't going to be fair intuitively he says the most obvious injustice of this system is that it permits distributive shares to be improperly influenced by factors arbitrary from a moral point of view such as whether you've got a good education or not whether you grew up in a family that supported you and developed in you a work ethic and gave you the opportunities so that suggests moving to a system of fair equality of opportunity and that's really the system that mike was advocating earlier on what we might call a merit-based system a meritocratic system in a fair meritocracy the Society sets up institutions to bring everyone to the same starting point before the race begins equal educational opportunities Head Start programs for example support for schools in impoverished neighborhoods so that everyone regardless of their family background has a genuinely fair opportunity everyone starts from the same starting line well what does Rawls think about the meritocratic system even that he says doesn't go far enough in remedying or addressing the moral arbitrariness of the natural lottery because if you bring everyone to the same starting point and begin the race who's going to win the race who would win to use the runners example the fastest runners would win but but is it their doing that they happen to be blessed with the athletic prowess to run fast so role says even the principle of meritocracy where you bring everyone to the same starting point may eliminate the influence of social contingencies and upbringing but it still permits the distribution of wealth and income to be determined by the natural distribution of abilities and talents and so he thinks that the principle of eliminating morally arbitrary influences in the distribution of income and wealth requires going beyond what mike favours the meritocratic system now how do you go beyond if you bring everyone to the same starting point and you're still bothered by the fact that some are fast runners and some are not fast runners what can you do well some critics of a more egalitarian conception say the only thing you can do is handicap that's the fast runners make them wear lead shoes but who wants to do that that would defeat the whole point of running the race but wall says you don't have to have a kind of leveling equality if you want to go beyond a meritocratic conception you permit you even encourage those who may gifted to exercise their talents but what you do is you change the terms on which people are entitled to the fruits of the exercise of those talents and that really is what the difference principle is you establish a principle that says people may benefit from their good fortune from their luck in the genetic lottery but only on terms that work to the advantage of the least well-off and so for example Michael Jordan can make 31 million dollars but only under a system that taxes away a chunk of that to help those who lack the basketball skills that he's blessed with likewise Bill Gates he could make his billions but he can't think that he somehow morally deserves those billions those who have been favored by nature may gain from their good fortune but only on terms that improve the situation of those who have lost out that's the difference principle and it's an argument from moral arbitrariness Rawls claims that if you're bothered by basing distributive shares on factors arbitrary from a moral point of view you don't just reject a feudal aristocracy for a free market you don't even rest content with a meritocratic system that brings everyone to the same starting point you set up a system where everyone including those at the bottom benefit from the exercise of the talents held by those who happen to be lucky what do you think is that persuasive was who finds that argument unpersuasive the argument from moral arbitrariness yes I think that in the egalitarian proposition the more talented people I think it's very optimistic to think that they would would still work really hard even if they knew that part of what they made would be given away so I think that the only way for for the more talented people to exercise their talents to the best of their ability is in the meritocracy and in a meritocracy what's your name Kate Kate does it bother you and Mike does it bother you that in a meritocratic system even with fair equality of opportunity people get ahead people get rewards that they don't deserve simply because they happen to be naturally gifted what about that um I think that it is arbitrary um and obvious obviously is arbitrary but I think that there that correcting for it would be detrimental um and um because it would reduce incentives is that why this incentives yeah Mike what do you say they were all sitting in this room and we have undeserved we are undeserved glory of some sorts that you should not be satisfied with the perfect process of your life because you have not created any of this and I think from a standpoint of not just this room us being upset but from a societal standpoint we should have some kind of a gut reaction to that feeling that you know the guy who runs the race he doesn't he actually harms us as opposed to maybe makes me run that last ten yards faster and that makes the guy behind me run ten yards faster and the guy behind him ten yards faster all right so Mike let me ask you you talked about effort before effort do you think when people work hard to get ahead and succeed that they deserve the rewards that go with effort isn't that the idea behind your defensive you know of course bring Michael Jordan here I'm sure you can get him and have him come and defend himself about why he makes 31 million dollars I think what you're going to realize is his life was a very very tough one to get to the top and that we are basically being the the majority of pressing the minority in a different light it easy to pick on him their eyes effort you know what all right you've got youth this way you I've got a futile effort you know what Rawls answer to that is even the effort that some people expend conscientious driving the work ethic even effort depends a lot on fortunate family circumstances for which you we can claim no credit now let's hey we're going to let let's do the test let's do a test here never mind economic class those differences are very significant put those aside psychologists say that birth order makes a lot of difference in work ethic striving effort how many here raise your hand those of you here who are first in birth order I am too by the way Mike I noticed you raise your hand if the case for the meritocratic conception is that efforts should be rewarded doesn't Rawls have a point that even effort striving work ethic is largely shaped even by birth order is it your doing Mike is it your doing that you were first in birth order then why Rahl says of course not so why should income and wealth and opportunities in life be based on factors arbitrary from a moral point of view that's a challenge that he puts to market societies but also to those of us at places like this a question to think about for next time a Justice of the United States Supreme Court what do they make it's it's just under two hundred thousand dollars there's another judge who makes a lot more than Sandra Day O'Connor you know who it is Judge Judy how did you know that Judge Judy you know how much he makes 25 million dollars now is that just is it fair we ended last time with that remarkable pole you remember the poll about birth order what percentage of people in this room raised their hands was it to say that they were the firstborn 75 80 percent and what was the significance of that if you're thinking about these theories of distributive justice remember we were discussing three different theories of distributive justice three different ways of answering the question how should income and wealth and opportunities and the good things in life be distributed and so far we've looked at the libertarian answer that says the just system of distribution is a system of free exchange of free market economy against a background of formal equality which simply means that jobs and careers are open to anyone Rawls says this represents an improvement over aristocratic and caste systems because everyone can compete for every job careers opened talents and beyond that the just distribution is the one that results from free exchange voluntary transactions no more no less then Wells argues if all you have is formal equality jobs open to everyone the result is not going to be fair it will be biased in favor of those who happen to be born to affluent families who happen to have the benefit of good educational opportunities and that accident of birth is not a just basis for distributing life chances and so many people who notice this unfairness Rawls argues I led to embrace a system of fair equality of opportunity that leads to the meritocratic system stay or equality of opportunity but Wall says even if you bring everyone to the same starting point in the race what's going to happen who's going to win the fastest runners so once you're troubled by basing distributive shares on morally arbitrary contingencies you should if you reason it through be carried all the way to what Rawls calls the Democratic conception of more egalitarian conception of distributive justice that he defines by the difference principle now he doesn't say that the only way to remedy or to compensate for differences in natural talents and abilities is to have a kind of leveling equality a guaranteed equality of outcome but he does say there's another way to deal with these contingent these people may gain may benefit from their good fortune but only on terms that work to the advantage of the least well-off and so we can test how this theory actually works by thinking about some pay differentials that arise in our society what does the average school teacher make in the United States do you suppose roughly it's a little more 40 40 mm what about David Letterman how much do you think David Letterman makes more than a school teacher 31 million dollars David Letterman is that fair the David Letterman makes that much more than a school teacher well Rawls's answer would be it depends whether the basic structure of society is designed in such a way that Letterman's 31 million dollars is subject to taxation so that some of those earnings are taken to work for the advantage of the least well-off one other example of a pay differential a Justice of the United States Supreme Court what do they make it's it's just under two hundred thousand dollars here's Sandra Day O'Connor for example there she is but there's another judge who makes a lot more than Sandra Day O'Connor you know who it is Judge Judy how did you know that you watch no but you hurt your right Judge Judy you know how much she makes there she is 25 25 million dollars now is that just is it fair well the answer is it depends whether this is against a background system in line with the difference principle where those who come out on top in terms of income and wealth are taxed in a way that benefits the least well-off members of society now we're going to come back to these wage differentials pay differentials between a real judge and a TV judge the one Marcus watches all the time what I want to do now is return to these theories and to examine the objections to Rawls's more egalitarian theory the difference principle there are at least three objections to Rawls's difference principle one of them came up last time in the discussion and a number of you raised this worry what about incentives isn't there the risk if taxes reach 70 80 90 percent marginal rate that Michael Jordan won't play basketball that data David Letterman won't do late night comedy or that CEOs will go into some other line of work now who among those who are defenders of Rawls who has an answer to this objection about the need for incentives yes go ahead stand up Rawls's idea is that there should only be so much difference that it helps the least well-off the most so if there's too much equality then the least well-off might not be able to watch late-night TV or might not have a job because their CEO doesn't want to work so you need to find the correct balance where taxation still leaves enough incentive for the least well-off to benefit from the talents good and what's your name Tim Tim all right so Tim is saying in effect that Rawls's takes account of incentives and could allow for pay differentials and for some adjustment in the tax rate to take account of incentives but Tim points out the standpoint from which the question of incentives needs to be considered is not the effect on the total size of the economic pie but instead from the standpoint of the effect of incentives or disincentives on the well-being of those at the bottom right good thank you I think that is what Rawls would say in fact if you look in Section 17 where he describes the difference principle he allows for incentives the naturally advantaged are not to gain merely because they are more gifted but only to cover the costs of training and education and for using their endowments in ways that help the less fortunate as well so you can have incentives you can adjust the tax rate if taking too much from David Letterman or from Michael Jordan or from Bill Gates winds up actually hurting those at the bottom that's the test so incentives that's not a decisive objection against Rawls's difference principle but there are two weightier more difficult objections one of them comes from defenders of a meritocratic conception the argument that says what about effort what about people working hard having a right to what they earn because they've deserved it they've worked hard for it that's the objection from effort and moral desert then there's a another objection that comes from libertarians and this objection has to do with reasserting the idea of self-ownership doesn't the difference principle by treating our natural talents and endowments has common assets doesn't that violate the idea that we own ourselves now let me deal first with the objection that comes from the libertarian direction Milton Friedman writes in his book free to choose life is not fair and it's tempting to believe that government can rectify what nature has spawned but his answer is the only way to try to rectify that is to have a leveling equality of outcome everyone finishing the race at the same point and that would be a disaster this is an easy argument to answer and Rawls addresses it in one of the most powerful passages I think of a theory of justice it's in section 17 the natural distribution and here he is talking about the natural distribution of talents and endowment is neither just unjust nor is it unjust that persons are born into society at some particular position these are simply natural facts what is just and unjust is the way that institutions deal with these facts that's his answer to libertarian Less a fair economists like Milton Friedman who say life is unfair but get over it get over it and let's see if we can at least maximize the benefits that flow from it but the more powerful libertarian objection to Rawls is not libertarian from the libertarian economists like Milton Friedman it's from the argument about self ownership developed as we saw in Nozick and from that point of view yes it might be a good thing to create headstart programs and public schools so that everyone can go to a decent school and start the race at the same starting line that might be good but if you tax people to it to create public schools if you tax people against their will you coerce them it's a form of theft if you take some of Letterman's 31 million tax it away to support public schools against his will the state is really doing no better than stealing from him it's coercion and the reason is we have to think of ourselves as owning our talents and endowments because otherwise we're back to just using people and coercing people that's the libertarian reply which Rawls answer to that objection he doesn't address the idea of self-ownership directly but the effect the moral weight of this argument for the difference principle is maybe we don't own ourselves in that thoroughgoing sense after all now he says this doesn't mean that the state is an owner in me in the sense that it can simply commandeer my life because remember the first principle we would agree to behind the veil of ignorance is the principle of equal basic liberties freedom of speech religious liberty freedom of conscience and the like so the only respect in which the idea of self-ownership must give way comes when we're thinking about whether I own myself in the sense that I have a privileged claim on the benefits that come from the exercise of my talents in a market economy and Rawls says on reflection we don't we can defend rights we can respect the individual we can uphold human dignity without embracing the idea of self-possession that in effect is his reply to the libertarian I want to turn now to his reply to the defender of a meritocratic conception who invokes effort as the basis of moral desert people who work hard to develop their talents deserve the benefits that come from the exercise of their talents well we've already seen the beginning of Rawls's answer to that question and it goes back to that poll we took about birth order his first answer is even the work ethic even the willingness to strive conscientiously depends on all sorts of family circumstances and social and cultural contingencies for which we can claim no credit you can't claim credit for the fact that you most of you most of us happen to be first in birth order and that for some complex psychological and social reasons that seems to be associated with striving with achieving with effort that's one answer there's a second answer those of you who invoke effort you don't really believe that moral desert attaches to effort take two construction workers one is strong and can raise four walls in an hour without even breaking a sweat and another construction worker is small and scrawny and it has to spend three days to do the same amount of work no defender of meritocracy is going to look at the effort of that weak and scrawny construction worker and say therefore he deserves to make more so it isn't really effort this is the second reply to the meritocratic claim it isn't really effort that the defender of meritocracy believes is the moral basis of distributive shares its contribution how much do you contribute but contribution takes us right back to our natural talents and abilities not just effort and it's not our doing how we came into the possession of those talents in the first place all right suppose you accepted these arguments that effort isn't everything that contribution matters from the standpoint of the meritocratic conception that effort even isn't our own doing does that mean the objection continues does that mean that according to Rawls moral desert has nothing to do with distributive justice well yes distributive justice is not about moral desert now here Rawls introduces an important and a tricky distinction it's between moral desert on the one hand and entitlements to legitimate expectations on the other what is the difference between moral deserts and entitlements consider two different games a game of chance in a game of skill take a game of pure chance say I play the Massachusetts state lottery and my number comes up I'm entitled to my winnings but even though I'm entitled to my winnings there's no sense in which because it's just a game of luck no sense in which I morally deserve to win in the first place that's an entitlement now contrast the lottery with a different kind of game a game of skill now imagine the Boston Red Sox winning the World Series when they win they're entitled to the trophy but it can be always asked of a game of skill did they deserve to win it's always possible in principle to distinguish what someone's entitled to under the rules and whether they deserve to win in the first place that's an antecedent standard moral desert now Rahl says distributive justice is not a matter of moral desert though it is a matter of entitlements to legitimate expectations here's where he explains it a--just scheme answers to what men are entitled to it satisfies their legitimate expectations is founded upon social institutions but what they are entitled to is not proportional to nor dependent on their intrinsic worth the principles of justice that regulate the basic structure do not mention moral desert and there is no tendency for distributive shares to correspond to it why does Rawls make this distinction what morally is at stake one thing morally at stake is the whole question of effort that we've already discussed but there's a second contingency a second source of moral arbitrariness that goes beyond the question of whether it's to my credit that I have the talents that enable me to get ahead and that has to do with the contingency that I live in a society that happens to prize my talents the fact that David Letterman lives in a society that puts a great premium puts a great value on a certain type of smirky joke that's not his doing he's lucky that he happens to live in such a society but this is the second contingency this isn't something that we can claim credit for even if I had sole unproblematic claim to my talents and to my effort it would still be the case that the benefits I get from exercising those talents depend on factors that are arbitrary from a moral point of view what my talents will reap in a market economy what does that depend on what other people happen to one or like in this society it depends on the law of supply and demand that's not my doing certainly not the basis for moral desert what counts as contributing depends on the qualities that this or that society happens to prize most of us are fortunate to possess in large measure for whatever reason the qualities that our society happens to prize the qualities they need that enable us to provide what society wants in a capitalist society it helps to have entrepreneurial Drive in a bureaucratic society it helps to get on easily and smoothly with superiors in a mass democratic society it helps to look good on television and to speak in short superficial sound bites in a litigious society it helps to go to law school and to have the talents to do well on ell SATs but none of this is our doing suppose that we with our talents inhabited not our society technologically advanced highly litigious but a hunting society or a warrior society what would become of our talents then they wouldn't get us very far no doubt some of us would develop others but would we be less worthy would be be less virtuous would be would we be less meritorious if we live in that kind of society rather than in ours Rawls's answer is no we might make less money and properly so but while we would be entitled to less we would be no less worthy no less deserving than we are now and here's the point the same could be said of those in our society who happen to hold less prestigious positions who happen to have fewer of the talents that our society happens to reward so here's the moral import of the distinction between moral desert and entitlements to legitimate expectations we are entitled to the benefits that the rules of the game promised for the exercise of our talents but it's a mistake and a conceit to suppose that we deserve in the first place a society that values the qualities we happen to have in abundance now we've been talking here about income and wealth what about opportunities and honors what about the distribution of access of seats in elite colleges and universities it's true all of you most of you firstborn worked hard strived developed your talents to get here but Rawls asks in effect what is the moral status of your claim to the benefits that attach to the opportunities you have our seats in colleges and universities a matter a kind of reward and honor for those who deserve them because they've worked so hard or are those seats those opportunities and honors entitlements to legitimate expectations that depend for their justification and those of us who enjoy them doing so in a way that works to the benefit of those at the bottom of society that's the question that Rawls's difference principle poses it's a question that can be asked of the earnings of Michael Jordan and David Letterman and Judge Judy but it's also a question that can be asked of opportunities to go to the top colleges and universities and that's a debate that comes out when we turn to the question of affirmative action next time don't miss the chance to interact online with other viewers of Justice join the conversation take a pop quiz watch lectures you've missed and learn a lot more visit justiceharvard.org it's the right thing to do funding for this program is provided by additional funding provided by"}], "Justice: What's The Right Thing To Do? Episode 09: \"ARGUING AFFIRMATIVE ACTION\"": [{"content": "[Music] funding for this program is provided by additional funding provided [Music] by last time we were discussing the distinction that RS draws between two different types of claims claims of moral desert on the one hand and of entitlements to legitimate expectations on the other RS argued that it's a mistake to think that distributive justice is a matter of moral dessert a matter of rewarding people according to their virtue today we're going to explore that question of moral dessert and its relation to distributive justice not in connection with income and wealth but in its connection with opportunities with hiring decisions and admission standards and so we turn to the case of affirmative action you read about the case of Cheryl Hopwood she applied for admission to the University of Texas law school Cheryl hoard had worked her way through high school she didn't come from an affluent family she put herself through Community College and California State University at Sacramento she achieved a 3.8 grade point average there later moved to Texas became a resident took the law school admissions test did pretty well on that and she applied to the University of Texas law school she was turned down she was turned down at a time when the University of Texas was using an affirmative action admissions policy a policy that took into account race and ethnic background the University of Texas said 40% of the population of Texas is made up of African-Americans and mexican-americans it's important that we as a law school have a diverse student body and so we are going to take into account not only grades and test scores but also Al the demographic makeup of our class including its race and ethnic profile the result and this is what Hopwood complained about the result of that policy is that some applicants to the University of Texas law school with a lower academic index which includes grades and test scores than hers were admitted and she was turned down she said she argued I'm just being turned down because I'm white if I weren't if I were a member of a minority group with my grades and test scores I would have been admitted and the statistics the admissions statistics that came out in the trial confirmed that African-American and Mexican-American applicants that year who had her grades and test scores were admitted it went to federal court now put aside the law let's consider it from the standpoint of justice and morality is it fair or is it unfair does Cheryl Hopwood have a case a legitimate complaint were her rights violated by the admissions policy of the law school how many say how many would rule for the law school and say that it was just to consider race and ethnicity as a factor in admissions how many would rule for Cheryl Hopwood and say her rights were violated so here we have a pretty even split all right now I want to hear from a defender of Cheryl Hopwood yes you're basing something on that's an arbitrary Factor you know Cheryl couldn't control the fact that she was white or not in a minority and therefore you know it's not as if it was like a test score that she worked hard to try and show that she could you know put that out there you know that she had no control over her race good and what's your name Bri okay Bri stay right there now let's find someone who's uh who has an answer for Brie yes there are discrepancies in the educational system and majority of the time I know this in New York City the schools that minorities go to are not as well funded are not as well supplied as white schools and so there is going to be a discrepancy naturally between minorities and between whites if they go to better schools and they will not do as well on exams because they haven't had as much help because of a worse school system so let me just interrupt you just to tell me your name Anisha Anisha Anisha you're pointing out that Minority kids may have gone in some cases MH to schools that didn't give them the same Educational Opportunity as kids from affluent families yes and so the test scores they got may actually not represent their true potential because they didn't receive the same kind of help that they might have received had they gone to a school with better funding all right Anisha has raised the point that colleges still should choose for the greatest academic scholarly promise but in reading the test scores and grades they should take into account the different meaning those tests and grades have in the light of educational disadvantage in the background so that's one argument in defense of affirmative action inisha argument correcting for the effects of unequal preparation educational disadvantage now there are other arguments suppose just to identify whether there is a is a competing principle here Suppose there are two candidates who did equally well on the tests and grades both of whom went to First Rate schools two cand candidates among those candidates would it be unfair for the college or university for Harvard to say we still want diversity along racial and ethnic Dimensions even where we are not correcting for the effects on tescor of educational disadvantage what about in that case Bri if it's that one thing that puts you know someone over the edge then it's I guess that would be you know justifiable if everything else about the individual first though everything they consider about that person's you know talents and where they come from and who they are without these arbitrary factors is the same without these arbitrary factors you call but before you were suggesting bre that race and ethnicity are arbitrary factors outside the control of the applicants true I would agree with that and your general principle is that admissions shouldn't reward arbitrary factors over which people have no control right all right uh who else who else would like to thank you both who else would like to get into this what do you say well first of all uh I'm for affirmative action temporarily but uh what for two reasons first of all you have to look at the University's purpose it is to educate their students and um I feel that different races people coming from different races have different backgrounds and they contribute differently to you know the education and second of all um when you say they have equal backgrounds they that's not true when you look at the broader picture and you look at slavery and these are this is kind of a reparation I think uh affirmative action is a temporary solution to alleviate um history and uh the wrongs done to African-Americans in particular and what's your name David David you say that affirmative action is Justified at least for now as a way of compensating for past Injustice the Legacy of slavery and segregation right who wants to take on that argument we need now a Critic of affirmative action yes go ahead I think that what happened in the past has no bearing on what happens today and I think that discriminating based on race should always be wrong whether you're discriminating against one group or another just because our ancestors did something doesn't mean that that should have any effect on what happens with us today all right good I'm sorry your name is Kate Kate all right who has an answer for Kate yes um I just wanted to comment and say that tell us your name uh my name is Monsour because of slavery because of past injustices today we have a higher proportion of African-Americans who are in poverty who face less less opportunities than white people and so because of slavery 200 years ago and because of Jim Crow and because of segregation today we have Injustice based on race Kate um I think that there are differences obviously but the way to fix those differences is not by some artificial fixing of the result you need to fix the problem so we need to address differences in education and differences in um in upbringing with with programs like Head Start and giving more funding to lower income schools rather than trying to just fix the result so it makes it look like it's equal when really it isn't yes well with regard to affirmative action based on race I just want to say that white people have had their own affirmative action in this country for more than 400 years it's called nepotism and quid proquo so there's nothing wrong with correcting the Injustice and discrimination that's been done to black people for 400 years good tell us wait tell us your name Hannah Hannah all right who has an answer for Hannah and just to add to Hannah's point because we need we need now someone to respond Hannah you could have also mentioned legacy admissions exactly I was going to say if you disagree with affirmative action you should disagree with Legacy admission because it's obvious from looking around here that there are more white legacies than black legacies in the history of Harvard University and explain what legacy admissions are well legacy admissions is giving an advantage to someone who has an arbitrary um privilege of their parent having attended the University to which they're applying all right so a reply for Hannah yes in the balcony go ahead first of all if affirmative action is making up for past injustice how do you explain minorities that were not historically discri discriminated against in the United States who get these advantages in addition You could argue that affirmative action perpetuates divisions between the races rather than achieve the ultimate goal of race being a relevant factor in our society and what tell us your name Danielle Hannah I disagree with that because I think that by promoting diversity in an institution like this you further educate all of the students especially the white students who grew up in predominantly white areas it's certainly a form of Education to be exposed to people from different backgrounds and you put white students at an inherent disadvantage when you surround them only with their own kind why should race necessarily be equated with diversity there's so many other forms why should we assume that race makes people different again that's perpetuating the idea of racial division within our universities and our society Hannah with regard to um African-American people being given a special Advantage it's obvious that they bring something special to the table because they have a unique perspective just as someone from a different religion or socioeconomic background would as well as you say there are many different types of diversity there's no reason that racial diversity should be eliminated from that criteria yes go ahead racial discrimination is illegal in this country and I believe that it was African-American leaders themselves when Martin Luther King said he wanted to be judged not on the color of his skin but by the content of his character his Merit his achievements and I just think that to do to decide solely based on someone's race is just inherently unfair I mean if you want to if you want to correct based on disadvantaged backgrounds that's fine but there are also disadvantaged white people as well it shouldn't matter white tell us your name Ted Ted yes think of Hopwood it's unfair to count race or I assume you would also say ethnicity or religion yes do you think she has a right to be considered according to her grades and test scores alone there no there's there is more to with than that you need to universities need to promote diversity and I so you agree with the goal of promoting diversity there's ways to promote diversity besides discriminating against people solely based on a factor that they cannot control all right so what makes it wrong is that she can't control her race she can't control the fact that she's white that's the that's the heart of the unfairness to her Bri made a similar point that basing admissions on factors that people can't control is fundamentally unfair when are you say there's a lot of things you can't control and if you're going to go it through it based on Merit like just based on your test scores a lot of what you can achieve has to do with like the family background that you raised it if both your parents were um scholarly then you have more of a chances of actually being more scholarly yourself and getting those grades and you can't control what kind of family you born into so I me good what tell that's that's a great rejoiner what's your name uh da da Ted are you you against um advantages that come from the family you were born into what about legacy admissions I mean I I I do believe that in terms of like a legacy admission you shouldn't have a special preference I mean there is a legacy admission You could argue as another part of verse you could say it's important to have a small percentage of people that have a a several generation family in family attendance at a place like Harvard however that should not be a a f an advantaged Factor like race that should just be another part promoting diversity should it count at all I think that alumni status should it count at all Ted yes it should it should count all right I want to step back for a moment from these arguments thank you all for these contributions we're going to come back to you if you've listened carefully I think you will have noticed three different arguments emerg from this discussion in defense of considering race and ethnicity as a factor in admissions one argument has to do with correcting for the effects for the effects of educational disadvantage that was anisha's argument this is what we might call the the corrective argument correcting for differences in educational background the kind of school people went to the opportunities they had and so on that's one argument what's worth noticing though is that that argument is consistent in principle with the idea that only academic promise and scholarly potential should count in admissions we just need to go beyond test scores and grades alone to get a true estimate of academic promise and scholarly ability that's the first argument then we heard a second argument that said affirmative action is Justified even where there may not be the need to correct for educational disadvantage in a in a particular applicant's case it's Justified as a way of compensating for past wrongs for historic injustices so that's a compensatory argument compensating for past wrongs then we heard a third a different argument for affirmative action from Hannah and others that argued in the name of diversity now the diversity argument is different from the compensatory argument because it makes a certain appeal to the social purpose or the social mission of the college or university there are really two aspects to the diversity argument one says it's important to have a diverse student body for the sake of the educational experience for everyone Hannah made that point and the other talks about the wider Society this was the argument made by the University of Texas in the Hopwood case we need to train lawyers and judges and leaders public officials who will contribute to the strength the Civic strength of the State of Texas and the country as a whole so there are two different aspects to the diversity argument but both are arguments in the name of the social purpose or the social Mission or the common good served by the institution well what about the force of these arguments we've also heard objections to these arguments the most powerful objection to the compensatory argument is is it fair to ask Cheryl Hopwood today to make the sacrifice to pay the compensation for an injustice that was admittedly committed and was egregious in the past but in which she was not implicated is that fair so that's an important objection to the compensatory argument and in order to meet that objection we would have to investigate whether there is such a thing as group rights or Collective responsibility that reaches over time so having identify that issue let's set it aside to turn to the diversity argument the diversity argument doesn't have to worry about that question about Collective responsibility for wrongs because it says for reasons Hannah and others pointed out that the common good is served is Advanced if there is a racially and ethnically diverse student body everyone benefits and this indeed was the argument that Harvard made when it filed a friend of the court brief to the Supreme Court in the 1978 case affirmative action case the baky case and the Harvard brief the Harvard rationale was cited by Justice Powell who was the Swing Vote in the case upholding affirmative action he cited that as providing the rationale that he thought was constitutionally acceptable Harvard's argument in its brief was this we care about diversity scholarly Excellence alone has never been the Criterion of admission the sole Criterion of admission to Harvard College 15 years ago diversity meant students from California and New York and Massachusetts city dwellers and farm boys violinists painters and football players biologists historians and classicists the only difference now Harvard argued is that we're adding raal and ethnic status to this long list of diversity considerations when reviewing the large number of candidates able to do well in our classes Harford wrote race May count as a plus just as coming from Iowa May count or being a good middle linebacker or pianist a farm boy from Idaho can bring something to Harvard College that a Bostonian cannot offer similarly a black student can usually bring something a white student cannot offer the quality of the educational experience of all students depends in part on these differences in the background and Outlook that students bring with them that was Harvard's argument now what about the diversity argument is it persuasive if it's to be persuasive it has to meet one very powerful objection that we've heard voiced here by Ted by Bri unless you're a utilitarian you believe that individual rights can't be violated and so the question is is there an individual right that is violated is Cheryl hopwood's right violated if she is used so to speak denied admission for the sake of the common good in the social mission that the University of Texas law school has defined for itself does she have a right don't we deserve to be considered according to our excellences our achievements our accomplishments our hard work isn't that the right at stake now we've already heard an answer to that argument no she doesn't have a right nobody deserves to be admitted notice how this gets us back to the issue of Dessert versus entitlement they're arguing there is no individual right that Hopwood has she doesn't deserve to be admitted according to any particular set of criteria that she believes to be important including criteria that have only to do with her efforts and achievements why not I think implicit in this argument is some something like rs's rejection of moral desert as the basis of distributive justice yes once Harvard defines its Mission and Designs its admission policy in the light of its Mission people are entitled who who fit those criteria they are entitled to be admitted but according to this argument no one deserves that Harvard College Define its Mission and design its admission criteria in the first place in a way that prizes the qualities they happen to have in abundance whether those qualities are test scores or grades or the ability to play the piano or to be a good middle linebacker or to come from Iowa or to come from a certain minority group so you see how this debate about affirmative action especially the diversity argument takes us back to the question of rights which in turn takes us back to the question of whether moral dessert is or is not the basis for distributive justice think about that over the weekend and we'll continue this discussion next [Music] time suppose we're Distributing flutes who should get the best one what's Aristotle's answer anyone his answer is the best flutes should go to the best flute players because that's what flutes are for when we ended last time we were considering Arguments for and against affirmative action counting RAC is a factor in Admissions and in the course of the discussion three arguments emerged three Arguments for affirmative action one of them was the idea that race and ethnic background should count as a way of correcting for the true meaning of test scores and grades getting a more accurate measure of the academic potential those scores those numbers represent second was what we call the compensatory argument the idea of writing past wrongs past Injustice and the third was the diversity argument and when Sherl Hopwood in the 1990s challenged the University of Texas law school school's affirmative action program in the federal courts the University of Texas made another version of the diversity argument saying that the broader social purpose the social mission of the University of Texas law school is to produce leaders in the legal community in the political Community among judges lawyers legislators and therefore it's important that we leaders who reflect the background and the experience and the ethnic and the racial composition of the State of Texas it's important for serving our wider social mission that was the University of Texas law school's argument then we considered an objection to the diversity argument which after all is an argument in the the name of the social Mission the common good we saw that RS does not simply believe that arguments of the common good or the general welfare should Prevail if individual rights must be violated in the course of promoting the common good you remember that was the question the challenge to the diversity rationale that we were considering when we finished last time and we began to discuss the question well what right might be at stake maybe the right to be considered according to factors within one's control maybe this is the argument that Cheryl Hopwood implicitly was making she can't help the fact that she's white why should her chance at getting into law school depend on a factor she can't control and then Hannah who was advancing an argument last time said Harvard has the right to Define its Mission any way it wants to it's a private institution and it's only once Harvard defines its mission that we can identify the qualities that count so no rights are being violated now what about that argument what I would like to do is to hear objections to that reply and then see whether others have an answer yes and tell us your name da da right you spoke up last time how do you answer that argument well I think there was two things there one of them was that a private institution could Define its Mission however it wants but then that doesn't make however it defines it right like I could Define my personal mission as I want to collect all the money in the world but does that make it even a good Mission so you can't like you can't say that just because a uh college is a private institution it could just Define it whatever it wants we still have to think about whether the way it's defining it is right and in the case of affirmative action a lot of people have said that since there's a lot of other factors involved we could why not race like if we already know that the system let's I want to stick with your first point here's DA's objection can a college or university Define its social purpose any way it wants to and then Define admissions criteria accordingly what about the University of Texas law school not today but in the 1950s then there was another Supreme Court casee against the admissions policy of the University of Texas law school because it was segregated it only admitted whites and when the case went to court back in the 50s the University of Texas law school also invoked its Mission our mission as a law school is to educate lawyers for the Texas bar for Texas law firms and no Texas law firm hires African-Americans so to fulfill our mission we only admit whites or consider Harvard in the 1930s when it had anti-jewish quotas president L president of Harvard in the 1930s said that he had nothing personally against Jews but he invoked the mission the social purpose of Harvard he said which is not only to train intellectuals part of the mission of Harvard he said is to train stock Brokers for Wall Street presidents and senators and there are very few Jews who go into those professions now here's the challenge is there a principal distinction between the invocation of the social purpose of the college or university today in the diversity rationale and the invocation of the social purpose or mission of the University by Texas in the 1950s or Harvard in the 1930s is there a difference in principle what's the reply Hannah well I think that the principle that's different here is um basically the distinction between inclusion versus exclusion I think that it's morally wrong of the university to say we're going to exclude you on the basis of your religion or your race that's Denial on the basis of arbitrary factors what Harvard is trying to do today with its diversity initiatives is to include groups that were excluded in the past good let's see if stay there let see if someone would like to reply go ahead as actually this was kind of in support of Hannah um rather than a reply but I was going to say another principal difference can be based on malice being the Jus or the motivation I guess for the historical segregation act so it's saying that we're not going to let blacks or Jews in because they're worse as people or as a group good so the element of malice isn't present and what's your name Stevie Stevie says that in the uh in the historic segregationist racist anti-semitic quotas or prohibitions there was built into them a certain kind of malice a certain kind of judgment that African-Americans or Jews were somehow less worthy than everybody else whereas present day affirmative action programs don't involve or imply any such judgment what it amounts to saying is so long as a policy just uses people in a way as valuable to the social purpose of the institution it's okay provided it doesn't judge them maliciously As Stevie might add as intrinsically less Worthy I'd like to raise a question doesn't that concede that all of us when we compete for positions or for seats in colleges and universities in a way are being used not judged but used in a way that has nothing to do with moral desert remember we got into this whole discussion of affirmative action when we were trying to figure out whether distributive justice should be tied to moral desert or not and we were launched on that question by RS and his denial his rejection of the idea the distributive justice whether it's positions or places in the class or income and wealth is a is a matter of moral desert suppose that were the moral basis of Harvard's admissions policy what letters would they have to write to people they rejected or accepted for that matter wouldn't they have to write something like this dear unsuccessful applicant we regret to inform you that your application for admission has been rejected it's not your fault that when you came along Society happened not to need the qualities you had to offer those admitted instead of you are not themselves deserving of a place nor worthy of praise for the factors that led to their admission we are in any case only using them and you as instruments of a wider social purpose better luck next time what was the letter you actually got when you were admitted perhaps it should have read something like this dear successful applicant we are pleased to inform you that your application for admission has been accepted it turns out lucky for you that you have the traits the that Society needs at the moment so we propose to exploit your assets for society's Advantage you are to be congratulated not in the sense that you deserve credit for having the qualities that led to your admission but only in the sense that the winner of a lottery is to be congratulated and if you choose to accept our offer you will ultimately be entitled to the benefits that attach to being used in this way we look forward to seeing you in the fall now there is something a little odd morally odd if it's true that those letters do reflect the theory the philosophy underlying the policy so here's the question they POS and it's a question that takes us back to a big issue in in political philosophy is it possible and is it desirable to detach questions of distributive justice from questions of moral desert and questions of virtue in many ways this is an issue that separates modern political philosophy from ancient political thought what's at stake in the question of whether we can put dessert moral desert aside it seemed when we were reading RWS that the incentive the reason he had for detaching distributive justice from moral dessert was an egalitarian one that if we set dessert to one side there's greater scope for the exercise of egalitarian considerations the veil of ignorance the two principles the difference principle helping the least well off redistribution and all that but what's interesting is if you look at a range of thinkers we've been considering there does seem to be a reason they want to detach Justice from dessert that goes well beyond any concern for equality libertarian rights oriented theorists of the kind we've been studying as well as egalitarian rights oriented theorists including RS and for that matter also including Kant all agree despite their disagreements over distributive justice and the welfare state and all of that they all agree that Justice is not a matter of rewarding or honoring virtue or or moral desert now why do they all think that it can't just be for egalitarian reasons not all of them are egalitarians this gets us to the big philosophical question we have to try to sort out somehow they think tying Justice to moral Merit or virtue is going to lead away from freedom from respect for persons as free beings well in order to see what they consider to be at stake and in order to assess their shared assumption we need to turn to a thinker to a philosopher who disagrees with them who explicitly ties Justice to honor honoring virtue and Merit and moral desert and that thinker is Aristotle now in many ways Aristotle's idea of justice is intuitively very powerful in some ways it's strange I want to bring out both its power its plausibility and its strangeness so that we can see what's at stake in this whole debate about Justice and whether it's tied to Desert and virtue so what is Aristotle's answered the question about Justice for Aristotle Justice is a matter of giving people what they deserve giving people their due it's a matter of figuring out the proper fit between persons with their virtues and their appropriate social roles well what does this picture of Justice look like and how does it differ from the conception that seems to be shared among libertarian and egalitarian rights oriented theorists alike Justice means giving each person his or her due giving people what they deserve but what is a person's due what are the relevant grounds of Merit or dessert Aristotle says that depends on the sort of things being distributed Justice involves two factors things and the persons to whom the things are assigned in general we say Aristotle writes that persons who are equal should have equal things assigned to them but here there arises a hard question equals in what respect Aristotle says that depends on the sort of thing we're Distributing suppose we're Distributing flutes what is the relevant Merit or basis of dessert for flutes who should get the best ones what's Aristotle's answer any one the best the best flute players right those who are best in the relevant sense the best flute players is it just to discriminate in allocating flutes yes all Justice involves discrimination Aristotle says what matters is that the Discrimination be according to the relevant Excellence according to the virtue appropriate to having flutes he says it would be unjust to discriminate on some other basis in giving out the flutes say wealth just giving the best flutes to the people who can pay the highest price or nobility of birth just giving flutes to Aristocrats or physical Beauty giving the best flutes to the most handsome or chance having a lottery Aristotle says birth and Beauty may be greater Goods than the ability to play the flute and those who possess them may surpass the flute player more in these qualities than he surpasses them in his flute playing but the fact remains that he is the person who ought to get the best flute it's a strange idea this comparison by the way that I mean could you say am I more handsome than she is a good lacrosse player it's a strange kind of comparison but putting that aside Aristotle says we're not looking for the best overall whatever that might mean we're looking for the best musician now why this is important to see why should the best flutes go to the best flute players well why do you think anybody what best music they'll produce the best music well and everybody will enjoy it more that's not Aristotle's answer Aristotle is not a utilitarian he's not just saying that way there will be better music and everyone will enjoy it everyone will be better off his answer is the best best flutes should go to the best flute players because that's what flutes are for to be played well the purpose of flute playing the purpose is to produce excellent music and those who can best perfect that purpose ought properly to have the best ones now it may also be true as a welcome side effect that everyone will enjoy listening to that music so that answer is true enough as far as it goes but it's important to see that Aristotle's reason is not a utilitarian reason it's a reason that looks here's where you might think it's a little bit strange it looks to the purpose the point the goal of flute playing another way of describing this looking to the goal to determine what the just allocation the Greek for goal or end was tilos so Aristotle says you have to consider the point the end the goal the tilos of the thing in this case of flute playing and that's how you define a just allocation a just discrimination so this idea of reasoning from the goal from the tilos is called theological reasoning theological moral reasoning and that's Aristotle's way reasoning from the goal from the end now this may seem as I said a strange idea that we're supposed to reason from the purpose but it is does have a certain intuitive plausibility consider the allocation let's say at Harvard of the best tennis courts or squash courts how should they be allocated who should have priority in playing on the on the best courts well you might say those who can best afford them set up a fee system charge money for them Aristotle would say no you might say well Harvard Big Shots the most influential people at Harvard who would they be the senior faculty should have priority in playing on the best tennis courts no Aristotle would reject that some scientists may be a greater scientist than some varsity tennis player is a tennis player but still the tennis player is the one who should have priority for the best playing on the best tennis court there is a certain intuitive plausibility to this idea now one of the things that makes it strange is that in Aristotle's world in the ancient world it wasn't only social practices that were governed in Aristotle's view by theological reasoning and Theological explanation all of nature was understood to be a meaningful order and and what it meant to understand nature to grasp nature to find our place within nature was to inquire into and read out the purposes or the teoss of Nature and with the Advent of modern science it's been difficult to think of the world that way and so it makes it harder perhaps to think of Justice in a teleological way but there is a certain naturalness to thinking about even the natural world as teleologically ordered as a purpose of whole in fact children have to be educated out of this way of looking at the world I realized this when my kids were very young and I was reading them a book Winnie the Pooh and Winnie the Pooh gives you a great idea of how there is a certain natural childlike way of looking at the world in a theological way you you may remember a story of Winnie the Pooh walking in the forest one day he came to a place in the forest and from the top of a tree there came a loud buzzing noise winie the Pooh sat at the foot of the tree put his head between his paws and began to think here's what he said to himself that buzzing noise means something you don't get a buzzing noise like that just buzzing in buzzing without it's meaning something if there's a buzzing noise somebody's making a buzzing noise and the only reason for making a buzzing noise that I know of is because you're a bee then he thought for another long time and said and the only reason for being a bee that I know of is making honey and then he got up and he said and the only reason for making honey is so I can eat it so he began to climb the tree this is an example of theological reasoning it isn't it isn't so implausible after all now we grow up and we're talked out of this way way of thinking about the world but here's the question even if theological explanations don't fit with modern science even if we've outgrown them in understanding nature isn't there something still intuitively and morally plausible even powerful about Aristotle's idea that the only way to think about Justice is to reason from the purpose the goal the tilos of the social practice and isn't that precisely what we were doing when we were disagreeing about affirmative action you could almost recast that disagreement as as one about what the proper appropriate purpose or end of a university education consists in reasoning from the purpose or from the hos or from the end Aristotle says that's indispensable to thinking about Justice is he right think about that question as you turn to Aristotle's [Applause] politics don't miss the chance to interact online with other viewers of Justice join the conversation take a pop quiz watch lectures you've missed and learn a lot more visit visit justiceharvard.org it's the right thing to do [Music] [Music] [Music] [Music] funding for this program is provided by additional funding provided by [Music]"}], "Justice: What's The Right Thing To Do? Episode 10: \"THE GOOD CITIZEN\"": [{"content": "[Music] funding for this program is provided by additional funding provided [Music] by we turn to Aristotle after examining theories modern theories of justice that Tred to detach considerations of justice and rights from questions of moral desert and virtue Aristotle disagrees with Kant and r Aristotle argues that Justice is a matter of giving people what they deserve and the central idea of Aristotle's theory of justice is that in reasoning about Justice and rights we have unavoidably to reason about the purpose or the end or the Kos of social practices and institutions yes Justice requires giving equal things to equal persons but the question immediately arises in any debate about Justice equal in what respect and Aristotle says we need to fill in the answer to that question by looking to the characteristic end or the essential nature or the purpose of the thing we're Distributing and so we discussed Aristotle's example of flutes who should get the best flutes and Aristotle's answer was the best flute players the best flute player should get the best flute because that's a way of honoring the Excellence of flute playing it's a way of rewarding the virtue of the great flute player what's interesting though and this is what we're going to explore today is that it's not quite so easy to dispense with teleological reasoning when we're thinking about social institutions and political practices in general it's hard to do without teleology when we're thinking about ethics Justice and moral argument at least that's Aristotle's claim and I would like to bring out the force in Aristotle's Claim by considering two examples one is an example that Aristotle spends quite a bit of time discussing the case of politics how should political offices and honors how should political rule be distributed the second example is a contemporary debate about golf and whether the professional golfers association should be required to allow Casey Martin a golfer with a disability to ride in a golf cart both cases bring out a further feature of Aristotle's chological way of thinking about Justice and that is that when we attend to the Tios or the purpose sometimes we disagree and argue about what the purpose of a social practice really consists in and when we have those disagreements part of what's at stake in those disagreements is not just who will get what not just a Distributive question but also an honorific question what qualities what excellences of persons will be honored debates about purpose and tilos are often simultaneously debates about honor now let's see how that works in the case of Aristotle's account of politics when we discuss distributive justice these days we're mainly concerned with the distribution of income and wealth and opportunity Aristotle took distributive justice to be mainly not about income and wealth but about offices and honors who should have the right to rule who should be a citizen how should political Authority be distributed those were his questions how did he go about answering those questions well in line with his teleological account of Justice Aristotle argues that to know how political Authority should be distributed we have first to inquire into the purpose the point the tilos of politics so what is politics about and how does this help us decide who should rule well for Aristotle the answer to that question is politics is a about forming character forming good character it's about cultivating the virtue of citizens it's about the good life the end of the state the end of the political Community he tells us in book three of the politics is Not Mere life it's not economic exchange only it's not security only it's realizing the good life that's what politics is for according to Aristotle now you might worry about this you might say well maybe this shows us why those modern theorists of justice and of politics are right because remember for Kant and for RS the point of politics is not to shape the moral character of citizens it's not to make us good it's to respect our freedom to choose our Goods our values our ends consistent with a similar Liberty for others Aristotle disagrees any polus which is truly so called and is not merely one in name must devote itself to the end of encouraging goodness otherwise political Association sinks into a mere Alliance law becomes aere near Covenant a guarantor of men's rights against one another instead of being as it should be a way of life such as will make the members of apus good and just that's Aristotle's view apus is not an association for residents on a common site or for the sake of preventing Mutual Injustice and easing exchange Aristotle writes the end and purpose of aplus is the good life and the institutions of social life are means to that end now if that's the purpose of politics of the polus then Aristotle says we can derive from that the principles of distributive justice the principles that tell us who should have the greatest say who should have the greatest measure of political Authority and what's his answer to that question well those who contribute the most to an assoc iation of this character namely an association that aims at the good should have a greater share in political Rule and in the honors of the pulus and the reason is they are in a position to contribute most to what political Community is essentially about well so you can see the link that he draws between the principle of distribution for citizenship and political Authority and the purpose of politics but why you'll quickly ask why does he claim that political life participation in politics is somehow essential to living a good life why isn't it possible for people to live perfectly good lives decent lives moral lives when without participating in politics well he gives two answers to that question he gives a partial answer a preliminary answer in book one of the politics where he tells us that only by living in a polus and participating in politics do we fully realize our nature as human beings human being things are by Nature meant to live in a polus why it's only in political life that we can actually exercise our distinctly human capacity for language which Aristotle understands has this capacity to deliberate about right and wrong the just and the unjust and so Aristotle writes in book one of the politics that the polist the political Community exists by nature and is prior to the individual not prior in time but prior in its purpose human beings are not self-sufficient living by themselves outside of political Community a man who is isolated who's unable to share in the benefits of political Association or who has no need to share because he's already self-sufficient such a person must be either a beast or a God so we only fully realize our nature we only fully unfold our human capacities when we exercise our faculty of language which means when we deliberate with our fellow citizens about Good and Evil right and wrong just and the unjust but why can we only exercise our capacity for language in political Community you might ask Aristotle gives a second part A Fuller part of his answer in the nicomaki ethics an excerpt of which we have among the readings and there he explains that political deliberation living the life of a citizen ruling and being ruled in turn sharing and Rule all of this is necessary to Virtue Aristotle defines happiness not as maximizing the balance of pleasure over pain but as an activity an activity of the soul in accordance with virtue and he says that every student of politics must study the soul because shaping the soul is one of the objects of legislation in a good city but why is it necessary to live in a good city in order to live a virtuous life why can't we just learn good moral principles at home or in a philosophy class or from a book live according to those principles those rules those precepts and leave it at that Aristotle says virtue isn't acquired that way virtue is only something we can acquire by practicing by exercising the ver virtues it's the kind of thing we can only learn by doing it doesn't come from book learning in this respect it's like flute playing you couldn't learn how to play a musical instrument well just by reading a book about it you have to practice and you have to listen to other accomplished flute players there are other practices and skills of this type cooking there are cookbooks but no great chef ever learns how to cook by reading a cookbook only it's the kind of thing you only learn by doing joke telling is probably another example of this kind no great comedian learns to be a comedian just by reading a book on the principles of Comedy it wouldn't work now why not what do joke telling and cooking and playing a musical instrument have in common such that we can't learn them just by grasping a precept or a rule that we might learn from a book or a lecture what they have in common is that they are all concerned with getting the hang of it but also what is it we get the hang of when we learn how to cook or play a musical instrument or tell jokes well Discerning particulars particular features of a situation and no rule no precept could tell the comedian or the Cook or the great musician how to get in the habit of the practice of Discerning the particular features of a situation Aristotle says virtue is that way too now how does this connect to politics the only way we can acquire the virtue vires that constitute the good life is to exercise the virtues to have certain habits inculcated in us and then to engage in the practice of deliberating with citizens about the nature of the good that's what politics is ultimately about the acquisition of civic virtue of this capacity to deliberate among equals that's something we couldn't get living a life alone outside of politics and so that's why in order to realize our nature we have to engage in politics and that's why those who are greatest in civic virtue like Pericles are the ones who properly have the greatest measure of offices and honors so the argument about the distribution of offices and honors has this teleological character but also an honorific Dimension because part of the point of politics is to honor people like Pericles it isn't just that Pericles should have the dominant say because he has the best judgment and that will lead to the best outcomes to the best consequences for the citizens that's true and that's important but a further reason people like Pericles should have the greatest measure of offices and honors and political Authority and sway in the polist is that part of the point of politics is to single out and honor those who possess the relevant virtue in this case civic virtue Civic Excellence practical wisdom to the fullest extent that's the honorific dimension bound up with Aristotle's account of politics here's an example that shows the link in a contemporary controversy the link to which Aristotle draws our attention between arguments about Justice and rights on the one hand and figuring out the TS or the purpose of a social practice on the other not only that the case of Casey Martin and his golf cart also brings out the link between debates about what the purpose of a social practice or a game is on the one hand and the question of what qualities should be honored on the other the link between thology and honor based principles of distributive justice who was Casey Martin well Casey Martin is a very good golfer able to compete at the highest levels of golf but for one thing he has a rare circulatory problem in his leg that makes it very difficult for him to walk not only difficult but dangerous and so he asked the PGA which governs the pro tour in golf to be able to use a golf cart when he competed in professional tournaments PGA said no and he sued under the American for Disabilities Act he sued in a case that went all the way to the United States Supreme Court the question the Supreme Court had to answer was does Casey Martin have a right that the PGA provide him allow him to use the golf cart on the tour or not how many here think that from a moral point of view Casey Martin should have a right to use a golf cart and how many think that he should not have a right to a golf cart in the tournaments so the majority are sympathetic to Casey Martin's right though a substantial minority disagree let's first hear from those of you who would rule against Casey Martin why would you not say that the PGA must give him a golf cart yes since the Inception of golf because it's been part of the sport it's now intrinsically part of golf walking the course and thus because it's intrinsic to golf I'd argue that not being able to walk the course it's just not being able to perform an aspect of the sport which is necessary to performing at a professional level good stay there for a minute what's your name Tommy are you a golfer by the way Tom uh not so much but yeah a little bit are there any are there any golfers here I mean real golfers thank you Professor that was no no I'm just taking your word for it who are there is there someone here on the golf team yes tell us your name and uh tell us what you think uh my name is Michael and I usually take a cart so probably the probably the wrong person to ask is that why you're hand went up slowly when I yes all right um but Tom is saying let's uh Tom said a minute ago that at least at the professional level walking the course is essential to the game do you agree I would yes you do then why do you take a card and you call yourself a golfer no I'm no no no no I'm kidding I'm kidding what what do you say what do you say to that I I when I have walked of course it it does add tremendously to the to the game makes it a lot harder it really does yeah all right let's let's hear Michael and toms stay there let's hear from people who uh say that he should have a right to a golf cart why who's prepared to defend that position yes well I think the PGA should definitely be required um to give him a golf cart because they argue in the decision that it's not just a matter of he's not not experiencing fatigue for him he's still walking about a mile the cart can't go everywhere with him um and in that mile he still experiencing more fatigue and pain than a healthy player would so it's not as if you're removing the disadvantage what's your name Reva Reva what do you say to Tom's point that walking the course is essential to the game would be as if um a disabled player could play in the NBA uh but not have to uh run up and down the court well I think there are two um two responses to that first I don't think it's it's essential to the game um because most golfers who play particularly recreationally don't play with a Cartal like Michael and uh and on several of the tours um you can play with a cart on the Senior PGA Tour on the Nike tour um in a lot of the colleges events and those events are just as competitive and just as high level as the PGA Tour so really it's just a matter of selective reasoning if you argue that it's um an important part of the sport but even if it is he still does have to walk he still plays golf standing up it's not as if he's playing golf from a wheelchair all right uh who who else go ahead I think the whole point of a competition is that it calls out the best you know from the second best or from the third best and when we're talking about the national level we're talking about you know the highest of the highest and I think the what they're um arguing about here is the purpose of competition and I I think in the sake of competition you can't change the rules so the purpose of the competition includes walking that's an essential you agree with Tom and what's your name David the Supreme Court ruled that the PGA did have to accommodate Casey Martin and they did it on grounds that Reva mentioned that walking isn't really part of an essential part of the game they cited testimony saying that walking the court consumes no more calories than you get eating a Big Mac that's what walking is in Gulf according to the majority Scalia was in descent Jus as Calia agreed with David he said there is no purpose it's not and it's certainly not for to try to figure out the essential purpose of golf golf like any game is strictly for amusement and if there's a group that wants to have one version of the game they can have that version of the game and the market can decide whether people are amused and like and show up for that and watch the television broadcasts scalia's descent was an anti-aristotelian descent because notice two things things about the argument first we're thrust into a discussion about what the essential nature or purpose or tilos of golf really is Does it include walking and here's something I think is rumbling beneath the surface of this debate whether walking partly determines whether golf is really an athletic competition after all the ball sits still you have to put it in a hole it's is it more like basketall baseball and football Golf and athletic competition or is it more like Billiards the ball sits still there too you can be out of shape and succeed it involves skill but not athletic skill could it be that those professional golfers who excel at golf have a stake in golf being honored and recognized as an athletic event not just a game of skill like Billiards and if that's what's at stake then we have a debate about the purpose theological Dimension and also a debate about honor what virtues really does the game of golf honor and recognize two questions to which Aristotle directs our attention we'll continue on this case next time [Music] what what's strange and seem paradoxical to me about Aristotle's Viewpoint is that if you walk like a pirate and you talk like a pirate you shouldn't be an investment banker because that's that's not what you inherently supposed to do if you have a peg leg and an eye patch and a disgruntled disposition you know uh you should be on a pirate ship on the high seas um so he doesn't his uh some would say some would say the the distinction between the two vocations is not as clear as you [Applause] suggest when we ended last time we were talking about whether Casey Martin has a right to ride in a golf cart in the PGA tournaments and it's worth remembering how we got into this debate and what's at stake for an understanding of political philosophy remember we were looking at Aristotle's theory of justice and one way of describing his approach to Justice we've called it te logical te logical because he says to allocate rights we first have to figure out the purpose or the end of the social practice in question another way of describing Aristotle's account of justice is that Justice is for him a matter of fit it's a matter of fitting persons with their virtues and excellences to the appropriate roles now I want to finish our discussion about Casey Martin and his claim for a golf cart and then go back to one more consequential application in Aristotle namely the question of slavery what do you think about Casey Martin's request should there be an accommodation or not given the nature of the game and of the tournament and its purposes isn't it discrimination if he's not provided the golf cart as an accommodation say some others reply no if he got a cart it would be unfair to the other golfers because they exert themselves become winded fatigued walking the course that's where we left it what about the fairness argument okay Jenny my question was why doesn't the PGA just make the option of a cart available to all golfers um from our readings I learned that there are many golf tournaments other than the PGA where using a carts is not prohibited and for something like the seniors tournament it's even allowed and encouraged so why doesn't the PGA just do that let everybody use a card or give everyone the option of using a card and let them pick so the traditionalist can say well I still choose to walk the course but I do that knowing that I will be more tired at the end than the people who took the cart good all right so what about Jenny's solution for the sake of fairness don't give Casey Martin an advantage if indeed there is an advantage to riding in a cart let everyone who wants to use a card is everyone happy with that solution does it put to rest this whole dilemma who has an answer for Jenny yes as was brought up last time if you do that you you kind of ruin some the spirit of golf as a lot of people like to see it if you let everybody take a cart um even though gives everybody the same playing field now it sort of makes golf less of an athletic game like you pointed out last class it's just like um if someone decides to go into another Sport and they want an advantage like if you have swimming and then you say okay he wants flippers so why don't we just allow everyone to have flippers during swimming and what would that do to the Olympic swimming competition if people were free to use Jenny and here we better let Jenny reply to this D says it would sort of spoil the spirit of the athletic competition as if in Olympic swimming you let anyone who wanted to swim with flippers all right Jenny what do you say to Da it would spoil the spirit of it you're also ruining the spirit of golf by not letting people who are really passionate about the game and very good at it compete simply because of an aspect of golf which is not the main point of golf is you use this Club to make strokes and hit it into a hole I'm sorry I'm not a golfer but that's basically my the gist of the game from what I see it and I was reading the PJ versus Casey Martin decision and that was one of the um senten that they said is because walking the course is not an inherent part of golf only swinging the club is good so Jenny replies to Da well it isn't really essential anyhow to the course so we're back to the purpose I mean I'm sure there are like wheelchair basketball there are certain um different competitions that can be made for people who may only be able to use their arms right yes Michael what do you think and you just said that there's stuff like wheelchair wheelchair basketball where if you can't play basketball there's another option I think there's other options than the PGA Tour but the PGA Tour is like the it's it's the best it's the Pinnacle and you have to have certain requirements fulfill to to perform all right Michael you want to say to Casey Martin you go there is a such a thing as the Special Olympics for those who are disabled go play in the golf golfing version of the spectral Olympics that's what you would say Michael yeah I think that walking is part of the sport of golf and Casey Martin you know he can't if he can't walk the course I don't think he should be able to play on the PGA all right good thank you very much for that exchange what comes out of this Exchange that goes back to Aristotle's theory of Justice well one thing is the question is walking an essential part of golf and the Very fact that deciding whether there is a right for Casey Martin that the PGA must respect seems to depend as Aristotle suggests it must on debating and resolving the question is walking essential to the game of golf that's one moral of the story but there's a second moral to the story from an Aristotelian point of view what's at stake here this is the second Aristotelian stake in this debate is honor Casey Martin wants the accommodation so that he can compete for for the honor of winning the best tournaments now why is it that the professional golfers the great golfers testified in this case Jack Nicholas Tom Kite in the readings against letting him use a cart and they I suspect would be equally vehement Jenny in opposing your suggestion of letting everyone ride a cart and this goes back in a way to do Point how to put this gently professional golfers are sensitive about whether their sport is really a sport because if everyone rode around in a cart or could then it would become clear or clearer depending on your point of view that golf is not really an athletic competition but rather a game a game of skill but not a sport and so not only the question of debating the purpose theological feature but also from the standpoint of viewing debates about the purpose of golf what's essential to golf those debates Aristotle suggests inevitably are also debates about the allocation of Honor because part of the purpose of golf is not just to amuse Spectators scul is wrong about that from Aristotle's point of view it's not just to provide entertainment it's not just to make people happy it's not an a mere Amusement it's honoring it's rewarding it's recognizing a certain kind of athletic Excellence at least those who have achieved the highest honors have a powerful stake in maintaining that view now some of you took the position the Scalia position this is an incredibly difficult and silly question Scalia said what is the essential nature of golf it's not the kind of thing that the United States Supreme Court is equipped to decide or should decide that's Scalia but he only says that because he takes a very strong and as it happens anti-aristotelian position on what a game is it is the very nature of a game to have no object no point except Amusement says Scalia that is what distinguishes games he says from productive activity you can just imagine what kind of sports fans CIA must be and so he says it's impossible to say that any of a game's arbitrary rules is essential and then he quotes Mark Twain's disparaging remark about golf he says many consider walking to be the central feature of golf hence Mark Twain's classic criticism of the sport a good walk spoiled but Scalia misses an important feature of games and the arguments about rights and fairness that arise from games when he casts Games sports athletic competitions as solely for the sake of amusement as solely a utilitarian activity but an arist helan view of sport says no it's not just about Amusement Real Sports real athletic events are also about appreciation not just amusement and people who follow Sports and care about sports and play sports know this which is another way of saying there's a difference between a sport and a mere spectacle and the difference is that a sport is a practice that calls forth and honors and prizes certain excellences certain virtues and the people who appreciate those virtues are the true fans the informed fans and for them watching the sport is Not Mere Amusement but that means that it's always possible to make sense of a debate about what feature of a sport is essential to it we can make sense of these arguments never mind the question whether the court should decide the PGA in its own internal deliberations can make sense of that debate which is why they cared very much about their view insisting on their view that walking and exertion and fatigue are essential not peripheral parts of sport well this is all to illustrate the theological and the honorific feature of debates about rights which Aristotle says we need to take account of in thinking about Justice now I want to begin for us to consider whether Aristotle's theory of justice is right or wrong whether it's persuasive or unpersuasive I want to get your thoughts about that but I want to anti anticipate one obvious and important objection if Justice is about fit fitting persons to roles matching virtues to the appropriate honors and recognition if that's what Justice is does it leave room for freedom and this is one of the main objections to Aristotle's chological account of Justice if certain roles social roles are fitting or appropriate to me where does that leave my right to choose my social roles my life purposes for myself what room does tileology leave for freedom and in fact may remember RS rejects teleological accounts of Justice because he says that theological theories of Justice threaten the equal basic rights of citizens so let's let's begin to examine whether Aristotle is right and in particular whether it's his theological way of thinking about Justice is at odds with freedom now one obvious reason to worry is Aristotle's defense of slavery he defends slavery which existed as an institution in the Athens of his day well what is his defensive slavery two things two conditions have to be met for slavery to be just first it has to be necessary and Aristotle says at least in our society slavery is necessary why is it necessary if there are to be citizens who are freed from manual and IAL and household chores to go to the assembly to deliberate about politics there have to be some who look after those menial tasks the mere necessities of life he says unless you could invent in some science fiction a technological fix then there are going to be those who have to do the hard and difficult and menial labor if there are to be citizens deliberating about the good and realizing their nature so slavery is necessary for the life of the polus for there to be open to Citizens the life of deliberation of argument of practical wisdom but there's a further condition that has to be met slavery has not only to be necessary for the community as a whole to function but it also has to be the case remember the Criterion of fit it also has to be the case that there are some people for whom being a slave is the just or the fitting or the appropriate condition now Aristotle agrees that by his own standards both of those conditions must be met must be true if slavery is to be just and then in a deplorable passage he says well it is true that there are some people who are fit by Nature who are cut out to be slaves these are people who differ from Ordinary People in the same way that the body differs from the soul these are people who are meant to be ruled and for them their nature is best realized if they're slaves they can recognize reason in others but they can't partake of it they can't exercise it and somehow we can know this now Aristotle must have known that there was something dodgy something strained about this claim because he quickly acknowledges that those who disagree may have a point and what those who disagree point out is that there are a lot of people in Athens who are slaves not not because they were born to be slaves or fit to be slaves but because they were captured they were losers in a war and so Aristotle admits that as practiced in ancient Athens slavery didn't necessarily line up with who actually is fit or Born To Be A Slave because some actual slaves just were slaves by bad luck by being captured in a war and on Aristotle's own account even if it's necessary to have slavery for the sake of this of citizenship it's unjust if people who aren't properly slaves are cast in that role there is a misfit Aristotle recognizes that slavery for those who aren't fit for the task is a kind of coercion the reason slavery is wrong is not because it's coerced coercion is an indicator that it's wrong because it's not natural if you have to coer someone into a role that's a pretty good indication that they don't belong there that that role isn't fitting for them and Aristotle recognized this so all of this is to say the example of slavery Aristotle's defense of it doesn't show that there's anything wrong in principle with te logical argument with the idea of justice as fit between persons and roles because it's perfectly possible within Aristotle's own terms to explain what's wrong with this application this practical application that he made of his theory I want to turn to the larger challenge to Aristotle in the name of freedom but before I do that I want to see what people think of Aristotle's account of justice as fit his theological way a reasoning about Justice and the honorific dimension of Rights and of distributive justice that emerged in our discussion of flutes and politics and golf questions of clarification about Aristotle or objections to his overall account yes my objection to Aristotle is that he wants to match uh a person to a role and you know if if you walk like a pirate and you talk like a pirate you know you should be a pirate and and that is what is right um and so what what's strange and seem paradoxical to me about Aristotle's Viewpoint is that if you walk like a pirate and you talk like a pirate you shouldn't be an investment banker because that's that's not what you inherently supposed to do if you have a peg leg and an eye patch and a disgruntled disposition you know uh you should be on a pirate ship on the high seas um so he doesn't his uh some would say some would say the the distin between the two vocations is not as clear as you suggest all right but that's good I take the point yes go ahead it just seems to ignore individual rights so I might be the perfect janitor in the whole world and I can do that job the most efficiently out of anybody that exists right now but I might not want to do that I might want to do any other number of Pursuits and it seems to say that that isn't really good option for me all right and what's your name Mary Kate good all right let's uh let's take a couple more yes I think that the golf cart exchange sort of brought up what I see is my main objection to this theological um mode of reasoning I mean Michael I think that was your name right believes that walking is an inherent part of Gulf myself I believe that walking is not an inherent part of gulf and I feel that no matter how long we debate this particular point of contention we're never going to reach an accord the theological framework of reasoning I believe doesn't really allow us to come to any sort of agreement all right and what's your name Patrick Patrick all right let me try to address this set of objections to Aristotle let me start with Patrick's it's an important objection we had to debate about whether walking is essential to golf and even in so seemingly trivial or at least contained a case as that we couldn't agree how can we possibly hope to agree when the stakes are higher and when we're debating the fundamental purposes or ends a political community and so if we can't agree on what the ends or the goods of our shared public life consist in how can we base Justice and rights on some notion of what the end or the purpose or the good consists in that's an important objection so much so that much modern political Theory takes that worry about disagreement over the good as its starting point and concludes that Justice and rights and constitutions should not be based on any particular conception of the good or the purposes of political life but should instead provide a framework of rights that leaves people free to choose their conceptions of the good their own conceptions of the purposes of life now Mary Kate said what if a person is very well suited to having a certain role like the role of being a janitor but want something else wants to reach higher wants to choose another way of life so that goes back to this question about Freedom if we take our bearing as persons from roles that are said to fit our nature shouldn't it at least be up to us to decide what those roles are in fact shouldn't it be up to us to Define what roles are suitable to us and that's going to take us back to the confrontation between Aristotle on the one hand and K and rs on the other Kant and rs think Patrick has a point they say precisely because people disagree in pluralist societies about the nature of the good life we shouldn't try to base Justice on any particular answer to that question so they reject heliology they reject the idea of tying Justice to some conception of the good what's at stake in the debate about Tey say Rian and Conan liberals is this if you tie Justice to a particular conception of the good if you see Justice as a matter of fit between a person and his or her roles you don't leave room for freedom and to be free is to be independent of any any particular roles or Traditions or conventions that may be handed down by my parents or my Society so in order to decide as between these two broad Traditions whether Aristotle is right or whether Kant and rs are right we need to investigate whether the right is prior to the good question one and we need to investigate what it means to be a free person a free moral agent does freedom require that I stand toward my roles my ends and my purposes as an agent of choice or as someone trying to discover what my nature really is two big questions and we'll take them up next [Music] time don't miss the chance to interact online with other viewers of Justice join the conversation take a pop quiz watch lectures you've missed and learn a lot more visit Justice harvard.org it's the right thing to do [Music] [Music] [Music] [Music] funding for this program is provided by additional funding provided by [Music]"}], "Justice: What's The Right Thing To Do? Episode 11: \"THE CLAIMS OF COMMUNITY\"": [{"content": "funding for this program is provided by additional funding provided by today we turn to Kant's reply to Aristotle Kant thinks that Aristotle just made a mistake it's one thing Kant says to support a fair framework of Rights within which people can pursue their own conceptions of the good life it's something else and something that runs the risk of coercion to base law or principles of justice on any particular conception of the good life you remember Aristotle says in order to investigate the ideal Constitution we have first to figure out the best way to live Kant would reject that idea he says that constitutions and laws and rights should not embody or affirm or promote any particular way of life that's at odds with freedom for Aristotle the whole point of law the purpose of the polis is to shape character to cultivate the virtue of citizens to inculcate Civic excellence to make possible a good way of life that's what he tells us in the politics for Kant on the other hand the purpose of law the point of a constitution is not to inculcate or to promote virtue its to set up a fair framework of Rights within which citizens may be free to pursue their own conceptions of the good for themselves so we see the difference in their theories of justice we see the difference in their account of law or the role of a constitution the point of politics and underlying these differences are two different accounts of what it means to be a free person for Aristotle we're free insofar as we have the capacity to realize our potential that leads us to the question of fit fit between persons and the roles that are appropriate to them figuring out what I'm cut out for that's what it means to lead a free life to live up to my potential Kant rejects that idea and instead substitutes his famously demanding notion of freedom as the capacity to act autonomously freedom means acting according to a law I give myself freedom as autonomy part of the the appeal part of the moral force of the view of content of Rawls consists in the conception of the person as a free and independent self capable of choosing his or her own ends the image of the self is free and independent offers up if you think about it a powerful liberating vision because what it says is that as free moral persons we are not bound by any ties of history or of tradition or of inherited status that we haven't chosen for ourselves and so we're unbound by any moral ties prior to our choosing them and that means that means that we are free and independent sovereign selves we're the authors of the only obligations that constrain us the communitarian critics of Kantian and Rawls in liberalism acknowledge that there is something powerful and inspiring in that account of freedom free independent choosing self but they argue it misses something it misses a whole dimension of moral life and even political life it can't make sense of our moral experience because it can't account for certain moral and political obligations that we commonly recognize and even prize and these include obligations of membership loyalty solidarity and other moral ties that may claim us for reasons that we can't trace to an act of consent alasdair macintyre gives an account but he calls a narrative conception of the cell it's a different account of the self human beings are essentially storytelling creatures MacIntyre argues that means I can only answer the question what am i to do if I can answer the prior question of what story or stories do I find myself apart that's what he means by the narrative conception of the self what does this have to do with the idea of community in belonging MacIntyre says this once you accept this narrative aspect of moral reflection you will notice that we can never seek for the good or exercise the virtues only as individuals we all approach our circumstance as bearers of particular social identities I am someone's son or daughter a citizen of this or that city I belong to this plan that tried this nation hence MacIntyre argues what is good for me has to be the good for someone who inhabits these roles I inherit from the past of my family my city my tribe my nation a variety of debts inheritances expectations and obligations these constitute the given of my life my morale starting point this is in part what gives my life its moral particularity that's the narrative conception of the self and it's a conception that sees the self as claimed or encumbered at least to some extent by the history the tradition the communities of which it's a part we can't make sense of our lives not only is a psychological matter but also as a moral matter in thinking what we ought to do without attending to these features about us now MacIntyre recognizes that this narrative account this picture of the encumbered self puts his account at odds with contemporary liberalism and individualism from the standpoint of individualism I am what I myself choose to be I'm a biologically be my father's son but I can't be held responsible for what he did unless I choose to assume such responsibility I can't be held responsible for what my country does or has done unless I choose to assume such responsibility but MacIntyre says this reflects a certain kind of moral shallowness even blindness it's a blindness at odds with the full measure of responsibility which sometimes he says involves collective responsibility or responsibilities that may float from historic memories and he gives some examples such individualism it's expressed by those contemporary Americans who deny any responsibility for the effects of slavery upon black Americans saying I never owned any slaves or the young German who believes that having been born after 1945 means that what Nazis did to Jews has no moral relevance to his relationship to his Jewish contemporaries McIntyre says all of these attitudes of historical amnesia amount to a kind of moral abdication once you see that who we are and what it means to sort out our obligations can't be separated shouldn't be separated from the life histories that define us the contrast he says when the narrative account is clear for the story of my life is always embedded in the story of those communities from which I derived my identity I am born with the past and to try to cut myself off from that past is to deform my present relationships so there you have in McIntyre a strong statement of the idea that the self can't be detached shouldn't be detached from its particular ties of membership history story narrative now I want to get your reactions to the communitarian critique of the individualist or the voluntarist the unencumbered self but let's make it concrete so that you can react to more than just the theory of it by looking at the two different accounts of moral and political obligation that arise depending on which of these conceptions of the person one accepts on the liberal conception moral and political obligations arise in one of two ways there are natural duties that we owe human beings as such duties of respect for persons Quay persons these obligations are universal then as Rawls points out there are also voluntary obligations obligations that we owe to particular others insofar as we have agreed whether through a promise or a deal or a contract now the issue between the liberal and communitarian accounts of the self is there another category of obligation or not the communitarian says there is there is a third category that might be called obligations of solidarity or loyalty or membership the communitarian argues that construing all obligations as either natural duties or voluntary obligations fails to capture obligations of membership or solidarity loyalties whose moral force consists partly in the fact that living by them is inseparable from understanding ourselves as the particular persons we are what would be some examples and then I want to see how you would react to them examples of obligations of membership that are particular but don't necessarily flowed from consent but rather from membership narrative community one situation the most common examples are ones to do with the family the relation between parents and children for example suppose there were two children drowning you could save only one of them one was your child the other was a stranger's child would you have an obligation to flip a coin or would there be something morally obtuse if you didn't rush to save your child now you may say well parents have agreed to have their children so take the other case the case of children's obligation for their parents now we don't choose our parents we don't even choose to have parents there is that asymmetry and yet considered two aging parents one of them yours the other strangers doesn't it make moral sense to think that you have a greater obligation to look after your aged parent then to flip a coin or to help the strangers now is this traceable to consent not likely or take a couple of political examples during World War two French Resistance pilots flew bombing raids over occupied France one day one of the pilots received his targets and noticed that the village he was being asked to bomb was his home village he refused not disputing that it was as necessary as the target he bombed yesterday he refused on the ground that he couldn't bring himself it would be a special moral crime for him to bomb his people even in a cause that he supported the cause of liberating France now do we admire that if we do the communitarian argues it's because we do recognize obligations of solidarity take another example some years ago there was a famine in Ethiopia hundreds of thousands of people were starving the Israeli government organized an airlift to rescue Ethiopian Jews they didn't have the capacity to rescue everyone in Ethiopia they rescued several hundred Ethiopian Jews now what's your moral assessment is that a kind of morally troubling partiality a kind of prejudice or as the Israeli government thought is there a special obligation of solidarity that this airlift properly responded to well that takes us to the broader question of patriotism what morally speaking is to be said for patriotism there are two towns named Franklin one is Franklin Texas and the other is just across the Rio Grande River Franklin Mexico what is the moral significance of national boundaries why is it or is it the case that we as Americans have a greater responsibility for the health and the education in the welfare and public provision for people who live in Franklin Texas then equally needy people just across the river living in Franklin Mexico according to the communitarian account membership does matter and the reason patriotism is at least potentially a virtue is that it is an expression of the obligations of citizenship how many are sympathetic to the idea that there is this third category of obligation the obligation obligations of solidarity or membership how many are sympathetic to that idea and how many are critical of that idea how many think all obligations can be accounted for in the first two ways all right let's hear from the critics of the communitarian idea first yes my biggest concern with the idea of having obligations because you're a member of something or because of solidarity is that it seems that if you accept those obligations as being sort of morally binding then there's a greater occurrence of overlapping obligations a greater occurrence of good versus good and I don't know if this sort of framework allows us to choose between them good in much your name so you worried that if we recognize obligations of membership or solidarity since we inhabit different communities their claims might conflict and what would we do if we have competing obligations yes well one solution is that we could view ourselves as ultimately members of the human community and that then within that we have all these smaller spheres of that you know I am an American or I am a student at Harvard and so the most important community to be to be obligated to is the community of human beings and then from there you can sort of evaluate which other ones are most important to you so the most univer and what's your name Nikola so Nikola you say the most universal community we inhabit the community of humankind always takes precedence yes Patrick are you satisfied No why not um it seems rather arbitrary that we should choose the universal obligation over the more specific obligation I might also say that I should be obligated first to the most specific of my obligations for instance take my family as a small unit of solidarity perhaps I should be first obligated to that unit and then perhaps to the unit of my town and then my country and then the human race good thank you let's I want to hear from another critic of the communitarian view we have the objection well what if Goods collide who objects to the whole idea of it who sees patriotism is just a kind of prejudice that ideally we should overcome yes patriotism reflects a community membership that's a like a given I think the problem is that whereas some memberships are natural narratives the narrative of citizenship is a constructed one and I think a false one because as the river is just a historical accident it makes no sense that because the lottery of birth threw me into the United States as opposed to Mexico that that's the membership that I should be a part of good and what's your name Elizabeth Elizabeth who has a reply yes I think in in general uh we have to ask where do our moral obligations arise from anyway and I think basically there'd be two places from which they could arise one would be kin another one would be reciprocity and isn't the closer you are associated to other people there's a natural reciprocity there in terms of having interactions with those people you interact the neighbors on your street with the other people in your country through economic arrangement I don't know and you don't know those people in Franklin Texas any more than you know the people in Franklin Mexico do you presumably you're naturally more connected with the people in your own country in terms of interaction and trade than you are with people in other countries good who else I'll go ahead yeah I think that a lot of the basis for a patriotism can be compared to like school spirit or even house fear that we see here where freshmen are sorted into houses and then within a day they have developed some sort of attachment or a pride associated with that house and so I think that we can probably draw a distinction between a moral obligation for communitarian beliefs and sort of just a sentimental emotional attachment good way to say you stay there what's your name Rina what about go back to my example about the obligation of the childhood the parent would you say the same thing there it's just a maybe or may not be a sentimental toy but it has no moral weight well I mean I'm not entirely certain that accident in the initial stage is something that will preclude like moral obligations later and so you know just because we were randomly sorted into a house or just because we don't choose who our parents are what country born into doesn't necessarily mean that we won't like develop an obligation based on some type of benefit I guess just sort of see your obligation to your parent that's greater than two agent parents around the world is only because and insofar as you're repaying a benefit that your parent gave you when you were growing up yeah I mean I would say that if you look at cases of adoption where you know you have a biological parent somewhere else that you don't interact with and then you have a parent you know who adopted you most people would say that if you had to pick between them in the case of you know aging parents that your obligation would lie more with the person who raised you and who had exchanges with you meaningfully may ask you one more question about the parent sure do you think that a person with a bad parent owes them less I don't know because I've never had a bad parent I think that's a good place to end thank you we'll continue with this next time thank you if I were working on an egg problem set for example and I saw that my roommate was cheating that might be a bad thing for hoot for him to do but I wouldn't turn him in you would not turn him in I wouldn't turn him in and I think that I would argue that's the right thing to do because of my obligation um you know you don't have a duty to tell the truth to report someone who cheated today I'd like to take I'd like to consider the strongest objections to the idea that there are obligations of solidarity or membership then I want to see if those objections can be met successfully one objection emerged in the discussion last time Patrick said well if obligations flow from community membership and identity we inhabit multiple communities doesn't that mean that our obligations will sometimes conflict so that's one possible objection and then Rina said these examples meant to bring out the moral force of solidarity and membership examples about parents and children about the French resistance fighter asked to bomb his own village in drawing back about the airlift by Israel of Ethiopian Jews these examples they may be intuitively evocative Rina said but really they're pointing to matters of emotion matters of sentiment not true moral obligations and then there were a number of objections not necessarily to patriotism as such but to patriotism understood as an obligation of solidarity and membership beyond consent this objection allowed that there can be obligations to the communities we inhabit including obligations of patriotism but this objection argued that all of the obligations of patriotism or of community or membership are actually based on liberal ideas and perfectly compatible with them consent either implicit or explicit or reciprocity Julia rod how for example on the website said that liberalism can endorse patriotism as a voluntary moral obligation patriotism and familial love both fall under this category because after all Julia points out the content framework allows people free rein to choose to express virtues such as these if they want to so you don't need the idea of a non-voluntary particular moral obligation to capture the moral force of community values where's Julia okay so did I summarize that that fairly there is action Julia actually is in line with what Rawls says about this very topic you weren't aware of that you came up with it on your own that's pretty good Rawls says when he's discussing political obligation he says it's one thing if someone runs for office or enlist in the military they're making a voluntary choice but Rawls says there is I believe no political obligation strictly speaking for citizens generally because it's not clear what is the requisite binding action and who has performed it so Rawls acknowledges that for ordinary citizens there is no political obligation except insofar as some particular citizen willingly through an act of consent undertakes or chooses such an obligation that's in line with Julia's point it's related to another objection that people have raised which is it's perfectly possible to recognize particular obligations to one's family or to ins country provided honoring those obligations doesn't require you to violate any of the natural duties or requirements of Universal respect for persons quite persons so that's consistent with the idea that we can choose if we want to to express a loyalty to our country or to our people or to our family provided we don't do any injustice within the framework acknowledging the priority that is of the universal duties the one objection that I didn't mention is the view of those who say that obligations of membership really are a kind of collective selfishness why should we honor them isn't it just a kind of prejudice so what I'd like to do perhaps if those of you who have agreed who wrote and who have agreed to defect to press these objections perhaps if you could gather down all together will form a team as we did once before and we'll see if you can respond to those who want to defend patriotism conceived as a communal obligation now there were a number of people who argued in defense of patriotism as the communitarian view conceives it so let me go down now and join the critics the critics of communitarianism if there's a microphone that we could use somewhere okay thanks Kate who as the critics of patriotism communal patriotism gather their forces here Patrick if you want to you can join as well arena and others who have spoken or addressed this question are free to join in but I would like to hear now from those of you who defend patriotism and defend it as a moral obligation that can't be translated back into purely consent-based terms can't be translated into liberal terms where's Ajay Kumar Ajay everybody seems to know you all right let's hear from Ajay you said I in the same way I feel I owe more to my family than to the general community I owe more to my country than to humanity in general because my country holds a great stake in my identity it is not prejudice for me to love my country unless it is prejudice for me to love my parents more than somebody else's so Ajay what would you say to this group stand up I think that there's some fundamental moral obligation that comes from a communitarian responsibility to people and groups that form your identity I mean even like I'll give the example that you know there are a lot of things about our government right now that I'm not in favor of but part of my identity is that America value is a free society where we can object to certain things and I think that's an expression of patriotism as well and I'd go back to the parent example or even in Harvard I think you know I owe more to my roommates because they make up my Tenny than I do to the Harvard community as a whole and I think that applies to our country because there are certain things that growing up here yes we can't choose if we can't choose our parents things like that but it makes up part of our identity okay who would like to take that on hike yeah both the obligation to others simply by virtue of being in their their um being influenced by them I'm a German citizen and if I had been born 80 years earlier than I would have been a citizen of Nazi Germany and for some reason I just don't think that I would have to feel obligated towards Germany um because I benefited from action of Nazis I mean I guess my response to that would be you have hundreds of thousands of protestors the United States right now who hold up signs that say pieces patriotic and I'm sure there are people in this room who don't agree with that I personally do and I would say that they're strongly objecting to basically everything the Bush administration is doing right now but they still consider themselves loving their country because they're furthering the cause of what they see is best for the country and I tend to agree with that as a patriotic movement well but how is that then how do you still favor your country how is that so patriotic I mean isn't that more sentimental attachment where's the obligation they're not to bring this back to John Locke but I'd like to bring this back to John Locke so I mean in his conception of um you know when people joined society there's there's still some outlet like if you if you're not satisfied with your society you know you do have a means of exit even though we had a lot of concerns about how you're born and it's not very feasible he still provides that option if we want to say that your obligation to society is a moral one that means that prior to knowing exactly what that society is going to be like or what your position is going to be in that society that means that you have a binding obligation to like a complete unknown body that that could be you know completely foreign to all of your personal beliefs or you know what you would hope to be do you think that that kind of communal obligation or patriotism means writing the community a a blank moral check basically yeah like I think that we can you know I think it's reasonable to say that as you grow and as you develop within that community that you acquire some type of obligation based on reciprocity but to say that you have a moral obligation I think requires a stronger justification well anyone else like to address that I guess we could say that you you could argue that you're morally obliged to society by the fact that there is this reciprocity I think it's the idea that you know we participate in society we pay our taxes we vote this is why we could say that we owe something to society but beyond that I don't think there's anything inherent in the fact that we are members of the society itself that we owe and anything I think is insofar as we as the society gives something gives us protection safety security then we owe the society something but nothing beyond what we give this assign who wants to take that on Rahul I don't think we I don't think we give the community a blank moral check in that sense I think we only give it a blank moral check when we abdicate our sense of civic responsibility and when we say that the debate doesn't matter because patriotism is a vice I think that patriotism is important because it gives us a sense of community a sense of common civic virtue that we can engage in the issues even if you don't agree with the way the government is acting you can still love your country and hate the way it's acting and I think because out of that love of country you can debate with other people and have respect for their views but still engaging in debate if you just say that you know page 2 is a vice you drop out of that debate and you and you see the ground to people who are more fundamentalist who have a stronger view and who make worse the community it instead we should engage the other members of the community on that same moral ground well now this what we hear from a Jain Rahul is a very pluralistic argumentative critically minded patriotism whereas what we hear from ICANN the critics of patriotism here is the worry that to take patriotic obligation in a communal way seriously involves a kind of loyalty that doesn't let us just pick and choose among the beliefs or actions or or practices of our country what more what's left of loyalty if all we're talking about Ajay and Rahul if all we're talking about is loyalty to principles of justice that may happen to be embodied in our community or not as the case may be in if not then we can can reject its course I don't know I've sort of given a reply I got carried away I'm sorry who liked go ahead Julia yeah I think that patriotism you needed to find what that is it sounds like you know you would normally think that we are given a more weak definition here page which is amongst us but it almost sounds like your definition is merely to have some sort of civic involvement in debating within your society and I think that that kind of undermines maybe the moral some of the moral worth of patriotism as a virtue as well I think if you can consent to a stronger form of patriotism if you want that's a stronger I guess more obligation and even what you're suggesting what we really need to sharpen the issue is an example from the defenders of communitarianism of a case where loyalty can actually compete with and possibly outweigh universal principles of justice isn't that what that's the test they really need to meet isn't it all right so that's the test you need to meet or any any among you who would like to defend obligations of membership or solidarity independent of ones that happen to embody just principles who has an example of a kind of loyalty that can and should compete with universal moral claims respect for persons go ahead yeah if I were working on an egg problem set for example and I saw that my roommate was cheating that might be a bad thing for her for him to do but I wouldn't turn him in you would not turn him in I wouldn't turn him in and I think that I would argue that's the right thing to do because of my obligation him you know it may be wrong but that's what I would do and you know I think that's what most people would do as well right that's now there's a fair test he's not slipping out by saying he's invoking in the name of community some universal principles of justice what's your name stay there what's your name it's dan dan so what do people think about Dan's case that's a harder case for the ethic of loyalty isn't it but a truer test how I agree with Dan so loyalty Dan loyalty has its part a sense it how many disagree with Stan Peggy oh well I agree with Dan but I agree that it's a choice that we make but it's not necessarily right or wrong I mean I'm agreeing that I'm going to make the wrong choice because I'm gonna choose my roommate but I also recognize that choice isn't morally right so you're still translating even Dan's loyalty you're saying well that's a matter of choice but what's the right thing to do the most people put up their hand saying Dan would be right to stand by his roommate and not turn him in let's go ahead also I think as a roommate you have insider information and that might not be something you want to use that's might be something unfair to hold against you know you're spending that much time with the roommate obviously you're going to learn things about about him and I don't think it's fair to reveal that to a greater community but it's loyalty Wojtek you you agree with Dan that yes oil T is a ethic at stake here absolutely you don't have a duty to tell the truth to report someone who cheated not if you're if you've been advantaged into getting that kind of information before our critics of patriotism leave I want to give you another version a more public example of what will I guess we should call it Dan's dilemma Dan's dilemma of loyalty and I want to get the reaction of people to this this came up a few years ago in Massachusetts does anyone know who this man is Billy Bulger that's right who is Billy Bulger he was president the Massachusetts state Senate for many one of the most powerful politicians in Massachusetts and then he became president of the University of Massachusetts now Billy Bulger did you hear the story about him that bears on Dan's dilemma Billy Bulger has a brother named Whitey Bulger and this is Whitey Bulger his brother whitey is on the FBI's most wanted list alleged to be a notorious gang leader in Boston responsible for many murders and now a fugitive from justice but when when the US Attorney they called Billy Bulger then the president of the University of Massachusetts before the grand jury and wanted information on the whereabouts of his brother this fugitive and he refused to give it us attorney said just to be clear mr. Bulger you feel more loyalty to your brother than to the people of the Commonwealth of Massachusetts and here's what Billy Bulger said I never thought of it that way but I do have a loyalty to my brother I care about him I hope that I'm never helpful to anyone against him I don't have an obligation to help anyone catch my brother and you would agree how many would agree with the position of Billy Bulger let me give one other example and then we'll let the critics reply the critics of loyalty as we'll describe it here's a an even more fateful example from a figure in American history robert e lee now robert e lee on the eve of the civil war was an officer of the Union Army he opposed secession in fact regarded as treason when war loomed Lincoln offered Lee to be the commanding general of the Union Army and Lee refused and he described in a letter to his sons why he refused with all my devotion to the Union he wrote I have not been able to make up my mind to raise my hand against my relatives my children my home by which he meant Virginia the Union is dissolved I shall return to my native state and share the miseries of my people save in her defense I will draw my sword no more here's a real test Dan for your principle of loyalty because here is the cause of the war against not only to save the Union but against slavery and Lee is going to fight for Virginia even though he doesn't share the desire of the southern states to secede now the communitarian would say there is something admirable in that whether or not the decision was ultimately right there's something admirable and the communitarian would say we can't even make sense rina we can't make sense of Lee's dilemma as a moral dilemma and thus we acknowledge that the claim of loyalty arising from his sense of narrative of who he is is immoral not just sentimental emotional tug all right who would like to respond to Dan's loyalty to Billy Bulger's loyalty or to robert e lee's loyalty to virginia what do you say it Julia okay well I think that this is these are some classic examples of you know multiple spheres of influence and that you have conflicting communities that your family in your country I think that's one reason why the idea of choice in your obligation is so important because how else can you resolve this you have if you're morally obligated and there's no way out of this need for loyalty to both communities your tract there's nothing you can do you have to make a choice and I think that being able to choose based on other characteristics than merely you know the arbitrary fact that you're a member of this community is important otherwise it's left to use randomness well Julia the issue isn't whether these whether Dan makes a choice or Billy Bulger or robert e lee of course they make a choice the question is on what grounds on what principle should they choose the communitarian doesn't deny that there's a choice to be made the question is which choice on what grounds and should loyalty as such way Andre now you want to alright go ahead what do you say why one of the things we've noticed in the three examples is that the people who've all chosen the most immediate community of which they're part the more local one and I think there's something to be said for that it's not just random they're there I mean there doesn't seem to be conflict because they know which one is more important and it's their family over the ak10 class their state over their country and their family over the Commonwealth of Massachusetts so I think that's the answer to which is more important you think that the local the more particular is always the weightier morally Andre well I mean there seems to be a trend in the three cases I would agree with that I think and I think most of us would agree that your family takes precedence over the United States perhaps which is why you go with dan dan loyalty to the roommate over act 10 and the truth yeah exactly I would because I mean I need truth-telling not the truth of act n yes all right so we understand yes but on the same example in terms of family you had cases in the civil war where brother was pitted against brother on both sides of the war where they chose country instead of family so I think the exact same more shows that different people have different means of making these choices and that there is no one set of values or one set of morality that communitarians can stick to and personally I think that's the biggest problem with communitarians that we don't have one set of standard moral obligations and tell me your name Samantha so Samantha you agree with Patrick Patrick's point the other day that there may be if we allow obligations to be defined by community identification or membership they may conflict there may they may overlap they may compete and there is no clear principled Andre says there's a clear principle the most particular the other day in Nicola who is sitting over here whereas Nicola said the most universal you're saying Samantha the scale of the community as such can't be the decisive moral factor so there has to be some other moral judgement all right let's first let's let our defence our critics of communal patriotism let's express our appreciation and thank them for their having stood up and responded to these arguments to find the issue let's turn to the implications for justice of the positions that we've heard discussed here one of the worries underlying these multiple objections to the idea of loyalty or membership as having independent moral weight is that it seems to argue that there is no way of finding principles of justice that are detached from conceptions of the good life as they may be lived in any particular community suppose the communitarian argument is right suppose the priority of the right over the good can't be sustained suppose instead the justice and rights unavoidably are bound up with conceptions of the good does that mean that justice is simply a creature of convention of the values that happen to prevail in any given community at any given time one of the writings we have among the communitarian critics is by Michael Walzer he draws the implications of justice this way justice is relative to social meanings a given society is just if it's substantive life has lived in a certain way in a way that is faithful to the shared understandings of the members so Walters account seems to bear out the worry that if we can't find independent principles of justice independent that is from conceptions of the good that prevail in any given community that we're simply left with justice being a matter of fidelity or faithfulness to the shared understandings or values or conventions that prevail in any given society at any given time but is that an adequate way of thinking about justice well let's take a look at a short clip from the documentary eyes on the prize goes back in the 1950s in the south here are some situated American Southerners who believe in the tradition in the shared understandings of segregation listen to the arguments they make about loyalty and tradition and see if they don't make you uneasy about tying arguments about justice to the shared understandings or traditions that prevail in any given society at the moment it's from eclipse this land is composed of two different cultures of white culture and a colored culture and I live close to them all my life but I'm told now that we've mistreated them and that we must change and these changes are coming faster than I expected and I'm required to make decisions on a basis of a new way of thinking and it's difficult difficult for me it's difficult for all of them well there you have it narrative selves situated selves invoking tradition doesn't that show us that justice can't be tied to the shared understandings of goods that prevail in any given community at any given time or is there a way of rescuing that claim from this example think about that question and we'll return to it next time don't miss the chance to interact online with other viewers of justice join the conversation take a pop quiz watch lectures you've missed and learn a lot more visit justiceharvard.org it's the right thing to do funding for this program is provided by additional funding provided by"}], "Justice: What's The Right Thing To Do? Episode 12: \"DEBATING SAME-SEX MARRIAGE\"": [{"content": "[Music] funding for this program is provided by additional funding provided by [Music] [Music] we ended last time talking about the narrative conception of the self we were testing the narrative conception of the self and the idea of obligations of solidarity or membership that did not flow from consent that claimed us for reasons unrelated to a contract or an agreement or a choice we may have made and we were debating among ourselves whether there are any obligations of this kind or whether all apparent obligations of solidarity and membership can be translated into consent or reciprocity or a universal Duty that we owe persons quate persons and then there were those who defended the idea of loyalty and of patriotism so the idea of loyalty and of solidarity and of membership gathered a certain kind of intuitive moral force in our discussion and then as we concluded we considered what seems to be a pretty powerful counter example to that idea namely the film of those Southern segregationists in the 1950s and they talked all about their Traditions their history the way in which their identities were bound up with their life history do you remember that and what flowed from that history from that narrative sense of identity for those Southern segregationists they said we have to defend our way of life is this a fatal or a decisive objection to the idea of the narrative conception of the self that's the question we were left with what I would like to do today is to advance an argument and see what you make of it and let me tell you what that argument is I would like to defend the narrative conception of the person as against the voluntarist conception I would like to defend the idea that there are obligations of solidarity or membership then I want to suggest that there being such obligations lends Force to the idea when we turn to justice that arguments about Justice can't be detached cannot be detached after all from questions of the good but I want to distinguish two different ways in which Justice might be tied to the good and argue for one of them now the voluntarist conception of the person of c and rolls we saw was powerful and liberating a further appeal is its Universal aspiration the idea of treating persons as persons without prejudice without discrimination and I think that's what led some among us to argue that okay maybe there are obligations of membership but they are always subordinate they must always be subordinate to the duties that we have to human beings as such the universal duties but is that right if our encompassing loyalty should always take precedence over more particular ones then the distinction between friends and strangers should ideally be overcome our special concern for the welfare of friends would be a kind of prejudice a measure of our distance from Universal human concern but if you look closely at that idea what kind of a moral Universe what kind of moral imagination would that lead you to the enlightenment philosopher montue gives perhaps the most powerful and I think the ultimately the most honest account of where this Relentless universalizing tendency leads the moral imagination here's how monu put it he said a truly virtuous man would come to the aid of the most distant stranger as quickly as to his own friend and then he adds listen to this if men were perfectly virtuous they wouldn't have friends but it's difficult to imagine a world in which persons were so virtuous that they had no friends only a universal disposition to friendliness the problem isn't simply that such a world would be difficult to bring about that it's unrealistic the deeper problem is that such a world would be difficult to recognize as a human world the love of humanity is a noble sentiment but most of the time we live our lives by smaller solidarities this may reflect certain limits to the bounds of moral sympathy but more important it reflects the fact that we learn to love Humanity not in general but through its particular Expressions so these are some considerations they're not knockdown arguments but moral philosophy can't offer knockdown arguments but considerations of the kind that we've been discussing and arguing about all along well suppose that's right one way of assessing whether this picture of the person and of obligation is right is to see what are its consequences for justice and here's where it confronts a serious problem and here we go back to our Southern segregationists they felt the weight of History do we admire their character these segregationists who wanted to preserve their way of life are we committed to saying if we accept the idea of solidarity membership are we committed to saying that Justice is tied to the good in the sense that Justice means whatever a particular Community or tradition says it means including those Southern segregationists here it's important to distinguish two different ways in which Justice can be tied to the good one is a relativist way that's the way that says to think about rights to think about Justice look to the values that happen to Prevail in any given community at any given time don't judge them by some outside standard but instead conceive Justice as a matter of being faithful to the shared understandings of a particular tradition but there's a problem with this way of tying Justice to The Good the problem is that it makes Justice wholly conventional a product of circumstance and this deprives justice of its critical character but there is a second way in which Justice can be tied with or bound up with the good on this second non relativist way of linking Justice with conceptions of the good principles of Justice depend for their justification not on the values that happen to Prevail at any given moment in a certain place but instead on the the moral Worth or the intrinsic good of the ends rights serve on this non- relativist view the case for recognizing a right depends on showing that it honors or advances some important human good this second way of tying Justice to the good is not strictly speaking communitarian if by communitarian you mean just giving over to to a particular Community the definition of justice now what I would like to suggest that of these two different ways of linking Justice to The Good the first is insufficient because the first leaves Justice the creature of convention it doesn't give us enough moral resources to respond to those Southern segregationists who invoked their way of life their Traditions their way of doing things but if Justice is bound up with the good in a non- relativist way there's a big challenge a big question to answer how can we reason about the good what about the fact that people hold different conceptions of the good different ideas about the purposes of key social institutions different ideas about what social goods and human goods are worthy of honor and recognition we live in a pluralist society people disagree about the good that's one of the incentive to try to find principles of justice and rights that don't depend on any particular ends or purposes or Goods so is there a way to reason about the good before addressing that question I want to address a slightly easier question is it necessary is it unavoidable when arguing about Justice to argue about the good and my answer to that question is yes it's unavoidable it's necessary so for the remainder of today I want to take up I want to try to advance that claim that reasoning about the good about purposes and ends is an unavoidable feature of arguing about Justice it's necessary let me see if I can establish that and for that I'd like for us to begin a discussion of same-sex marriage now same-sex marriage draws on implicates deeply contested and controversial ideas morally and religiously and so there's a powerful incentive to embrace a conception of Justice or of rights that doesn't require the society as a whole to pass judgment one way or another on those hotly contested moral and religious questions about the moral permissibility of homosexuality about the proper ends of marriage as a social institution so clearly if there's an incentive to resolve this question to Define people's rights in a way that doesn't require the society as a whole to sort out those moral and religious disputes that would be very attractive so what I would like to do now is to see using the same-sex marriage case whether it's possible to detach one's views about the moral permissibility of homosexuality and about the purpose the end of marriage to detach those questions from the question of whether the should recognize same-sex marriage or not so let's begin I would like to begin by hearing the arguments of those who believe that there should be no same-sex marriage but that the state should only recognize marriage between a man and a woman do I have volunteers I had two there were two people I asked people who had voiced their views already on the Justice blog Mark L and Ryan mcaffrey where where are you okay uh Mark and where's Ryan all right let's go first to Mark I have sort of a theological understanding of um the purpose of Sex and the purpose of marriage and I think that for people like myself who are a Christian and also a Catholic the purpose of sex is one for its procreative um usage two for a unifying purpose between a man and a woman within the within the institution of marriage you have a certain conception of the purpose or the tilos yeah of human sexuality which is bound up with procreation right as well as Union yeah and the essence of marriage the purpose of marriage as a social institution is to give expression to that tilos and to honor that purpose namely the procreative purpose of marriage is that a fair summary of your view yeah where is Ryan go ahead do you agree more or less with Mark's reasons yes I agree um uh I think that uh the ideal of marriage is involves procreation and it's fine that you know homosexuals would go off and um and and cohabitate with each other but that the government doesn't have responsibility to encourage that all right so the government should not encourage homosexual Behavior by conferring the recognition of marriage yeah it would be wrong to Outlaw it but encouraging it is not necessary who has a reply yes Hannah I'd just like to ask a question to Mark um let's say you got married to a woman you did not have sex with her before marriage and then when you became married it became evident that you were an infertile couple do you think that it should be illegal for you to engage in sex if you if children will not result from that act yeah I I think that it is moral and that's why I gave the the two-fold purpose so like a woman say I think older couples can get married someone a woman who's Beyond um who's already had menopause and who can't have a child because I think that sex has these it has purposes Beyond procreation I hate to be UNC but have you ever engaged in masturbation well all right yeah you don't you don't have to answer that you can yeah I think I I I all right just a minute no right make your make your I'd like to respond to that no I think wait look we've we've done pretty well over a whole semester and we're doing pretty well now dealing with questions that most people think can't even be discussed in a university setting and Hannah you've got you have a powerful Point make that point as a general argument rather than rather than as an interrogative but make the point what's the what's the principle that you're appealing what's the argument you have in mind all right well biblically put it in the third rather rather rather than in the second person make make the argument go ahead okay biblically masturbation or onanism is not permissible because it's um you know spilling your seed on the earth when it's not going to result in the birth of a child but what I'm saying is you know you're saying that sex you know there's something wrong with sex if it doesn't produce children or reinforce the marriage bond but then how can you say that there's something wrong that you know masturbation is permissible if masturbation obviously is not going to you know create a child yeah I think marriage is society's way to create this separate institution where they say this is what we hold as a virtue yes every day we fall short and people fall short in so many different other ways but I think that if you personally fall short in some moral sphere as we all do that doesn't take the right of you to argue you all right I want you you to stay there I want to bring in some other voices and we'll continue stay there if you would go ahead I think that the response to the masturb tell us my name is Steve Steve all right um the response to the masturbation issue is uh it's not something that's permissible I don't think anyone will argue that that homosexual sex is impermissible it's just that Society has no place in letting you marry yourself if masturbation is something that you do well all right Hannah [Applause] all right Steve has draw all right that's a good argument Steve has drawn our attention to the fact that there are two issues here one of them is the moral permissibility of various practices the other is the fit between certain practices whatever their moral permissibility with the honor or recognition that the state should Accord in allowing marriage so Steve has a pretty good okay counterargument what do you say to Steve um well I think that it's clear that human sexuality is something that is you know inherent in I believe most people and it's not something you can avoid and masturbation I mean yeah you can't marry yourself but I don't think that takes away from the fact that you know homosexuals are people too and I just I can't I can't understand why they wouldn't be able to marry each other if you want to marry yourself I mean I I don't know if you can legally do that that's fine but I don't wait wait wait wait wait now here we're deciding we here we're deliberating as if legislators what the law should be okay so you said Steve that's fine does that mean as a legislator you would vote for a law of marriage that would be so broad that it would let people marry themselves well I mean that that's really Beyond The Pale of like anything that would really happen but I don't think that but in principle yeah in principle yes yeah sure I mean if Steve wants to marry himself I'm not going to stop him I I think and you would confer State recognition on that solo marriage sure and while we're at it what about consensual polygamous marriages I I actually think that if the male and the female are like if the wives and the man and the husband or the husbands and the wife are consenting it should be permissible who else there I know there are a lot of people who yes okay down here stand up and tell us your name uh Victoria Victoria so we're talking about the theological reasoning here for marriage but I think the problem is that we're talking about it within the Catholic Viewpoint whereas the theological and the point to marriage for another religion or someone who's an atheist could be completely different and the government does doesn't have a right to impose the theological reasoning for cathol Catholicism on everyone in the state which is what my problem is with not allowing same-sex marriage because I mean your beliefs are your beliefs and that's fine but civil union is not marriage within the Catholic church and the state has a right to recognize a civil union between whoever it wants but does not have a right to impose the beliefs of a certain minority or majority or whoever it is based on a religion within our state all right Victoria good a question do you think the state should recognize same-sex marriage or just same-sex civil unions as something short of marriage well I think that the state doesn't have a right to recognize it as marriage within a church because that is not their place but whereas civil union I see civil union as essentially the same thing except not under a religion and the state has a right to recognize a civil union all right so Victoria's argument is that the state should not try to decide the question of what the teos of marriage is that's only something that religious communities can decide um who else um my point is I don't see why uh we feel like State should recognize marriages at all uh so I'm like one of these 7 people who voted State should not recognize any marriages because I believe it is like it is a union between a male and a female or two males or two females but there's no reason to like ask state to give permission to me to unite myself and some might say that like if State recognizes these marriages it will help children it will have a b binding effect but in reality I don't think it actually has a binding effect all right tell us your name cesan so Victorian sesan's comments differ from earlier parts of the conversation they say the state shouldn't be in the business of honoring or recognizing or affirming any particular tilos or purpose of marriage or of human sexuality and ceson is among those who says therefore maybe the state should get out of the business of recognizing marriage at all here's the question unless you adopt San's position no State recognition of any kind of marriage is it possible to choose between to decide the question of same-sex marriage without taking a stand on the moral and religious controversy over the propery Los of marriage thank you very much to all of you who have participated we'll pick this up next time you did a great job when we first came together some 13 weeks ago I tried to warn you that once the familiar turns strange once we begin to reflect on our circumstance it's never quite the same again I hope you have by now experienced at least a little of this unease because this is attension that animates critical reflection and political Improvement and maybe even the moral life as well we have two remaining questions to answer first is it necessary is it unavoidable to take up questions of the good life in thinking about Justice yes and is it possible to reason about Justice yes I think so let me try to develop those answers to those two questions now as a way of addressing those questions we began last time to discuss the question of same-sex marriage and we heard from those who argued against same-sex marriage on the ground that the purpose or tilos of marriage is at least in part procreation the bearing and raising of children and then there were those who defended same-sex marriage and they contested that account of the purpose or tilos of marriage arguing we don't require as a condition of heterosexual marriage that couples be able or willing to procreate we allow infertile couples to marry this is Hannah point in the exchange with Mark but then there was another position expressed at the end of our discussion by Victoria who argued we shouldn't try to decide this question we shouldn't at least at the level of the state at the level of law try to come to any agreement on those questions about the good because we live in a pluralist society where people have different moral and religious convictions and so we should try to make law and the framework of Rights neutral with respect to these competing moral and religious views now it's interesting that others some others who favor the idea of neutrality argued not in favor of restricting marriage to a man and a woman nor in favor of Permitting same-sex marriage they argued in the name of neutrality for a third possibility which is that government get out of the business of recognizing any kind of marriage that was the third possibility now Andrea meos had an interesting contribution to this debate she had a rejoiner to people who argue for neutrality where is Andrea all right Andrea would you be willing share with us the view if we can get you a microphone share share with us your view why do you think that it's a mistake for the state to try to be neutral on moral and even religious questions like same-sex marriage I don't know that it is possible because people's lives are completely embedded in how they how they view the world and um maybe I just agree with Aristotle that the role of of the government is helping people live in a sort of like having a collective understanding of what what is wrong and what is right is it possible and one could ask the same question of abortion that we've been asking of same-sex marriage do you think it's possible to decide whether abortion should be permitted or prohibited without taking a stand or making a judgment about the moral permissibility of abortion no I don't think it is and I think that's why it's such a controversy because people are so deeply committed to like their fundamental beliefs about whether a fetus is a life or if it isn't so it's if I believe that like a fetus is a living being and has rights and and has like fundamentally the right to live then it's very hard for me to say but I can put that aside and let you do what you want because that's like me saying well despite my beliefs I'm going to let you commit what to me is murder so and I mean that's just that's just all right and the analog the analogy in the same-sex marriage case is you said you're a defender of same-sex marriage yes but you only came to that view once you were persuaded on the underlying moral question right well I think particularly in the US so many people's um beliefs are driven by their religious beliefs and um like Mark the other day I'm Christian I'm Catholic and I had to decide for myself like on a lot of thought a lot of prayer a lot of conversations with other people that I disagreed with the Catholic standpoint that homosexuality itself is in a sin and once I came to that sort of conclusion in my personal relationship with God like I mean that sounds hokey right that's like oh religious but a lot of people are religious and that's where they draw their beliefs and their views from um that's when I could say yeah I'm I'm down with the state saying go samesex marriage because I'm okay with that and I I think that's morally okay good thank you now who would like to who would like to reply if you can perhaps hang on there for a moment who would like to reply to Andre's idea that in order to decide the question of same-sex marriage it's necessary to sort out the question about the moral status of homosexuality and figuring out the purpose the tilos the proper end of marriage who disagrees with Andrea on that point yes well uh I think you absolutely can separate your moral opinion and uh what you think the law should be for example I think abortion is unequivocally morally wrong but I do not believe that illegalizing abortion makes it go away I don't believe illegalizing abortion stops IT and therefore I am pro-choice and I do believe the woman should have the choice as a gives them more safety just as maybe morally I don't want to get married to a man but I'm not going to try to um you know um impede someone else's freedom to do what they wish to do in terms of uh the law Andrea whether the law makes something legal or illegal is it's implicitly um approving or disapproving something so if you say like by making abortion legal we're saying it's okay as a society collectively we're saying it's okay with us in our society to abort a fetus if we make it legal um if we make it illegal then we're saying collectively at a as a society it's not okay and that's why Society have tell tell us your name before my name is Daniel Daniel what are you saying are are we saying collectively that it's okay are we saying that collectively we don't want women who are going to have an abortion anyway to go to clinics on the side alleys and have it you know unsafe conditions all right bring it to the same-sex marriage case why don't you have to decide that which position you're in favor of same-sex marriage Daniel being legally permitted I think it absolutely should be legally permitted because it's not something telling me that I need to have I need to marry a man I I absolutely don't I don't see if two men are consenting adults and want to get married I don't see how I could even object to that all right there's no harm there there's no harm done either way even if it even if it is morally wrong according to me all right let let me um let me turn to the way the Massachusetts Court who made this Landmark ruling in the same-sex marriage case grappled with the very issue that Andrea and Dan have been uh discussing here thanks to both of you very much what did the court say this was in the Goodridge case which required the state of Massachusetts to extend marriage to same-sex couples the court started out well the court was conflicted if you read that opinion carefully the court was conflicted as between the two positions we've just been hearing defended by Andrea and by Dan the court begins and this is Chief Justice Margaret Marshall's opinion it begins with an attempt at liberal neutrality many people hold deep-seated religious moral and ethical convictions that marriage should be limited to the union of one man and one woman and that homosexual conduct is immoral many hold equally strong religious moral and ethical convictions that same-sex couples are entitled to be married that homosexual person should be treated no differently than their heterosexual neighbors this is the court neither view answers the question before us what is at stake is quote respect for individual autonomy and equality under law at stake is an individual freely choosing the person with whom to share an exclusive commitment in other words an issue is not the moral worth of the choice but the right of the individual to make it so this is the liberal neutral strand in the court opinion bantra strand the one that emphasizes autonomy Choice consent but the court seemed to realize that the liberal case the neutral case for recog izing same-sex marriage doesn't succeed doesn't get you all the way to that position because if it were only a matter of respect for individual autonomy if Government were truly neutral on the moral worth of voluntary Intimate Relationships then it should adopt a different policy which is to remove government and the state Al together from according recognition to certain associations certain kinds of unions rather than others if Government really must be neutral then the consistent position is what we here have been describing as the third position the one defended in the article by Michael Kinsley who argues for the abolition of marriage at least as a state function perhaps a better better term for this is the disestablishment of religion this is kinsley's proposal he points out that the reason for the opposition to same-sex marriage is that it would go beyond neutral Toleration and give same-sex marriage a government stamp of approval that's at the heart of the dispute in Aristotle's terms an issue here is the proper distribution of office and honors a matter of social recognition same-sex marriage can't be justified on the basis of liberal neutrality or non-discrimination or autonomy rights alone because the question at stake in the public debate is whether same-sex unions have moral worth whether they're worthy of honor and recognition and whether they fit the purpose of the social institution of marriage so Kinsley says you want to be neutral then let churches and other religious institutions offer marriage ceremonies let department stores and casinos get into the ACT if they want to this is Kinsley let couples celebrate their Union in any way they choose and consider themselves married whenever they want and if three people want to get married or if one person wants to marry himself or herself and someone else wants to conduct a ceremony for them and declare them married let them if you and your government aren't implicated what do you care this is Kinsley but this is not the position that the Supreme Judicial Court of Massachusetts wanted they didn't call for the abolition or for the disestablishment of marriage the court did not question government's role in conferring social recognition on some intimate associations rather than others to the contrary the court waxes eloquent about marriage as quote one of our community's most rewarding and cherished institutions and then it goes on to expand the definition of marriage to include partners of the same sex and in doing so it acknowledges that marriage is more than a matter of tolerating choices that individuals make it's also a matter of social recognition and honor as Justice Marshall wrote in a real sense there are three Partners to every civil marriage two willing spouses and an approving State marriage is at once a deeply personal commitment but also a highly public celebration of the ideals of mutuality companionship intimacy Fidelity and family this is the court now this is reaching well beyond liberal neutrality this is celebrating and affirming marriage as an honorific as a form of public recognition and therefore the court found that it couldn't avoid the debate about the teos of marriage Justice Marshall's opinion considers and rejects the notion that the primary purpose of marriage is procreation she points out that there's no requirement that applicants for a marriage licens who are heterosexuals ATT test to their ability or their intention to conceive children fertility is not a condition of marriage people who cannot stir from their deathbed May marry so she advances all kinds of arguments along the lines that we began last time about what the proper and the essential nature of the tilos of marriage is and she concludes not procreation but the exclusive and permanent commitment of the partners to one another is the essential point and purpose of marriage now nothing I've said about this court opinion is an argument for or against same-sex marriage but it is an argument against the claim that you can favor or oppose same-sex marriage while remaining neutral on the underlying moral and religious questions so all of this is to suggest that at least in some of the hotly contested debates about Justice and rights that we have in our society the attempt to be neutral the attempt to say it's just a matter of consent and choice and autonomy we take no stand that doesn't succeed even the court which wants to be neutral on these moral and Rel ious disputes finds that it can't what then about our second question if reasoning about the good is unavoidable in debates about Justice and rights is it possible if reasoning about the good means that you must have a single principle or rule or Maxim or Criterion for the good life that you simply plug in every time you have a disagreement about morality then the answer is no but having a single principle or rule is not the only way not the best way of reasoning either about the good life or about Justice think back think back to to the arguments that we've been having here about Justice and about rights and sometimes about the good life how have those arguments proceeded they've proceeded very much in the way that Aristotle suggests moving back and forth between our judgments about particulars particular cases events stories questions back and forth between our judgments about particular cases and more general principles that make sense of our reasons for the positions we take on the particular cases this dialectical way of doing moral reasoning goes back to the Ancients to Plato and Aristotle but it doesn't stop with them because there is a version of Socratic or dialectical moral reasoning that is defended with great clarity and force by John rolls in giving an account of his method of justifying a theory of Justice you remember it's not only the veil of ignorance and the principles that RS argues for it's also a method of moral reasoning reasoning about Justice that he calls reflective equilibrium what is the method of reflective equilibrium it's moving back and forth between our considered judgments about particular cases and the general principles we would articulate to make sense of those judgments and not just stopping there because we might be wrong in our initial intuitions not stopping there but then sometimes revising our particular judgments in the light of the principles once we work them out so sometimes we revise the principles sometimes we revise our judgments and intuitions in the particular cases the general point is this and here I quote RS a conception of Justice can't be deduced from self-evident premises its justification is a matter of the mutual support of many considerations of everything fitting together into one coherent View and later in a theory of Justice he WR moral philosophy is Socratic we may want to change our present considered judgments once their regulative principles are brought to light well if RS accepts that idea and advances that notion of reflective equilibrium the question we're left with is he applies that to questions of Justice not to questions of morality and the good life but and that's why he remains committed to the priority of the right over the good he thinks the method of reflective equilibrium can generate shared judgments about Justice and the right but he doesn't think they can generate shared judgments about the good life about what he calls comprehensive moral and religious questions and the reason he thinks that is that he says that in modern societies there is a fact of reasonable pluralism about the good even conscientious people who reason well will find that they disagree about questions of the good life about morality and religion and rs is likely right about that he's not talking about the fact of disagreement in pluralist societies he's also suggesting that there may be persisting disagreements about the good life and about moral and religious questions but if that's true then is he warranted in his further claim that the same can't be said about Justice isn't it also true not only that we as a matter of fact disagree about Justice in pluralist societies but that at least some of those disagreements are reasonable disagreements in the same way some people favor a Libertarian theory of Justice others a more egalitarian theory of justice and they argue and there is pluralism in our society as between free market Les aair libertarian theories of justice and more egalitarian ones is there any difference in principle between the kind of moral reasoning and the kind of disagreements that arise when we debate about Justice and the meaning of free speech and the nature of religious liberty look at the debates we have over appointees to the Supreme Court these are all disagreements about Justice and rights is there any difference between the fact of reasonable pluralism in the case of justice and rights and in the case of morality and religion in principle I don't think that there is in both cases what we do when we disagree is we engage with our interlocutor as we've been doing here for an entire semester we consider the arguments that are provoked by particular cases we try to develop the reasons that lead us to go one way rather than another and then we listen to the reasons of other people and sometimes we're persuaded to revise our view other times we're challenged at least to shore up and strengthen our view but this is how moral argument proceeds with Justice and so it seems to me also with questions of the good life now there remains a further worry and it's a liberal worry what about if we're going to think of our disagreements about morality and religion as bound up with our disagreements about Justice how are we ever going to find our way to a society that Accords respect to fellow citizens with whom we disagree it depends I think on which conception of respect one accepts on the liberal conception to respect our fellow citizens moral and religious convictions is so to speak to ignore them for political purposes to rise above or abstract from or to set aside those moral and religious convictions to leave them undisturbed to carry on our political debate without reference to them but that isn't the only way or perhaps even the most plausible way of understanding the mutual respect on which Democratic life depends there is a different conception of respect According to which we respect our fellow citizens moral and religious convictions Not By ignoring but by engaging ing them by attending to them sometimes by challenging and contesting them sometimes by listening and learning from them now there's no guarantee that a politics of moral and religious attention and engagement will lead in any given case to agreement there's no guarantee it will lead even to appreciation for the moral and religious convictions of others it's always possible after all that learning more about a religious or a moral Doctrine will lead us to like it less but the respect of deliberation and engagement seems to me a more adequate more suitable ideal for a pluralist society and to the extent that our moral and religious disagreements reflect some ultimate plurality of human Goods a politics of moral engag engagement will better enable us so it seems to me to appreciate the distinctive Goods our different lives Express when we first came together some 13 weeks ago I spoke of the exhilaration of political philosophy and also of its dangers about how philosophy works and has always worked by arranging us from the familiar by unsettling our settled assumptions and I tried to warn you that once the familiar turns strange once we begin to reflect on our circumstance it's never quite the same again I hope you have by now experienced at least a little of this unease because this is the tension that anim it critical reflection and political Improvement and maybe even the moral life as well and so our argument comes to an end in a sense but in another sense goes on why we asked at the outset why do these arguments keep going even if they raise questions that are impossible ever finally to resolve the reason is that we live some answer to these questions all the time in our public life and in our personal lives philosophy is inescapable even if it sometimes seems impossible we began with the thought of Kant that skepticism is a resting place for human reason where it can reflect upon its dogmatic wanderings but it is no dwelling place for permanent settlement to allow ourselves simply to acquiesce in skepticism or in complacence K wrote can never suffice to overcome the restlessness of reason the aim of this course has been to awaken the restlessness of reason and to see where it might lead and if we have done at least that and if the restlessness continues to afflict you in the days and years to come then we together have achieved no small thing thank you thanks thank you thanks thanks thanks a lot thank you don't miss the chance to interact online with other viewers of Justice join the conversation take a pop quiz watch lectures you've missed and learn a lot more visit justiceharvard.org it's the right thing to do [Music] [Music] [Music] [Music] funding for this program is provided by additional funding provided by [Music] [Music]"}], "Justice with Michael Sandel - CCCB: Bioethics: Testing utilitarianism": [{"content": "Now consider, another doctor case. This time your transplant surgeon, and you have five patients each\ndesperate need of an organ transplant in order to\nsurvive. One needs a heart, one a lung, one a kidney, one a liver, the other a pancreas. You have no organ donors, you are about to see them die, and then it occurs to you."}, {"content": "That in the next room there's a healthy diet who came in for a\ncheck-up. (LAUGHTER) And he's, (LAUGHTER) you like that, (LAUGHTER) he's taking a nap, (LAUGHTER) you could go in very quietly yank out the five organs that person\nwould die. But you can save the five  how many would do it,\nanyone."}], "Justice with Michael Sandel - BBC:  Justice: Torture and human dignity": [{"content": "K's emphasis on human dignity has led him to be called the father of Human Rights and his influence remain strong in modern Germany the first article of the Constitution declares that human dignity shall be inviable never to be compromised but what happens when respecting someone's dignity prevents us from acting to save an innocent life in 2002 yob vler the 11-year-old son of a prominent German banking family was kidnapped a few days later the police arrested Magnus Gaffin after he had collected The Ransom money but he refused to say where his victim was hidden the deputy police chief of Frankfurt told this uh kidnapper that if he doesn't tell where he where the child is hidden he would suffer uh in a way that he cannot even imagine he threatened torture threatened him with torture exactly the threat worked Gaffin admitted that he had already killed the boy and hidden the body he was given a life sentence for murder but remarkably the deputy police chief was also prosecuted and convicted of violating the kidnapper rights you're trying to save an innocent child and here you have the criminal who kidnapped him the the argument against it is that there are some inherent qualities in a person that the person cannot forfeit even by doing the worst Deeds uh possible according to Canan ethics uh uh you're not allowed to just use a person uh to just abuse him to hurt him to torture him in order to get something out of him even if the purpose of this was good because that's using a person as a means rather than respecting him as an end exactly even though he's a criminal a kidnapper even though it's a criminal even though we think he didn't really act terribly you know he didn't really have much dignity uh in his own actions why should you treat him you know with respect and dignity exactly you are not allowed to treat a person as a means for another end now here's what a utilitarian would say a utilitarian would say you've defended Kant on his categorical principle but you've just shown what's morally absurd about the Canan position within the utilitarian way of thinking about moral issues or moral cases you cannot distinguish in the end anymore what kind of action is good and what kind of action is bad it's it's totally relative in some instances it's good to torture in other instances is not good to torture what about respect for human dignity well again I would say what about respect for the Dignity of the child right I mean here's a child who is locked up somewhere um going to die slowly from from hunger and thirst um there's no way that's a dignified thing to do to the child as a utilitarian I would say if I know that I can save the child and I don't then I'm responsible for that child's death and and that's what in my view CS refuse to acknowledge their responsibility for the things that they don't do that could save lives now in the German case the kidnapping case they were confident that they had identified the perpetrator let's assume that's the case but the perpetrator still won't talk even under torture but he would talk if you tortured his 14-year-old daughter would you do it I think I mean that would be much a much harder case you know in an emotional level I think to torture someone who is you know has done something horrible is something that you can psychologically come at more easily than to torture somebody who's completely innocent um so if it's simply the one-on-one case here I would say no um because the child that you're torturing is just as innocent as the child who's dying but if there are 10 children who but if you up the numbers um I suppose I'm going to come under a lot of pressure and um perhaps I will say I don't know if I could do it but I perhaps I would say if you really knew that that was going to get the information to save the 10 children then you would then the right thing do would be to torture one to save 10 even an innocent girl she's Innocent but so are the 10 innocent of course and it's a matter of numbers and it's a matter of numbers in the end as a war reporter I have to say you know I I can see I I speak to people who were victims of this kind of thinking uh you know if you if you talk to people who were tortured badly tortured exactly with that kind of argument um it it's so evident why you need Cent thinking as the guidance per se to stop people from thinking they could use others as a means it's it's for me that's you know it's it's I I I see on every single trip I make to whichever country wherever I speak to people who um you know were abused who were tortured who were mistreated with such kind of argument that it's it's full purpose but it there's a good end to this there's a reason why we could torture people it's devastating to see that so I'm I'm you know I'm deep I'm deeply convinced that Kanan thinking uh is is the best guidance we have to protect human rights the V metler case prompted much debate over Germany's constitutional commitment to human dignity"}], "Justice with Michael Sandel - CCCB:  Bioethics: Designer children": [{"content": " It's a story of a couple who wanted to have a child. They wanted their child to be born deaf. The reason is that both of the partners were themselves deaf, and they wanted a child like themselves. So they sought out a sperm donor. They needed a sperm donor in any case, because this was a lesbian couple. They sought out a sperm donor who was himself deaf and who had five generations of deafness in his family. They conceived a child, and they succeeded. Their child was born deaf. The case of a deaf couple who wanted to have a deaf child, raises one of the hard questions of the boundaries. They argued that deafness is not a disability, but a distinctive identity. Now, is deafness a disability? Were they impairing the child, or were they creating a child with an identity like theirs? That was a big debate. It was a controversial case. So we do, I think, have to recognize that there will be borderline cases, and we will have to argue as a society in debate how to regard deafness, or a tendency to obesity, or baldness, or what about teeth, straightening of teeth in orthodontia? Are these medically necessary, or are they purely preferential? But what this means is that the new era of genetic technology requires that we have a public debate about the meaning of health, and I would say also the lip... of genetic technology. I think some of the most penetrating, interesting criticisms and worries about biotechnology and genetic engineering have come to us in popular culture, including novels and films. As most of the parents of their time, they were decided that their next son came to the world in what he had become in the natural world."}, {"content": "His extravagant ovules, Mary, have been fertilized with Antony's sperm. After the exploration, we have been as young as the others and two very young. Naturally, there is always a disposition of any kind of illness. Only to choose the most compatible candidate. First, we can decide the sex."}, {"content": "Have you thought about it? We would like Vincent to have a brother to play with him. Of course, hello Vincent. I think there is a tendency today to embrace genetic technology and bioengineering, not only for health, where I think it's entirely appropriate, but also to give parents more choice about the genetic characteristics of their children. One of the most successful sperm banks in the world is called California Cryobank. It's a for-profit company they sell sperm, and they sell sperm, which is carefully catalogued according to it's the genetic characteristics of the donors. And very few donors are accepted. How do they choose the sperm donors? This company. They advertise for donors in college newspapers. The compensation, what do you suppose the compensation is? It's up to $900 per month. Ivy League sperm, they advertise. Not only that, they provide detailed information about the physical. characteristics of each donor, ethnic origin, college major. Now, the company has no eugenic purpose. They just want to make money. It's a commercial company. And I think that represents a danger. And because what it does, really, is to turn children and childbearing into an extension of the consumer society to turn children into commodities. But in principle, what those technologies will make possible will be an explosion of responsibility of parents for the genetic design of their children. Yeah, now get ready for the age of designer babies. And LA fertility clinics says it will soon allow parents to choose traits like gender, hair color, eye color, and skin color. Doctors there using technology usually use the screen for diseases."}, {"content": "And there is not a single law on the book in this country to stop them. So this is the first self-replicating species that we've had on the planet whose parent is a computer. It also is the first species to have its own website encoded in its genetic code. So in that case, it's possible that children will come to hold their parents responsible for their genetic characteristics, for their height, for their physical appearance, maybe even for their academic performance. I think that would damage the relation between parents and children. And it would really be also the commodification of children. And I think those consumer uses of genetic engineering are morally impermissible. But basically, there are two agencies who can ultimately decide. There is the market, which essentially is what will make these decisions if there is no public collective decision. Or there are democratic institutions. And I hope that democratically, we will have a public debate and a public decision-taking about the ethical limits of new biotechnology."}, {"content": " It's a story of a couple who wanted to have a child. They wanted their child to be born deaf. The reason is that both of the partners were themselves deaf, and they wanted a child like themselves. So they sought out a sperm donor. They needed a sperm donor in any case, because this was a lesbian couple. They sought out a sperm donor who was himself deaf and who had five generations of deafness in his family. They conceived a child, and they succeeded. Their child was born deaf. The case of a deaf couple who wanted to have a deaf child, raises one of the hard questions of the boundaries. They argued that deafness is not a disability, but a distinctive identity. Now, is deafness a disability? Were they impairing the child, or were they creating a child with an identity like theirs? That was a big debate. It was a controversial case. So we do, I think, have to recognize that there will be borderline cases, and we will have to argue as a society in debate how to regard deafness, or a tendency to obesity, or baldness, or what about teeth, straightening of teeth in orthodontia? Are these medically necessary, or are they purely preferential? But what this means is that the new era of genetic technology requires that we have a public debate about the meaning of health, and I would say also the limits of genetic technology. I think some of the most penetrating, interesting criticisms and worries about biotechnology and genetic engineering have come to us in popular culture, including novels and films. As most of the parents of their time, they were determined that their next child came to the world in which he had become in natural fashion. His extravagant ovules, Mary, have been divided with Ant\u00f3nio's sperm. After the exploration, we have been given as young men and women very healthy. Naturally, there is always a disposition to any type of illness that would be needed. Only to choose the most compatible candidate. First, we can decide the sex."}, {"content": "Have you thought about it? We should have been told that Vincent had a brother to play with him. Of course, hello Vincent."}, {"content": "Hello. I think there is a tendency today to embrace genetic technology and bioengineering, not only for health, where I think it's entirely appropriate, but also to give parents more choice about the genetic characteristics of their children. One of the most successful sperm banks in the world is called California Cryobank. It's a for-profit company they sell sperm, and they sell sperm, which is carefully catalogued, according to the genetic characteristics of the donors. And very few donors are accepted. How do they choose the sperm donors? This company. They advertise for donors in college newspapers. The compensation, what do you suppose the compensation is? It's up to $900 per month. Ivy League sperm, they advertise. Not only that, they provide detailed information about the physical characteristics of each donor, ethnic origin, college major. Now, the company has no eugenic purpose. They just want to make money. It's a commercial company. And I think that represents a danger. And because what it does really is to turn children and childbearing into an extension of the consumer society, to turn children into commodities, but in principle, what those technologies will make possible is to create the explosion of responsibility, of parents for the genetic design of their children. Yeah, now get ready for the age of designer babies, and LA fertility clinics, as it will soon allow parents to choose traits like gender, hair color, eye color, and skin color."}, {"content": "Doctors there are using technology, usually use the screen for diseases, and there is not a single law on the book or a genetic code. So this is the first self-replicating species that we've had on the planet whose parent is a computer. It also is the first species to have its own website encoded in its genetic code. So in that case, it's possible that children will come to hold their parents responsible for their genetic characteristics, for their height, for their physical appearance, maybe even for their academic performance. I think that would damage the relation between parents and children, and it would really be also the commodification of children. And I think those consumer uses of genetic engineering are morally impermissible. But basically, there are two agencies who can ultimately decide. There is the market, which essentially is what will make these decisions if there is no public collective decision, or there are democratic institutions. And I hope that democratically we will have a public debate and a public decision taking about the ethical limits of new biotechnology."}], "Justice with Michael Sandel - BBC: Justice: Collective responsibility": [{"content": "Germany today still bears the marks of it's morally burdened history the remnants of the Berlin wall that divided the city during the Cold War the stark lines of Nazi architecture and now a massive work of public art a few hundred meters from the German parliament the memorial to the murdered Jews of Europe the genocide of six million for Germany's post-war generations the insistence on human dignity is one way of coming to terms with the horror of the Holocaust my generation is still morally responsible for the Holocaust I think it doesn't matter if I committed the crime or whether it was not doesn't even matter whether my grandparents personally committed any crimes or guilty of you know committing such crimes that's irrelevant these were so outrageous crimes and they were not just committed by individuals they really were committed by an entire society it was a collective crime that was committed that explains why I think there's a collective responsibility when I was a child we traveled with a school trip to Denmark and children Denmark would throw stones at us in the air glasses lots of kids I knew they were right taking responsibility for the sins of past generations is a powerful moral idea but it's not clear that counsel Asif II can make sense of it for Kant we are responsible only for the acts we freely choose not for our country's past or for the crimes of our grandparents do you think this idea that you've articulated so eloquently of identity being shaped by nation culture history could can't make sense of it Marley probably not I think the number of isn't a because can't did not have I think a strong understanding of the psyche I mean he it's you know it's not a psychologically informed philosopher to some extent that's irrelevant he would consider the idea of the sense of guilt I think or the sense of shame or the sense of inheriting something from you know generations before you I don't think he would have even thought about this but would he go even further and have a principled reason not to attribute any moral responsibility probably it's interesting I mean it's interesting when he I mean he doesn't speak about this so we can with speculating but you were right I mean to some extent probably he would have been against a generation taking responsibility from a previous one because he somehow that would also mean that generation is just an instruments of an earlier generation Kant's insistence that morality means stepping back from our particular identities raises a difficulty if all morality is something I will or choose what about obligations of solidarity obligations bound up with the history of my people in my country and there's a bigger question is it possible to define justice without first figuring out the meaning of the good life without first reflecting on the best way to live these days we try to avoid bringing questions of virtue into debates about justice and politics people disagree after all about the best way to live but can politics really be neutral on moral and spiritual questions to explore this we turn to what may seem an unlikely place 2500 years ago in ancient Athens we find a more demanding idea of citizenship and of politics than is familiar these days for Aristotle politics was not just about maximizing GDP or even protecting individual rights it was about the good life Aristotle lived and taught in Athens in the fourth century BC"}], "Justice with Michael Sandel - NHK: The Ultimate Choice": [{"content": "Mira you know ii wakamono turtle a stolen car smashed an America Harbor to die Nakano got civets Chino Konami mom Shanghai but and I know Canoga say that Tokyo Denardo with Bono back City Hara bhara holding ship in a serenade sustained kkeut Akana union august okra guru paronychia okinawa tossed at eva sanli to do GT kono sekai yo to ikea NOPA he vatos I see no Miccio Serena's [Music] thank you mama my name my cute something de la nip under oxidizing Saito's second Ohana ot monster talk you become deaf echo Josiah story Tony table day sec I need to trans don't Amanda yo Naga Crockett a unit ringy no dingy occasionally in Boston in Japan I think there was much more of a sense that the people could rely on each other and everyone was willing to make a sacrifice and to help and you know you're still seeing it at the nuclear power plants that people are willing to go out there and to help their fellow you know citizens and do what they need to do oh no Meah sankaku dr. Emoto eat and SK domine ho chi minh's Oh Korean I know their consent I tossed a stone no family doctor kimochi Artem IVA Keene shakuhachi day no Monday tennis - tada disco Oh bachata uncle Gary bass yoga a no Chiquitita tell Kody say it's similar to flying an airplane airplanes are dangerous their inherent risks and flying but just because certain times airplanes break down and there are terrible disasters as a result that doesn't mean we stop using them certain sometimes are the only means to the end and nuclear energy is the same I think um what distinguish the problem of nuclear power is that the scope and the scale of the crisis is different from like airplane or other technologies from this crisis we know this new colleague actually affect China and also America so I think it needs words attention and words effort the philosopher Rousseau jean-jacques Rousseau Rousseau wrote it seems that the sentiment of humanity evaporates and weakens in being extended over the entire world he was suggesting that human sympathy and concern can't be global can't be universal you see Medusa right ET terrae you to belittle me no movie omitted his name a Korea second Hatano koto they enact a given at Inari doctor in Cataumet at Amoy Maison des Cara Emma I didn t know moonlight au revoir una mano but I did sir Marathi Feeny Oh sir Thomas Kelly doe Canada CMAs Alden item we must name in this age where communication is at the heart of the matter I think that it is possible to to sympathize with countries a half a half a world away and I think that it's important to note that in the case where there's a natural disaster I think that sort of brings us together as a community but I am a little bit of schedule skeptical about whether we can really move towards a identity of universal or global citizen as we call I felt a lot of pride in the humans that weren't looting that weren't hoarding and in kind of finding out information like this of things going on in Japan of actions of the Japanese people of you know people that were acting as heroes things like this I felt a human pride KOMO me pono Manasa so steady no moat Sen go Giotto you say hi you know Stojko cannoli Rondon Akane Nanako Amida's take rarebit own de Nile's santa's degree domina Domo Oreo dough [Music]"}], "BBC Radio's The Public Philosopher with Michael Sandel | Institute of Politics": [{"content": "thank you thank you hello and welcome to Harvard University my name is Michael sandel very soon Americans will choose a president Barack Obama and his Challenger Mitt Romney seem to agree on one thing at least this election offers a fundamental choice between two different visions of the role of government and of America's future I'd like to invite those of you gathered here students and members of the general public and our radio audience on the BBC to listen to two contrasting statements about the meaning of individual success and about who owes what to whom if you've been successful you don't you didn't get there on your own you you didn't get there on your own I'm always struck by people who think well it must be cuz I was just so smart there are a lot of smart people out there it must be because I worked harder than everybody else let me tell you something there a whole bunch of hardworking people out there if you were successful somebody along the line gave you some help there was a great teacher somewhere in your life somebody helped to create this unbelievable American system that we had that allowed you to thrive somebody invested in roads and bridges if you got a business that you didn't build that somebody else made that happen I know that there are some people who believe that if you simply take from some and give to others that we'll all be better off it's known as redistribution it's never been a characteristic of America just a tape came out uh a couple of days ago with the president saying yes he believes in redistribution I don't I believe the way to lift people and to help people have higher incomes is not to take from some and give to others but to create wealth for all of us to create an economy so strong it lifts everybody this idea of redistribution follows from the idea that if you have a business you didn't build it someone else did that it's the same concept that see government is responsible for everything that's G on here and therefore government can take and and and give as it chooses it's an entirely foreign concept that will not work that has not worked that has never worked anywhere in the world now the first statement by President Obama was widely viewed as a gaff Republicans have mocked the notion that the successful owe their success to somebody else or to the government the second statement by Mitt Romney came on the heels of a gaff of its own a secretly recorded video showing him tell a secretly recorded video showing him telling wealthy donors that 47% of Americans pay no income tax are dependent on the government believe that they are victims and believe that they are entitled to health care to food to housing to you name it an astute Observer once defined a gaff is when a politician inadvertently says what he actually believes I'd go further these two so-called gaffs actually represent a rare moment in this campaign when the two candidates were CAU thought expressing thoughts that Verge on political philosophy much of the debate in this campaign revolves around taxes and Health Care President Obama favors higher taxes on the wealthy Governor Romney favors tax cuts for everyone including the most affluent and then there is the recently enacted healthc care reform commonly called Obamacare I wants to repeal it Obama wants to keep it but lying just beneath the surface of these debates are big questions of political philosophy what is a fair Society who is entitled to what and what is the moral significance of individual success in a market economy let's begin with Healthcare let's put aside the complex details of the recent Healthcare reform form and focus on a question of principle a question about entitlement considering the consider the following statement every American is entitled to decent Health Care regardless of his or her ability to pay let's see what people here think about that statement do you agree or you do you disagree let's see by a show of hands how many agree agree with the statement every American is entitled to decent Health Care regardless of his or her ability to pay raise your hand if you agree with that statement and how many disagree with that statement all right here at Harvard's Kennedy School of government the majority agree with that statement a minority disagree let's begin with those who disagree about everyone being entitled to healthare regardless of their ability to pay why do you disagree who will get our discussion going who else yes in the back hey there my name is Aaron uh I disagree with this because it implies uh if they're entitled to a service or a product that someone else is going to be providing that for them and I'm one of the someone else's and I don't feel that I or anyone else should be forced to have to pay for anyone else's services and products you're Wonder Erin you're one of the someone else's right and and you don't want to be forced coerced to pay for somebody else's health yep yes do you agree um well well my name is Andrea and um the point I want to make is first of all I don't understand what decent healthc care means that to me is I don't know what you're saying but I I know I have come from a family of doctors and my sister her F some of her College friends were very bright and they actually work at bank Capital with Romney and went and made tons of money she worked very hard went to medical school and you know slept on a bed that was wrapped up with cords cuz she didn't have any money and she she's now in her 50s and is finally making some money a doctor she's C she's very bright she's one of the best and the brightest went to the best schools not Harvard but but the other medical school that is often considered the best in the country and she doesn't feel like she should be punished right now and she gives 20 I think it's more than 20% I think she gives 30% of her time for free as part of of the services that she offers as a doctor and she doesn't feel like she should be penalized anymore and she's willing to help people but why should doctors be punished and if you want decent Health Care you have to have decent people um you know you want the best and the brightest to be your brain surgeon or to be your heart surgeon or to care for you and if you're punishing those people you're not going to get those kind of services healthare what why do you think that it it necessarily would involve punishing doctors suppose the government taxed the taxpayers is generally at a sufficient level to be able to pay all doctors a handsome generous amount that wouldn't be punishing doctors would you be for that that's not what Obama said said doctors made too much money no but but my question is would you be in favor of that if doctors were very well paid by the government by the taxpayer to look after everyone's Health would you be against that in Prin principle I'm not against that in principle but I don't really think doctors are not trained in nutrition and I've had personal experiences in that and when you're they're good when you're really sick they're not good as preventative okay thank you for that who else disagrees with the idea that every American is entitled to decent health care and that the government should tax people if necessary to provide it who else disagrees with that idea yes when we talk about entitlements we talk about rights and uh a right to Health Care being created by force is never a right a right cannot be extorted from somebody else at the point of of a knife at the uh at at the pay's throat a knife you're not referring to what surgeons do well you're talking about the state this is there is a certain point but this this is this this leads away from from the principle of Rights all right so you would say and what's what's your name classus Claus you would say that there is no right to healthare uh well we have to Define what is a right well is there you on your definition of a right is there a right to healthare no uh because a right uh is only a right to action read the uh Declaration of Independence there are a few enumerated rights in the Declaration of Independence I remember them which says which says life liberty in the pursuit of happiness yes yes and these are uh principles of action life is action because uh you you pursue the values that sustain your life okay who else who else takes a similar view go ahead all right and then we'll come down here again uh my name is Jay I think my opinion kind of comes to a similar degree as the woman who spoke earlier about that the that coercing someone to offer service someone else isn't necessarily fair but given your premise that everyone is being paid my the other concern would be at what level does decent Health Care become like does everyone have a right to live forever do you have a does the government have a right like have an obligation to pay for everything forever is that a system that can possibly work or possibly be sustainable what about Services normally provided in hospitals which don't include infinite levity is everyone entitled to those Jay again it becomes very comp complicated because you can have like heart transplants and all there are any number of things that are that are possible with modern medicine that just become it becomes extravagant at some point it's unfair it's not it doesn't seem right but you have to make a decision about distribution hi my name is Karen uh not only is it coercive to the people who are being forced to pay for this and being forced to provide these services but it's also cive on the people who are receiving these Services um in a lot of places where you have you know Universal medicine there's often not a lot of options about what you're able to choose and what's able what you're able to choose is right for yourself and so let's let's stick on with the idea of coercion your name is Karin Kerwin Karin Karin Karin it's coercive to whom to tax people for healthcare to the taxpayer right everyone and all right let's let's take that question of coercion it's coming come up a couple of times and let's hear if there is someone who has a reply to it someone who believes that everyone is entitled to Health Care um keep the microphone there and let's let's hear who has a reply yes hi my name is dval um regarding coercion I think um if you take this idea if you extrapolate this idea of coercion and you apply it to taxes and you're against coercion when it comes to taxes it also means that you're against any kinds of any kind of taxes to begin with right so then you're asking for a government that has no revenue from taxpayers at all so that actually goes beyond Healthcare right is that what you believe in to an extent I am often not not in favor of a lot of Cove taxes there's a lot of ways to generate Revenue that don't involve taxes um so you think government should not have any Revenue whatsoever from any kinds of taxpayers because that's coercive there's a lot of ways you can get tax taxes that don't involve like tax on the income tax for example I don't support an income tax because that generates taxes from someone else's productivity uh generating taxes from say consumption I think I would be more in favor of a consumption tax but for healthcare um yeah it's coercive to take people's money and then tell them how to receive Health the health that they want but aren't you electing government to make the decision on what where to apply whatever taxes they you know generate so you're saying there might be some kinds of taxes that would be okay to get but then you're kind of saying but it's not okay for the government who's getting that tax from whatever kind of income it's coming from to decide what it should be doing with it well there's taxes that go to protecting people's rights I support taxes that go to protecting people's rights so protecting people's right to property for for example as defined in you know the Declaration of Independence so you support a police that protects people's right to own their property it protects the protection of people um those kinds of taxes are in favor of but you know saying you're taking taxes to apply them to people uh for health care that they're necessarily not in favor of in like telling people how to have healthare telling people what kinds of healthare they're allowed to have so here so here we have a position a in the US what is a a familiar libertarian position and Ron Paul the libertarian candidate for the Republican nomination articulated it the libertarian position that taxation in order to protect property rights to protect people from force and coercion to provide for National Defense perhaps and the courts is one thing but taxation for the sake of redistribution or for the sake of providing Health Care to everyone to provide for welfare is a different matter and it's wrong because it's coercive do I have it right yes all right now who would like to reply who disagrees with that view of Taxation for health care and can explain what what you see is wrong with it my name is RBA um I'd like to go back to what someone said previously about the right um um Healthcare is not a service or a product it's a basic dignity human right for everyone and along with those rights along with those rights come responsibilities I prefer one don't want to live in a society that doesn't base the human dignity of life and to be a decent standard of living for everyone I would like I like to live in a society where we have that responsibility for one another I wouldn't want to live in a society where we throw our poor sick people into the street because they can't afford it and that's the type of society I expect my government to give me so along with that right that I want to give everyone to have decent basic maybe let's call it basic if not decent a basic health care I I take on that responsibility of giving whatever contribution I have to give so that I can have my children raised in a society that is decent I human beings and let me ask you how do you answer the libertarian objection to what you've just said that it might be a wonderful idea to provide Health Care to everyone but doesn't it involve coercing people by taking their money their resources against their will how do you answer the coercion argument you pay for what you get for if I'm not paying anything then I don't expect to live in a decent Society a decent Society is one that's judged on how they treat their most vulnerable I will pay to live there so I don't feel coerced if I'm getting good value I'm getting good value and that I'm in a stable safe Society where I can raise my my kids as decent human beings that for me is not coercion I would gladly pay for that who disagrees with Ruba on the issue of coercion who disagrees with Ruba yes um hi my name is Sean uh I agree with a lot of what was just said actually I think it would be a terrible thing to live in a society that let people be destitute on the street let the sick go uh un unhelped and I think that's most people in this room agree with that and I think that's exactly why you don't need a government to do it everybody agrees that it would be horrible to do these things charitable organizations are designed to deal with these types of things religious institutions are designed to historically fraternal societies have been able to do these things uh there's there's no problem with helping people there's no problem with providing Aid to the poor the problem is with the coercion mechanism used where you take from people involuntarily through taxation through government to provide benefits to other people it if you as long as it's done voluntarily these are very worthwhile great goals and Sean why is it a bad thing if if it's a worthwhile goal for private Charities why is it not also a worthwhile goal for Collective State action for people of a democracy to tax themselves to advance those worthy goals there's nothing wrong with people donating to the government the very fact that we have taxation is proof it's not a donation because it's forced you if the government is willing to accept charitable donations but you don't give it there if in fact it's not a very effective way to do it you'd be better off giving it to American Red Cross to giving it to Catholic uh uh hospitals to giving it to other institutions that could do it more effectively and more efficiently this is why people don't donate to the federal government they donate it to actual institutions that are much better able to handle poor all right so it would be a good thing for private charity to help people with their health care needs but the government should not coers people should not coers taxpayers to provide for this end what do you say I'm and I would go back to the notion of the social contract and uh if we pay taxes and we go to war to go to war you need to be alive so the first basic argument is to be alive and to be healthy in order to leave the basic notion of alive but isn't live so if you're paying taxes for going to war I mean that would be coercive much more than paying taxes to have a decent healthare and tell us about the social contract tell me your name again yel yel the social contract you point to Y now some people have referred to here Defenders of libertarianism here have referred to the US declaration of independence which says that there is a right to life liberty and the pursuit of happiness happiness now you yel have referred to the social contract what is the social contract exactly and when did we sign up for it well it comes from the French first but uh it comes from the French people I think the the origins we can trace them back track them back to the French people but once you have the Declaration of Independence and you have these three things I mean the pursuit of happiness and being alive they're there so being happy wait wait wait I still want to know about the social contract what is it exactly well you give away you give away some of your of your rights you give it to the state you give away that and the the state respects those rights and Al not only respects those rights but provides for security provides for health provides for other Basics that a human to live a a decent life and is there one social contract for the whole world does each Nation have its own social contract did people actually sign up for it or is it something that we just imagine well as we're multiple human beings with different basic beliefs it varies and everyone every country every state has a different notion and interpretation of the social contract um I can tell that some countries have adopted those Notions into the Declaration of Independence such as France and the US yes my name is sheru and back to the idea of coercion I would say that a society that allows the majority of the poor to go without basic necessities would in fact be coercive because it would be inducing poverty so there's coercion in allowing poverty and desperate economic necessity to persist there's coercion in that yes if people live lives that are under the shadow under the burden yes and this stems from a la yes then they're coerced in what sense are they coerced I would say that the stems from a lack of equal opportunity because I believe that when when we talk about the like life liberty and the pursuit of happiness that doesn't really like that is only in an equal society and if we aren't all born into equal means and equal opportunity then there will be no Pursuit of Happiness for some yes what do you say hi um I personally kind of agree uh my name is John I believe that a society that does not provide for the poorest part of the population is essentially I mean there's a lot of coercion going on in the society that we don't think about there's the property rights if if if I go into your garden and and you call the police on me they will coers me out of the garden because you have the right to that house um the society is is a massive uh entity that that has stuff you give and stuff you take back to the social contract and I I just feel people just too easily bind to this argument that the people who who get entitlements are the people who don't work that I mean you have so many injustices that have that have accumulated over the years it redistribution makes sense on sorry I I'm just rambling um sounds I I do think there is a lot of coercion in the society even just basically with property rights if we are enforcing that we should give back uh to people if if uh it's it's say give or take so you say you you agree with the suggestion earlier that there is coercion built into society and people who are sick and can't get health care are effectively coerced that people who are poor and can't send their children uh to get an education are coerced they're not living free lives is that what you're suggesting John if if they are trapped in poverty if if they cannot find a way out if you're not giving them the opportunity to educate themselves if you're not giving them the chance because sickness is random it can happen to anyone you can do dumb things you can increase the risks but sickness is random and and if it can happen to anyone when it happens to the poor and when you don't give them the chance to to get decent medical treatment you essentially give them a disadvantage and so so you coers them into staying down and just keeping them down keeping them down and therefore people who are ill and can't get a healthc care lack the opportunity to rise people who don't have enough to eat and aren't provided for lack genuine equality of opportunity and likewise with education and Welfare you would say and what's interesting here is that on both sides of this argument about health care and for that matter about the welfare state the value being appealed to as I hear the discussion is the same value there are different versions of it but the value at stake seems to be Freedom as against coercion there's a disagreement about what counts as coercion the libertarian voices that argue against an entitlement to Health Care say that taxing people to pay for other people's Health Care is coercing them the Defenders of a right to Health Care also invoke the freedom coercion idea and they say people who lack the basic necessities of life including Healthcare are not truly free but are in effect coerced I want to see if there are any other arguments in favor of a right to health care in favor of the idea that the members of a society owe one another good health care and Welfare that does not rely on the idea of freedom or its opposite coercion is there anyone who has an argument in favor of Health Care that draws on other other values yes um good night my name is Juan Pao I'm from Colombia and I'm sorry if I will be emotional but this is a topic that involves a lot of feelings and more if uh I'm coming from a a very poor country with we deal with with with what you are talking about and I'm really surprised that uh that uh actually there are some people that could question that statement that you firstly uh appointed you're surprised that some people are against the right to healthcare yeah exactly I'm like very very surprised and why and why do you think it should go without saying that there is a right to healthare what what would be your reason well and um I don't believe that any people and any person should be not able to access to health care I will it's it seems like the people who are in in favor of of not having a health care uh they they they don't see what is going on around uh I I will invite them to go to Colombia and see these people they don't have anything and uh but I I I think that you can go uh like some corners and you will see homeless people that that need the some help and it could be just a thing of of Human Rights well you see it is a fundamental human right it's a fundamental all let's see what other let's see what others have to say yes my name is Ben um in the United States we many of us believe that uh public education especially for children is a very important foundation for a thriving democracy that one cannot effectively participate in democracy without an adequate education I would extend that and say without an adequate uh Health Care System our democracy cannot Thrive I think that there's also a national security basis for that in an age of being interconnected in a global World in an age of pandemics and other Mass diseases that affect Public Health we cannot allow people to go untreated if one person is suffering not only is that an injustice for that individual but it also endangers the General Health of a society Global wellbeing let me ask you about your argument from democracy why does democracy require that everyone in the society be provided health care and education so democracy one of the assumptions that I think the founding fathers in the United States discussed Thomas Jefferson and so forth argued that we need informed knowledgeable people if we have people that are misinformed Med or uninformed they're participating in a deliberative decision-making process the deliberations will not be informative so we have to have a basis of common standards people have to understand that 2 plus 2 equals 4 Etc and I would argue that if you're not adequately healthy you cannot engage in in that deliberative process if you're too sick to participate in a political process democracy suffers what do you say I'm I can say it again I'm Joyce and I can understand that people think look at the person who sick and wants the person to get well and I'm not I don't have a lot of information about health care but I have about housing and the government involvement in housing in my business ended my business I bought a piece of property I lived there I was so completely harassed by Hud people I could no longer in a year and a half I had to sell the property people paid twice two extra months rent to rent because of Hud's involvement so you think that government regulation want the government involved with Healthcare it's too important and I cannot imagine that the government in fact I worked for the government and I was a warranted Contracting officer I know what goes on in a government office it's seems like a good thing I think there are a lot of social programs that start out with a good intention but when you let the government do it it really doesn't work let me ask you this amount of money let me ask you this Choice the Medicare Medicare uh is a program in the United States providing uh government funded health care for people who have retired people 65 and older and this has been in place since the 1960s do you think government should get out of Medicare should should the US drop the Medicare program the Medicare program I honestly just don't know about but to start having all the health care in the country and having people dependent more and more on the government which really really doesn't work I think the intention might be good but I think the results will be awful thank you yes say it again Alex I'd like to start with the the issue of coercion that was going around and I think I can end at a different note I think most people are talking about with regards to coin the notion of forcing unwilling taxpayers against their will to provide health care for people who are in need and I think it's been mentioned a couple times in this room so far and I think it kind of gets to the root of the logic behind that way of looking at it is people describe it as people taking my money and giving it to somebody body else that idea of some other citizen you got to repeat that by but start again with the microphone closer to your mouth okay um I just the last two sentences I think uh people have mentioned the notion of being coerced into giving their money to somebody else and I think that notion kind of goes against a very kind of core value in the American culture of citizenship yeah it's not somebody else who's receiving your money it's a fellow citizen of America who's receiving your money and I think by looking at other citizens as some other entity who's not really part of a more perfect union with you um although that is it's very mat a matter of opinion but I think that kind of gets to the core of why there's that different View and we talked about the government's responsibility in defending basic human rights in the Declaration of Independence life liberty and the pursuit of happiness and I think the question there is is whether or not they're responsible for merely providing the potential for for those three rights or if they're responsibility for helping with the maintenance thereof all right let me ask you a question and tell me your name Alex Alex you say that the case Alex for Health Care government supported health care or welfare is not really a matter of asking taxpayers to pay for somebody else's needs health or welfare or housing correct it's asking people to support their fellow citizens corre so it's not really someone else correct now can you explain because you've heard there are critics here of this idea so I've heard yeah who do consider that taxing some to provide health care for others is a violation of the rights of those who are taxed why should we and by we I assume you mean the citizens of a country why should we not regard our fellow citizens as somebody else but instead as people for whom we're responsible well I think it goes back to the Declaration of Independence and that that notion of forming a more you know a more perfect union which is capable of ensuring the life liberty and the pursuit of happiness of all of those who are a member of the Union well let's take let's put aside the Declaration of Independence the language of forming a more perfect union actually is from the preamble to the US Constitution so Alex you've introduced the idea of forming a more perfect union where we don't regard our fellow citizens as somebody else but as as part of us is that the idea correct and I think people might underestimate how dependent we're all on each other with regards to maintaining our own personal rights and I think by assuming that one is capable of maintaining those rights solely on their own as an individual without the help of that greater Union um as you know it's questionable it sounds like it sounds almost like the idea your idea of citizenship almost sounds like the idea of a family if I'm looking after if I provide health care for my son or daughter or a family member that doesn't feel like paying for somebody else's Healthcare corre do you think that citizenship is kind of like being a member of a family is that what you're suggesting I think it can be considered like that and it can be considered otherwise and in that respect there's truly no right or wrong answer and what do you do Alex if people say I don't feel as though I'm connected in some deep way to people who live 2,000 miles away from me whom I've never met even though they are fellow Americans what would you say to them I would say they underestimate their dependency on the welfare of each and every citizen in this country in order to you know sustain their own personal rights I think there's more Mutual dependency than they might think so shared identity as some to do with mutual dependency correct and that provides an idea of commonality that you think argues for the obligation to provide everyone with health care and Welfare and maybe education correct what do you say my name is Skyler and I would like to argue that the utility Associated for all of us with providing universal healthcare is significant I think that the quality of my life depends on the quality of everyone else's so if we provide preventative care now then the cost of expensive treatments down the line will be lower and if we provide care to everyone I won't be exposed to contagious diseases as much so I think that Universal Health Care is a matter of increasing the common good of the entire Society and you say Skylar it's a matter of increasing the common good because it will promote Public Health it'll prevent epidemics that sort of thing exactly and and what do you think about Alex's suggestion that the common good requires that members of a political Community see themselves as being responsible for one another do you do you agree or disagree with that idea I think you can even be more selfish about it if you need to be it's not not about feeling some sort of kinship with the people around you very simply by providing this care it will increase your own utility um and help help you to live a healthier existence are you happy with that Alex well I think sometimes when you justify it even on that selfish level you get you know bogged down in the numbers and the details and I think the most solid argument that you could make for it is just truly in that ideological context of the common good I think when you start estimating how much your own um livelihood will be benefited by your specific you know dollar uh donations to the common good I think you'll be very hardpressed to come up with you know a solid piece of palpable gain at least in this lifetime but I think it just comes down to that ideological difference of that all right so so we we've actually heard three different AR arguments in favor of taxpayers supported health care of one kind or another I should mention that Obamacare is not a single-payer system it doesn't create uh National Health Services in the UK what it does is require it leaves the private insurance companies in place it requires those companies to accept everyone who wants to apply for healthcare regardless of pre-existing conditions and in return it tells the health insurance companies you'll get a lot more customers because we are also going to require that everyone must carry health insurance must buy health insurance of one kind or another but I've heard here three different arguments in favor of government supported Health Care One argument is a practical argument it's a public health argument that costs will be lower and the public health will be higher if everybody's covered that's that's an argument which doesn't require any strong moral claims about the common good or anything of the kind it's a practical argument the second argument is in the name of individual freedom and individual opportunity it's the idea that if people are burdened with illness or the risk of falling ill without the ability to pay then they're not really free they're not really free to choose their own way of life for themselves this you might call it is the freedom argument is a reply to the libertarian argument about coercion and so we have a disagreement about what respecting Freedom consists in the Libertarians say the taxpayer is coerced if they have to pay for health care for everyone the defender of Health Care who makes the freedom argument says no but people who live under the shadow of illness where they can't get health care they're not truly free and then there's a third argument beyond the Practical argument and the freedom argument there's an argument in the name of the common good it's the argument suggested by Alex that says taxing some to provide health care for other people is the wrong way of putting it what really is involved is we're in this together we share a common life and mutual responsibilities for one another so it's not really a matter of paying for somebody else's health care it's a matter of recognizing a mutual obligation of citizens to look after one another for the sake of the common good now one of the arguments that is still unresolved is an argument that has to do with the idea of redistribution we've heard the idea of redistribution debated between President Obama and Governor Romney and so I'd like to put a question another question to this audience is taxation for read distribution morally legitimate those who succeed in a market economy some say are entitled to their earnings and so it's wrong to redistribute a portion of their earnings to the less successful we've discussed this to some extent in our Healthcare debate just now but let's look more generally at the idea of Taxation for the sake of redistribution and let's see what people here think let's imagine some people who are very successful indeed who've made a lot of money who would come to mind Bill Gates Warren Buffett marus Zuckerberg who founded Facebook or maybe a famous sports star like Wayne Rooney you haven't heard of Wayne Rooney how many here so that the BBC Radio 4 audience can hear how many people at Harvard have heard of R way Rooney applaud if you have and and those who haven't you applaud now all right so it sounds to me like the majority haven't heard of him well he's he's a famous um well we would say here soccer player football player in the UK makes huge amounts of money but you can think instead if you like of Michael Jordan all right Bill Gates Warren Buffett Mark Zuckerberg Michael Jordan they're very successful they make a lot of money now let's see what people think about the moral status of those earnings how many would agree with the following statement those who succeed in a market economy are entitled to their earnings and so it's wrong to redistribute a portion of their earnings to those who are less successful how many agree with that raise your hand and how many disagree all right let's first hear from those who disagree why do you disagree why is it morally legitimate for the state to redistribute some of the earnings of those who are successful to those who are less successful yes um my name is Alexander um so I have three arguments to bring up uh for this three arguments yes you you're well armed here so uh first I would go back to John Lock and his concept of government and say that uh when he defined government he said that when people join a certain government and they stay within its jurisdiction they agree they voluntarily relinquish some of their right to property and they allow his government to do whatever he deems necessary with that part so all right well let me stop you on that one Alexander you're bringing up the idea John Lock's idea of the social contract earlier we had some discussion of the social contract and your idea is that since we all entered into a social contract somehow or other part of that contract was to let the government tax some the successful to help the less successful is that the idea yes and Alexander when did we enter into this social contract exactly well some some people might bring the counter argument that we were essentially forced by birth but wait wait wait wait back before we get to counterarguments when when did we enter when did you enter into the social contract did you ever sign it well I didn't sign it but I was born under a certain jurisdiction and if I stay there I tacitly agree with what it does so with the government that operates that jurisdiction so whatever they do you tedly agree with well so long as they don't do anything against that government I agree with it does that mean you agree with all of the policies of the government well not necessarily with each and every single one of them but with if I agree with the majority of the policies then I agree with the basic idea of the government and so Alexander you would say though you didn't actually sign a social contract the fact that you haven't picked up and left gives tcid agreement to the basic system of law that prevails in the country where you live yes all right so and that that is enough to justify ta taxing the successful to help the less advantaged well I would say so all right and you you had another argument what's that I was going to I was going to refer back to the idea of Economic equitability and that as long as some people make a certain sacrifice and as long as they work as hard as they can they deserve to get something in return and if this involves taxation than it is all right because in addition to efficiency we also have to ensure equitability and Taxation is one of these ways which government can use all right but we're trying to get at the question whether government should promote equality at all equality of income or wealth or condition you think the government should why well yes I believe that the government should because a big portion of how we take advantage of our opportunities and equal opportunities is luck and not luck doesn't favor everyone and if two people work as hard it doesn't necessarily mean that they will reach the same point because of the luck Factor so the fact that two people have worked as hard as they can and one had the benefit of the luck doesn't mean that the other person should not get at least as much as he deserves for the high all right so so you're invoking luck Alexander so when we look at successful people like Bill Gates or Wayne Rooney or Michael Jordan you're saying that part of their great success is due to luck and therefore they don't deserve it to keep it all not I'm not not necessarily but what's the luck involved what's the luck they had the I mean they had the benefit of L the way the way everything happened in their case could have happened the same way in someone else's case if if luck was on his side but it didn't so I do believe that essentially they all some some some part of their like people face trade-offs and one trade-off for getting that much luck is probably giving a little bit of your income to society all right thanks so the idea of luck yes what do you think hi my name's Alana and I just want to say that terming it redistribution for taxation purposes it's it's a red hairing term in frankly irrelevant Warren Buffett he drives on roads that are funded by the government he pumps his car with gas that is funded by the government in directly through government support for the oil industry Warren Buffett everywhere he turns is is benefiting from giving his tax money to the government so it's a simple matter of he's not entitled to hold on to his earnings because he's benefiting from what the government is doing with everyone's taxed earnings period who has a who has a reply my name is batina um I have here in my hand an iPhone and I have a pen that says Google on it both these companies have benefited our lives in immeasurably how many of us have made a Google search today how many of us how many of us used our iPhone or our smartphone to get here that that is worth so much more than the money that Steve Jobs or whomever Bill Gates has made in their lives sorry it's Alana again I want to say that that proves my point because the companies she she Note have benefited immeasurably from government support indirectly but yes how so who forced me to buy an iPhone research and development Mone for app Google gets tax breaks who forced me to buy an iPhone hi my name is an and I would argue that um each of us are given so many opportunities uh I myself and getting here to where I am studying um so many people were involved in my education ensuring that my Health and Welfare were taken care of um in making sure that the roads were paved so that um the school bus could take me to school um from South Central Angeles um to ensure um from even scholarships from Bill Gates and uh Warren Christopher to ensure that I could um learn more about energy and whatever else happen to be of interest to me to pursue a bigger public good um and beyond that um there's so many other public goods that happen to benefit um it takes a village right they say to raise a child well it also takes a village to maintain that child in wherever he or she may be um even Bill Gates the roads that he drives on like they were like people were saying earlier um are maintained by us but roads let's take the example of roads which come up again and again in fact it was one of the examples that President Obama used when he said you didn't build it I imagine that a Libertarian would say all right we can pay for roads there is such a thing after all as a toll road we can support it through user fees so everyone who uses a road pays for it by paying a toll put roads aside why are Bill Gates and Warren Buffett and Michael Jordan and successful people for that matter why are we an indebted to other people or our fellow citizens who may have had nothing to do themselves with the roads we ride on why are we indebted to them such that the successful should have some of their resources transferred to help the less successful because their wealth shouldn't be a measure of their potential uh everybody's Heth or each and every person who has touched their lives has helped them get to where they are but that shouldn't mean that those people who have been of support in some sort of way should not also reap in some sort of way the benefits whether they be Financial or otherwise um from their success all right so we have two arguments so far that I've heard for redistribution an is emphasizing a kind of General indebtedness to Society at large roads are sometimes the symbol of that important teachers along the way another symbol which President Obama referred to when he said you didn't build that so there's the indebtedness argument and there's the luck argument we heard earlier that those who are successful didn't aren't wholly responsible for their success but they enjoyed a lot of luck along the way so we have the argument from indebtedness the argument from luck are there any other arguments and then we'll let the Libertarians in the room reply any other arguments in favor of readed distribution yes my name is Peter I would look back to the economic coercion argument that were're looking at before and say that when the government is redistributing wealth it's not just saying that group a is paying for the welfare and Welfare permanently of Group C it's saying the government is providing a guarantee of everyone that you're going to have a minimum standard of living so if you lose your job you're not going to starve to death so it's not saying that Michael Jordan will always pay for people in the lower income to not be poor it's saying that if Michael Jordan were poor he would also be provided with that standard now obviously it's very like it's very unlikely that Michael Jordan is really going to be in danger of starvation in the near future but we also don't say that people who live in areas that have low crime rates don't have to pay for the police because they're not using that service we're saying that there's a there's a benefit that's provided to everyone in the society not just a given group in the society by the government and therefore everyone should pay for that because they are potential beneficiaries of it because they I might need those Services if I fall on Hard Times Yes but why can't I take out a private insurance policy that's the same idea that people have a right to those Services just as you could hire someone to protect you from crime rather than having to pay for everyone to have the police but we say that everybody has a right to not have certain harms inflicted upon them yes my name is Dave I'm not a libertarian I am not happy at being painted with the brush that painted Ron Paul I'm an originalist for the Constitution and I believe an individual initiative and I think that it was wrong to take the argument away from my sister here and counter it with specious arguments on behavior on behalf of redistribution the sovereignty the individual is at the foundation of the Constitution and I believe the argument that people who are taking initiative in the society are providing a benefit Way Beyond the measure of their private results from that Enterprise is an argument fully compatible with with what this young man said and we need not oppose specious contrary arguments against the Constitution yes what would you say yes in addition I would also like to argue tell tell us your name oh I apologize my name's Nicole um I'm coming from a purely libertarian standpoint I would like to argue against this idea that we have a entitlement to help to help out those who generally help out uh Society to those who have better benefited society as I would argue that their efforts have already been benefited through their income or through you know if they did build roads they were paid for that they didn't do it out of the goodness of their heart um if they were teachers they received pretty pretty good um benefits from the government of course not a good enough salary but nonetheless they they were paid back as we as a society deem necessary if we think that those people should deserve more money than say Michael Jordan or or the other famous individuals then we should as a society also focus on gifting or redistributing our money that way like by paying them more rather than by taxing me and giving them away the money all right so Nicole you're you're really reply offering a reply to the indebtedness argument you're saying it's true everyone uses the roads but the people who built the roads were paid it's true that people rise thanks to the wonderful teachers they had but those teachers were paid they weren't working for free so those debts if I hear you right those debts you're saying have been paid through the price system through the market through the compensation that these helpers have already received so what else is there to the idea of a continuing a persisting debt to society do I hear you right Nicole yes I think that this idea that there say I'm sorry so do I hear do I hear you right yes I I do totally believe that I think the only other argument that you could say to the indebtedness is that there's this concept of luck but I don't think that just because Michael Jordan was lucky enough to be born tall means that he's suddenly indebted to every other individual who gives their money um with consent to pay for their tickets I don't think that that that because he's lucky to have that ability requires that he give away his money oh all right now you're addressing the luck argument all right and let me see if I understand your reply to the luck argument you're saying yes Michael Jordan is lucky to be a g gifted basketball player sure he worked hard but I could work hard equally hard and never be as good a basketball player so yes there is some luck but that fact you're suggesting does not give society as a whole a claim on his earnings yes because if we allowed I think that if we allow a claim on his earnings then that leads to a very slippery slope in which if we say that we have a claim to the fruits of his labors which we would be if we're taxing his earnings from his income then we also saying that we have a claim over his body and his work which I don't necessarily think that a lot of people would be able to make that claim and all right let me ask you this Nicole I it's a powerful argument would you say though that in that the luck argument which you concede about Michael Jordan's talents let's say doesn't that undermine the idea that he morally deserves to keep all of the money he makes playing basketball very very well I don't think it undermines it I think it it's almost a corollary yes he was lucky but I don't think that that means that he's suddenly morally obligated to give this up okay thank you for that yes what do you say hi my name is gido I was wondering if you could also see healthc care as an investment just imagine a taxi driver in New York he's just a new citizen he's trying to make his money and he breaks his arm would it be a better investment to have give him some healthcare so he can fix his arm drive his car again and contribute to society or would you rather have have no healthcare and maybe you'll go down be somebody annoying on the street asking for money all the time what would you rather have so I rather see it as an investment healthare yes and that's an argument for for Universal healthare it's definitely for basic universal healthcare yes what do you say my name is Kevin and I'd like to to pose a question to those who believe that there should be no redistribution and the question is given that we live in a society that is highly unequal and one in which if you're born poor you're very very likely to live your entire life poor what's the moral justification for a society in which so many are so poor and so persistently poor all right stay there what would how would you like to reply it's Aaron yeah this is Aaron how youall doing all right speak directly to uh is it Peter Kevin uh speak directly to Kevin Kevin um it's pretty simple uh I do not want to be forced to give money that I've earned and I want to address a really important Point okay this is fundamental to to the principle that the country is founded on freedom uh and and protection of of specific rights mainly the right to property is critical for people it's important for people in order to pursue happiness and to maximize their happiness if I work for money which I go out to buy food if you take the money from me then I have less money for food therefore it's harder for me to survive I might have to work twice as hard or get three jobs you know to make up for that so and forget the basic rights you could always debate about what's basic what's basic for survival that's a gray area people should be able to keep everything they earn to maximize their happiness if I want to buy 50 flying saucers you know uh you know flying cars if I want to buy trips to to space on these on these new spaceships I should be able to do that to maximize my happiness and no one should be able to take any of that from from me all right does that address your point Kevin No in fact it it doesn't address my point my my question was what is the so we we have a we have a system so we we have a system which is enforced by our state which allows for a great deal of inequality and so the burden of justification in in this conversation has fallen upon redistribution but if we if we turn that question around and ask what is the moral justification for a system that allows for such inequality I don't understand that question can you can you yeah can you rephrase that well let let me else want to speak on that all right well I I'll give it a try sure yeah please Aon do you think that there's anything wrong with the inequality that worries Kevin anything wrong with what inequality the inequality of income and wealth that quite pronounced in many societies and especially this one is there anything wrong with that okay so is there anything wrong with fact that I have less money than you probably do is that what you're saying is there anything wrong with the fact that the that the top 1% that the top 1% in the United States own more wealth than the bottom 90% put together I don't see anything wrong with that no and but Kevin you do yes why I I think it it returns to the the issue of what constitutes a free Society um a free societ Society absolutely and why does it make the society less free if there are inequalities of income and wealth because I think that it's absolutely clear that without some basic equality uh the rights that you have legally cannot be exercised and enjoyed in a way that are are consistent with the values which I think in this room we all share which are a participatory democracy yes hi my name is David I think what we're wrestling with to some degree are some basic fundamental questions about how we want to live in a society right and some of the basic ideas that I've certainly grown up feeling as being a member of this country and Society is there should be at a bare minimum some kind of equality around opportunity right so that feels very real to me of equality of opportunity we don't all need to have the same amount of money but there should be some basic equality of opportunity and to achieve that you will need to pay for it so we're not talking about whether someone takes money away or not you're you're hard-earned money away we're talking about how much and the second piece of that is there's a basis principle here that those who have more have a greater ability to give more so we're not saying you know you made it it's mine I'm taking it away we're saying we all need to pay in to some degree there should be equality uh of opportunity and that those who have more are able to give more and some would go much further such as Warren Buffett and others who saying they have a right and a moral duty to give more all right I can see there are a lot of hands up people are are eager to get into this discussion but I want to step back from the discussions that we've had on health care and on taxation for redistribution and notice a couple of things about the arguments that we've had what we've really been having is not only a debate about who built it but also a debate about the moral legitimacy of the welfare state now the shape of that debate the underlying philosophical ideas animating it are different in the US than they are in many European countries and they're different in ways that I think have been brought out in this discussion notice how much of the debate we've just had has focused on competing conceptions of freedom and coercion those who oppose Universal healthare paid by the government and those who oppose taxation for redistribution argue not only that it will disrupt incentives they make a moral argument that that kind of redistribution is at odds with freedom it's a form of coercion it's forcibly taking from some their hard one earnings and giving those earnings to someone else and that's coercion those who defend a right to health care who support redistribution disagree in large part by disagreeing with that idea of freedom and coercion they invoke a rival notion of Freedom they say we're we're only free as persons and as citizens if we're not burdened by illness when we can't get health care or poverty or lack of Education we're not really free if we lack equality of opportunity to learn and prepare and train to compete effectively in the marketplace and so much of this debate has been about competing ideas of freedom and coercion this is a different debate from the one that goes on in much of the world about Taxation and redistribution in the welfare state there was a second kind of consideration that came up around the edges having to do with the common good one of the arguments we heard for the welfare state or for a right to Health Care is that it's not really paying for somebody else's health care or support or welfare it's really a way of recognizing the mutual obligations we have to our fellow citizens it's an expression of what we share it's required in the name of the common good the freedom argument and the argument in the name of the common good if you look at the history of the American welfare state in the history of American liberalism one of the Striking things is that for the most part the advances in the American welfare state have been made by liberals this goes all the way back to Franklin Roosevelt in the 1930s in the New Deal in the name of the freedom argument because this idea of individual freedom and equal opportunity and the right right to pursue our own destiny and vision of the good life this runs very deep in American public life so much so that the first first and the sturdiest instrument of the American welfare state the social security system was enacted by Franklin Roosevelt in 1935 not in the name of the common good not in the name of the mutual responsibilities of citizens for one another but it was designed to resemble a private insurance scheme everyone would be required to have a certain amount of their paycheck withheld to support it was said their retirement in dignity now in practice the US social security system does have an element of redistribution built into it but FDR said at the time we made it based on payroll contributions not the income tax so as to give the contributors a legal moral and political right to collect their pensions and their unemployment benefits with those taxes in there FDR said no damn politician can ever scrap my Social Security program now his program has persisted it's one of the most fixed features of the American welfare state and it's interesting to remember that its moral basis was an individualistic one it wasn't about taking responsibility for everybody's old age and retirement and we saw something similar with the next phase of the American welfare state in the 1960s Lindon Johnson's Great Society program when Medicare the the health insurance program government sponsored health insurance for retirees was enacted his war on poverty but here's how Lindon Johnson defended it he said we have diligently worked from social security to the war on poerty to enlarge the freedom of man this was in 1964 in his great campaign debate with Barry Goldwater a Libertarian and as a result Lyndon Johnson said Americans tonight are Freer to live as they want to live to pursue their Ambitions to meet their desires that at any time in all of our glorious history so in many ways American liberalism and the case the liberal case for the welfare state has taken its shape in the encounter with libertarian ideas and has based itself largely on the individualist idea of freedom that says as FDR once said necessitous men are not free men now this may seem strange to Europeans who draw typically for their welfare states on stronger Notions of social solidarity and the common good in America it seems we conduct these debates differently and so this brings us back to those two quotations from the presidential candidates from Obama and Romney with which we began you didn't build it said President Obama and what he seemed to be invoking was the idea of indebtedness and maybe also luck you relied for your success on all sorts of help that may not be visible but that matter morally and then Governor Romney says redistribution is not the American way we don't take from the successful and give to the unsuccessful that's not the way we do it Governor Romney says in America now in many ways what you didn't build it really means I think is this if you're successful recognize your luck recognize your indebtedness and don't inhale too deeply of your success it's not only your own doing in the thoroughgoing way that you might think I think that's the message of you didn't build it many people here have suggested that there is considerable moral force in that argument and yet it's worth asking a question if we step back from this it's worth asking a question if we step back from this debate and ask is that a persuasive argument is that an adequate argument is that an adequate argument for the well welfare state to say that freedom individual freedom and equality of opportunity require it and does American liberalism pay a price by not articulating and embracing more fully than it does other moral ideas drawn from traditions of social solidarity and the common good other arguments drawn from social solidarity and the common good I want to thank the audience here at Harvard University's Kennedy School of government and I also want to thank the audience on BBC Radio 4 please join me next week in Dallas Texas where we'll be debating the vexed issue of immigration and asking how far should an open Society go in accepting Outsiders and shall I do this second and I and I also have to give uh you thanks in another way thanks to the audience here at Harvard University's Kennedy School of government and thanks to our audience on BBC Radio 4 for listening to this second and final debate in the American edition of our series the public philosopher thank you all very much thank you it's okay to cough now you can all cough um I'm sorry about this but if you could just all hold on for just a few minutes we're going to uh have to ask you to wait around for a little bit but on the plus side you'll get to see some of the magic of radio because you're going to see that we're going to do a few retakes so just hold on and bear with us for a minute and we'll be back with you in about a minute time you can talk Talk Amongst yourselves you to staying to stay really really good so very good um"}], "#0 Introduction to C++ Tutorial Series | C++ Programming Tutorial | Aditya Burgula": [{"content": "hey guys welcome to another brand new tutorial series on c blisters i am aditya i'll be your instructor or teacher for this tutorial series now coming to the language that is c plus place it is a very beautiful language a popular language it is very old it is there from a long time a large community and after learning c plus place you can go ahead and do game development and then you can go and do competitive programming and it would be much easier for you to actually learn more languages after completing c plus plus because all depend on c plus plus if you take java it will be much easier for you to understand java if you go from learning c plus plus to java or python is also much easier so c plus is just like a programming language which you must actually begin with and it's worth that you are starting from c plus plus you through my tutorials and guys coming to the course design this actually not only a complete beginner tutorial series whereas even if you're from other programming languages such as python javascript dart java other program c sharp like these programming languages if you learnt already these programming languages or any of these then it would be much easier for you to understand c plus place and i'll be making it in a quick way so that you can grasp all the concepts clearly and the videos also will be mostly in a short video time around 10 minutes and sometimes in maybe advanced topics the video length may increase but most of the videos will be around 10 minutes or less than that so guys in the next video we'll be beginning with setting up our computer for c plus installation or development in c plus plus and guys please don't forget to subscribe to my channel so that you never miss any video updates on my channel for this siblings tutorial series and guys thanks for watching see you there in the next video"}], "#2 DataTypes and Variables in C++ | C++ Programming Tutorial | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i'm aditya and in this video guys we'll be starting to code and understand the secret space language so guys as this is a beginner beginner tutorial and we'll be starting from beginner and go to advanced level so first we must understand a concept called starter types and variables which is explained in every programming language at the very beginning so that you have a strong hold about the future concepts now i have just created simple kind of powerpoint slides so that it would be much easier for us to understand these data types and variables so let's go to the next slide and here we'll be discussing the basic stereotypes that even some advanced data types as well and you can even create your own data types so first the data type first editor which we're going to discuss is integer so here end so here i have written that used to store integers so in mathematics we have integers which can store next negative positive numbers including 0 and we have natural numbers which can only store positive numbers not excluding 0 and then whole numbers 0 and all the positive numbers integers which include negative zero and positive numbers so the same way here in c language c plus this language or c language we have a data type called as int to store integer type now let's go to the next one so float float is nothing but it is used to store decimal values or fractional values suppose like pi or anything like that pi cannot be stored in float because it is not so large it can it has some limits all these things have some limit to the number we can where they can store and here let's discuss the third one which is double so double can also store decimal values but has little bit more space to store so in c plus a programming language every data type has some specific space or kind of a storage which it can hold so here suppose for example it integer can only hold till numbers still positive 10 and negative 9 so that's like not exactly i'm just telling an example so here double also can increase so suppose here float has some 10 positive 10 limit and negative 9 limit then here in double it maybe increase and go to minus 100 plus 100 limit and negative 99 limit so like that it has some limits so here that is actually not the actual value let us go to the next one and that is car so car is actually used to store a single character suppose like a or symbol that's our car and the fifth one is string so a string is used to store sequence of characters so what do i mean by sequence of characters and the difference between care and string so care allows us to only store a single letter or a single symbol so the string allows us to store multiple characters inside a single data or location or a variable and that's about it and you can even add numbers but using this care and string you cannot perform operations and guys coming to the last one that is bool so bool data type is something which is used to store true or false values this is very much useful and very much used when we come to conditional statements so guys let us go to the next slide that is variables so till now we have learnt about what data types are and what are their types basic types that is end float double and then cat string bool now let us discuss what a variable is so we use variables to store these data types type of data now let us check this so here i have written variable r just like container sort box which can store something in it in c plus plus a variable can store value depending on the data type we want so for the beginner it might be a little bit difficult to understand so a variable so i just i think even i have kept like this so here as you can see so this is a box so in memory in c plus space when you run a program a memory will be created that's your ram so in that there will be a block of memory allocated for your variables you want to store data in your program right you just can't have temporary data all the time suppose your name your bank account details everything is stored inside a variable and that variable can have a type just now we discussed all the types that is integer float c plus plus allows all those types default in a default and here you can imagine it something like this so this is how you can imagine this box as memory memory location a particular memory location and it is of type and this box can only have integer title type it cannot have string data type it cannot have a cad data type or bool data type we have declared it as end and we can have it we can change it also but we'll be discussing in the future how we do that and now the value inside it is an integer number so that's how it works now let's go to the next slide an example of how we do that in c plus plus so guys here as you can see this is how we declare and assign a variable so this in my age here we are declaring so here in my age we are we are declaring and saying to the c brisbane compiler that when you run this program in the memory you create a variable called as my age and allocate a memory according to the data type so here the data type is end and it will also say that the data type whatever is mentioned should only be allowed as value so here when we have 20 that will only be inserted or used in the memory or kept in the memory if i add a character or letter suppose abcdefgh it will say no you have mentioned it as integer data type and this variable will only have integer data type so that's how it works so here first data type and then second variable name and then third the value which we want to store and there have been some more examples which we can see so car a and notice that this is how we mentioned a character so character representing character we use quotes single quotes and for string we use actually double quotes and inside that you can give multiple characters or multiple words so here in car only single letter you can even have a symbol also inside that no problem and bool so ismail as you can see and here we can just write true so bool can only have two values as i said that is true or false so here where we have kept true and float float is just used for this decimal values or fractional values so here i have just kept a simple pi number 3.14159 and i think you can notice over here this everything is ending with the semicolon so that's how you went whenever you declare a variable you end it with a semicolon so now let us go to the next slide so this is actually the range i have told you right it has some limit and that is it so here this is the size the size in the memory which it's gonna use so care has one byte it has two bytes and float has four bytes double has eight bytes and now this is the limit so care is restricted to only having so this actually i think it is as key sequence according to that number and here when we come to end here it is there so when you assign or add the value so let me go to the previous one so first let us see this so here the largest value which it can hold is three two seven six seven and now when i go to the previous slide if i add three to seven six eight which is one more than the pre actual limit then it will show up an error and say that it cannot add that value so that's how it works so this is the range which we have learned over here and here float also has this range and double also has as you can see float has little bit less and double has little bit more and guys one more concept which we'll be covering is data type modifiers so here i have written the definition as a modifier in sleep displays allows us to change the properties of a particular data type such as its size and restricting the value it can hold so now let us see what are the type modifiers so first is signed and next is unsigned and next is short and long so here first let us see what sign is so signed allows us multi allows us positive and negative values so that's like normal integer value and here unsigned allows only positive values so suppose we take best example as numbers and decimal values so it only allows positive values inside the positive decimal values and here short so here reduces the range capacity of the text right so previously we have learnt about the range right so here if i go to the previous one here we have lunch learned about the rate a range right so if i keep short end it's going to reduce the range of this if i keep longing it's going to increase the range it is going to increase the capacity which it can hold now let us go to the thing again and short and long long also it increases the capacity now here we have an example over here so here unsigned and mynum so this is going to say okay i'm only gonna store the positive value we have given the positive value it's gonna store it now that's correct as i have told you and now if i store minus 20 as i have told unsigned only stores positive values then it is wrong it won't allow that the compiler will give an error and here short so this is actually the limit right and now let's see yeah it is correct because short end or long short end and int are actually the same the limit doesn't actually much decrease doesn't decrease so much and here short end and i give 4000 then it's going to give me an error saying that no i won't take that much value i have a capacity and that is this one not more than that so guys that's how data types and variables work in c plus this i hope right now you have understood the concept very much clearly if you did not understand please watch the video again and have a clear understanding before going on to the next videos so guys that's it for this video i hope you like this video please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates and don't forget to like this video thanks for watching see you in the next video you"}], "#4 Basic Operators in C++ | C++ Programming Tutorial | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i'm aditya and in this video guys we'll be learning about operators in the previous video we have learned about the basic structure about c british language and we have seen how these oil main function and the ripple dot idea also works and this includes we have covered up the basic stuff how we can code and see blizzards and in this video we'll be only learning about operators in c space so in the previous video also we have covered about the basic ones less like addition minus multiplication so we'll be again revisiting them and checking them out so without wasting time let's get in the video so guys here as you can see i have written a comment so this actually called as multi-line comments so here as you can see a multi-line comment is written in this way so your slide forward slash star star and forward slash and whatever you write between these is nothing but a multi-line comment just like the single line comment that uh where we use the two lines is nothing but a single line comment and this is actually called a small deline command okay now let us type into operators so guys here i have just written a heading called as operator we have covered the plus operator in the previous video and the minus operator everything is same multiplication and this is division and here we have a vr operator what is this this actually called as a modulus operator or this is actually a division but it gives you reminder rather than the question and here we have plus plus increment operator and decrement operator so now let us check these three and guys you can even check out this page on wikipedia where it mentions all the operators in c plus language or c language and here there are actually a lot of categories arithmetic and then we have comparison logical operators and then bitwise operators assignment operators member pointer operators other operators so there are actually a lot a lot of operators so you can check this page and you can even learn some more things about simplified operators so now let us see how this works first let us check these three so three operators check these three operators so first let us check the difference between the normal uh forward slash operator and this modulus operator so for that i'll just create a variable over here and we'll just scroll it so that we have much nicer view so in a and here i'll just write two variables and i'll write a is equal to 10 and here p is equal to 2 so simple and here i'll just write c out and here we can just write 10 divided by 2 and into the semicolon and now let's run this program and as you can see we got 5 which is correct and just let us change this to a modulus operator and now let's okay i have just kept this like here and now let us run this and as you can see we got the remainder actually so as i've told you this modulus operator gives us the remainder sometimes reminder is also very useful for example when you when you are trying to write a program which finds out whether a particular number is an even number an odd number that time you would use a modulus operator to check it by division and check that if the remainder is 0 then that's even number when you divide it by 2. so when i keep 11 so and now i run this it's going to give me some remainder it's not going to give me 10 or 0 i mean so that's what you can do that and then actually lot of uses of modulus operator and it will be very useful in the future as well and now let us take this increment and decrement value so i'll just remove this and here i'll just write oh actually i forgot i actually created the variables for those two things but i still didn't use it okay let us write uh the same thing in the variables format so now let me just run this and here it will give us the same thing and here if i just keep the forward slash and now let's run this program it is the same thing so it was actually useless for me to create a variable uh two variables for actually printing it out where i just use the numbers directly so now i think i can delete this or okay let's use this right now so guys first let us check the increment operator and now let us run this and let us see what the output is so it has actually done nothing to it and it is actually used in loops a lot so let us see how it actually works so i'll just write a plus list and now let me just write c out and here i'll just write a and now let me just run this program and it should actually give us 11."}, {"content": "the reason it didn't print to the console before it is because of a concept called as uh post incrementation or pre-incrementation i don't remember the exact uh kind of what we call that so there's actually two ways of using this operator and that is this way that is plus plus and that is the previous way which we did after a now i'll just comment this line out which is like this and here i'll just write plus plus and now let me just run this program and should give us 11. so i think now you might have understood the difference between pre-increment and post increment operator so the thing is that when you write plus plus a it is updating the value of a as soon as possible and it's printing it so pre-increment so it increments and then runs the function or this thing whatever is there over here and after that if we use this thing and now let me just run this program it is actually printing whatever value is there first in the a and then it is actually incrementing the value to check that we can just write c out and a again in the next line and we should see 10 and 11 printed so as you can see uh i'll just write another statement called as and l and what this end l will do is that later we have got some syntax and that and we can even just remove that thing also and this end l will uh make the 11 go to the next line actually so this just like uh escape sequence if you're familiar with that it's no problem if you don't know so here as you can see the first print statement a plus plus it is actually printing the a value first and then it is incrementing that's why we got 10 whereas in the second one as it is incremented already that's why it is printing 11. now if i write here plus plus and it should give us 12 actually so now 10 and 12 should be the both printed values so as you can see we got 10 12 and the same way works with the minus operator as well so i'll just keep minus minus and plus plus and if we see that uh what is what will be the output let us see so it is 10 and 10. so here first we are minusing it to 9 and here we are incrementing it so let us have more clear view about how this works and now we must see how it works so as you can see we got nine and ten much more clear in understanding so i think you got this concept of pre-increment and post-increment pre-decrement and post decrement also if you did not understand you can keep it in the comment section below i'll even keep a more kind of a dedicated video explaining this pre-increment and post increment video separately and this actually operated in most of the programming languages so it would be very easy for you to even grasp the concept in other programming languages as well not only in c plus less so guys that's it for this video i think that video is going much longer so i hope you like this video please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates thanks for watching see you in the next video"}], "#6 Relational and Logical Operators | C++ Programming Tutorial | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i'm aditya and in this video guys we'll be checking out some of the more interesting topics involved inside the condition statements part in c plus this language not only specifically to c plus even if you're in other programming language such as c sharp java they're all similar so the concept is same in all of them but the implementation might be a little bit different depending on the language you're learning now in this video it is a secret space tutorial so we'll be checking out the secret way so specifically in this video we'll be learning about the c plus plus logical and relational operators i think we have covered some of them in the previous video where i introduced you about the condition statements and effects we have done some basic basic if else where we wrote some code in which a code executes while it is depending on condition so in this video we'll be actually learning about how we can modify those conditions using these operators so without wasting any time guys let's get to the video so guys here as you can see guys i have opened rebel dot id as usual and i have just opened a blank ripple and here we are just gonna add this line which i have told you in my previous videos that you must add using namespace and std so now guys we have added that and first of all let us see what all are the relational operators so for that we are going to have some comments so this is a multi-line comment if you are not familiar with that so we can just add any text in this comments so it doesn't matter what if you even if you write code it won't execute because it is just like reference purposes and here in this comments we'll be writing first is the greater than and lesser than and then we have greater than equal to and then lesser than equal to so these are some operators and some more we have that is not equal to so these are some basic relational operators and then we even have equal equal to as well i've got that so these are some basic relational operators and now coming to another type so i'll just write a heading over here saying that these are relational operator and now guys here let us check about some logical operators so in logical operators we have and and and then we have or that is two perpendicular lines and then we have not so not operator so in python these are very similar if you're coming from python we just use the and keyword so in python it would be like something like and so it would be like and and here it would be like or and if you're not from python don't worry this concept if you understand in one programming language in python it would be the same in most of any programming language the concept is the same so now let us see what these operators do so i think now you might have known these by seeing their operators so the symbols so greater than less than lesser than equal to greater than equal to now what are these logical operators so first let us cover this logical operators first so for that let us create some two variables and a and b comma c so simple variables so this is multiple variable declaration in the single line so i think i have even told that in my previous videos so now let us see let us write a condition so here if and here we'll just write a equal equal to 0 so this is a simple condition and here then i'll just print it so i'll just write a is zero so simple print statement and that's a string so i'll just end it with the angle as well e and dl and end of the semicolon so always remember use semicolon when you declare variables or when you print out something but don't use over here so suppose like over here where you write the condition so after this circular parenthesis there you must not add a semicolon or else it will give an error so you must not add there rather you must add these curly braces so would say that now this is an if block so if this condition is true this block whatever is there inside these two curly braces will be running if you add a semicolon it will end it so it won't recognize this curly braces or this block whole block now guys here as you can see we have written this now let's run this program and let us even initialize the value with zero and let's run it so we should get a 0 that's true now let us initialize b and c also with 0 and here c is equal to 0. now we can use the and operator in such a way so let us just keep like this b1 to understand this more clearly and here in the condition and here make sure that you end it with a semicolon and here in the condition we'll just use the and operator so and operator or operator and not operator are used with multiple conditions so these allow you to give multiple conditions inside a single if else block or single if else else if and else block so we have not yet covered about elsif right so don't worry about that that will be covering mostly in the next video so now uh as you can see i have kept the and operator and here i'll just write b equal equal to 1 so now as both of them are equal to 0 and equal to 1 and the initialization values are same now let's run this program and it should print the same thing so a is equal to 0 now let us see what if i change this to 0 now let's run this program there we see no output the reason is that when we add the and operator whatever condition it is working with conditions that is a is equal to 0 and b is equal to 0 it will check if both of them are giving me the value true if not if both are giving false then the whole condition this whole block won't run and if one is also giving false no condition this whole block won't work so sometimes we want like even if one condition is false it doesn't matter that much so that time we can use the or operator so the or operator will check at least one should give me true then only i'll run it in all the conditions given at least one should give true so now i'll just write and operator over here and let's make it a little bit more complex to understand this so not too complex but little bit so not let us not make it much complex and let us just keep it like this a equal equal to 0 and b equal equal to 0 and now as we have added the r operator now let's run this program and we should get a is equal to 0 a is 0 so it is printing the c out statement so now though we have one condition which is returning false that is b is not equal to 0 as you can see clearly over here that we have kept its value as 1 so that's how all operator works and and thick i think you can even know about the not operator right now so for this we'll use a bool value so that it can have a much clearer understanding we can have a much clearer understanding so for that i'll just create a variable called as bool is true and equals to true now let us see what happens over here i'll just write not true uh not it is not that not is true so this if statement after checking the condition it will written anyways a bool value and here also we are giving a boolean value so let us temporarily change this to false so that it makes much more sense and now we'll just write returning true so if it is if this line is being printed then it is returning true right so now let us run this so what this not operator will do is that it will just convert it to the opposite one so now i think we must just save it i think why did it run like this so let's run this again and here as you can see yeah we got returning true so it is actually converting with the false the value is false over here and now here i'll just add an else statement to make it much more easier so c out returning false so and here end it with a semicolon in l now let's run this program again and we should get the same result as we got previously now let us change this to true and now we must get returning false so i think now you might have understood about how this is working so when the value is being true it is this not operator is converting it to false and when the value is false it is converting it into true so that's how this not operator works and here we even use not equal to that's a little bit different from how it works so you can just write something like if we had the previous variables i'll just create them back or we'll just use the same variable if is true is not equal to false so it is not equal to false then it is writing returning true so this should also print as returning true so it is returning true that's also right and now if we write true it should give us returning false so i think now we are understanding how this condition is working sometimes it becomes little bit confusing even for me so just uh kind of check the control flow of this program how is it working the variables the assigned values so that you can understand more clearly if you have any doubt guys please comment down in the comment section below i'll be always ready to answer your questions or doubts so guys that's it for this video i hope you like this video please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates thanks for watching see you in the next video"}], "#7 Functions in C++ | C++ Programming Tutorial | Aditya Burgula": [{"content": "[Music] hey guys welcome back to another brand new video i'm aditya and in this video guys we'll be learning about functions in c plus programming language so till now we have covered about some basic conditional statements loops operators conditional operators logical so now we'll be diving into a new topic that is functions so functions are very common in any programming language you take like python java and they're also very interesting so guys without wasting the time let's get into the video so guys i think now you can see on the screen we have a cpus file open in these uh vs vs code so we have visual studio code all files over here for running and debugging i've already set it up everything and i have done this nsc plus plus folder so now let us discuss what a function is so a function is a way uh which you give a specific set of instructions in a kind of a group so that whenever you want suppose you want you want to have repeated code in your program uh that time you can create that repeat you can take that repeated code paste in a function and call that function whenever you want to actually use that task so now let us see this implementing so on how this function works so first let us write a basic function and one more thing is uh this whatever you see the main this itself is a function so this is called as the main function this is nothing but an entry point to the program so whenever the c plus this compiler actually checks all the c plus plus files we have suppose we have multiple c plus test files right now we only have one so when it checks all these cps plus files it will find for this main function in this we define all our entry point whatever task we want the application to do whatever we want the computer do for us so now let us see uh whatever we'll see how we output to the console so we have learnt right and the basic first video i guess we have thought so c out and here we write hello world so here instead hello world we'll write functions learning functions so so this is a basic uh output text output function which we do when it's commonly practiced so suppose it was in python what we would do is we'll write a function so we'll write like this print and here we'll write hello world or anything we want but in case of c plus plus what people mostly do is they use the c out that is standard output stream so instead of that let us make a function for this so let us call this uh void so let us create a function for printing to the console so first let us run this function and see if it works so i will go to terminal uh run start without debugging and build success now here we can see learning functions it's good now let us create an alternative for this which is much more simpler so i'll just reset the spelling yeah so this is how we write the function so here void and we give the function name so we'll give the function name as print and here inside this will give parameters so now what our parameters have said right so this over here will be is a string so we'll take a string as a parameter so now still you might not be able to understand what parameter is and what actually we are doing right now so i'll just write a simple function and then we'll see the implementation and then you may start getting things so understanding all those things what is happening right here so here we'll just write text so string text and here what we'll do is simply output see out text like this so here make sure i set like this text and what i can do is now call so print i can call this function nothing but using this function i'll use this function like and here we have seen that we have given parameter so this is nothing but the variables which the function will use so here we are using the string variable and whatever this variables we are mentioning here that this function will use should be uh given at the time when we are calling or using this function so this is declaration declaration and this is function calling so here nothing but we are calling the function or using function calling or function using it is it is mostly called as calling function calling no one uses using uh just for your uh understanding so i just i just wrote like this so here what we can give is a string so here i'll just give learning functions or let us just paste the string itself so ctrl c and ctrl v so that's very simple and now let us run so go to run and select ctrl f5 you can also use the shortcut key control f5 so here you can see we got two times learning functions learning functions so to see this in the next line what we'll do is we'll add over here and handle actually we can also do like this like slash and i think i have not talked much about the skf optic escape sequences so we'll also see about escape sequences so now it should actually have one extra line space so not in the next line but it will leave one line space completely free and the next line it will print so now let us go run and as you can see over here we have one line completely free and resprinting in the third line so first second second is completely free and third line as you can see it is simply executing the same c out but in our own function now let us use it with different data types so here we have mentioned right string so that is nothing but this parameter so the thing is one more thing is these are called as parameters so when you declare a function in function declaration whatever variables you are mentioning here the which will be used by the function these are called as parameters and whatever variables which you give while calling the function these are called as function arguments so very important note to remember people use usually use these words interchangeably but that's not chill the thing correct thing so you must know the actual meaning of what they mean so that was about our function arguments and function parameters uh so now let us give us uh an integer so here you can see we have only taken string right now what happens if we uh give an integer so as you can see here already we are getting an error so no suitable constructor x exists to convert from into a string actually so you might be not understanding what a constructor is you'll understand when we come to object-oriented programming and construct destructors for all these things so now if we run it won't run actually we'll get another so what i'll do is we'll create a new function so here i'll say void print so with the same name only so with the same name i'll take in integer and here what i'll do is c out same c out and i'll write interior and semicolon now as you can see over here the error disappears now let us see if this works actually so you can go here run run without div again and it should run successfully same so learning functions and 10 so that's great so what actually are we doing this what is this called right now this condition what we are doing right now over here so this is called as function overriding so what we are doing is uh function overloading so not overriding so almost both are same but applies to different context so i won't be explaining about both of them differences between both now let us just see what we are doing here so here what we are doing is so here you can see one overload so what we are doing is we are defining same function twice because we want to use that function with two different data types so that is nothing but function overloading when you want a different set of arguments to be used by the same function so here we are using different set right over here we are using a string and here we are using an integer so it is completely different data types the set what we're using trying to use so that's why we just can't directly give like some dynamic in python you don't need to mention all these data types but rather you can just give a variable name and it will automatically figure out what it is and then rightly do it you won't get any error like this but whereas c plus this is a statically type programming language so that's why we get this error we'll be discussing more about this core concepts of programming languages also soon so don't worry about that so that's why we are getting this error now uh we have run it right so we got the output correct so now let me explain about written values in functions so here you can see void void and over here also we got an int so what is this in void what what is this we are writing before the function so this is called as a written value so what happens is that when your function executes so here when this completes executing what happens is that so let me just create a variable called as int a equals print 10 and end and here let us return the value of what we are giving written integer and end it with a semicolon so just wait for a moment guys and here let us add a breakpoint over here uh i guess that's it and we'll add another print statement also so we'll let's write like print and we'll say hello exploring understanding return values so and end it with a semicolon always don't forget that thing that's very important and let us add breakpoint over here better yeah so now let us go and select start debugging now you will see so here our application is actually stored so it is just in the first line now i'll go to debug panel over here and here you can see the value of a so we are created we have created a variable a right so that value and currently nothing has happened on the console right now so i'll just go to the next line step over now it should print the first print statement it executed the function first function so it executed for successfully and just go on to the second line now still you can see the value of a is equal to 0 now let us go and click step forward and as soon as we go there the value of a will be equal to 10 so it is returning the value and storing it in a variable so now as soon as you see you can see we got 10 over here so that's how it works and here also you can see in the output we got 10. so now that is only nothing but written value we just written a variable and when you written that variable you can store it in a variable like how we did over here and use it in some other formats whichever you like so this is a basic example of how written values are used so that's what that was about it and now i can just go step and here it will still wait and program is done so so guys that was about a function so let us have a small recap so what exactly is a function so function is nothing but a set of tasks which you can group it together in a function and give it a specific name and you can also give parameters to the function while declaring it with those are nothing but the variables which you will be using in your function and whenever you want to use a same function with different or multiple data types which are not the same that is the same thing so string and here end that time you can use function overloading or different sets of parameters also that time you can use this function overloading and there's also concept of function overriding which we'll be discussing at the time of object-oriented programming or the oops concept and written value so a written value is nothing but a value which is written after the function has executed successfully or completed the task successfully and it returns a value and the written value can be of any type so it can be an integer a string but the main thing is that whenever you want the return value to be a specific type that time you must mention over here like in so as c plus plus is a statically type programming level if you want to written a string you must mention that it will be returning a string and here when i said to uh give written an integer as you can see we get an error so that is the main thing be careful about that whatever my value data type you mention over here make sure that you are returning the same thing and if you even don't written still you may get an error because it is compulsory you might be wondering why is it not working with this function that is in main we have given an int main function and we have set that value written value will be of integer but we are not returning anything the reason is it is exceptional only to the main function it automatically written 0 actually 0 or 1 i don't remember actually just something like 0 or 1 if the program executes successfully or not 0 1 like that so it's only an exception for main function but other all functions you will probably get an error so make sure that you check that when you declare and use your functions that you always be careful with whatever you're returning and make sure the data type is also correct so guys that was it for this video i think the video has gone a little bit long so thanks for watching guys please don't forget to like share and subscribe so guys thank you see you in the next video"}], "#8 Enums in C++ | C++ Programming Tutorial | Aditya Burgula": [{"content": "[Music] hey guys welcome back to another brand new video i'm aditya and in this video guys we'll be learning about enums in c plus this language so without wasting any time guys let us get into the video so guys i guess in the previous video we have learnt about functions and functions overloading and how we use functions in c plus list so that was an easy topic i guess for you guys now we'll be dealing with enums or most people call it like innomurations or shortly enums so what are actually these so these are just like your own kind of data type so let me demonstrate you what an enum is so suppose i wanna i'll create an enum called as colors and here i can say red and blue and green and yellow so like this i created an enum and make sure i end it with a semicolon so that error goes off so this is a small enum now what i can do is i can create a variable out of this so colors or else i can just keep it color so color my color is equal to red so here we get another so we'll just rename it to color and now the probably the error should have been gone so as you can see what are these values these are just like our own defined values the thing you can see is normally these are assigned from zero to one so these are all the text values which are given red blue green yellow and here red signify zero blue signifies one and two and three so instead of numbers representing your own values it can be sometimes useful actually so this is how enums work and and one more thing is that you can also add like this 10 and now the specific value will be equal to 10. now let us try to print what this value is so c out we'll just use c out and red or we'll just use my color so identify c out okay so we must use stdc out actually so we have not used using namespace right so we are getting that error and now let us go and click around without debugging so here we get an error oh is there a breakpoint okay so i'll just remove that and we'll write cn.get to actually stop after printing so that program won't close immediately std out cn and now i guess the problem should be gone now let us run without debugging and here you can see we got the value as 10 so that's how it work it is just like giving a name for some specific values you can have like this colors and more of anything like for log i think in the previous thing we i told about log or anything like that so i'll create a log function so not a class we'll create a function so here we'll say in log and here we'll say string text and here we'll take level level so now what is this level so just wait a second we'll create that also so we'll create an enum level and here we'll say info and then warning and then error so these are the three levels and make sure we end it to the semicolon and let us open here curly braces and let us use the using namespace so that error we get from string will be gone so enum name space std and in the semicolon so now all the errors should be gone and now what we'll do is we'll create a log function which we'll use in enum so simply what we're gonna do is we will write an if statement or we can just write a switch case also so we'll just deal with if now i don't think we have covered switch case more probably so if and we'll just write level is equal equal to level colon colon info so now we might be seeing what is this colon colon operator so it's just referring to the enum in fact i think we can also do it just without even level so like this also it works like this now if you want to be more specific you can just write it like that anyways this is also this will also work fine as you can see over here level and four so if level is equal to info then what we want to do is c out and we want to print a string same info and then that text and let us do and end it so this is one and i'll just copy this for the next two things also so that was it warning error and info now let us use this in our main function so paint main so here we can actually make this word because we are not written anything now let us create let us call this lock function log and we'll say no errors all fine and what i can do is i can give the level as info so here you can see info and press ctrl c and let us copy this two times and we'll say no errors but some [Music] but some fixes will just write fixes fix this and we'll keep this as warning some optimization left this might make much more sense and here we'll give errors in code so now uh we'll change this to errors yeah so now guys when we print uh this thing we must actually get uh in a different format for each of these so first we must get info and no error is all fine so let us see what actually happens and let us also write c in kit so that it doesn't quickly quit the program now if we go run without debugging and here you can see we got two different things let me just close this yeah so here we got you can see info no errors all fine warning and error now this is a much more easier way actually as you can see instead of using numbers and some other things variables to hold this we can use an enum so this was a very simple example of how you can use enums and what enums are they just like your own data type you can create your own data type and assign a value to it and automatically they will be assigned to 0 1 and 0 and continuously like incrementing 0 1 2 how many you have and you can also set them to some specific things also like zero one or i will deal much more with enums in an advanced video about them so that's it for this video guys i hope you liked it if you did please don't forget to like share and subscribe this channel and this video so thanks for watching guys see you in the next video"}], "#10 Introduction to Pointers in C++ | C++ Programming Tutorial | Aditya Burgula": [{"content": "hello guys welcome back to another brand new video i'm aditya and in this video guys we'll be learning the new interesting topic in c plus that is pointers so i guess you might have heard about pointers in c and c plus this and most of them get scared about what is this point is like memory and all those things it is not that complex guys it's actually very simple concept so without wasting your time guys let us get into the video so guys before getting into coding and understanding what pointers are let us actually have a theoretical explanation of what pointer is it is very simple guys it is nothing but it is just a variable which stores a memory address now it might be a little bit tricky to understand what does this mean so you can think a memory as a single line where they're just like boxes a line of boxes complete infinite line of boxes not infinite but a lot of the mother just like on a row so it is just like your house lane where all houses are there straight line just like that now each box has some separate value so like a box first box can have value one depends so you can manipulate the data and each box has an address just like a house in your lane has some address just like that in memory also it has some specific value so that value is also just like an integer so we are nothing but we are nothing but doing in pointers is that we are just storing that address so suppose i have a you know i have a variable uh which is like 10 you think now i am storing it whenever i create a c plus program it will be loaded in the memory all the variables whatever i create they will be all loaded in the memory now in that memory to identify where actually that variable exists we can use a pointer a pointer just links or shows us where that variable is located in the memory so now let us actually see how it is done so that you can have a clear idea so now guys let us also understand the syntax with that so first let me create a variable called as myware so by the way guys i'm using another ide called as a rider and this is uh this also supports c plus plus i'm using the right of unreal engine not the vs code so first let us get into the coding part and understanding what points are so first i'll create a variable called as myware and i'll give it like value 10. so when we run the program uh this variable will be stored in some memory address location so it will store it will be stored in some memory so now we'll create a pointer now for creating a pointer the syntax is very simple you just start with star symbol and you just say this and just write the variable name and then my variable name so it's very simple i think you can understand so when we write the star operator this is nothing but signifying that that variable is a pointer so it is pointing to some location memory address and now when we add this symbol what it means is that we are getting the memory address of that variable so here when we mention like this here saying the c plus was compiled as this variable is not like a normal variable it stores memory address rather than just like storing integers so and in that variable we want to store the memory address of this variable i think now it is done we'll just run this program and i'll add a stop point over here and what i'll do is hit click debug over here so i think you can see over here these are the two variables here you can see the variable section so these are two variables right now these variables are not at all initialized the compiler has just seen the main function line and it has just scan till this line it has not even seen this line so now when i click step forward it will actually see our code over here and it will initialize my wire with 10. so instead of 10 actually i'll just stop and i'll give like eight so it might be a little much more simpler now let me run oh i didn't debug sir so now you can see we have got again over here so still there is no variable assigned to my where it is some dummy value over here that is minus eight five eight double line so now let us click step forward and the c plus compiler will read this line and assign the value a to my bar so we can see the change is also here so here you can see as soon as we go through that line you can see that the value of my wire is equal to 8 and is also showing the type as integer now the value of pointer which we have created in pointer is simply like this nothing there's nothing with it now when i step the forward again then what will happen is it will take the memory address of this thing and it will paste it over here nothing so first let us see what is the memory address of this variable before we assign it to the value another pointer so i'll just right click over here and we'll see show in memory view so here you can see we got the address as 0x00594 so and here you can see the value of 8 is stored so same so this is how memory looks like it's just a linear very linear kind of stack line like this where all the datas are stored so here is a in our particular memory allocation it is stored now let us click step forward and see what happens so here you can see we got 594 so it is nothing but just having that address of that thing so here you can see we can also copy this and if we just click over here and show in memory it will actually show the exact thing eight over here you can see we again come to eight so now as we have learnt that now let us see how we can manipulate in that memory address using the pointer so i'll just close this minimize this and now to manipulate the value using a pointer what we can just do is that add the star symbol before the variable that is the pointer variable and just assign now you are kind of dereferencing that memory so you are saying the compiler that uh i have stored an address on this variable right pointer so just go to that address and instead of whatever value is there over there just paste it whatever i have given now so the value which we have given was 8 so it will just paste it to 10 so let us have 9 that might be a little bit simpler to see so now let us go and run so we started the debugging so let us step two two times so here you can see there are two variables now the memory location is ad4 so show in memory so here you can see ad4 now the value is eight so what we'll do is we'll go one step forward and you'll see the memory changing so i click this as you can see we got change so that's how you can change the values so that was very simple introduction to how pointers work in c plus list so guys another thing is that as you can see i'm using the rider ide most of you might not have it because it is just in a preview stage and mostly it will become a paid software and in visual studio code you can't see like this how we have seen the memory view so what you can do is if you have visual studio installed we should have 2019 so that's a full-fledged ide not a code editor like vs code so i have just opened it over here so here you can see uh i'll just remove this thing and i have already prepared it so i'll we'll paste the new one instead so so this is visual studio uh 2019 ide now what we'll do is we can also do the same thing over here we can also see the memory over here so what we'll do is we'll just click run over here and you can see here we got all the diagnostics tools and here you can see the watch here you can see the all the variables and their values so now what you need to do is go to debug and here windows and then memory memory one so now let us here also you can see step over the same thing as we saw in rider so here we have created variable 8 and now if i go here uh it's still in career so let us wait till that or we can actually think i can write like this and my where and here it is e08 so e08 here you can see we got eight stored now if i click step over here you can see we also got e08 so memory address which we have seen is being stored in this pointer and now when we again click step over it should change the value of 8 to 9 so when i click step over here you can see it is highlighted the value of 8 is being changed to 9. so that's a very simple and visual studio how it works in visual studio 19."}, {"content": "so guys that was about uh pointers a basic introduction to point is actually we can there are a lot more things like pointers much more deep into that and then references so we'll be learning them so in the next few videos so that's it for this video guys i hope you like it and if you did please don't forget to hit that like button share button and also don't forget to subscribe if you're new to the channel and hit the bell icon so thanks for watching guys see you in the next video"}], "#3 Playing with Basic C++ | C++ Programming Tutorial | Aditya Burgula": [{"content": " Hey guys, welcome to another brand new video, I am Aditya and in this video guys, we are checking out some of the simplest code how we write them. So we will be just covering the basic syntax and maybe learn about some more things, extra things. So without wasting time, let's get into the video. So guys, here I have opened a website called as Repul.IT, actually I'll just minimize it so that you can see the link."}, {"content": "So this website is called as Repul.IT, I am not sponsored anyway, I just use it for fun. So this is an online editor, if your system has low specs or anything like that, you can use it, it's completely free and the one thing is that whatever you create will be public and people can see them but no one will actually see them because until you share it. So I have created a C++ file, this actually supports a lot of programming languages. So as we are dealing with C++ right now, so we are using C++ over here and it has actually created a file called as main.cpp. So this actually a main file of our program. And here we have the terminal where the program will run. So I have just kept it in the side and here is the run button. So I hope you are clear with the end it everything and here we have even customizations, you can even do that, no problem."}, {"content": "So now let us start writing code. So first guys, I will just write hashtag include. As you can see, I have got some intelligence and what these are is nothing but header files. So in C++ everything, every file is just like a header file. So header file are just like prewritten code by some developers which we can use it now code. And it comes built in with the compiler. We have installed means the W compiler right. So in that you might have a show new include files, those are nothing but header files and those header files you can use them. So here we are going to, these are sets new map iOS. So these all are some of the header files, C math for math function, time, deck. So these are all the data structures and all those things. We will be including a basic header file which is called as include iOS stream. So you use this angular brackets and here I will just write iOS, TRAM. So as you can see I got it. So this is called as including how we include a file. And here we will be just writing, you can just write this code using name space STD. You don't need to actually worry about what this thing is right now at the beginning. You will soon understand how this thing works. And here we are going to write void main and keep two brackets and two curly braces press enter. And here we can just add some statement like C out. And here how do word and keep an exclamation mark and end it with a semicolon. And now we get okay. So this doesn't allow void actually. So let us write int and now we don't have any problems. So let us actually learn about what this function is doing over here. So int main and here see out hello world. So what exactly is this doing? So this int main this actually called as a function. So in C++ in any C++ program or in C++ file you will have this function called as int main, which is actually the entry point of any program whenever you run a program the compiler will actually look for this function. So this function to look for this function and whatever is there inside it that thing it will execute. Now let me just run this program and it will execute whatever is there inside this. So as you can see I have written C out hello world and it has printed hello world. So I think right now you might have even understood what the C out is. So this is just giving for output. So you use C out to give output to the console and here you use this angular bracket. So you are saying whatever is there on the right hand side just push it into the C out of stream or output stream and even you can take the input also the same way which for which we use C in. You might be a little bit confused about what this thing is using namespace sd. Now I can just keep like this two things and by the way this is called as commenting. So whenever you want to write something between your code which is not actually code and you just want to write so that when others read your code they should also be able to understand it easily. So you can just write like this I can just keep like this two slashes and I can write this basic CPP program. So here I can just add like this text which is just telling me that it is just giving some information about what this file is going to be. You can write actually anything it doesn't matter and usually you commented down like this you give information documentation. So now I have commented down and the compiler won't actually read it. will just ignore it, it won't see, okay there is two hashes then that's nothing, there's no code inside that. And now as soon as they commented it out, if I just remove this, you see the errors go away. And now if I add that, as you can see we got here C out. So here use of undeclared identifier C or did you mean SDDC out? So this actually scope resolution everything. So I can just write SDD call and call and. And now we can actually use the C out without any problem. And whenever we want to write C out, we must always do this SDD call and call and and see out. Which is little bit painful in the beginning. I recommend that you always remove that SDD and you just add this line using namespace SDD. In the future you will understand exactly how this thing works and you can even create your own namespaces. So now let us create some variables and check some operators also. Now guys, as in the previous video we have covered up with the variables and data types. Let us create a variable. So I hope you remember how we create a variable and how we use a data type also. So first I will just create a variable called as my name. So my name equals or I can just keep like this and or I can just write my underscore name. So here we call my underscore name equals the the and close the semicolon. Now here we got some error."}, {"content": "Okay."}, {"content": "Oh my God. I just kept a string into a string. I'll just write SD or I and G. I'm so sorry for the case."}, {"content": "Strength. So string is also a data type. Now the first line here what we are doing is called as declaration declaration and here we are doing initialization. So guys the first line over here is nothing but declaration. So we are saying that there's going to be a variable called as my name and in the seventh line over here or the second line we are creating. We are initializing with with some value. So we are keeping some value inside that variable so that we can even use it in the future and here also it is the same but it doesn't have any value. So this declaration and this is initialization. Now let us try to print it to the console simple things. So you can just write C out and I can just give like this to aros and here I just write my name. So just give the variable name and end it with the semicolon and as you can see the aros quave so always remember to and every statement the semicolon. There are actually places where you should not use semicolon. Most of the places you must add a semicolon. We will understand where we should not add and where we should add in the future lessons. So now let me just run this program and if you can see we got the output. So that was about how we can use a variable inside this and we learnt even about declaration and initialization. Now we will create a new variable and do some operations basic operations. So I will just write int into my number equals 20. So in a single line we are actually declaring it and initializing it with value so that is also possible. So now and even in single line you can even create and write create multiple variables actually. So now we do not need all these variables so I can just close this and here I will write a simple C out statement and I will just write my number plus 1 plus 2 and here I can just end it with a semicolon. And now let us run this program and it should mostly give us 23. So as you can see we got 23 over here I do not know if you are able to see I think you are able to see it. So the answer is 23 which is also right. So that is our basic operators you can even use a minus operator or the subtraction and for multiplication you can use the star and for division you can use this one and I think you have got all those things. We will be covering about operators in a very special video we will be learning about all the previous operators which C++ provides. So it will be a very interesting video and for this video guys that is it we have covered about the basic things where we have understood how the C++ program is structured and we have learnt about the main program or the main function and then we have learnt about the namespace thing we have does that work and we have printed some things to the console using the C out statement we have created some variables and done some basic operations. So guys I think that you might have got some of the idea about how C++ code is actually written and that is it for this video guys. I hope you like this video please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates."}, {"content": "Thanks for watching see you in the next video."}], "Justice: What's The Right Thing To Do? Episode 06: \"MIND YOUR MOTIVE\"": [{"content": "Funding for this program provided by additional funding provided by Now we turn, to the hardest philosopher that we're going to read in this\ncourse today we turn to Immanuel Kant who offers a different account of why we have a categorical duty to respect the dignity of persons and not to be use people as means merely even for good ends. Kant excelled at the university of K\u00f6nigsberg at the age of sixteen at the age of thirty one he got his first job as an unsalaried lecturer paid on commission based on the number of students who showed\nup at his lectures this is a sensible system that Harvard would\ndo well to consider luckily for Kant he was a popular lecturer and also an industrious\none and so he eked out a meager living it wasn't until  he was fifty seven that he published his first major work but it was worth the wait the book was the critique of pure reason perhaps the most important work in all of\nmodern philosophy and a few years later Kant wrote the groundwork for the metaphysics of morals\nwhich we read in this course I want to acknowledge even before we start that Kant is a difficult thinker but it's important to try to figure out what he's saying because what this book is about is well, it's about what the supreme principle of\nmorality this number one, and it's also it gives us an account one of the most powerful accounts we have of what freedom really is so let me start today. Kant rejects utilitarianism he thinks that the individual person all human beings have a certain dignity that commands our respect the reason the individual is sacred or the\nbearer of rights according to Kant, doesn't stem from the idea that we own ourselves, but instead from the idea that we are all rational beings we're all rational beings which simply means that we are beings who are capable of reason. we're also autonomous beings which is to say that we are beings capable of acting and\nchoosing freely now, this capacity for reason and freedom isn't the only capacity we have. we also have the capacity for pain and\npleasure for suffering and satisfaction Kant admits the utilitarians were half a right of course we seek to avoid pain and we like pleasure Kant doesn't deny this what he does deny is Bentham's claim that pain in pleasure are our sovereign masters he thinks that's wrong. Kant thinks that it's are national capacity that makes us distinctive, that makes us special\nthat sets us apart from and above mere animal existence. it makes us something more than just physical creatures with appetites. Now we often think of freedom as simply consisting in doing what we want or in the absence of obstacles to getting\nwhat we want that's one way of thinking about freedom. but this isn't Kant's idea of freedom Kant has a more stringent demanding notion of what it means to be free and though stringent and demanding, if you think it  \nthrough it's actually pretty persuasive Kant\u2019s reason is as follows when we, like animals seek after pleasure or the satisfaction of our desires of the\navoidance pain when we do that we aren't really acting\nfreely. why not? we're really acting as the slaves  of those appetites and impulses I didn't choose this particular hunger or\nthat particular appetite, and so when I act to satisfy it I'm just acting according to natural necessity and for Kant, freedom is the opposite of necessity there was an advertising slogan for the soft drink Sprite a few years ago the slogan was obey your thirst there there's a Kantian insight buried in that Sprite advertising slogan that in a way is Kant's point when you go for Sprite, or Pepsi you're really you might think that you're choosing freely\nsprite versus Pepsi but you're actually obeying something, a thirst, or maybe a desire manufactured\nor massaged by advertising you're obeying a prompting that you yourself haven't chosen or created and here it's worth noticing Kant\u2019s specially demanding idea of freedom what way of acting, how can my will be determined if not\nby the prompting sub nature or my hunger or my\nappetite, or my desires? Kant's answer: to act freely is to act autonomously and to act autonomously is to act according to a law that I give\nmyself not according to the physical laws of nature or to the laws of cause and effect which include my desire, to eat or to drink or to choose this food in a restaurant over that now what is the opposite what is the opposite of autonomy for Kant he invest a special term to describe the opposite of autonomy heteronomy is the opposite of autonomy when I act heteronomously I'm acting according to an inclination or a desire that I haven't chosen for myself so freedom is autonomy is this specially stringent idea that Kant insists on. now why is autonomy the opposite of the acting heteronomously or\naccording to the dictates of nature Kant\u2019s point is that nature is governed by laws laws of cause and effect for example suppose you drop a billiard ball it falls to the ground we wouldn't say the billiard ball is acting\nfreely why not? it's acting according to the law of nature according to the laws of cause and effect the law of gravity and just as he has an unusually demanding and stringent conception of freedom, freedom as autonomy, he also  has a demanding conception of morality to act freely is not to choose the best means to a given\nend it's to choose the end itself for its own sake and that's something that human beings can do and that billiard balls can\u2019t insofar as we act on inclination or pursue pleasure we fact as means to the realization of ends given outside us we are instruments rather than authors of the purposes we pursue that's the heteronomous determination of the\nwill on the other hand insofar as we act autonomously according to law we give ourselves we do something for its own sake as an end in itself when we act autonomously we cease to be instruments to purposes given outside us we become what we can come to think of ourselves as ends in ourselves. this capacity to act freely Kant tells us is what gives human life its special dignity. respecting human dignity means regarding persons not just as means but also as ends in them and this is why it's wrong to use people for the sake of other people's well being or happiness this is the real reason Kant says that utilitarianism goes wrong this is the reason it's important to respect\nthe dignity of persons and to uphold their rights. so even if there are cases remember John Stuart Mill said well in the\nlong run if we uphold Justice and respect the dignity of persons we will maximize human happiness. What would Kant's answer be to that? what would his answer be? even if that were true even if the calculus worked out that way even if you shouldn't throw the Christians\nto the lions because in the long run fear will spread, the overall utility will decline, the\nutilitarian would be upholding Justice and rights and\nrespect for persons for the wrong reason for a purely contingent reason for an instrumental reason it would still be using people even where the\ncalculus works out for the best in the long run, it would still\nusing people as means rather than respecting them as ends in themselves. so that's Kant's idea of freedom as autonomy and you can begin to see how it's connected to his idea of morality but we still have to answer one more question what gives an act it's moral worth in the first place if it can't be directed at utility or satisfying wants or desires,  what do you think gives an action it's moral worth? this leads us from Kant\u2019s demanding idea of freedom to his demanding idea of morality. What does Kant say? what makes and action morally worthy consists not in the consequences or in the\nresults that flow from it what makes an action morally worthy has to do with the motive with the quality of the will with the intention for which the act is down what matters is the motive and the motive must be of a certain kind. so the moral worth of an action depends on the\nmotive for which it's done and the important thing is that the person do the right thing for the right reason a goodwill isn't good because of what it affects or accomplishes,\nKant writes, it's good in itself even if by its utmost effort to goodwill accomplishes\nnothing it would still shine like a jewel for its own\nsake as something which has its full value in itself and so for any action to be morally good it's not enough that it should conform to the moral law it must also be done for the sake of the moral\nlaw. the idea is that the motive confers the moral worth on an action and the only kind of motive that can confirm moral worth on an action is the motive of duty well what's the opposite of doing something out of a sense of duty\nbecause it's right, well for Kant the opposite would be all of those motives having to do\nwith our inclinations and inclinations refer to all of our desires, all of our contingently given wants preferences impulses and the like only actions done for the sake of the moral\nlaw for the sake of duty only these actions have moral worth now I want to see what you think about this idea but first let's consider a few examples Kant begins with an example of a shopkeeper he wants to bring out the intuition and make plausible the idea that what confers moral worth on an action is\nthat it be done because it's right he says suppose there's a shopkeeper and an inexperienced customer comes in the shopkeeper knows that he could give the customer the wrong\nchange could shortchange the customer and get away with it at least that customer wouldn't know but the shopkeeper nonetheless says well if\nI shortchange this customer word may get out my reputation would be damaged and I would\nlose business so I won't shortchange this customer the shop keeper does nothing wrong he gives a correct change but does this action have moral worth? Kant says no. it doesn't have moral worth because the shopkeeper only did the right thing for the wrong reason out of self-interest that's a pretty straightforward case. then he takes another case the case of suicide. he says we have a duty to preserve ourselves now, for most people who love life, we have multiple reasons for not taking our own lives so the only way we can really tell the only way we can isolate the operative\nmotive for someone who doesn't take his or her life is to think to imagine someone who's miserable and who despite  having an absolutely miserable life nonetheless recognizes the duty to preserve one's self and so does not commit suicide. the force of the example is to bring out the motive that matters and the motive that matters for morality is doing\nthe right thing for the sake of duty. let me just give you a couple of other examples the better business bureau what's their slogan, the slogan of the better business bureau? honesty is the best policy it's also the most profitable. this is the\nbetter business bureaus full page ad in the new York times honesty it's as important as any other asset because a business the deals in truth, openness\nand fair value cannot help but do well come join us and profit from it What would Kant say about the moral worth of the honest dealings that members of the better business bureau. What he says that here's a perfect example that if this is the reason that these companies deal honestly with their\ncustomers their action lacks moral worth this is Kant\u2019s point or couple of years ago at the university\nof Maryland there was a problem with cheating and so they initiated an honor system and they created a program with local merchants that if you signed the honor pledge\nnot to cheat you would get discounts often to twenty five\npercent of local shops now what would you think of someone motivated to uphold an honor code with all the discounts it's the same as Kant\u2019s shopkeeper the point is what matters is the quality of the will the\ncharacter of the motive and the relevant motive to morality can only be the motive of duty not the motive of inclination. and when I act out of duty and when I resist as my motive for acting inclinations or self-interest even sympathy and altruism, only then am I acting freely. only then and I acting autonomously, only then is my will not determined or governed by external considerations. that's the link between Kant\u2019s idea of freedom and of  morality. now I want to pause here the see if all of this is clear or if you have some questions or puzzles they can be questions of clarification or they can be challenges if you want to challenge this idea that only the motive of duty confers moral worth on the action\naction what do you think I actually have two questions of clarification the first is there seems to be an aspect\nof this that makes it sort of self-defeating in that once you\u2019re conscious of  what morality is you can sort of alter your\nmotive to achieve that end of morality give me an example what do you have in mind the shopkeeper example if he decides that he wants to give the person of\nmoney is to do the right thing and he decides that\u2019s his motive to do so because he was the moral then isn't that sort\nof defeating trying to isn't that sort of defeating the purity of his action\nif  morality is determined by his motive is his motive is to act morally so you're imagining a case not of the purely selfish calculating shopkeeper but of one who says well he may consider shortchanging the customer but then he says not, while my reputation might suffer if word\ngets out, but instead he says actually  I would like to be the kind of honest person who gives the right change to customers simply because it's the right thing to do or simply because I want to be moral because I want to be moral I want to be a good person and so I'm going to conform all of my actions to\nwhat morality requires it's a subtle point, it's a good question Kant does acknowledge you're pressing Kant on an important point here, Kant does say there has to be some incentive to obey the moral law it can't be a  self-interested incentive that would defeat it by definition so he speaks of a different kind of incentive from an inclination\nhe speaks of reverence for the moral law so if that shopkeeper says I want to develop a reverence for the moral law and so I'm going to act, so I'm going to\ndo the right thing then I think he's there, he's there as far as Kant\u2019s concerned because he's formed his motive his will is conforming to the moral law once he sees the importance of it so it would count it would count and secondly very quickly what stops morality from becoming completely\nobjective in this point? what stops morality from becoming completely subjective, yea, like how can if there's, if morality is completely\ndetermined by your morals then how can you apply this or how can it be enforced?"}, {"content": "that's also a great question, what's your name?"}, {"content": "my name's Ahmady. Ahmady? all right if acting morally means acting according to a moral law out of duty and if it's also to act freely in the sense of autonomously it must mean that I'm acting according to a law that I give\nmyself that's what it means to act autonomously Ahmady is right about that  but that does raise a really interesting\nquestion if acting autonomously means acting according to a law\nI give myself that's how I escape the chain of cause and effect and the laws of nature what's to guarantee that the law I give myself when I'm acting out of duty is the same as the law that Ahmady is giving himself and that each of you gives yourselves well here's the question how many moral laws from Kant\u2019s point of view are there in this\nroom are there a thousands or is there one he thinks there's one which in a way does go back to this question\nall right what is the moral law, what does it tell us so what guarantees, it sounds like it to act autonomously is to act according\nto one's conscience according to a law one gives oneself but what guarantees that we, if we all exercise our reason we will\ncome up with one and the same moral law? that's what Ahmady wants to know. here's Kant's answer, the reason that leads us to the law we give ourselves as autonomous beings is a reason it's a kind of practical reason that we share as human beings it's not idiosyncratic the reason we need to respect the dignity of persons is that we're all rational\nbeings we all have the capacity for reason and it's the exercise of that capacity for a\nreason which exist undifferentiated in all of us that makes us worthy of dignity, all of us and since it's the same capacity for reason unqualified by particular autobiographies and circumstances it's the\nsame universal capacity for reason that delivers the moral law it turns out that to act autonomously is to act according to a law we give ourselves exercising our reason but it's the reason we share with everyone as rational beings not the particular reason we have given\nour upbringing, our particular values our particular interests it's pure practical reason in Kant's terms which legislates apriori regardless of any particular contingent or empirical ends. Well what moral law would that kind of reason deliver? what is its content?"}, {"content": "to answer that question you have to read the groundwork and we'll continue with that question next\ntime. For Kant,  morally speaking suicide is on a par with murder it's on a par with murder because what we violate when we take a life when we take someone's life, our's or somebody\nelse's, we use that person we use a rational being we use humanity as a means and so we fail to respect humanity as an end today we turn back to Kant, but before we do remember this is the week by the end of which all of you will basically get Kant, figure out what he's\nup to you're laughing no, it will happen Kant's groundwork is about two big questions, first what is the supreme principle of morality second how is freedom possible? two big questions now, one way of making your way through this dense philosophical book is to bear in mind a set of opposition or contrasts or\ndualisms that are related. today I\u2019d like to talk about them today we're going to answer the question, what\naccording to Kant, is the supreme principle of morality and in answering that question in working\nour way up to Kant\u2019s answer to that question, it will help to bear in mind three contrasts or dualisms that Kant sets out the first you remember had to do with the motive according to which we act and according to Kant, only one kind of motive is consistent with morality the motive of duty doing the right thing for the right reason what other kinds of motives are there Kant sums them up  in the category inclination every time the motive for what we do is to satisfy a desire or a preference that we may have, to pursue\nsome interest we're acting out of inclination now let me pause to see if if in thinking about the question of the motive of duty of good\nwill see if any of you has a question about that much of Kant's claim. or is everybody happy with this distinction what do you think? go ahead. when you make that distinction between duty and\ninclination is there ever any moral action ever? I mean you could always kind of probably find some \nkind of some selfish motive, can't you? maybe very often people do have self-interested\nmotives when they act Kant wouldn't dispute that but what Kant is saying is that in so far as we act morally that is in so far as our actions have\nmoral worth what confers moral worth is precisely our capacity to rise above self-interest and\nprudence and inclination and to act out of duty some years ago I read about a spelling bee and there was a young man who was declared the winner of the spelling bee a kid named Andrew, thirteen years old the winning word, the word that he was able\nto spell was echolalia does anyone know what echolalia is? it's not some type of flower no, it is the tendency to repeat as an echo, to repeat\nwhat you've heard anyhow, he misspelled it actually but the judges misheard him they thought\nit spelled it correctly and awarded him the championship of the national spelling bee and he  went to the judges afterward and said actually I misspelled it I don't deserve the prize and he was regarded as a moral hero and he was written up in the new York times misspeller is the spelling bee hero there's Andrew with is proud mother and but when he was interviewed afterwards listen to this, when he was interviewed afterwards he said quote the judges said I had a lot of integrity but then he added that part of his motive was quote I didn't want to feel like a slime all right what would Kant say? I guess it would depend on whether or not that was a marginal reason or the predominant reason\nin whether not and why he decided to confess that he didn't actually spell the word\ncorrectly good and what's your name. Vasco."}, {"content": "that's very interesting is there anyone else who has a view about this? does this show that Kant\u2019s principle is too stringent too demanding what would Kant say about this? yes I think that Kant actually says that it is the pure motivation that comes out\nof duty that gives the action moral worth, so it's like for example in this case he might have more than one motive, he might\nhave a motive of not feeling like a slime and he might have to move of  doing the right thing in and of itself out of duty and so while there's\nmore than one motivation going on there does not mean that action is devoid of moral\nworth just because he has one other motive so because the motive which involves duty is\nwhat gives it moral worth. goo, and what's your name? Judith well Judith I think that your account actually\nis true to Kant it's fine to have sentiments and feelings that support doing the right thing provided they don't provide the reason for acting so I think Judith has actually a\npretty good defense of Kant on this question of the motive of duty, thank you now let's go back to the three contrasts it's clear at least what Kant means when he\nsays that for an action to have moral worth it must be\ndone for the sake of duty not out of inclination but as we began to see last time there's a connection between Kant\u2019s stringent notion of morality and especially demanding understanding of freedom and that leads us to the second contrast the link between morality and freedom a second contrast describes two different ways that my will can be determined autonomously and heteronomously according to Kant I'm only free when my will is determined autonomously which means what? according to a law that I give myself we must be capable, if we're capable of freedom\nas autonomously, we must be capable of acting accordingly\n0:37:26.0laws that's given or imposed on us but according to a law we give ourselves but where could such a law come from? a law that we give ourselves? reason, if reason determines my will then the real becomes to power to choose independent of the dictates of nature or inclination or circumstance so connected with Kant\u2019s demanding notions of morality and freedom is especially demanding notion of reason well how can reason determine the will there are two ways and this leads to the third\ncontracts Kant says there are two different commands of reason in a command of reason Kant calls an imperative an imperative is simply an ought one kind of imperative, perhaps the most familiar\nkind, is a hypothetical imperative. hypothetical imperatives use instrumental reason if you want x then do y it's means ends reason. if you want a good business reputation then don't shortchange your customers word may get out. that's a hypothetical imperative. if the action would be good solely as a means to something else Kant writes,\nthe imperative is hypothetical if the action is represented as good in itself and therefore as necessary for a will which of itself accords with reason then the imperative categorical. that's the difference between a categorical imperative and a hypothetical\none a categorical imperative commands categorically which just means without reference to or\ndependents on any further purpose and so you see the connection among these three parallel contrasts to be free in the sense of autonomous requires that I act not out of a hypothetical imperative but out of the categorical imperative so you see by these three contrasts Kant reasons his way  brings us up to you he's derivation of the categorical imperative well this leaves us one big question what is the categorical imperative? what is the supreme principle of morality what does it command of us? Kant gives three versions three formulations of the categorical imperative. I want to mention two and then see what you think of them. the first version the first formula he calls the formula of the universal law act only on that maxim whereby you can at the same time will that\nit should become a universal law and by maxim what does Kant mean? he means a rule that explains the reason for what you're doing a principle for example promise keeping suppose I need money, I hundred dollars desperately and I know I can't pay it back anytime soon I come to you and make you a promise, a false promise, one\nI know I can't keep please give me a hundred dollars today lend me the money I will repay you next week is that consistent with the categorical imperative, that false\npromise Kant says no and the test the way we can determine that the false promise is at odds with categorical imperative is try to universalize it. universalize the maxim upon which you're about\nto act if everybody made false promises when they needed\nmoney then nobody would believe those promises there\nwould be no such thing as a promise and so there would be a contradiction the maxim universalized would undermine\nitself that's the test that's how we can know that the false promise is wrong well what about the formula of the universal law you find it persuasive? what do you think? I have a question about the difference between\ncategoricalism and a hypothesis that  if you're going to act.. Between categorical\nin hypothetical  imperatives? right. if you\u2019re going to act with a categorical imperative so that the maxim doesn't undermine itself it sounds like I am going to do X because\nI want y I'm going to not lie in dire need because I want the world to function in such\na way that promises kept. I don't want to liquidate the practice\nof promises. Right. it sounds like justifying a means by an ends it seems like an instance of consequentialist\nreasoning you're saying. and what's your name?"}, {"content": "Tim. well Tim John Stuart Mill agreed with you he made this criticism of Kant he said if I universalize the maximum and find that the whole practice of promise keeping\nwould be destroyed if universalized I must be appealing somehow to consequences if that's the reason not to tell a false promise so John Stuart Mill agreed with that criticism\nagainst Kant but John Stuart Mill was wrong you're in good company though you're in good company, Tim Kant is often read as Tim  just read him as appealing to consequences the world would be worse off if everybody lied because then nobody could\nrely on anybody else's word therefore you shouldn't lie that's not what Kant is saying exactly although it's easy to interpret him as saying that I think what he's saying is that this is the test this is the test of whether the maxim corresponds with the categorical imperative it isn't exactly the reason it's not the reason the reason you should universalize to test your maxim is to see whether you are privileging your particular needs and desires over everybody else's it's a way of pointing to this feature to this this feature to this demand of the categorical  \nimperative that the reasons for your actions shouldn't depend or their justification on your interests, your needs, your special\ncircumstances being more important than somebody else's that I think is the moral intuition lying\nbehind the universalization test so let me spell out the second Kant\u2019s second version of the categorical imperative perhaps in a way that's more intuitively accessible than the formula of universal law it's the formula of humanity as an end Kant introduces the second version of the categorical imperative with the following line of argument we can't base the categorical imperative on any particular interests, purposes, or ends because then it would be only relative to the person whose ends they\nwere but suppose there was something whose existence has in itself and absolute value an end in itself then in it and in it alone would there be the ground of a possible a\ncategorical imperative well, what is there that we can think of as having it's end in\nitself Kant\u2019s answer is this I say that man and in general every rational being exists as an end in himself not nearly as a means for arbitrary use by this or that will and here Kant distinguishes between persons on the one hand and things on the other rational beings are persons the don't just have a relative value for us but if anything has they have an absolute\nvalue an intrinsic value that is rational beings have dignity they're worthy of reverence and respect this line of reasoning leads Kant to the second formulation of the\ncategorical imperative which is this act in such a way that you always treated humanity whether in your own person or in the person of any other never simply as a means but always at the same time as an end so that's the formula of humanity as an end the idea that human beings as rational beings are ends in themselves not open to use merely as a means when I make a false promise to you I mean using you as a means to my ends to my desire for the hundred dollars and so I'm failing to respect you, I'm failing to respect your dignity I'm manipulating you now consider the example of the duty of against suicide murder and suicide are at odds with the categorical imperative\nwhy? if I murdered someone I'm taking their life for some purpose. either because I'm a hired killer or I'm in the throws of some great anger\nor passion well I have some interest or purpose that is particular for the sake of which I'm using them as a means murder violates the categorical imperative for Kant, morally speaking suicide is on a par with murder it's on a par with murder because what we\nviolate when we take a life when we take someone's life our's or somebody\nelse's we use that person we use a rational being we use humanity as a means and so we fail to respect humanity as an end and that capacity for reasons that humanity that commands respect that is to ground of dignity that humanity that capacity for a reason resides undifferentiated in all of us and so I violate that dignity in my own person if I commit suicide and in murder if I take somebody else's life from a moral\npoint of view they're the same and the reason they're the same has to do with the universal character and ground of the moral law the reason that we have to respect the dignity of other people has not to do with anything in particular about them and so respect, Kantian respect is\nunlike love in this way it's unlike sympathy it's unlike solidarity or fellow feeling\nfor altruism because love and those other particular virtues\nare reasons for caring about other people have to do with who they are in particular but respect for Kant respect is respect for  humanity which is universal for a rational capacity which is universal and that's why violating it in my own case is as objectionable as violating it in the case of any other questions or rejections? I guess I'm somewhat worried about Kant\u2019s statement that you cannot use a person\nas a means because every person is an end in and of themselves because it seems that that everyday in order to get something accomplished\nfor that day I must use myself as a means to some end and I must use the people around me as a means\nto some ends as well for instance suppose that I want to do well in a class and I have to write a\npaper I have to use myself as a means to write the paper suppose I want to buy something, food. I must go to the store, use the person working behind the counters as a means for me to  \npurchase my food. You're right, that's true what's your name? Patrick Patrick you're not doing anything wrong you're not violating the categorical imperative when you use other people as a means that's not objectionable provided when we deal with other people for the sake\nof advancing our projects and purposes and interests, which we all do, provided we treat them in a way that is consistent with respect for their dignity and what it means to respect them is given by the categorical imperative. are you persuaded? do you think that Kant has given a compelling account a persuasive account of the supreme principle of morality? re-read the groundwork and we'll try to answer that question next\ntime. don't miss the chance to interact online with other  \nviewers of Justice join the conversation, take a pop quiz catch up on lectures you've missed, and learn a lot  \nmore. Visit justiceharvard.org it's the right thing to do funding for this program is provided by additional funding provided by"}], "Justice: What's The Right Thing To Do? Episode 05: \"HIRED GUNS\"": [{"content": "Funding for this program is provided by Additional funding provided by When we ended last time we were discussing Locke's idea of government\nby consent and the question arose what are the limits on government that even the the agreement of the majority can't override that was the question we ended with we saw in the case of property rights that on Locke's view a democratically elected government has\nthe right to tax people it has to be taxation with consent because it does involve the taking of people's\nproperty for the common good but it doesn't require the consent of the each individual at the time the tax is enacted or collected what it does require is a prior act of consent to join the society to take on the political obligation but once you take on that obligation you agree\nto be bound by the majority so much for taxation but what, you may ask about the right to life can the government conscript people and send them into battle what about the idea that we own ourselves is the idea of self possession violated if the government can through coercive legislation and enforcement\npowers say you must go risk your life to fight in Iraq what would Locke say? does the government have\nthe right to do that? yes in fact he says in one thirty nine he says what matters is that the political authority or the military authority not be arbitrary that's what matters he gives a wonderful example he says a a sergeant even a sergeant let alone a general, a sergeant can command a soldier to go right up to the face of a cannon where he is almost sure to die that the sergeant can do the general can condemn the soldier to death\nfor deserting his post or for not obeying even a desperate order but with all their power over life and death what these officers can't do is take a penny of that soldier's money because that has nothing to do with the rightful authority that would be arbitrary and it would be corrupt so consent winds up being very powerful in\nLocke, not consent of the individual to the particular tax or military order, but consent to join the government and to be \nbound by the majority in the first place that's the consent that matters and it matters so powerfully the even the limited government created by\nthe fact that we have an unalienable right to life liberty and property even that limited government is only limited\nin the sense that it has to govern by generally applicable laws, the rule of law, it can't\nbe arbitrary that's Locke. well this raises a question about consent. Why is consent such a powerful moral instrument in creating political authority and the obligation\nto obey today we begin to investigate the question\nof consent by looking at a concrete case the case of military conscription. now some people say if we have a fundamental right that arises from the idea that we own ourselves it's a violation of that right for a government to conscript citizens to go fight in wars. others disagree others say that's a legitimate power of government, of democratically elected government\nanyhow, and that we have an obligation to obey let's take the case the united states fighting a war in Iraq. news accounts tell us that the military is having great difficulty meeting its recruitment targets consider three policies that the US government might undertake to deal with the fact that it's not achieving its recruiting targets solution number one increase the pay and benefits to attract a sufficient number of soldiers, option number two shift to a system of military conscription have a lottery and who's ever numbers are drawn go to fight in Iraq, system number three outsource, hire what traditionally have been called mercenaries people around the world who are qualified, able to do the work, able to fight well and who are willing to do it for the existing wage so let's take a quick poll here how many favor increasing the pay? huge majority. how many favor going to conscription? all right maybe a dozen people in the room favor conscription. what about the outsourcing solution? okay so there maybe  about two, three dozen. during the civil war the union used a combination of conscription and the market system to fill the ranks of the military to fight in\nthe civil war it was a system that began with conscription but if you were drafted and didn't want to serve you could hire a substitute take your place and many people did you could pay whatever the market required in order to find a substitute people ran ads in newspapers in the classified ads offering five hundred dollars sometimes a thousand dollars for a substitute who would go fight the civil war in their place in fact it's reported that Andrew Carnegie was drafted and hired a substitute to take his place for an amount that was a little less than the amount to spend for\na year on fancy cigars now I want to get your views about this civil war system call it the a hybrid\nsystem conscription but with the buyout provision how many think it was a just system how many\nwould defend the civil war system? anybody?"}, {"content": "one, anybody else? to three four five. how many think it was unjust? most of you don't like the civil war system\nyou think it's unjust, let's hear an objection why don't you like it? what's wrong with it?"}, {"content": "yes. well by paying three hundred dollars for to be exempt one time around you're really putting\na price on valuing human life and we established earlier that's really hard\nto do so they're trying to accomplish something that\nreally isn't feasible. good, so so paying someone three hundred or five hundred or a\nthousand dollars you're basically saying that's what their life\nis worth you. that's what their life is worth it's putting a dollar value on life that's good, and what's your name? Liz. Liz. well who has an answer for Liz you defended the civil war system what do you say? if you don't like the price then you have the freedom to not be sold or for  so it's up to you and I don't think it's necessarily\nputting a specific price on you and if it's done by himself I don't think there's anything\nthat's really morally wrong with that. So the person who takes the five hundred dollars let's say, he's putting his own price on his life on the risk of his life and he should have the freedom to choose to\ndo that. exactly."}, {"content": "what's your name? Jason. Jason thank you. now we need to hear from another critic of\nthe civil war system. yes. it's a kind of coercion almost of people who\nhave lower incomes for Carnegie he can totally ignore the draft three hundred dollars\nis you know irrelevant in terms of his income, \nbut for someone of a lower income they are essentially being coerced to draft to be drafted or I mean it's probably they're not able to find a\nreplacement the tell me your name. Sam. Sam, all right so you say Sam that when a poor laborer buys his, accepts three hundred dollars to fight\nin the civil war he is in effect being coerced by that money given his economic circumstances whereas Carnegie can go off pay the money and not serve I want to hear if someone has a reply to Sam's argument that what looks like a free exchange is actually coercive who has an answer to to Sam. go ahead I'd actually agree with him. You agree with him I agree with him in saying that it is coercion in the sense that it robs an individual of his ability to reason properly okay and what's your name? Raul. ok so Raul and Sam  agree that what looks like a free exchange, free choice\nvoluntary act is actually coercion it involves coercion it's profound coercion of the worst kind because\nit falls so disproportionately upon one segment of society good, all right so Raul and Sam have made a powerful point who would like to reply who has an answer for Sam and Raul? Go ahead I just I don't think that these drafting systems are\nreally terribly different from you know all volunteer army sort of recruiting strategies the whole idea of you know having benefits in pay for joining the\narmy is you know sort of a coercive strategy to get people to  join it is true that military volunteers come from disproportionately,\nyou know, lower economic status and also from certain regions of the country\nwhere you can use the patriotism to try and coerce people,\nif you're like it's the right thing to do to volunteer to go over to Iraq. and tell me your name. Emily. alright Emily  says  and Raul you're going to have to reply to\nthis so get ready Emily says fair enough there is a coercive element to the civil war system when the laborer takes the place of Andrew Carnegie for five\nhundred dollars Emily concedes that but she says if that troubles you about the civil war system shouldn't that also trouble you about the volunteer army today? and let me,  before you answer, how did you vote on the\nfirst poll, did you defend a volunteer army? I didn't vote. you didn't vote. either way you didn't vote but did you sell your vote to the person sitting\nnext to you? no, all right so what would you say to that argument? I think that the circumstances are different and\nthat there was conscription in the civil war there is no draft today and I think that the volunteers for the army today have a more profound sense of patriotism that is\nof an individual choice than those who were forced into the military in the civil war somehow less coerced. less coerced. even though  there is still inequality in American society\neven though as Emily points out the make-up of the American military is not reflective\nof the population as a whole. Let\u2019s just do an experiment\nhere how many here have either served in the military or have a family member who has served in the military in this generation not parents family members in this generation and how many have neither served nor I have any brothers or sisters who have served does that bear out your point Emily? Alright now we need we need to hear from most of you defended the idea of the of the all-volunteer military overwhelmingly and yet overwhelmingly people consider the civil war system unjust Sam and Raul  articulated reasons for objecting to the civil war system it took place against a background of inequality and therefore the choices people made to\nbuy their way into military service were not truly free but at least partly coerced then Emily extends that argument in the form of a challenge all right everyone here who voted in favor of the all-volunteer army should be able should have to explain well what's the difference in principle doesn't the all-volunteer army  simply universalize the feature that almost everyone find objectionable in the civil war buy-out provision did I state that challenge fairly Emily? ok, so we need to hear from a defender of the all-volunteer military who can address Emily's challenge who can do that? Go ahead the difference between the civil war system\nand the all-volunteer army system is that in the civil war you're being hired not by the government but\nby individuals and as a result different people to get hired\na different individuals, get paid different in the case of the all-volunteer army\neveryone who gets hired is hired by the government and gets paid the same amount it's precisely the universalization of all of essentially paying your service you pay your\nway to the army that makes the all  volunteer army just. Emily? I guess I'd frame the principal \nslightly differently, on the all-volunteer army it's possible for somebody to just\nstep aside and not really think about, you know, the war at all. it's possible to say well I \ndon't need the money, you know I don't need to have an opinion about this\nI don't need to feel obligated to take my part and defend my country with a coercive system, I'm sorry,  with an explicit draft, then you know there's the threat at least that every\nindividual will have to make some sort of decision you know, regarding military conscription and you\nknow perhaps in that way it's more equitable you know it's true that Andrew Carnegie might not serve in any case\nbut in one you know he can completely step aside from it and in the other there is some level\nof responsibility. While you're there Emily,  so what system do you favor conscription I would be hard to say but I think so\nbecause it makes the whole country feel a sense of responsibility for the conflict instead\nof you know having a war that's maybe ideologically supported by a few but only if there's no you know, real responsibility. good. who wants to reply, go ahead. so I was going to say that  the fundamental difference between the \nall-volunteer army and then the army in the civil war is that in all volunteer army if you want to volunteer\nthat fact comes first and then the pay  comes after whereas in the civil wars system the people who are volunteering, who are accepting the pay aren't necessarily doing it because they want to, they're just doing it for\nthe money first. what motivation beyond the pay do you think is operating in the case of the all volunteer army? Like patriotism for the country. patriotism well what about pay. And a desire to defend the country and  there's some motivation in pay but the fact that it's first and foremost in an all-volunteer army\nwill motivate them first, I think personally okay you think it's better, and tell me your\nname. Jackie. Jackie do you think it's better if people\nserve in the military out of a sense of patriotism than just for the money yes definitely because that people who that was one of the main problems in the civil\nwar I mean is that the people that you're getting\nto go in it or to go to war aren't necessarily people who want to fight and\nso they won't be as good soldiers as they will be had they been there because they wanted\nto be all right what about Jackie\u2019s having raised the question of patriotism that patriotism is a better or a higher motivation\nthan money for military service who, who would like to address that question? patriotism absolutely is not necessary\nin order to be a good soldier because mercenaries can do just as good of a job of the job as anyone who waves the American flag around and wants\nto defend what the government believes that\nwe should do. did you favor the outsourcing solution? yes sir. all right so let  Jackie respond, what's your name? Phillip what about that Jackie? so much for patriotism if you've got someone who's heart is in it more than another person's they're going to do a\nbetter job when it comes down to the wire and there is like a situation in which someone has to put their life on the line someone who is doing it because they love this country will be more willing to go into danger than\nsomeone who's just getting paid they don't care they've got the technical skills but they don't care what happens because the\nreally have they have nothing, like, nothing invested in this country there's another aspect though once we\nget on to the issue of patriotism if you believe patriotism as Jackie does, should be the foremost consideration and not money does that argue for or against the paid army we have now we call it the volunteer army, though if you\nthink about it that's a kind of a misnomer a volunteer army as we use the term is\na paid army. so what about the suggestion that patriotism should be the primary motivation for military service not money? does that argue in favor of the paid military that we have or does it argue for conscription and just to sharpen that point building on Phil's\ncase for outsourcing if you think that the all-volunteer army, the paid army is best because it lets the market allocate positions according to people's preferences\nand willing willingness to serve for a certain wage doesn't the logic that takes you from a system of conscription to the hybrid civil war system to the all-volunteer army doesn't the the idea of expanding freedom of choice in the market doesn't that lead you all the way if you followed\nthat principle consistently to a mercenary army? and then if you say no Jackie says no, patriotism should count for something doesn't that argue for going back to conscription if by patriotism\nyou mean a sense of civic obligation let's see if we can step back from the discussion that we've had and see what we've learned about consent as it applies to market exchange. we've really heard two arguments two arguments against the use of markets and exchange in the allocation of military service one was the argument raised by Sam and Raul the argument about coercion the objection that leading the market allocate military service may be unfair and may not even be free if there is severe inequality in this society so that people who buy their way into military service are doing so not because they really want to but because they have so few economic opportunities\nthat that's their that's their best choice and Sam and Raul say there's an element of coercion\nin that that's one argument. then there is a second objection to using the market to allocate military service that's the idea that military service shouldn't be treated as just another job for\npay because it's bound up with patriotism and civic obligation this is a different argument from the argument about unfairness and inequality and coercion it's an argument that suggests that maybe\nwhere civic obligations are concerned we shouldn't allocate duties and rights by the market now we've identified two broad objections what do we need to know to assess those objections to assess the first the argument from coercion\ninequality and fairness, Sam, we need to ask what inequalities in the background conditions\nof society undermine the freedom of choices people make to buy and sell their labor question number one. question number two, to assess the civic obligation\npatriotism argument we have to ask what are the obligations of citizenship is military service one of them or not what obligates us as citizens what is the\nsource of political obligation is it consent or are there some civic obligations we have even without consent for living in sharing in a certain kind of society. we haven't answered either of those questions but our debate today about the civil war system and the all-volunteer\narmy has at least raised them and those are questions we're going to return\nto in the coming weeks. Do you think you should be able to bid for a baby that's up for adoption? That's Andrew's Challenge. Do I think that I should be able to bid for a baby? I'm not, sure. it's a market. today at I\u2019d like to turn our attention and get your views about an argument over the role of markets in the realm of human reproduction and procreation. now with infertility clinics people advertise for egg donors and from time to time in the Harvard Crimson ads appear for egg donors, have you seen\nthem? there was one that ran a few years ago it wasn't looking for just any egg donor, it was an ad that offered a large financial\nincentive for a donor from a woman who was intelligent athletic at least five foot ten and with at least fourteen hundred or above on her SAT's how much do you think the person looking for this together was willing\nto pay for an egg from a woman of that description what would you guess? thousand dollars? fifteen thousand? ten? I\u2019ll show you the ad fifty thousand dollars for an egg but only a premium egg what do you think about that? well there are also sometimes ads in the Harvard crimson and in a other college\nnewspapers for sperm donors so the market in reproductive capacities is an equal opportunity market well not exactly equal opportunity they're\nnot offering fifty thousand dollars for sperm but there is a company a large commercial sperm bank that markets sperm it's called California cryobank it's a for-profit company it imposes exacting standards on the sperm it recruits and it has offices in Cambridge between Harvard and MIT and in Palo alto near Stanford cryobank's marketing materials play up the prestigious source of its sperm here is  from the web site of cryobank the information here they talk about the compensation although compensation should not be the only\nreason for becoming of sperm donor we are aware of the considerable time and\nexpense involved in being a donor so you know what they offer? donors will be reimbursed seventy five dollars per specimen up to nine hundred dollars a month if you\ndonate three times a week and then they add, we periodically offer incentives such as such as movie tickets our gifts certificates for the extra time\nand effort expended by participating donors it's not easy to be a sperm donor they accept fewer than five percent of the\ndonors who apply their admission criteria are more demanding than Harvard's the head of the sperm bank said the ideal sperm donor is six feet tall with a college degree brown eyes blond hair and dimples for the simple reason that these are the traits that the market has shown the customers want quote, quoting the head of the sperm bank, if our\ncustomers wanted high school dropouts we would give them high school dropouts. so here are two instances the market in eggs for donation and the market\nin sperm that raise a question a question about whether eggs and sperm should or should not be bought and sold for money. as you ponder that I want you to consider another case involving a market and in fact a contract in human reproductive, in the human reproductive capacity and this is the case of commercial surrogate motherhood. and it's a case that wound up in court some years ago it's the story of baby M it began with William and Elizabeth Stern, a professional couple wanting a baby but they couldn't have one of their own, at least not without medical risk to Mrs. Stern. they went to an infertility clinic where they met Mary Beth Whitehead a twenty nine-year-old mother of two the wife of a sanitation worker she had replied to and ad that the center had placed seeking the service of a surrogate mother they made a deal they signed a contract in which William Stern agreed to pay Mary Beth Whitehead a ten thousand dollar\nfee plus all expenses in exchange for which Mary Beth Whitehead agreed to be artificially\ninseminated with William Stern's sperm, to bear the child and then to give the baby to the Sterns well you probably know how the story unfolded Mary Beth gave birth and changed her mind she decided she wanted to keep the baby the case wound up in court in New Jersey so let's take put aside any legal questions and focus on this issue as a moral question how many believe that the right thing to do in the baby M case would have been to uphold the contract, to enforce the contract? and how many think the right thing to\ndo would have been not to enforce that contract? so it's about the majority say enforce so let's now hear the reasons that people have either\nfor enforcing or refusing to enforce this contract first from those, I want to hear from someone\nin the majority, why do you uphold the contract why do you enforce it? who can offer a reason?"}, {"content": "yes. stand up. it's a binding contract all the parties involved knew the terms of the contract before any action was\ntaken it's a voluntary agreement the mother knew what she was getting into all four are intelligent adults regardless of\nformal education or whatever so it makes sense if you know what you're getting into\nbeforehand and you make a promise you should uphold that promise in the end. Ok, a deal\nis a deal in other words? Exactly."}, {"content": "And what's your name? Patrick is Patrick\u2019s reason the reason that most of\nyou in the majority favored upholding the contract? yes? 0:36:37.769,0:36:38.969\nall right now let's hear from someone who would not enforce the contract what do you say to Patrick? Why not? Yes well I mean I agree I think contracts should\nbe upheld when all the parties know all the information\nbut in this case I don't think there's a way a mother before the child exists could actually know how she's going to feel about that child so I don't think the mother actually had all\nthe information she didn't know the person that was going\nto be born and didn't know how much she would\nlove that person so that's my argument so you would not, and what's your name? Evan Wilson Evan he says he would not uphold the contract\nbecause when it was entered into the surrogate mother couldn't be expected to know in advance how she would\nfeel so she didn't really have the relevant information when she made that contract who else who else would not uphold the contract? I think, I also think that a contact should\ngenerally be uphold but I think that the child has an inalienable right to  its actual mother and I think that if that mother wants it then that  \nchild should have a  right to that mother. you mean the biological\nmother not the adoptive mother. right."}, {"content": "and why is that, first of all tell me your name. Anna. Anna, why is that Anna? because  I think that that bond that is created by nature is stronger than  \nany bond that is created by you know a contract. good thank you. Who else, yes. I disagree I don't think that a child has a inalienable right to her biological mother I think that adoption and surrogacy \nare both  trade offs and I agree with the point made that day it's a voluntary agreement, an individual\nmade, and you can't apply coercion to this argument you can't apply the objection from coercion to this argument. correct. what's your name? Kathleen Kathleen, what do you say to Evan, that though there may not have been, Evan\nclaimed that the consent was tainted not by coercion but by lack of adequate information she couldn't have known the relevant information\nnamely, how she would feel about the child I don't think her emotion content plays into this I think the emotional content or her feelings\nplays into this, I think in, you know, in a case of law, in the justice of this scenario, her change of feelings are not relevant\nif I give up my child for adoption and then I decide later on that I really want that\nchild back too bad, it's a trade-off it's a trade off that the mother has made. so a deal is a deal, you agree with Patrick? I agree\nwith Patrick, a deal is a deal, yes. good, yes. I would say that though I'm not really sure if I agree with  the idea that the child has a right to their mother I think the mother definitely has a right\nto her child. and I also think there are some areas where market  \nforces shouldn't necessarily penetrate, I think that the whole surrogate mother area smacks a little bit of dealing in human beings it seems dehumanizing and it doesn't really seem right so that's my main reason and what is could, tell us your name. I'm Andrew. Andrew. what is dehumanizing about buying and selling the right to a child for money, what is the humanizing about it? well because you're buying someone's biological right I mean you can't and the law as it states you can't sell your own child\nlike were you to have a child I believe that the law prohibits you selling\nit to another person. so this is like baby selling? Right. To a certain extent, I mean though\nthere is a contract with another person, you've made agreements and whatnot there is an undeniable emotional bond that takes\nplace between a mother and child and it's wrong to simply ignore this because you've\nwritten out something contractually. you want to reply to Andrew? to stay there you point out that there is an undeniable emotional  \nbond I feel like when in this situation\nwe're not necessarily against adoption or surrogacy in itself we're just sort of pointing \nout the emotional differences well but wait, it's easy to break everything down to  \njust numbers and say well we have contracts like you're buying and selling a\ncar but there are underlying emotions I mean\nyou're dealing with people I mean these are not objects to be bought and sold\nbut what about Andrew's claim that this is like baby selling I believe that adoption and\nsurrogacy should be permitted whether I actually will partake in it  is not really relevant but I think that\nthe government should, the government should give its citizens the rights to allow for adoption and surrogacy. But adoption,\nadoption is not according to.. Is adoption baby selling? well do you think you should be able to to bid for a baby that's up for adoption that's Andrew's challenge Do I think that I should be able to bid for a baby? I'm not... sure. it's a market I mean, I feel like the extent to which it's been\napplied I'm not sure if the government should be able to permit it and I have to think about  \nit more but,  Alright fair enough, are you satisfied Andrew? well ya, I think surrogacy should\nbe permitted I think that people can do it but I don't think that it should be forced upon\npeople that once a contract is signed it's absolutely\nlike the end-all I think it's unenforceable so people should be free, Andrew, to enter into\nthese contracts but it should not be enforceable in a court not in a court no. who would like to turn on one side or the other I think I have an interesting perspective\non this because my brother was actually one of the people who donated to a sperm bank  and he was paid a very large amount of money he was six feet tall, but not blond he had dimples though, so he actually has, I'm an aunt now and he has a  \ndaughter she donated sperm to a lesbian couple in Oklahoma\nand  he has have been contacted by them and he \nhas seen pictures of his daughter but he still does not feel an emotional bond\nto his daughter he just has a sense of curiosity about what\nshe looks like and what she's doing and how she is he doesn't feel love for his child so from this experience I think the bond\nbetween a mother and a child cannot be compared to the bond between the\nfather and the child. That's really interesting."}, {"content": "what's your name?"}, {"content": "Vivian. Vivian so we've got the case of surrogacy, commercial\nsurrogacy and it's been compared to baby selling and\nwe've been exploring whether that analogy is apt and it can also be compared, as you point\nout to sperm selling but you're saying that sperm selling and baby selling or even surrogacy are very different. Because they're unequal services. they're unequal services and that's because Vivian you say that the tie, the bond, yes and also the time investment  that's given by a mother, nine months cannot be compared to the man, you know going into a sperm bank looking at pornography you know, and depositing into a cup. I don't think  \nthose are equal good. Alright so we, Because that's what happens in a  \nsperm bank. alright so, this is really interesting we have notice the arguments that have come out so\nfar, the objections to surrogacy the objections to  enforcing that contract, are of at least two kinds there was the objection about tainted consent this time not because of coercion or implicit coercion but because of imperfect or  flawed information so tainted or flawed consent can arise either because of coercion or because of a lack of  relevant information at least according to one argument that we've\nheard and then a second objection to enforcing the surrogacy contract was that it was somehow the humanizing. now when this case was decided by the court what did they say about these arguments? the lower court  ruled that the contract was enforceable neither party had a superior bargaining position a price for the service was struck and a bargain\nwas reached one side didn't forced the other neither had disproportionate bargaining power then it went to the new Jersey supreme court and what did they do they said this contract is not enforceable they did grant custody to Mister Stern as the father because they thought that would\nbe in the best interest of the child but they restored the rights of Mary Beth Whitehead and left it to lower courts to decide exactly what the visitation rights should be they invoked two different kinds of reasons along the lines that Andrew proposed first there was not sufficiently informed consent the court argued under the contract the natural mother is irrevocably  \ncommitted  before she knows the strength of her bond\nwith her child she never makes a truly voluntary informed decision for any decision prior to the baby's birth is, in the most important sense, uninformed. that was the court then the court also made a version of the second argument against commodification in this kind of case this is this the sale of a  child the court said or at the very least the sale of a  mother's right to her child whatever idealism may motivate the participants,\nthe profit motive predominate, permeates and ultimately governs the transaction and so regardless the court said, regardless\nof any argument about consent or flawed consent or full information there are some things in a civilized society that money can't buy, that's what the courts\nsaid in voiding this contract well what about these two arguments against the extension of markets to procreation and to reproduction how persuasive are they? there was, it's true, a voluntary agreement a contract struck\nbetween William Stern and Mary Beth Whitehead but there are at least two ways that consent\ncan be other than truly free first if people are pressured or coerced to give their agreement and second if their consent is not truly informed and in the case of surrogacy the courts said a mother can't know even one who already has kids of her own, what it would be like to bear a child and give it up for pay. so in order to assess criticism, objection number one, we have to figure out just how free does a voluntary exchange have to be with\nrespect to the bargaining power and equal information question number one. how do we assess the second objection? the second objection is more elusive, it's more difficult Andrew acknowledged this right? what does it mean to say there's something\ndehumanizing to make childbearing a market transaction? well one of the philosophers we read on this subject Elizabeth Anderson tries to give some bring some philosophical\nclarity to the unease that Andrew articulated she said by requiring the surrogate mother to repress whatever parental love she feels for the child surrogacy contracts convert women's labor into a form\nof alienated labor the surrogate\u2019s labor is alienated because she must divert it from the end from the and which the social practices of pregnancy rightly promote, namely an emotional bond with her child so what Anderson is suggesting is that certain goods should not be treated as open to use or to profit certain goods are properly valued in ways other than use what are other ways of valuing and treating? good that should not be open to use? Anderson says there are many, respect, appreciation, love, honor, awe, sanctity there are many modes of valuation beyond use and certain goods are not properly valued if they're treated simply as objects of use. how do we go about evaluating that argument\nof Anderson? in a way it takes us back to the debate we had with utilitarianism is use the only, in utility is use, the only proper way of treating goods? including life military service procreation childbearing? and if not, how do we figure out how can we determine what modes of valuation are fitting are appropriate to those goods several years ago there but the scandal surrounding\na doctor an infertility specialist in Virginia named\nCecil Jacobson he didn't have a donor catalog because unknown to his patients, all of the sperm he  \nused to inseminate his patients came from one donor doctor Jacobson himself. at least one woman who testified in court\nwas unnerved at how much her newborn daughter looked just like him now it's possible to condemn doctor Jacobson for failing to inform the\nwomen in advance that would be the argument about consent the columnist Ellen Goodman described the bizarre scenario as follows doctor Jacobson, she wrote, gave his infertility\nbusiness the personal touch but now the rest of us, she wrote, are in for a round of second thoughts about sperm donation Goodman concluded that fatherhood should\nbe something you do not something you donate, and I think what she was doing and what the philosopher Elizabeth Anderson\nis doing and what Andrew was suggesting with this argument\nabout dehumanization is pondering whether there are certain goods\nthat money shouldn't buy not just because of tainted consent but also perhaps because certain goods are properly valued in a way a higher than mere use those at least are the questions we're going\nto pursue with the help of some philosophers in the weeks to come don't miss the chance to interact online with other\nviewers of Justice\n0:54:01.280,0:54:03.829join the conversation, take a  \npop quiz, watch lectures you've missed, and learn a lot more. Visit justiceharvard.org, it's the right thing to do."}, {"content": "funding for this program is provided by Additional funding provided by"}], "Justice with Michael Sandel - BBC: Fair pay?": [{"content": "is it fair that Wayne Rooney earns more than a care worker is everybody voted let's see what the results are really well divided 46 percent say yes it's fair 54 percent the majority but not a huge majority say it's unfair let's begin our discussion I'd like to hear first from someone who thinks that it is fair that Wayne Rooney makes more than a care worker what would be your reason who's willing to start off the discussion yes over here in the front what would you say really provides the service that many people derive a great deal of pleasure from and that they're willing to pay a great deal to enjoy very few people other than Rooney can do that that's why he gets paid a lot very few people other than Rooney can do that and that is what exactly is that provide a service namely entertaining football in a way that very few other footballers can do that yields a great deal of pleasure yeah to people as evidenced by the fact that they're willing to pay high ticket prices to go to the games and that's why it's fair absolutely and what's your name Paul Paul all right now who disagrees who who disagrees with our first two contributors and thinks these pay differences are unfair yes toward the front and if everybody and has an equal chance in life then maybe pay differences would be fair not of that scale I still don't agree with that scale but also you said that people think people enjoy the service he provides well a lot of people be dead without care workers services I think you need to value here to sum up what you value in society more media and tell us your name I'm Louis so Louis do you think that the care worker actually makes a more important contribution to society than Wayne Rooney does um I'd argue that that kind of things difficult to value but yet in the short term I'd much if I was ill I might try to have a care worker Paul what do you say the lowest I to if I was ill but rather have a carer you know than Wayne Rooney nevertheless I think I'm an economist for my sins I think it's a matter of supply and demand care workers provide a very valuable service but there are many people who were willing to do that and able to do that so you need to pay them a lower wage to elicit supply of care services much harder to get people with the skills and talents of Wayne Rooney and therefore he deserves to make more absolutely all right who else would like to reply to Paul who doesn't think that in virtue of his scarce and rare and much appreciated talent who disagrees that he deserves therefore to earn more yes the woman sitting I'm not sure that the laws of supply and demand are necessarily fair there might be what rules our society but I'm not sure that what they are is fair and if you're looking about at the contribution that's being made to the good of society I think although I'm with Louis it's very hard to evaluate I think probably most of us would agree maybe not that a care worker gives more to people than Wayne Rooney because all he gives his pleasure and what she gives us care which is very valuable contribution and what most of us would rather have if we've got the choice between the two so and tell us your name season Susan so Susan I want to take up the first point you made Susan says that the law of supply and demand does not define what's fair"}], "Dart Programming Tutorial | #1 Installing and Setting Up Dart | Aditya Burgula": [{"content": "[Music] you guys welcome back to my channel so in this video we'll be getting started with installing dart so that we can write our program into our programming language so you can just go to your favorite search engine and search dot SDK and the first result which you get is this dot dot dev and get the dart SDK so click on that and there you will find a downloads page where you can download so here as we can see we got something like Windows Linux and Mac's but this is not how we are going to install using this chalk or it's actually kind of a command-line tool but we won't be doing that rather will be downloading it as a zip file and then installing it so just click this link over here just as I play right now so here we have some kind of channels over here as you can see stable channel beta Channel and dev channel we will be using stable channel so depending on your system architecture you can choose between 32 or 64 my computer is 64-bit so I will be using the 64 bit so click on the data SDK or kind of text and then it will start downloading so have actually downloaded it so it's around 209 MB have actually downloaded it so I won't be downloading utak okay now coming to the installation file so here I have downloaded it no just extract it anywhere you want but I would highly suggest or recommend you that you extract extract in the c f-- local disk c so that you don't face any problems in the future because just the kind of basic folder where all your programs are going to be installed so actually have previously installed out SDK as you can see over here but as for this video tutorial I will be installing it again but not in the same folder rather in another folder so just click on the zip file and try to extract it so here we got extract files and extract here so as I'm I will be extracting in this folder so guys please files and folders directly I need to go to in Syria next is there another important thing which we want note is the bin folder so it has all these things as you can see 429 MB so just click on this and here on the title where you can see navigation bar here you just double click on this and you'll get the link or the location so just copy that thing so guys for saving it into the path you must just open control panel as I have opened it right over here and go to system and security here as we can see just go to the systems menu and here we'll find all the information about the current system and here you must go to advanced system settings over here so click on that and there will be a pop-up dialog box where you'll have more options so in this search for environment variables so here we have the Box environment variables so it is in the Advanced tab and environment variables so open that thing and here we can see that we have kind of options over here say path so this path thing is very mean main thing for installation so here you must add dart SDK so click new and add it so as I previously said that I have installed it it is already added to my path now if I again added to the part it may cause some problems I won't be doing that but please be do please do that in your system so that you can at least rent out programs right ok so now we are actually now adding the path as I have told you the first one the user variables we are adding it to only to the current user who is using this if you want to add it to the system you can even add it here in the below bar also so here we see system variables and here I suggest that you add it to all your users and even the system so that everyone can use it so here you can just click new and and after you add them and click OK just again click OK over here and it will change save the changes and click OK and finish that's it guys this is how we install dot SDK or dart VM install in our system now one more main thing which we need is an IDE so we'll be using Visual Studio code so Visual Studio code is a very popular idea guys it's very lightweight it also even you should be honest doesn't have proper specs or very low specs for that you can just use this ID it is very kind of small MB size it's the size is very small runs very fast no problems no issues with that editor so this event by Microsoft so just search for vs code so vs called download for Windows depending on your operating system you can download it so here we get this website called download visual studio mat Linux or Windows just click on this so when you click on this you will be getting a pop like Windows Mac or just click on this blue button windows and it will start downloading and guys I will not be having the windows install this vs called installation because I have already installed it rather I will just tell you that the same installation is also not very complex it's very simple so what you need to do is that just click on this and run the exe file or the system installer file and that time it will ask you just agree with the license and just continue and when it asks for additional task select all of them and continue it will install it there's nothing much complicated in that that's why I won't be showing it and so after you install will be opening Visual Studio code and will configure it so that we can write - code in that so that is menu in completely installed we just flew to a code it might be looking somewhat like this so actually I have a dark theme you can add whatever theme you like for me it maybe you like a light color theme or somewhat like that so after you install you will get kind of welcome paste like this there after that you're just going to open this extension tab over here on the left hand side so click on this extensions and here you can install extensions and the main extension which we need is called as dark so click dot or type dot inside the search box and we'll get the first result so the dot this one we must install dot language support foot and debugger for visual pseudo code and despite dart code so these are the kind of tip team and google who developed art so they have download this plug-in also so you can install this and probably after you install it will ask you to restart your IDE so just click on the tree start or reload but and it will automatically do it for you so after that we are completely set up and we can run dot program so guys if you are facing any issues just go to command line so here I'll be opening the internal terminal in this as you can see over here terminal just click over here and a new terminal just open the new terminal so it will open a new terminal via Scott has an inbuilt terminal gates so here you can open any kind of terminal so here you can even choose if you want to use bash or anything like that I'll be temporarily using command prompt i even have gate bash powershell you can use whatever your favorite one is so here to check if dart is properly installed click in this type dot - - version the ers i4m and press ENTER and it's installation was successful you will get dart VM version and other stuff so guys if you get the successful message we are completely done with installing dart and an IDE in the next video we'll be getting started with programming in Dart so please be sure to subscribe to my channel and hit the bell I can so that you never miss any updates thanks for watching"}], "Dart Programming Tutorial | #2 DataTypes and Variables in Dart | Aditya Burgula": [{"content": "hey guys welcome to my channel I'm Athiya and in this video we'll be starting to program in dart language and we'll be covering the basic stuff like data types and variables in this video so without wasting time let's get into the video guys right now I have opened Visual Studio code and I'm on a file called main door tart so as you can see over here I have the dot folder mailed or tart and then here we have a main function so main function is where your code starts to execute from so if you write it outside won't execute if you write it inside only inside of these curly braces you can see from there only it will start executing so first we'll cover about data types and variables so first we'll learn about data types so in dart language we have int so I just write heading so that it would be easy for you data types so here I have written data types and no the first data type is in credit I and the second we are going to learn is double and the third string and fourth one is pool or pool and the last one is dynamic so here int so n does nothing but it is used to store an integer value so that integer value can either be positive value or a negative value so now we have here end and here we have double the next one so the double is nothing but it is used to store decimal values for fractional values so you can store point zero zero one or point one zero one zero zero zero one so like that you can store all the fractional decimal or floating point values so if you are from C place place we use the float so the float keyword and here the third one is nothing but string so string is just like using kind of it is used to store character sequence of characters just like your name and name address so one thing is that they cannot perform calculations whereas int and double can perform calculations and string cannot perform calculations so that is one of the thing to remember and the next one is boon so bool is actually used to store two kind of values only two kind of values true or false so it can store true or false either of them it depends on the condition so this bull data type is going to be extensively used when we come to conditional statements so the last one is dynamic so what is this dynamic type I think you can kind of kind of predict what it's going to be so dynamic is a data type which can store any kind of value it can store into that a type double data type string data type bool data type and anything so lists and maps which are kind of data structures but will not be covering them right now so a dynamic can't store any kind of data so what is the use of having all these data types when you just have a data type or a dynamic data type which can store any kind of value so actually there's a concept of static and dynamic typing so when we use only these kind of when we want to use an integer we only use the entry word to represent an integer that time it is called a static and whereas dynamic the value is being able to change so that time it is called as dynamic programming so where the Tara type can be changed so I see it we have int double string pool and dynamic we have covered them it might be a little bit confusing for you to understand right now so let's try to code it and understand and now let us even while coding we live and understand about the variables as well so to make an integer datatype I just use a keyword int and here I'll just write my age equals some so I'll just declare a variable called my age so what is a variable over here so variable is my age so what exactly is the definition of a variable so variable is nothing but a box or a storage container in memory and that storage container box is used or referenced using this name so here we have given the name as my age so it will be referenced as my age so the container which name is my age okay next the my age container doesn't have any content or value inside it here we can give a value so one thing to remember is that we cannot give the floating-point numbers like this because we have already declared that it's going to only have an integer datatype so if we keep like this we are gonna have more errors so that's great we have learned about declaration declaration and here we have learned what initialization initialization okay now let's move ahead and we'll just print this out so I'll just write print and I can just pass the variable inside it so and end it with a semicolon I think you are noticing that I'm always ending every statement with a semicolon okay now let's run this program to run this program I'll be using the terminal don't use his Run button so here I'll just open a new terminal and here you will even get a shortcut key which which will be helpful for you so to open it quickly so here to run any dart program first you write the dart name so dot and then I write the file name so it does mein daughter so main dot dot press enter and now as you can see we have got six seven eight four three so case that was about integer datatype no I can even change it to double also qub le so double data type and still as you can see we don't get any error now let's run this program again and check out so here you can see double well if we add a double over here you can see that it has already added a decimal value like point zero so you can even give integer values but it will add more precision so in future rows if you want to add more precision you didn't just use double so let me just clear this and I'll just even close this thing okay so this was about integers and doubles now let us go ahead and learn about strings the strings are teletypes which you can store to use a sequence of characters so what do I mean by streak of sequence of characters so I can illustrate string my name equals so I'll directly declare and initialize at the same time like this so other the\u00e1-- so I'll write like this and we are here declaring it and here we are also initializing it in the same line now as you can see I have enclosed some using double quotes you can even use single quotes also so there's no Rodman you can use double or single quotes in dark okay that was about how we declare and initialize now let us come to the point of what makes it different from integers and double so you cannot actually perform calculations like subtraction division but you can even perform addition which is called as concatenation but will be not covering it right now so I just can't multiply with other like that other Thea into or some other name are the chain to bucola like that it doesn't work if I do all the place bucola it will do some kind of output which I'll be showing you in the next video so see the next video also so what happens concatenation or if you are very equally you can check out on the internet what concatenation is so here we can write any kind of numbers are also possible and you can even store special symbols also so that's nothing much in this string datatype it is used to store just text so that was about strength now let's come to bool defe type so bool and I'll just write is how a school is a student so I'll just write a student the still de NT I'm a student so I just write true so a bool data type is going to have only two back we search say the true or either false so I think you must have understood and I can even just replace it with false so the standard I was actually used in conditional statements extensively usual condition statements okay guys so here we have covered about these first four I think so int double and string that's great now let's learn about the last one which is dynamic and here also we can see dynamic no if I write dynamic equals so I should write dynamic my name equals are the Theia and end it and let's again print this friend and alike my name and now let's open the terminal now I'll just open a new terminal so I'll just write over here dart main dot dart so and now I press run and it's going to give me the output as odds tail now let us change the data type so I think I have told you that dynamic data type can show any kind of hair type so I will just type number and now we don't get any errors so if I was to keep it as a string we will get some error so if I keep like this as you can see over here it has given length the value of end cannot be assigned to a variable of type string so what does this dynamic to actually so dynamic so dynamic is nothing but it is used to store any kind of data and you can ever change it in the future without any warning suppose there's even another keyword called as bad you can use where so this is actually somewhat a type safe know what doesn't actually specify what kind of data type you're using but once you declare it as a number over here we are using a number so it is an integer data type so I can illustrate if I in the next time if I write my name equals the string data type so I always write are the Thira and end it with a semicolon still you are getting that string can be assigned to a variable of type int so once you initialize it for the first time that time it's gonna set its data type of my name as integer and if you again reinitialize with another data type rather than the data type which you are used for by initializing for the first time then you are going than ever thrown up like the string can't be used as an integer is already declared in that at the time of initialization so that was about this guy's dynamic and Static typing or data types and variables so I think it might be little bit hard to understand for you guys right now so just watch this video again if you are not getting it and in the next video we'll be looking some more over the stereotypes and variables so thanks for watching please be sure to subscribe to my channel and I said well I can so that you never miss any updates"}], "Dart Programming Tutorial | #4 Basic Operators In Dart | Aditya Burgula": [{"content": "hey guys welcome back to my channel i'm aditya and in this video we'll be learning or understanding about operators in dart which is very easy and one thing is that if you are coming from c plus list or python or java like that then these operators are very similar to them you can just check out the increment and decrement operator if you're coming from a python because there we don't have plus plus and minus minus you can check that how it works and after that you can go to the next video if you're completely beginner to any programming language or you're completely starting programming right now you can just continue watching this video so without wasting your time let's get into the video so guys here as you can see i have just a main method and i have written some operators in dart so here we have plus minus star and this hash forward slash and then this percentage symbol and then we have plus plus minus minus and we even have operators like plus equals and then these are similar to python you can i think you can guess it in python also we use like these operators for incrementing and decrementing okay first let us start with the first operator plus minus so we'll not uh do this plus minus and star star is for multiplication this is a very similar in mathematics like i think you can even understand them so very simple operators we will start from division because there are actually two types of division operators the forward slash and forward slash and percentage so let us check out the difference between these two division operators so i'll just write a simple print statement to check them so let us divide 10 by two simple division so 10 divided by 2 so we are using the first division operator so this one then let's run this open a new terminal so terminal and then click new terminal and to run a program always uh write this command dot and then you write the file name main dot dot so press enter and we got 5.0 so always remember that whenever you do double uh means whenever you do a division you are going to get the result in double value so uh if you are seeing if you are not seeing the directive double is a data type which can be used to represent decimal values or fraction values so when we divide sometimes we we are going to get a decimal value or sometimes you might get a whole number but still it shows us in a decimal value so that it can be more precise okay the second operator is percentage symbol so what does this thing do so let me just replace that with percentage so here percentage and now let's run this again and we see some difference the percentage symbol gives us the answer as zero so why is that so when we were using only the forward slash that time it was giving us the output of uh means the output as quotient so it is giving 2 divided by 10 that is 5 5 is the quotient and when we were doing this percentage symbol that time we are getting the remainder of the uh calculation so when you divide what you get the remainder that time that is going to be printed so suppose i keep it to three then we are going to get some big we are going to get some remainder so see as you can see over here we got remainder if we search for the question it will go on give me till infinity maps no it doesn't so as you can see it is continuously dividing three three three three three so that was about these two division operators so i think you know about these operators uh the basic operators like plus minus star and then forward slash and percentage symbol now let's move ahead and learn about these operators so these are increment and decrement operators so first these two not these two so this is increment operator and decrement operator so for understanding this i'll just create a variable so i'll write int a or i'll write in num1 equals 1 simple and then here next we'll write num1 and what was the first operator plus plus so we'll write plus plus and close the line and again we'll print over here print num1 and before that also before doing the operator increment operator we'll also print again the num so print num1 and close it so i'll just clear this and let's go here so oh so we did we made uh okay so now press go to the terminal and as you can see when we are printing for the first time without performing the increment operation we are gon we are getting the same value as num1 what we assign to it after incrementing we are gonna we are getting two so that is incrementing so it always increments by one so this is useful when we are doing when we are doing uh loops which will be covering in the future also so don't worry about that we'll be doing that in loops especially in for loops and while loops there we use these increment operators and same you can even do minus minus so let's run this again and we are going to get 1 and 0 as you can see minus minus okay that's great now let us check this operator or plus equals minus equals and we even have star equals also like uh star equals and then division equals you can do pretty much everything like all the four base five basic operators which are over here plus equals minus equal star equals forward slash equals and percentage equals so these all are represented like if i write num plus equals now 10 so i'll write 10 and close it this simply means that num1 equals num 1 plus 10 so i think you're getting it uh so here this simply represents as num1 is equal to num1 plus 10. in python we actually don't have uh these plus plus and minus minus operators if you are coming from python so that time we use these so we use these operators for incrementing we will just write so when we replace it with one it will be like num1 is equal to num1 plus one so a lot of ones so that was about these operators you can even replace it with one uh minus so i'll just replace plus with minus and here we it will just be replaced with minus so here num one num num one equals num one minus one that's actually a lot of nums okay so we have covered up some of the basic operators i think you are very similar with them right now so that's not much complicated it's very easy nothing much there in this just like simple operators mathematical operators but even in conditional statements we'll be exploring some more operators so please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates thanks for watching and see you in the next video"}], "Dart Programming Tutorial | #8 Lists in Dart | Aditya Burgula": [{"content": "hey guys so welcome back to another brand new video so guys in the previous video we have covered about functions or methods the basic stuff so we have declared some basic functions like add and create and then we have called those functions given some parameters and called using arguments so you might be a little bit confused right now so let us go from those functions part and let's come to kind of data structures so these are kind of some interesting stuff we'll not be going too deep into these data structures and not so just like light touch we'll be just having uh so we'll be just learning about what these data structures are so this video will be covering about list so let's list is nothing but an array you can think of it as so an array another programming language is an arrays group of elements so list is all the same and mostly in the next video also we'll be covering about another data structure called as map in dot so as of this video only list so without wasting time let's get into the video so guys as you can see in the we have just a small main function over here and here first let's declare a list so it is same way how you declare variables using var the same way you can declare lists so i'll just use the keyword list and then i'll declare a variable so i'll just write my list or let's give some meaningful name like friends names so friends names and here i'll keep square brackets so this tells the dot compiler that it's a list so here we don't get any error and here we just get a blue marks so don't worry about that and here we can give multiple items inside that so here i can just give like i'll just give my name and then here i'll give kumar and then i'll give one more name maybe so i just kept it outside so lake lux and here are the so here i have simple list where i have my friends names only five six members i think one two three four five so before going ahead and printing all these things i just want to tell you one thing is that now we are seeing this list the first element of the list is actually represented by zeros so every element in the list is represented using numbers which makes it much more easier like getting a item from a list and adding an item from a list and doing some operations on a particular item item on a list so numbers are actually used to reference these so numbers always uh the counting always starts from zero in programming if you take even in any programming language it will always start from zero so here are there this is represented with zero then one then two then three then 4 so this is how in referencing works so now a small example so without first let's print the whole list and check out does it work or not so write a print function and i forgot to tell you print is also a function in the last video print is also a function which is pre-declared so it is already declared and we can directly use it so there is no declaration but it is there somewhere it is there in the kind of core library the print function definition but we are not able to see it right now but we are able to use it right now we are able to call print function okay now let's not talk about print function so let's see about this list so here i'll just write friends so here i got intellisense and now go to terminal and run the script and as you can see it has printed the whole list same as it is it has just removed those two codes and now we can even see all the variables now let's try another way of printing a particular item from list so here i can just write 0 as i told you we can use the numbers to reference a variable an element inside the list so here i can just run the program again and as you can see it has printed aditya so as i have told you the first element is represented as number zero and then so on one two three four so like that if i keep some four and then again let's come back to the terminal and let's run it so as you can see it has printed the last element it has not printed luxury as you can see one if you count from normal way of counting we'll see one two three four but you must count from 0 so 0 1 2 3 4 so that's how it works and you can even perform kind of methods or you have some functions which you can perform on them so here we have add function and then we have remove and dot length now let's see first what this dot length will give us so actually this function will give us the number of items inside the list so now by press as you can see we got five so one two three four five so this actually doesn't start from zero so only the reference thing or the thing uh all that stuff starts from zero whereas the normal counting like dot length gives us from normal one to five one to six how many other elements are there okay now let's check some more functions like we have what else functions we have on this so we have add so first function is add now here we can add a variable so i'll just write like this keep up i'll just add a string variable so i'll just write some other name like uh david so david so here we are getting some error so what is that error let us see okay so we are printing it actually so we must remove it out from the print statement so then we won't get the error so i'll just write ctrl x and here we'll just paste this and as you can see we got the error off just end up with the semicolon and now let's print it so friends names go to terminal run the program and as you can see we got aditya kumar ram laksh aathi and at the last it has actually added david so that's how it works we can for checking it whether it added or is it previously there so we'll see this we'll add it before adding it now here i have added it it's a lot of add so the function name is add and i'm using the word add so here you can see i think the difference i'll just expand this a little bit so here first before adding it before adding the element it was still ati and after using the add function and adding a variable we are getting another item which is david great now let's check some more functions so here first function we checked was add and now let's see what else functions we have so keep the dot operator and you'll get all the functions so add all so add all will give us uh means you can add multiple items in that you can use a for loop and assign it to a variable or you can create another list and add it so i'll just write add all and you can add list of all the items so i can write rde and enclose with brackets uh quotes and here i'll write adi so capital rd let's write jack okay so now let's run this program and let's check if this works so as you can see it has worked pretty much the same so in the add only add function we were only able to add a single element whereas when in add all you can add multiple elements so let me just close this let's check some more functions like what else are there so it's hard to memorize that's why we have this intellisense which always helps us so here we have dot any dot s dot map dot clear so clear will clear all the elements so let's check this thing so run this program and as you can see before clearing the where all the elements were there instead and after running the clear function all elements push so all elements are gone so those were some of the functions you can try them out if you find any difficulty in understanding what a particular function is you can just see over here when you go to a function here you'll get a documentation if you are still not able to find it you can just comment down below i'll be always ready to answer your questions so that's it for this video guys i hope you like this video and in the next video as i have told you we are not ending with this beginners right now so we even have a maps and maybe more also so please be sure to subscribe to my channel so that you never miss these interesting programming tutorials on dart so see you in the next video"}], "Dart Programming Tutorial | #10 Sets in Dart | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i am aditya and in this video guys we'll be learning about another data structure in dart and it is called a set we'll be learning about that so without wasting time let's get into the video so guys right now as you can see on the screen i have already written some code to make it much easier while explaining so guys here we have a main dot function so first here i have declared a list called as my list and i have added some values inside them i have added my name my value have given some random integer number and a boolean value even in set i have created a new set and as you can see notice over here we are using the same curly braces which we used in the map so even sets use this curly braces but they are not key value pairs so that's the main difference so here my name and my value again an integer value and again a boolean value and here you can see we are doing a particular operation in all of these in two of these that is we are adding an element and here to the list we are adding the same item the same string item which is already present inside it and to the set also we are adding the same item which is already present in it let's run this program and check it and here we must see and i think mostly we should get an error or it should actually not do anything so as you can see over here we we got two things and it is printing like my name my value 2827 that integer number and then we have true and then we have my name so this function was successfully executed and here when we come to the set as you can see you can differentiate between these uh two output using these curly braces and the square brackets so this is the list the first one is list and the second one is set so here you can see though we have written this function like dot add and we have set the same value to be added again it has not actually added it so sets do not allow duplicate so one thing to remember about it is sets do not allow duplicate and rest all it is the same it is similar to a list and these are even there in most of the programming language like c plus stl library so let us say now let's see some of and we'll just even remove this list so that you understood right now the main difference between a list and set and we'll write set dot and here it should give us some functions so here we have first we'll check the add function we have tried it right so we'll give some value and i'll just give integer inside this quotes and now let's run this program again and it should print successfully because this is a unique value which does not exist in the set so if it does exist before then it wouldn't be added just like before when we did the my name thing that time it was existing before so it did not add it it allows only unique elements and now i think you might have even got the add all also so add all and here i can have actually i can give another set inside it using the same curly braces and i can write adithya and here inside this also another like likes and here comma and then cars so like that you can give multiple values inside them and notice that they are all different and inside a set you can see the syntax i think the syntax it has gone totally okay what happened okay it has been cleared actually so yeah now i think it should work cars yeah i'm sorry for that guys something happened by mistake and now let's run this program over here and as you can see it has printed my name and it has printed till the boolean value and here it has been oh my god i mistyped my name so i can just remove it a-d-i-t-y-a and now it is perfect let's run it again and we should get it aditya likes cars so like that it works same as a list you can add multiple items but make sure when you are using sets use the curly brackets and guys let us check some more operators like dot clear i think you can find and dot contains so what is this contains actually so contains will actually check and return a boolean value that if this value which we give inside it is present in the set or not i think we've we have covered this in the list i think if i don't remember i don't remember it properly so now we'll again check it and it should mostly give some boolean value for us and as you can see okay we have to we have to print it i think so print so guys as you can see we got true so this function method or this thing which is my set dot contains and we have inside that we have given a value called as my value and here it is already existing over here and we gave it over here and we are printing the output which is a boolean value which is which it is actually returning the function dot contain contains his returning and we are getting it as true so it does exist now if you're confused you can watch the video again or i'll just give documentation to the dart so that you can explore more and more kind of these methods so let's explore some more methods print uh okay we'll write my set so sct dot and here somewhat i think you can understand clear it will remove all the clear and here we have difference element and these all are actually arrow function types so here we have first so let us check this i think we have not seen this in list i think maybe it is there and actually we must print it also this one is also actually a variable member value we call that member variable so and control press enter and it should print my name so this is the first element inside the set you can see and it is printing that so guys let's see some more kind of functions which we can do that is my set i'll just write my set dot and here we have clear i think you might have understood clear and we'll check the alt at element so we'll use that and we'll write 0 press enter and then open the new terminal and press enter and it should give us the first element so it is just like indexing operator what we use so we cannot actually use the square bracket operator because that's only specific to list if we want we can actually declare that operator but totally that's totally advanced if i use like the c set and here i give 0 it will actually give me some error saying that it is not defined so the operator square brackets isn't defined for the type set dynamic try defining the operator square brackets so you must actually declare it actually they did not declare it for us because it is it doesn't make any sense because set is totally a different thing now let us go and check some other functions so my set dot so every so we still did not come to these arrow functions most of them are arrow functions as you can see most of them like contains all and iterable objects first where and followed by for each is empty and is not empty iterator lost so we'll check this last where okay so these all are actually very big and length so we actually did not cover arrow functions so if you cover them then it would be much easier if you're from javascript you could have understood right now what exactly is an arrow function and you can just execute same as javascript how you do that so i can just write dot main dot dot and here so length it has we must print it here i can just say control v and now let's run this program and as you can see it has printed as four and they're like that many of the functions you can check them out and i think you got the main idea of what exactly a set is how we write its syntax how we get an element using the index using the function called as element i think element at and so you can do like that we'll be covering about advanced kind of methods and functions of set list and map all together after we complete the functions arrow functions actually we have covered functions but after covering arrow functions and some more kind of advanced topics then we'll come and understand about some of the advanced functions available in this like suppose dot for each and there are a lot of them even in list these are almost similar to all the collections and all these data structures so if you can see dot clear these are very simple almost the same you can see first and here we even have is empty so is empty will actually written as false so because it is not empty so i think you're getting it so this is actually a variable a variable and the main difference between a variable and function is that a function will have these and it is nothing but parentheses and inside this we can give an argument or pass an argument whereas a variable or variable will not have it so guys i hope you like this video please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates thanks for watching see you in the next video"}], "Dart Programming Tutorial | #12 Input and Output in Dart | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i'm aditya and in this video guys we'll be learning about input and output in that language so this is actually a thing which should be covered in the beginning itself but i thought i would explain all the interesting concepts and later come on to this because it's very basic and it's very easy to understand right now after you learned all these things it would be very damn easy for you to understand this thing also so with operation time let's get into the video so guys here as you can see i just have a main dot dot file and i'll just close this one extra dot file it is there and here in the main file we are gonna and one more thing to remember is that i have added this dot io library so we are working with input and output streams so they are called as streams input stream and output streams so that's why we must include this library also dot io so guys now we will just see how we usually print to the console so i'll just write flutter so framework for dot and now let me just run this program and as you can see it has printed flutter perfectly and it has exited the program so whatever is there in the print function is being executed now the io library provides us std out of standard output stream which gives us more functionality rather than just the sprint function so let's see what else functionality it gives us so for using that i'm gonna write std out and here i'll just write dot dot operator and here as you can see it provides us with multiple functions and member variables you can call them so here first we will be discussing about these in the last which we have that is right line right all and right so now let us check the first one which is right and here i can just give my okay i'll just give flutter itself i'm fed up of writing my name on all the videos guys i'm sorry for that if you are also fed up with that so now let me just run this program again so guys as you can see it has also printed flutter the same way as the print function did and now we are gonna add ln to it so it is right line so it was right std out dot right and now we are adding std dot right line so now let us see what this does to the program so i think you can see the difference that when we are using right it has only printed that it has only taken one line and it has printed it out and after that it exited it whereas right line prints it at one line takes another line space and or goes to the next line and then exits it whereas in right it actually prints it and exits in that line itself so that's how it works right and right line and now let us see the other one which is right all i think so it is right all so as you can see right all and here it's gonna take an iterable object suppose like map sets or list and it does a special thing which would be very fascinating for you to see that so i'll just give some values inside this thing so i'll just write so these are some of the popular frameworks web frameworks and mobile app frameworks and now if we hover on this we'll get a description about what this function will do and here it says iterates over a given list of objects and so as you can see list of objects and here writes them in sequence and after that if separator is provided so here we have optional parameters so in the previous video while we are discussed about functions that time we covered this which is an optional parameter and named parameter if you have not seen that check that video and then come back over here and here as you can see the square brackets over here also they're not that this is an optional parameter and this optional parameter is a separator so what exactly is separator so it will separate each elements so first let us see how it works without giving a separator so i'll run this program and here as you can see it has printed all in the same line that is flutter react angular simple now let us add a separator and see how it works so i'll just write comma and here i'll give some dash i'll give dash and here let me just run this program and as you can see it has separated each element with the dash as you can see over here so that's how it works you can not only add a dash you can add pretty much any value i'll just give a space inside that and it will also give space inside that as you can see in the output so flutter react angular so that's how it works right all so it is giving more functionality than actual print function so print function doesn't have this if you take in python it has that separator thing but in that if you want to use it you must use this standard output stream and this function right all and they're more functions but it might be a little bit difficult for you guys right now to understand all those functions so we won't be covering that and now let's go to the input input part of standard library or standard streams so we are going to write std and we are going to use std in and here we are going to use the read line sync and here the description also as you can see it says read a line from stdin and whatever it reads from that input is a string data type so let me just use this and i'll keep like this so now if i run this program it will ask me for an input so i can give anything and it will exit so that's it and i can even store it in a variable so if i want to store it in a i'll just write var my where equals and here we can use the std out so first end it with the semicolon here study out so it is better we'll use print function for now writing that much big line but better you use the print function itself because it's very short and easy to write when you need more customization for your output statements that time you can use standard output it is not necessary and compulsory that you must use the standard output you can use the print function as usual now i'll just write my where so it will print my wire inside the terminal when i run this program so i'll just write like this and it's asking me for input and i'll press like this and it is printing that so let us check the type of it dot or runtime type if you remember this runtime type and now let's again go back to the terminal and let me just give a string value and it is still that now let me just give a numerical value still it is a string now to actually convert it we can use the same way how we did in kind of when we were doing the type conversions thing so that time i used int dot parse so if you remember n dot parse function to convert it to an integer number and now let us go back to this and here i'll give like this and as you can see it has changed successfully to end and here we can even change it to double as well so d-o-u-b-l-e and let us go back over here and double and three point so something random value is double that's great so guys that's what's about the standard input and standard output in dart i hope you like this video please be sure to subscribe to my channel and hit the bell icon so that you never miss any updates and don't forget to like this video as well thanks for watching see you in the next video"}], "Dart Programming Tutorial | #13 Introduction to Object-Oriented Programming (OOPS) | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i am aditya and in this video guys we'll be starting something interesting i hope you might have guessed or if you have not guessed guys we are starting object-oriented programming dot language so guys hats off to you first of all that you have completed almost the basics of this programming language that is start and actually it is a very tough job in the as as a beginner for you guys to actually learn all these basic stuff and i have taken almost 11 to 12 videos i think for completing all these things and now we'll be stepping ahead and learning about advanced topics like this oops concept and guys one more thing is that we have not actually totally covered about basic concepts in our dart language there's still more left but we just can't keep staying here and learning all the basics and almost 20 videos like that it may even take more mass to them so we'll be just stepping ahead and learning this and go on like that it is up to you that how you master all these concepts so guys without wasting your time right now let us go and learn what oops concept is so let's dive in so guys here uh you can see that we have a file open so guys what exactly is oops concept or object oriented programming so most of the people who are new to programming world hearing this word called as oops they get like tensed and worried about what exactly is this oops oh my god object 200 having what is it about so no need to worry guys it's a very simple concept so let me just take as an example in game development uh you first create a model or whenever we want to create a key and design actually uh i'm talking about game game development because i'm actually a little bit more interested in that so what happens in game design is actually that mostly we create first what exactly is the game is gonna be like a blueprint of how it's gonna work and then according to the blueprint we'll be implementing things in the game and we'll be creating like that depending on the blueprint so same goes uh with the object-oriented programming as well so object oriented programming so we see everything as objects now as i have told you the example of a game development scenario where we create a blueprint and then implement it in the game development process same way in our lives also uh there's actually like we can take our life as an example as a blueprint so suppose i just say i am a human right so i am a male human so you can take you can write it down on paper just like uh i have brown eyes i have two ears so whatever things description you right about that that's nothing but a blueprint about how i am looking and you can even write functions about what i can do i can talk i can sleep i can walk so whatever you write all the functions and all the properties of myself just like the game development group blueprint same like that if you write in a paper that's nothing but a class so that's how object-oriented programming works and taking that class or the blueprint you create an object so you can say that i am an object of that paper of the information in the paper so i hope you're getting it might be a little bit difficult to get this concept in the beginning don't worry guys you watch this video again you'll surely get it and now guys in the programming style it's just called as class and it has all the natural things which we have just like inheritance so inheritance is just like there are kids right then there are brothers they inherit all the features of their parents same like that one object can inherited inherit features from another object so that's similar and there are multiple forms so just like multiple forms is that when we are with friends we behave little bit differently when we are with parents we behave differently so there's multiple kinds of mindset with us right when we think when we talk with people same like that objects also behave differently depending on the situation that is nothing but polymorphism and then we have abstraction so abstraction is simple it is just like uh like private things and public things some things you tell it to the public some things you keep it to yourself and then we even have protected some things you don't want to tell it to the whole public but you want to tell it to some people just that is just like abstraction and then we have encapsulation so encapsulation is nothing but just like using these variables and functions so variable you can just take it as i have two eyes so you can just keep ice number equal to 2 that's nothing but a variable simply in programming terms so now i can use these eyes to see so c is a function and these two are nothing but variables so function and variables are being used together by each other so that's nothing but encapsulating so i hope you got these four main concepts and oops that people most get confused a lot of times so now let us see a basic implementation of a class or a blueprint how we use it in that programming language so guys first we'll write class and here i think you might even see in the intellisense so here we got a snippet so here i'll just write like this and let us declare something like a human so just the same example which have taken human and guys here we can actually create variables so and ice number of eyes i can just keep number and now i'll just end it with a semicolon so this variable inside that and here we can even create multiple variables like hands so i won't write my hands and i want like number of hands like that so i'll just write hands and then legs so usually humans have like that you can even create your own blueprint like an area like five hands five legs so that would be little bit more funny but as it is programming it is not real world you can create whatever you want know or not even care about it but it depends on the condition when you are developing a software you will use this object to end programming a lot so here we just created i think three basic variables and now let us create a constructor so now what exactly is a constructor so now as we have created this variables when we actually create an object or initialize an object so that time so this actually class so you might be able to what is uh creating an object initializing an object so as this class right now this is not actually the object itself this we are just defining that an object will be like this so using this blueprint we must create an object so here for simple uh demonstration i'll just create human so i'll just create myself so ah so human aditya and here that's done we have created a human object and here we can just write you uh i think it yeah sorry i can just write aditya dot number of ice and i'll get the number of ice i have so that's how it works so now and i think i must even change it to a over here so that small a always uh the class name should actually start with the capital letter rather than the uh variable itself now guys we must actually define a constructor so we were not even getting some intel essence right that will all be fixed after we define a constructor so now what exactly is a constructor right now these all variables are having the value of null so we must actually give them some value right so that's why we use a constructor and constructor doesn't have any return type so you won't write in or void so you will just write human and here define it just like this and you won't write any statement like that as i mentioned and here i can just write or if i can even give named like that so i can just write in and mostly i'll even enclose this into like this so these are all optional parameters now i can just create something like if so now it will check actually what are these values if they are equal to null then set it to this and here it will even go to the if statement else and all those things and let us check actually how does this work really or not i think i have made some mistake i don't know it happens in programming you can make mistakes now let us check it so i'll just write aditya dot and here we must actually okay here we have declared the variable now let us actually give some values so for giving i can just write lex is equal to two and suppose let us give just like three and i'll change it to something like alien human is an alien and here we'll even give a comma and we'll say hands is equal to 4 so let us leave the eyes itself same like that and now guys let us print them so print and here we'll write alien dot and here we'll just write number of uh hands and ends to the semicolon so here we get some error so guys we get an error the reason is that we must actually enclose it within the main function and after that all the errors will go off so now i'll just keep over here like this and all the errors are gone as you can see so we were actually just keeping it in the class itself so now i think the class is also inside a whole separate block and the main function is also in a whole separate block so now guys let us run this program so to run this program we'll just open the terminal and here i'll just write dart main dot dot and now guys as you can see the output we got four so the number of ants which we gave is four and the legs is equal to three so now even let us print the number of legs as well so ctrl c and let's give control v three times to check all the values so now let us run this program again by using the command dot main dot dot and here we actually get null and none so there's actually some problem as i mentioned i have made some small mistake so it has made a mistake and right now the video is also going very long so we'll just fix this error in the next video and in that video we'll even be covering about more options how we can use functions with this so don't worry we'll fix it we'll learn more interesting topics guys and it's common you will also make a lot of mistakes guys so i hope you might have got the idea about how oriented oops concept works so guys that's it for this video i hope you like this video please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates thanks for watching see you in the next video you"}], "Dart Programming Tutorial | #14 Fixing the Error Using Switch-Case Statement| Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i am aditya and in this video guys we'll be fixing the error which i made in the previous video and we'll be even learning some interesting topics as well so without wasting any time let's get in the video so guys here as you can see on the screen we have an ifall statement in the previous video i have not actually shown you how i have written this so that i could just save some time but actually we do not need this we'll be learning another topic which is switch case statement if we use if else at this point it may be a little bit difficult for us to understand and write more precisely whereas which case statements make it much more easier to understand and more precise as well more easy to write so first i'll write switch case i don't know if we have discussed this i don't think we have discussed so now we'll be learning about that and here first i'll write ice i'll just write a sample code and then i'll explain what it is happening over here so ice and here case is equal to null and here we'll set this dot number of eyes is equal to 2 so now what exactly is happening over here to understand this much more clearly i'll just keep an image in the screen right now so that it's just like a flow chart switch case float start and here first this ice as you can see single expression so the expression here is nothing but ice so first it is taking the expression and here case so in case it will take the value it's going to have so it will check it's a case constant so it will check if ice is equally equal to null so if it is yes if it is equal to null then it will run this code whatever is there here and it will break so break is nothing but it will get quit this whole loop or this statement and if it is no it will go to the another statement whatever we can add multiple statements like that so i'll add case three like that so case three case one case two so like that we can add multiple statements so i'll add like that so you can add like that how many other statements you want it doesn't matter so if it only goes false that time only it will run and if you don't add this break so it won't actually run so perfectly what will happen is if you have multiple states uh cases so that time when this case comes true and it executes the code inside over here it goes and checks the other statement ads as well so that actually increases some time and you can even get some error so that's why it is better that you add break so break will quit the whole loop over here and what happens if none of the cases which are which we have given are coming as false so that time this default will run so i can just give like this dot number of i's is equal to ice so now what exactly is happening here is that first we are taking the variable ice which uh which is an optional variable over here and we are checking if user does not give any value so if user does not give any value its actual value will be equal to null so it is not having any value rate so then we will keep a default value that is 2 number of hands is equal to 2 and it will quit the program after this break statement now suppose a user gives a value that time this case will become false right so it doesn't work out the value is not equal to null so it will come to this default whatever is there in the default statement it will start executing that so what it is what we have written over here is that just set the number of eyes is equal to the value given by the user that is nothing but ice so like that it works uh so i'll just copy this for other three variables as well so ctrl c and here we'll paste it so that's it and now we can change the variables so guys now i have completely written it down properly so here first with case statement we'll check for the ice so if it is equal to null since user did not give any value it will keep the default value which is 2 if user has given any value then we'll set that value as the number of i's and here for hands also the same two hands default and here you might be a little bit getting confused about this default break try out yourself some more examples so here switch this just like an fl statement but in a different manner of writing these statements so that's it very simple concept and now let us run this program so we'll give a will actually add a string so now enclose with this curly braces so that it identifies this whole thing as a variable so if i don't keep that then it is identifying only alien because of this dot operator so you can also do the same thing add a curly braces and here the same thing will do that so now guys i have completely written it down properly so number of hands number of legs and i'll just remove this extra space so now it's perfect and now we'll run this program and check out what the output is so to run this program we'll just use the terminal and here we'll write that main dot dot and now let me just press enter and it should run perfectly and here because the answer number of hands is equal to 4 so here what we have given is 4 and that's that's correct and number of legs is equal to 3 what we have given is also correct and number of eyes we actually did not give anything so it's taking the default value so what is the default value we gave it as 2. now suppose i keep one over here and again run the program that time we are getting one so i think now we are understanding how this is working so i'll just reset it back to two so guys mostly that's it for this video and i would just like to summarize what we have learned till right now so a class is nothing but a blueprint of what we are trying to create so here we are trying to create a human so this human class is having all the variables and here we have a constructor so a constructor is something which initializes is a special function so actually it is a function which initializes all the variables of a class so these all are the variables and this constructor is responsible for initializing all the variables if you do not give any kind of constructor or you do not do not mention your own constructor default constructor will be made by the dart compiler itself and that will be running which will set all the values to actually null so now we have given this so it is actually setting according to our statements so that's how it works and always remember that the constructor name should be always equal to the class name and it is not going to have any written type suppose like in or void like that so it's not going to have anything like that so as it is special function so that is the reason and here this is the way how we can create a object of a class we are creating a human object so and we have kept the name name of the object as alien and here we have given its legs and hands and then we have printed it out so i think now you might have understood about how it is working so in the next video we'll see how we can use functions not in this video i thought about telling this video but i just want to make a separate video explaining all the concepts like function overloading and then we even have operator overloading many advanced topics interesting topics as well don't get scared by all these concepts so that's it for this video guys i hope you like it please don't forget to subscribe to my channel and share it with your friends family everyone so thanks for watching see you in the next video"}], "Dart Programming Tutorial | #15 Introduction to Inheritance in Dart | Aditya Burgula": [{"content": "Hello Guys welcome back to another\u00a0\nbrand new video I am\u00a0Aditya\u00a0 In this video guys we'll be learning a new\u00a0\nconcept of object Object Oriented Programming\u00a0\u00a0 or OOPs so if I have not told you before\u00a0\u00a0 there are actually four main pillars\u00a0\nof Object Oriented Programming or OOPs that is abstraction polymorphism and then\u00a0\ninheritance and then encapsulation so i guess\u00a0\u00a0 i have told this before if not i i'm telling this\u00a0\nright now so today we'll be specifically going\u00a0\u00a0 deep dive into the concept of inheritance and\u00a0\nwe'll be also giving i'll also give you a summary\u00a0\u00a0 of what other four other three are so without\u00a0\nwasting your time guys let us get into the video\u00a0\u00a0 so guys let us discuss about what\u00a0\nthese four lists are so abstraction\u00a0\u00a0 abstraction is very simple it is like what data\u00a0\nwhatever data you have in your class or functions\u00a0\u00a0 how you wanna show it like you wanna hide\u00a0\nsome things or you want to show keep it public\u00a0\u00a0 a better example would be Java or C++\nwhere if you declare some variables as private\u00a0\u00a0 they cannot be accessed in the object instance\u00a0\nand if you keep it public it can be accessed by\u00a0\u00a0 anyone and C++ and Java i guess they also have a\u00a0\nkeyword called as protected also so which means\u00a0\u00a0 it can only be accessed by the sub classes so\u00a0\nnow what is the subclass we'll be deep diving\u00a0\u00a0 into that right now so that was about abstraction\u00a0\nand polymorphism is like when an object behaves\u00a0\u00a0 differently according to different situations so\u00a0\nwe'll be also seeing that also and then we have\u00a0\u00a0 inheritance which will be going deep dive\u00a0\ninto that and inheritance i think i have\u00a0\u00a0 told the concept so inheritance is where uh an\u00a0\nobject inherits some features or characteristics\u00a0\u00a0 from that object into its own so our class\u00a0\ninherits features from that class to another class\u00a0\u00a0 so that was about inheritance and then we\u00a0\nhave i think we have covered about them\u00a0\u00a0 encapsulation encapsulation is very simple\u00a0\nwhen variables and functions together combine\u00a0\u00a0 to create new tasks or whatever to solve a\u00a0\nproblem that is nothing but encapsulation\u00a0\u00a0 so it's very simple now let us go deep dive\u00a0\ninto what an inheritance is inheritance concept\u00a0\u00a0 so in most programming languages like c plus\u00a0\nlist i am very familiar with c plus list so what\u00a0\u00a0 happens is that in c plus uh you actually\u00a0\ncan inherit a lot of feature uh features\u00a0\u00a0 from different classes but dart only allows to\u00a0\ninherit features from only one class there are\u00a0\u00a0 alternative methods so first let us see the basic\u00a0\nimplementation of inheritance and then i think\u00a0\u00a0 you may get to understand what i'm talking about\u00a0\nso here so let us write a longer class actually\u00a0\u00a0 so here i'll write class so basic class definition\u00a0\nstarts like this class and here i'll write logger\u00a0\u00a0 so a logger class is just like logging to\u00a0\nthe console whatever info we want so here\u00a0\u00a0 uh let us make a constructor\u00a0\nand here we'll say print and now\u00a0\u00a0 let us create a special function called log void\u00a0\nso let the return type be y and we'll say log log then we'll say it will take a string and let\u00a0\nit be text and here we'll write print text so this\u00a0\u00a0 is a simple function now what we'll do is make a\u00a0\ncustom log so another class so i'll write custom more better examples of this can be\u00a0\nlike a vehicle a base class of vehicle\u00a0\u00a0 like here we have logger rate so we can\u00a0\nhave a vehicle and a car as a subclass\u00a0\u00a0 so just like custom logger over here so logger let\u00a0\nme just add the class keyword class custom logger\u00a0\u00a0 and here what we'll do is do the same thing so\u00a0\u00a0 we'll write void we'll actually copy the same\u00a0\nthing and change it a little bit so uh now we\u00a0\u00a0 have created like this so this is totally two\u00a0\ndifferent classes so when we create a new object\u00a0\u00a0 of these both it will be almost the same so not\u00a0\nthe same i'm sorry so these are two different\u00a0\u00a0 separate classes now what we can do is if we want\u00a0\nthis function in the custom logger instead of\u00a0\u00a0 retyping this function again what we\u00a0\ncan do is just write extents and write\u00a0\u00a0 log now here you can see we get annotate override\u00a0\nmethods so we'll also discuss about overriding\u00a0\u00a0 of functions so for now let's just keep it\u00a0\nlike this and we'll just write custom logger and here we'll just write super and here i\u00a0\ndon't think we can okay let us just close this\u00a0\u00a0 so the super is nothing but calling the base\u00a0\nclass constructor over here you can see right\u00a0\u00a0 so it is nothing but calling it now what we'll do\u00a0\nis we'll create an instance of it so custom logger is equal to new let us give it a name my logger is equal to new or we'll just write custom number and end it with a semicolon so now what we can do is we can call my logger\u00a0\ndot and here we can see the log method\u00a0\u00a0 so here you can see log now here it\u00a0\nis asking for text and let us say from\u00a0\u00a0 from my logger so as you can see over here in\u00a0\nthis class we have never declared or initialized\u00a0\u00a0 this function anywhere defined so we never\u00a0\ndeclared and defined this function called as\u00a0\u00a0 log we whatever whatever we have defined is in\u00a0\nthis for this class that is logger class and we\u00a0\u00a0 are inheriting so we are inheriting a feature that\u00a0\nis a function in this case and we are using it so\u00a0\u00a0 now let us end it with a semicolon and run this\u00a0\nprogram so run without debugging so here you can\u00a0\u00a0 see we got a logger class instantiated and from\u00a0\nmy logger so we call this log function and this\u00a0\u00a0 constructor so this constructor is calling the\u00a0\nbase class constructor so this is called as the\u00a0\u00a0 base class constructor and this is called as a\u00a0\nsub class so base class and subclass so let me\u00a0\u00a0 just write over here so we are inheriting\u00a0\nfrom logger class into custom class and in\u00a0\u00a0 the constructor of this subclass we are calling\u00a0\nthe base class constructor so that's why we are\u00a0\u00a0 getting logger class instantiated now let us\u00a0\ncreate a log a class direct log class and let\u00a0\u00a0 us add one more functionality to this instead\u00a0\nof log we'll just write a new function like\u00a0\u00a0 print line something like that log line will\u00a0\nwrite like dog line a new separate function\u00a0\u00a0 what it will do is like it will create\u00a0\nit will just print the same thing\u00a0\u00a0 print text and in the end we'll add two new\u00a0\nlines so i'll just take argument as string\u00a0\u00a0 and we'll have text and here what we can do\u00a0\nis enclose it to this and two curly brackets\u00a0\u00a0 and you keep a dollar sign and here slash and\u00a0\nkeep it like this so here we got some error\u00a0\u00a0 i guess there's an undefined name text so here it\u00a0\nis text and now i guess the problem is gone so it\u00a0\u00a0 will actually keep two new lines after printing so\u00a0\nthis is only available in the custom logo function\u00a0\u00a0 not available in the logger function so let us\u00a0\nsee that so logger create a new logger object\u00a0\u00a0 and we'll say here we'll actually give it\u00a0\nlike my custom logo my log is equal to log\u00a0\u00a0 that's like finally always king log log and\u00a0\nnow what we'll do is see as you can see it\u00a0\u00a0 is still functional because logger class also\u00a0\nhas the log function now let us use a specific\u00a0\u00a0 means only a function which is only specific\u00a0\nto the subclass like let us use custom\u00a0\u00a0 logger we have already created my custom\u00a0\nlogger dot and here you can see we get\u00a0\u00a0 log line and here also we can say and here\u00a0\nwhat you can do is end it with a semicolon\u00a0\u00a0 and now if we try to do it with my\u00a0\nlogger which is the base class of this\u00a0\u00a0 we only have the lock function as you can see so\u00a0\ni hope you're getting the point now now we'll just\u00a0\u00a0 remove this and now let us run this again so here\u00a0\nyou can see logger class instantiated two times\u00a0\u00a0 so because we are creating two objects over here\u00a0\nso one over here and one over here and what you\u00a0\u00a0 can do is actually object or let us take a string\u00a0\nsub class name so and let us make this actually\u00a0\u00a0 optional subclass name yeah i forgot so yeah here\u00a0\nand we'll write if subclass name is equal equal to\u00a0\u00a0 null just like this null then what you do is just\u00a0\nprint like this log a class instantiate it else\u00a0\u00a0 so print okay so now we are done with\u00a0\nthis so and here while calling let us give\u00a0\u00a0 custom logo okay so here do we get an errors so\u00a0\nnow let us make it into equals and now the problem\u00a0\u00a0 should be gone so yeah now let us run this program\u00a0\nand here i guess here yeah here you can see first\u00a0\u00a0 we have created the custom logo object and here we\u00a0\ncan see logger class instantiated from sub class\u00a0\u00a0 of name custom logger and then we created a new\u00a0\nobject of logger this logger class instantiated\u00a0\u00a0 and from my logger and function specific to\u00a0\ncustom logger only that is logging so this was\u00a0\u00a0 about how inheritance works and i've shown some\u00a0\nfeatures so always remember this keyword called\u00a0\u00a0 as super here actually you can create now you\u00a0\ncan have your own constructor function also like\u00a0\u00a0 uh print and press like this so here you can see\u00a0\nwe have declared our own constructor over here and\u00a0\u00a0 with that we are also calling the constructor of\u00a0\nthe base class and giving it an argument of sub\u00a0\u00a0 class name and printing custom logger instantiated\u00a0\nnow let us run this program again so here\u00a0\u00a0 so here you can see logger class instantiated\u00a0\nfrom subclass and here again we get custom\u00a0\u00a0 logger instantiated so as you can see it\u00a0\nis first calling the base class constructor\u00a0\u00a0 and giving the required arguments later after\u00a0\nthat it is calling the constructor function\u00a0\u00a0 whatever we have defined over here and after\u00a0\nthat as you can see we have logger class soon\u00a0\u00a0 now what else we can do is that we can overwrite\u00a0\nfunction so mostly we'll discuss this in the next\u00a0\u00a0 video so thanks for watching guys i hope you have\u00a0\nunderstood what inheritance looks like in dart\u00a0\u00a0 so it might be a little bit complicated you can\u00a0\nwatch the video once or twice till you get it if\u00a0\u00a0 you have any doubts please keep it in the comment\u00a0\ndown below i'll always try my best to answer\u00a0\u00a0 every one of your doubts and questions so\u00a0\nthanks for watching guys please be sure\u00a0\u00a0 to subscribe to my channel and never forget to\u00a0\nhit that bell icon so see you in the next video"}], "Dart Programming Tutorial | #11 More on Functions | Aditya Burgula": [{"content": " Hey guys, welcome to the brand new video I am Antia and in this video guys we will be learning about some things on functions, especially we will be learning about how we can use optional parameters and named parameters in dot language which is also a feature provided by dot language for us. So without wasting time let's get into the video. So guys right now here on the screen I have a dot main dot dot file and here I think we can remove this dot collection. So we don't read it right now because in the previous video we have covered about the three basic kind of previous videos we have got about three basic collections or data factors that is list maps and sets. So if you have not seen them you can go and check them out and they can come over here. So guys first let us declare a function. So to declare a function first we write the written data type. So I think I even have not covered about the written data type which I will be covering in this video as well. So here first I will write I will give a name kind of my function my function and here let us declare it. So we take parameters right normally we take parameters such as int a comma int b. So like that we take the parameters right but sometimes we don't need a parameter which is sometimes optional. You sometimes you may need it in your function and if it is even not there your function is fine. So that time you can use optional functions or named parameters, optional parameters I am sorry optional parameters or named parameters. So for doing that for the next two types as I have to do optional parameters. First we will see for optional parameters you will use syntax in my list. So you will keep the two square brackets and inside this you will mention your parameters. So now these are your optional parameters you can name any of them nothing no problem and here you can name your required parameters int b. So like that I can do like that and now inside this function I will just write if a. So I will just remove this int b function int b parameter because we don't need that right now as we are only covering about this thing and here I will write is not equal to null. So null is something when there is no value inside it. Suppose we didn't give anything to a. So suppose they did not give any value or they did not use the optional parameter a. That time the variable a will be assigned to null. So if the user gives any value to the optional parameter then it will have that same value if user doesn't give then it will have null and here I will just write like this if and then print and here we will give a string and here I will say dollar symbol. So dollar symbol and a. So you use dollar symbol just called as formatting also. So in python you use dot format method if you are similar to python if you are coming from python you use dot format method and if I am in java i javascript I think we use the same dollar symbol to actually represent the variables inside a string. So here we are using a string double quotes right. So like that I can use that and here a is given as optional parameter and now here else I will say print. So I will write print and I will say optional parameter is not given and now we will end to the semicolon and here let us run this function. So to run it I can just call it so my function and here I will end to the semicolon notice you see that when we have added the square brackets it is not showing any error in the function call. Now as soon as I remove those brackets we get an error saying that one positional argument is expected. So now as soon as I add this it is changing it to an optional parameter. So it does not actually require it. No let us run without giving any any value inside it. So for that I can just go to the terminal and write dot. So see a less first and dot main dot dot and press enter and it should say that optional parameter is not given. So we have not given it. So here the value of int a is not known. So I will just when print the value value equals value of a equals dollar a. And now let us go back over here again on this program and as you can see optional parameter is not given value of a is equal to null. So I have told you if there is no value inside it then it is assigned as null. So now let us give some value to the optional parameter. Let me just close this thing and here let us let me just give an interior value. So here we have int a and no. Let us run this program again and we should get h7 is given as optional parameter. So that's about optional parameters. So guys now let's cover named parameters in Dart. So for that I can just delete the previous one and I'll use curly braces inside and here I'll write int h. So here I n and t okay now int h like that I have given a name the parameter here. I can just write h. So as you can see it has given me age colon. So you use colon and here I can say 15. So that's my age so I'll just give like that. So now it is accepting it. Now if I remove this still no problem. It will still work. Now let us just run this program again and here we are getting okay. We have we should change this to actually age. So here age and here also age and here age. So now let me just run this program again and optional parameter of age. So here also if we can change it to age then still we can have a better understanding or better printing. So here we can say optional parameter is not given to value of age is equal to null. So this is named parameter we can write named and so that's what it works and now let me just give a value inside that. So I'll write age, age, colon and here I'll give some value. And now let's run this thing and here you can see 787 is given as optional parameter. Okay."}, {"content": "I did not change it. Let's leave it like no. So that's it about named parameters and that's why flutter is so famous because it is very similar in flutter. If you're not familiar with flutter in flutter uses named parameters a lot is a lot. So that's why it became famous because this named parameter syntax is very similar to CSS or cast-cading style sheets in web development style. So there you use call-ins and you separated to commas or semi-call-ins. So that's why it was very similar very easy and people liked it a lot and that is the reason it is becoming very famous. The flutter and dark to grammar language, especially the flutter framework. Okay guys now I have covered about the optional parameters and named parameters. So I think I did not see about the written data type in the functions explanation video. So let's cover that over here. So what exactly is a written data type? So written data type or written value is something that is written up with the function is executed. So right now when the function this function is completely finished, it is not doing anything. Sometimes we want the function to do something after it completes a task. So that's what suppose like checking it or doing something or returning a value mostly you return a value. So that's what we'll do over here."}, {"content": "So I'll just try to return."}, {"content": "So here we have changed it to white. So white tells us that why does when we are creating a function saying that it has a written type of void, we are telling it that it is not going to return any value. So for right now I'll just change it to int. So right now I'm saying that return integer value and here I'll write a return H and H plus one. So this is a simple written statement. So after running this program, I'm written in T H plus one. So let's run this program and see does it work actually or how do we use it first? So first let me run this program and here nothing much difference. So let me just clear this here less and here I just give my age as 15. And after running this function, I'll just I'll create a variable called as where my name or my age equals my function. And here I'll just add like this my function. So here I think I have made a small mistake by not writing function. So I'll just write function and here function and here let me just give the value of age equals 15. And in the last we'll just print my age and get rid of the semicolon. Now let's see what will actually happen."}, {"content": "I think now we are getting the concept. So let's run this program and here we can see 15 is given as optional parameter. So it is actually running twice. I'll just remove this one."}, {"content": "So it becomes much clear. So here as you can see it has executed this program successfully when we wrote this print my age function. So after execution it is returning a value and that value is nothing but 15 plus one. And here it is given the six which we have written over here. So let me just comment this out first and let us see what happens without this. Let me just run this program and here it has run this program actually. So actually I'm sorry guys I just told you I think I told you that it is running in the print statement. No it is actually whenever we assign it it is running that thing function. So guys I hope right now you got the concept clearly."}, {"content": "If you have not understood anything so you can comment down in the comment section below. So guys that's it for this video. I hope you like this video. Please be sure to subscribe to my channel and hit that bell icon to never miss any update. And if you like this video if you like it so see you in the next video."}], "Dart Programming Tutorial | #6 Conditional Statements(for-loops) | Aditya Burgula": [{"content": "[Music] hey guys welcome to another brand new video i am aditya and in this video we will be learning about condition statements only but we'll be covering loops part of the condition statements so now before going on to coding about how these things work let us understand what exactly is a loop so let's have a small example to understand this more clearly so suppose you have a lot of friends like so i have almost 30 to 60 friends now what if i wanna use the names of my friends and add some kind of funny ending or do some kind of operation with their names or just simply print their names onto the console so that time i would uh rather write print statements the number of times the number of names i have rather i would use loops to make my life much easier printing the names so now it might be totally confusing to you right now so let's see how we do that so i'll just declare a variable before itself so i'll just declare a variable variable called count equals some hundred so i have some 100 friends and now let's use a loop so mainly there are three loops in dart and these are mostly same in most of the programming languages like we have for loop for each or foreign loop and then we have while loop and you even have do while also we'll be covering all of them but for this weed as we are still beginning the dart programming language we'll be just using for loop so in the snippet as you can see we have a simple for loop format so here first thing which we see over here is a variable called i so it's a temporary variable after the loop is done executing this variable will no longer be there in the scope i mean it would be dead there won't be any variable called i if you want to use outside the slope again you must declare it as i so you just can't use again reassign it will give an error saying that this variable is not declared because it's only being used in the for loop and coming to the second part is nothing but a condition conditional statements so for loops also depend on a condition so here this is depending on a condition that i is less than or equal to count so first the variable is declared initialized it is checked for a condition and after checking if the condition is true it will do whatever is there inside this block so i'll just write i so it will do whatever is there in this block so it will print the value of i and after doing all the things inside the block then it will come and increment the value of i so after incrementing it will become one again it will come here check the value check the condition again it will print check and increment so it will continuously go on like this after some time when the condition comes to false where it would be 100 is less than count or means 100 is less than 100 which is not true that time it will not execute this block so to check it out ourselves let's open this and let me just clear this and here we'll run the command dot main dot dot and here as you can see it has printed numbers from 0 to 100 if you see over here 0 1 3 4 5 6 000 until 9 9 n actually the reason is that when it comes to 100 it is saying that i is less less than count means 100 is less than 100 which is not true so we can just keep less than equal to that time if we run the program again so it should print a still hundred so as you can see the last number we got was hundred and you can even change this to one to actually print it from exactly one so that's how we can use loops there are actually a lot of cases how we use loops you can iterate over when loops and iterating is the same term iterating this continuously going through a particular item so like the nestle just like my friends names i have a database full of my friends names i wanna iterate through my friend's name so i wanna just go to one friend's name again do some operation there again go to the next friend's name so that is called as iterating or looping through each item so it might be totally confusing i suggested you watch this video once more so you get more clear understanding of what exactly is loops if you're coming from another programming language like c sharp c plus plus java the concept is very same you can just go to our next video where we'll be covering about more advanced topics so guys that's it for this video i hope you like this video please be sure to subscribe to my channel and hit that bell icon so that you never miss any updates thanks for watching see you in the next video"}], "Dart Programming Tutorial | #5 Conditional Statements (if-else) | Aditya Burgula": [{"content": "hey guys welcome back to my channel i'm anthea and in this video we'll be learning about conditional statements or will be starting to learn conditional statements as till now we have not yet covered but we have done the basic stuff like uh data types operators variables type conversions so without wasting time let's get into the video so guys as i've said we'll be covering about conditional statements one thing i just want to tell you is that if you are from another programming language like c plus plus java or from python like that the syntax is very similar the concepts are also same in any programming language you can just skip this video or and start watching from the next video so and if you're completely bigger keep watching this video okay so what exactly is a conditional statement we'll be covering if else right now uh mostly in the next video we'll be starting loops so what exactly is this if else or a condition statement so the simple uh definition is that a condensed statement is a group of tasks which will be done when a particular condition is true so in the data type section also have told that booleans are going to be used so here is where we use booleans or boolean data type so guys the syntax is also very similar uh the intellisense is giving me some blocks so i can just use this kind of templates so here we got if and else so let's see how how we can do this so before uh working with the statement i'll just declare a variable so that it would be much easier so i'll just write a in okay in a equals 10 now if so here we have an if block so if it's gonna take a condition so in this brackets we are going to give a condition so i can just write if a is greater than 9 so these are these we have operators like greater than less than less than equal to same like mathematics so i won't be telling them right now because that's very simple guys so those operators nothing much in them so as you can see we have if a is greater than 9 so this is actually a condition if a is greater than 9 so i'll just show you if this is a condition or not it will return a boolean value so i'll write bool condition equals a greater than 9 and let's print this to check if that is really a condition or not so here we'll write contagion so remove one extra bracket is there and now let's just remove this f block also so open a new terminal for running and then here the syntax is very similar dot main dot dot press enter and okay we have got one error okay and now again press [Music] run so as you can see the bool value is returning so here we have given a condition a is greater than 9 so 10 is greater than 9 and it is returning a boolean value that is either true or false so as it is true we are getting true so now we have understood that booleans are used in conditional statements so somewhat so now let us use the effects so if and we give a condition in these brackets so if k greater than 9 and here we'll write print a okay we'll write we'll give a string so we'll write a is greater and close it with a semicolon and always forget to check always check if it is ending with proper quotes or not sometimes you may do such mistakes because you're a beginner and even i do some mistakes now let's run this program and check out the answer so as you can see we got a is greater now what if i change this to 7 now let's run this program nothing happens so when the condition is turning out to be false for that that time we use a block called as else block so if the conditions block false then you use the else block and in this you write whatever we want to do so i write print i'll give a string a is lesser and now end it with a semicolon now let's run this program again and as you can see we have got the output as a is lesser so that was about if and else so i think you're gone you have understood this little bit uh it takes a little bit time to understand this condition statements and loops all these things so try to practice more see some examples and if you have any doubt please write it in the comment comments down below so thanks for watching please be sure to subscribe to my channel and hit the bell icon so that you never miss any updates see you in the next video"}], "Justice: What's The Right Thing To Do? Episode 03: \"FREE TO CHOOSE\"": [{"content": "Funding for this program provided by Additional funding provided by When we finished last time, we were looking at John Stuart Mill's and his attempt to reply to the critics of Bentham's utilitarianism in his book Utilitarianism,   Mill tries to show that critics to the contrary, it is possible within utilitarian framework to distinguish\nbetween higher and lower pleasures, it is possible to make qualitative distinctions of worth, and we tested of that idea with the Simpsons in the Shakespeare excerpts and the results of our experiment seemed to call into question Mill's distinctions because a great many of you reported that you prefer the Simpsons but that you still consider Shakespeare to be the higher for the worthier pleasure that's the dilemma with which our experiment confronts Mill. what about Mill's attempt to account for especially weighty character of individual rights and justice in chapter\nfive of utilitarianism? he wants to say that individual rights are worthy of special respect in fact he goes so far as to say that justice\nis the most sacred part and the most incomparably binding \npart of morality but the same challenge could be put to this part of Mill's defense why is justice the chief part and the most binding part of our morality? well\nhe says because in the long run if we do justice and if we respect rights, society as a whole will be better off in the long run. well what about that? what if we have a case where making an exception\nand violating individual rights actually will make people better off in the long run is it all right\nthen? to use people? and there's a further objection that could be raised against Mill's case for justice and rights suppose the utilitarian calculus in the long run\nworks out as he says it will such that respecting people's rights is a way of making everybody better off\nin the long run is that the right reason is that the only reason to respect people? if the doctor goes in and yanks the organs from the healthy patient\nwho came in for a checkup to save five lives there would be adverse effects in the long\nrun eventually people would learn about this and would stop going in for checkups is it the right reason is the only reason that you as a doctor won't yanked the organs out of a healthy\npatient that you think well if I use him in this way in the long run more lives will be lost? or is there another reason having to do with intrinsic respect for the\nperson as an individual and if that reason matters and it's not so clear that even Mill's utilitarianism can take account of it fully to examine these two worries or objections to Mill's defense we need to we need to push further we need to ask in the case of higher or worthier pleasures are there theories of the good life that can provide independent moral standards for the worth of pleasures? if so what do they look like? that's one question in the case of justice and rights if we suspected that Mill is implicitly leaning\non notions of human dignity or respect for persons that are not, strictly speaking, utilitarian we need to look to see whether there are some\nstronger theories of rights that can explain the intuition which even Mill shares the intuition that the reason for respecting individuals\nand not using them goes beyond even utility in the long run. today we turn to one of those strong theories of rights strong theories of rights say individuals matter not just as instruments to be used for a\nlarger social purpose or for the sake of maximizing utility individuals are separate beings with separate lives worthy of respect and so it's a mistake according to strong theories rights, it's a mistake to think about justice or law by just getting up preferences and values the strong rights theory we turn to today is libertarianism libertarianism  take individual rights seriously it's called libertarianism because it says the\nfundamental individual right is the right to liberty precisely because we are separate individual\nbeings we're not available to any use that the society might desire or devise. precisely because\nwe're individual separate human beings we have a fundamental right to liberty and that means a right to choose freely to live our lives as we please provided we respect other people's rights to do the same that's the fundamental idea Robert Nozick one of the libertarian philosophers we read  for this course puts it this way individuals have rights so strong and far-reaching are these rights that they raise the question of what, if anything the state may do. so what does libertarianism say  about the role of government or of the state well there are three things that most modern states do that on the libertarian theory of rights are illegitimate are unjust one of them is paternalist legislation that's passing laws that protect people from\nthemselves seat belt laws for example or motorcycle helmet laws the libertarian says it may be a good thing if people wear seat belts, but that should be up to them and the state the government has no business coercing them, us  to wear seat belts by law its coercion so no paternalist legislation number one. number two no morals legislation many laws try to promote the virtue of citizens or try to give expression to the moral values of the society as a whole. libertarians say that's also a violation of the right to liberty take the example of, well a classic example\nof legislation offered in the name of promoting morality traditionally, have been laws that prevent sexual intimacy between gays and lesbians the libertarian says nobody else is harmed nobody else's rights are violated so the state should get all of the business entirely of trying to promote virtue or to enact morals legislation. and the third kind of law or policy it is ruled out on the libertarian philosophy is any taxation or other policy that serves the purpose of redistributing income or wealth from the rich to the poor redistribution is a kind of, if you think about it says libertarianists, a kind of coercion what it amounts to is theft by the state or by the majority if we're talking about a democracy from people who happen to do very well and\nearn a lot of money now Nozick and other libertarians allow that\nthere can be a minimal state that taxes people for the sake of what everybody needs the national defense police force judicial system to enforce contracts and property rights but that's it. Now I want to get your reactions to this third feature of the libertarian view I want to see who among you agree with that idea and who disagree and why and just to make a concrete and to see what's at\nstake consider the distribution of wealth in the united states. The united states is among the most In-egalitarian societies as far as\ndistribution of wealth, of all the advanced democracies now is this just or unjust well what is the libertarian say the libertarian says you can't know just from the facts I just given you you can't know whether that distribution it's just or unjust. you can't know just by looking at a pattern\nor a distribution or a result whether it's just or unjust you have to know how it came to be you can't just look at the end  state or the\nresult you have to look at two principles the first he calls justice in acquisition or in initial holdings and what that means simply is did people get the things they use to make their money fairly so we need to know was there justice in the initial holdings,\ndid they steal the land or the factory or the goods that enabled them to make all that\nmoney? if not, if they were entitled to whatever it was that\nenabled them to gather the wealth the first principle is met. the second principle is  did the distribution arise from the operation of free consent people buying and trading on the market as you can see the libertarian idea of justice corresponds to a free market conception of justice provided people got what they used  fairly didn't steal it and provided the distribution results from the free choice\nof individuals' buying and selling things the distribution is just and it's not it's unjust. so let's, in order to fix ideas for this discussion, take an actual example who's wealthiest person in the united states, wealthiest person in\nthe world Bill Gates, it is, you're right."}, {"content": "here he is."}, {"content": "you'd be happy too now, what's his net worth? anybody have any idea? that's a big number during the Clinton years remember there was\na controversy, donors, big campaign contributors were invited to stay overnight in the Lincoln\nbedroom at the white house I think if you contributed twenty five thousand\ndollars or above someone figured out at the median contribution that got you invited to stay a night\nin the Lincoln bedroom Bill Gates could afford to stay in the Lincoln\nbedroom every night for the next sixty six thousand years somebody else figured out how much does he get paid on an hourly basis and so they figured out since he began Microsoft suppose the worked about fourteen hours per day a reasonable guess and you calculate this is net wealth it turns out that his rate of pay is over a hundred and fifty dollars not per hour, not per minute a hundred and fifty dollars, more than a hundred\nand fifty dollars per second which means which means that if on his way to the office Gates noticed a hundred-dollar bill on the\nstreet it wouldn't be worth his time to stop and pick it up now most of you would say someone that wealthy surely we can tax them to meet the pressing needs of people who lack of education or lack enough to eat or lack decent housing they need it more than he does and if you were a utilitarian what would you do? What tax policy would you have you'd redistribute in a flash wouldn't you because you would know being a good utilitarian that taking some, a small amount, he's scarcely going to notice it, but it will make a huge improvement in the lives and in the welfare\nof those at the bottom but remember the libertarian theory says we can't just add up and aggregate preferences and satisfactions that way we have to respect persons and if he earned that money fairly without violating anybody else's rights in accordance with the two principles of justice\nin acquisition and justice in transfer, then it would be wrong it would be a form of coercion to take it away Michael Jordan is not as wealthy Bill Gates but he did pretty well for himself you want to see Michael Jordan? there he is his income alone in one year was thirty one million dollars and then he made another forty seven million\ndollars in endorsements for Nike and other companies so his income was in one year seventy eight million the require him to pay say a third of his earnings to the government to support good causes like food and health care and housing and education\nfor the poor that's coercion that's unjust that violates his rights and that's why redistribution is wrong. Now, how many agree with that argument agree with the libertarian argument that redistribution for the sake of trying to help the poor is wrong? and how many disagree with that argument? all right let's begin with those who disagree? what's wrong with the libertarian case against redistribution? I think these people like Michael Jordan have\nreceived,  we're talking about working within the society they received a larger gift from the society and they have a larger\nobligation in return to give that through distribution you know you can say that Michael Jordan may\nwork just as hard as someone who works you know doing laundry twelve hours, fourteen hours\na day but he's receiving more I don't think it's fair to say that you\nknow it's all on his  inherent hard work. All right let's hear from defenders of libertarianism why would it be wrong in principle to tax the rich to help the poor. My name is Joe and I collect skateboards."}, {"content": "I've since bought a hundred skate boards and\nlive in a society the hundred people I'm the only one with skateboards suddenly\neveryone decides they want skateboard they come into the house to take my, they take ninety\nnine of my skateboards. I think that is unjust now I think in certain circumstances, it becomes necessary to overlook injustice and perhaps\ncondone that injustice as in the case of the cabin boy being killed for food if people are on the verge of dying perhaps it is necessary to overlook that injustice but I think it's\nimportant to keep in mind they were still committing injustice by taking people's belonging or assets. Are you saying\nthat taxing Michael Jordan say at thirty three percent tax rate for good causes to feed the hungry is theft I think it's unjust, yes I do believe it's theft,\nbut perhaps it is necessary to condone that theft. But it's theft. Yes. why is it theft, Joe? because why is it like your collection of skateboards? it's theft because or at least in my opinion and by the libertarian opinion he earned that money fairly and it belongs to him and so take it from him is by definition theft. alright let's see if there is  who wants to reply to Joe? yes go ahead I don't think this necessarily a case in which you have\nninety nine skateboards and the government, or you have a hundreds skateboards\nand the government is taking ninety nine of them it's like the it's like you have more skateboards than there are days in the year, you have more skateboards than\nyou're going to be able to use your entire lifetime and the government is taking part of those. And I think that if you're operating in society in which the government in which the government doesn't redistribute\nwealth that that allows for people to amass \nso much wealth that people who haven't started from the equal footing in our hypothetical\nsituation, that doesn't exist in our real society, get undercut for the rest of their lives. so you're worried that if there isn't some\ndegree of redistribution if some are left at the bottom there will be no genuine equality of opportunity alright. the idea that taxation is theft, Nozick takes that point one step further he agrees that it's theft he's more demanding than Joe, Joe says it is\ntheft, maybe in an extreme case it's justified maybe a parent is justified in stealing a loaf of bread to feed his or her hungry family so Joe is a what? What would you call yourself\na compassionate quasi libertarian? Nozick says, if you think about it taxation amounts to the taking of earnings in other words it means taking the fruits of my labor but if the state has the right to take my earnings or the fruits of my labor, isn't that morally the same as according to the state the right to claim a portion of my labor? So taxation actually is morally equivalent to forced labor because forced labor involves the taking of my leisure, my time, my efforts just as taxation takes the earnings that I make with my labor. And so for Nozick and for the libertarians taxation for redistribution is theft as Joe says, but not only thing left it is morally equivalent to laying claim to certain hours of a person's life and labor so it's morally equivalent to forced labor if the state has a right to claim the fruits\nof my labor that implies that it really has an entitlement  to my labor itself and what is forced labor? forced labor Nozick points out it's what? it's slavery because if I don't have the right, the sole right to my own labor then that's really to say that the government\nor the political community is a part owner in me and what does it mean for the state to be\na part owner in me? if you think about it it means that I am a slave that I don't own myself so what this line of reasoning brings us to is the fundamental principle that underlies the libertarian case for rights what is that principle? it's the idea that I own myself it's the idea of self-possession if you want to take rights seriously if you don't want to just regard people as \ncollections of preferences the fundamental moral idea to which you will be lead is the idea that we are the owners or the proprietors\nof our own person and that's why utilitarian goes wrong and that's why it's wrong to yank the organs\nfrom that healthy patient you're acting as if that patient belongs to you or to the community but we belong to ourselves and that's the same reason that it's wrong to make laws to protect us from\nourselves or to tell us how to live to tell us what virtues we should be governed by and that's also why it's wrong to tax the rich to help the poor even for good causes\neven to help those who are displaced by the hurricane Katrina ask them to give charity but if you tax them it's like forcing them to labor could you tell Michael Jordan he has to skip next week's games and go down to help the people displaced by hurricane Katrina? morally it's the same so the stakes are very high so far we've heard some objections to the libertarian argument but if you want to reject it you have to break into this chain of reasoning\nwhich goes taking my earnings is like taking my labor but taking my labor is making me a slave and if you disagree with that you must believe in the principle of self-possession those who disagree gather your objections and we'll begin with them next time. anyone like to take up that point? yes I feel like  when you live in a society you give up that right, I mean technically, if I want to\npersonally  and kill someone because they offend me, that is \nself-possession. Because I live in a society I cannot do that Victoria, are you questioning the fundamental premise of self-possession? yes. I think that you don't really have self-possession \nif you choose to live in a society because you cannot just discount the people around you. we were talking last time about libertarianism I want to go back to the arguments for and\nagainst the redistribution of income but before we do that just one word about the  state Milton Friedman the libertarian economist he points out that many of the functions that we take for granted as properly belonging to government, don\u2019t they are paternalist. one example he gives is social\nsecurity  he says it's a good idea for people to save for their retirement during their earning years but it's wrong it's a violation of people's liberty for the government to force everyone whether they want to or not to put aside some earnings today for the sake of their retirement. If people\nwant to take the chance or if people want to live big today and live a poor retirement that should be their choice they should be\nfree to make those judgments and take those risks so even social security would still be at odds with the minimal state that Milton Friedman argued for it's sometimes thought that collective goods like police protection and\nfire protection inevitably create the problem of free riders\nunless their publicly provided but there are ways to  prevent free riders, there are ways to restrict even seemingly collective goods like\nfire protection I read an article a while back about a private fire company\nthe Salem Fire corporation in Arkansas you can sign up with this Salem Fire Corporation pay a yearly subscription fee, and if your house catches on fire they will come and put out the fire but they won't put out everybody's fire, they will only put it out if it's a fire in the home of subscriber or if it starts to spread  and to threaten  the home of a subscriber the newspaper article told the story of a\nhomeowner who had subscribed to this company in the past but failed to renew his subscription his house\ncaught on fire the Salem Fire Corporation showed up with\nits trucks and watched the house burn. Just making sure that it didn't spread the fire chief was asked well he wasn't exactly the fire chief I guess \nhe was the CEO he was asked how can you stand by with fire equipment and allow a person's home to burn? he replied once we verified there was no\ndanger to a member's property we had no choice but to back off according to our rules. If we responded to\nall fires, he said, there would be no incentive to subscribe the homeowner in this case tried to renew\nhis subscription at the scene of the fire but the head of the company refused you can't wreck your car, he said, and then\nbuy insurance for it later so even public goods that we take for granted\nas being within the proper province of government can, many of them, in principle be isolated, made exclusive to those who pay. that's all to do with the question of collective goods and the libertarian's injunction against paternalism let's go back now to the arguments about redistribution now, underlying the libertarian's case for the minimal states is a worry about coercion, but what's wrong\nwith coercion? libertarian offers this answer to coerce someone to use some person for the sake of the general welfare is wrong because it calls into question the fundamental fact that we own ourselves the fundamental moral fact of self-possession or self ownership the libertarian's argument against redistribution begins with this fundamental idea that we\nown ourselves Nozick says that if this is society as a whole can go to Bill Gates or go to Michael Jordan and tax away a portion  of their wealth, what the society is really asserting is a collective property right in Bill Gates or in Michael Jordan but that violates the fundamental principle that we belong to ourselves now we've already heard a number of \nobjections to the libertarian argument what I would like to do today it's to give the libertarians among us a chance to answer the objections that have been raised and some have been some have already identified themselves have agreed\nto come and make the case for libertarianism to reply to the objections\nthat have been raised so raise your hand if you are among the libertarians\nwho's prepared to stand up for the theory and response to the objections you are? Alex Harris. Alex Harris who he's been a star on the web blog, alright Alex come here stand-up  we'll create a libertarian corner over\nhere and who else other libertarians who will join what's you're name? John. John Sheffield, John, and who else wants to join other brave libertarians who are prepared to take on yes what's your name Julia Roto, Julia come join us over there now while the, team libertarian Julia, John, Alex while team libertarian is gathering\nover there let me just summarize the main objections that I've heard in class and on the web site objection number one and here I'll come down too, I want to talk\nto team libertarian over here so objection number one is that the poor need the money more that's an obvious objection a lot more than than do Bill Gates and Michael Jordan objection number two it's not really slavery to tax because at least in a democratic society there's not a slave holder it's congress it's a democratic, you're smiling Alex, you're\nalready a confident you can reply to all of these so taxation by consent of the governed is not\ncoerced third some people have said don't be successful like Gates owe a debt to society for their success that\nthey repay by paying taxes who wants to respond to the first one the\npoor need the money more all right you're John John all right John what's the answer, here I'll hold it. alright the poor need the money more,\nthat's quite obvious  I could use money you know I certainly wouldn't\nmind if Bill Gates gave me a million dollars I mean I'd take a thousand but at some point you have to understand that the benefits of\nredistribution of wealth don't justify the initial violation of the property right if you look at the argument the poor need\nthe money more at no point in that argument you contradict\nthe fact that we extrapolated from agreed upon principles that people own themselves we've extrapolated that people have property\nrights and so whether or not it would be a good thing or a nice thing or even a necessary thing for the survival\nof some people we don't see that that justifies the violation\nof the right that we logically extrapolated and so that also I mean they're still exist this institution of of individual philanthropy, Milton Freidman makes \nthis argument alright so Bill gates can give to charity if he wants to but it would still be wrong to coerce him exactly to meet the needs of the poor. are the two of you happy with that reply?"}, {"content": "anything to add?"}, {"content": "alright Go ahead, Julie? Julia, ya, I think I could also ass I guess I could add that there's a difference between needing something and deserving\nsomething. I mean in an ideal society everyone's needs would be met but here we're arguing what do we deserve as a society and the poor don't deserve the benefits that would flow from taxing Michael\nJordan to help them. Based on what we've come up with here, I don't think you deserve something like that. Alright let me, push you a little bit on that Julia the victims of hurricane Katrina are in desperate need of help would you say that they don't deserve the help that would come from the federal government through taxation. okay that's a, difficult question I think this is a case where they need help not deserve it, but I think again if you hit a certain level of of requirements to reach sustenance, you're going to need\nhelp, like if you don't have food or place to live that's a case of need. So need is one\nthing and dessert is another. exactly who would like to reply? Come back to that first point that he made about the property rights of the\nindividual the property rights are established and enforced by\nthe government which is a democratic government and we have representatives who enforce those rights, if you live in a society that operates under\nthose rules then it should be up to the government to decide how  those resources that come about through taxation are distributed\nbecause it's through the consent of the governed and if  you disagree with it you don't have to live in that society where that operate. Alright, good so, and tell me your name. Raul Raul is pointing out actually Raul is invoking point number two if the taxation is by the consent of the governed it's not coerced it's legitimate Bill Gates and Michael Jordan are citizens of the United\nStates, they get to vote for congress and they get to vote their policy convictions just like everybody else who would like to take that one on? John? Basically what the libertarians are objecting to in this case is the middle\neighty percent deciding what the top ten percent are doing for the bottom ten percent with\nwait wait wait, John, majority, don't you believe in democracy? well right but at some point, don't you believe in the, I mean, you say\neighty percent ten percent, majority, majority rule is what? majority! exactly but, in a democracy aren't you\nfor democracy? Yes I'm for democracy but, hang on, democracy and mob rule are not the same thing. Mob rule? mob rule. But in an open society, you have recourse  to address that through your representatives and if the majority of the consent of those who are govern doesn't agree with\nyou then you know, you're choosing to live in the society and you have to operate under what the majority of the society concludes Alright, Alex, on democracy, what about that? The fact I have, you know, one five hundred thousandth\nof a vote for one representative in congress is not the same thing as my having the ability to decide for myself how to use my property rights. I'm a drop in the bucket  and you know while.. You might lose the vote exactly and they might take? and I will, I mean I don't have the decision right now of whether not to pay taxes\nif I don't get locked in jail or they tell me to get out of the country. Now Alex, let me make a small case for democracy and see what you would say. why can't you we live in a democratic society with freedom\nof speech why can't you take to the hustings, persuade your fellow citizens that taxation is unjust and try to get a majority? I don't think that people should be, should have\nto convince two hundred and eighty million others simply in order to exercise their own rights, in order to not have their self\nownership violated. I think people should be able to do that without having to convince two hundred eighty million people. Does that\nmean you're against democracy as a whole? No I just believe in a very limited from\ndemocracy whereby we have a constitution that severely limits the scope of what decisions can be made democratically Alright so you're saying that democracy\nis fine except where fundamental rights are involved, and I think you could win if you're going on the\nhustings let me add one element to the argument you\nmight make maybe you could say, put aside the economic\ndebates taxation suppose the individual right to religious liberty\nwere at stake then Alex you could say on the hustings, surely you would all agree that we shouldn't put the right to individual\nliberty up to a vote yeah that's exactly right  and that's why we have constitutional amendments\nand why we make it so hard to amend our constitution. so you would say that the right to private property the right of Michael Jordan to keep all the\nmoney he makes at least to protect it from redistribution is that same kind of right with the same kind of weight as the right to freedom of speech the right to religious liberty, rights that\nshould trump what the majority wants absolutely the reason why we have a right\nto free speech is because we have a right to own ourselves, to exercise our voice  in any way that we choose. alright, good. alright who would like to respond\nto that argument about democracy being, alright there stand up I think comparing religion and economics, it's not\nthe same thing the reason why Bill Gates was able to make\nso much money is because we live in an economically and socially stable society and if the government didn't provide for the\npoorest ten percent as you say, through taxation then we would need more money for police to prevent crime and so either way there would be more taxes\ntaken away to provide what you guys calling and then necessary things that the government provides. What's your name?"}, {"content": "Anna. Anna let me ask you this why is the fundamental right to religious liberty different the right Alex asserts as a fundamental right to private property and to keep what I earn what's the difference between the two? because you wouldn't have you wouldn't be able to make money, you wouldn't be able to own property there wasn't socially like if society wasn't stable."}, {"content": "and that's very different from religion that's\nlike something personal, something you can practice on your own in your own your own home whereas like me practicing my religion isn't going to affect another  \nperson, whereas if I'm poor  and I'm desperate, I might commit a crime to feed my family and that can affect others. Okay thank\nyou would it be wrong for someone to steal a loaf of bread to feed his starting family is that wrong? I believe that it is. let's take let's take a quick\npoll of the three of you, you say yes it is wrong. it violates  property rights it's wrong. even to save the starving family? I mean there\nthere definitely other ways around that and by justifying now hang on hang on before you laugh at me before justifying the act of stealing you have to look at violating the right that we've already agreed\nexists, the right of self-possession and the possession of I mean, your own things we agree on property\nright. Alright, we agree it's stealing so property rights are not the issue, alright so why\nis it wrong to steal even to feed your starving family? sort of the original argument that\nI made in the very in the very first question you asked, the benefits of an action don't justify, don\u2019t make the action just well what would you say Julia? Is it right to steal a loaf of bread to feed a starving family or to steal\na drug that your child needs to to survive I think I'm okay with that honestly, even from the libertarian  \nstandpoint, I think that okay saying that you can just take money arbitrarily from people who have a lot\nto go to this pool of people who need it but you have an individual who's acting on\ntheir own behalf to kind of save themselves I think you said  from the idea of self-possession they are also in charge of protecting  \nthemselves and keeping themselves alive so therefore even from a libertarian standpoint that might\nbe okay Alright that's good, that's good. Alright what about number three up here isn't it the case that the successful, the wealthy owe a debt, they did do that all by themselves\nthey had to cooperate with other people that they owe a debt to society and that that's expressed in\ntaxation. DO you want to take that on Julie? okay this one, I believe that there is not a debt to society in a sense that how did people become\nwealthy? they did something that society valued highly I think that society has already been providing for them if anything I think it's everything is cancelled out,\nthey provided a service to society and society responded by somehow they got\ntheir wealth well be concrete, in the case of Michael\nJordan, some, I mean to illustrate your point there were people who helped him make money,\nteammates the coach people taught him how to play, but those you're saying, but they've all\nbeen paid for their services exactly and society derived a lot of benefit and pleasure\nfrom watching Michael Jordan play and I think that that's how he paid his debt\nto society good, who would, anyone like to take up that point? I think that there's a problem here that we're assuming that a person has self-possession\nwhen they live in a society I feel like when you live in a society you give up that right. I mean  \nif I wanted personally to kill someone because they offend me that\nis self-possession. Because I live in a society, I cannot do that I think it's kind of an equivalent to say, because I have more money I have resources that\nthat could save people's lives is it not okay for the government to take that\nfrom me? it's self-possession only to a certain extent\nbecause I'm living in a society where I have to take account of people around me. so are\nyou questioning, what's your name? Victoria. Victoria, are you questioning the fundamental premise of self-possession? Yes. I think that you don't really have self-possession\nif you choose to live in a society because you cannot just discount the people\naround you. Alright I want to quickly get a response of the libertarian team to the last point. the last point builds on, well maybe it builds on Victoria's suggestion\nthat we don't own ourselves because it says that Bill Gates is wealthy that Michael Jordan makes a huge income isn't wholly their own doing it's the product of a lot of luck and so we can't claim that they morally deserve all the money they make. who wants to reply to that, Alex? You certainly could make the case that it is not, that their wealth is not appropriate to the \ngoodness of their hearts but that's not really the more the morally relevant issue. the point is that they have received what they have through the\nfree exchange of people who have given them their holdings usually in exchange for providing\nsome other service. good enough I want to try to sum up what we've learned\nfrom this discussion but first let's thank John Alex and Julia for a really wonderful job, toward the end of the discussion just now Victoria challenged the premise of this line of reasoning this\nlibertarian logic maybe, she suggested, we don't own ourselves after all if you reject the libertarian case against redistribution there would seem to be an incentive to break into the libertarian line of reasoning at the earliest, at the most modest level which is why a lot of people disputed that taxation is morally equivalent to forced labor but what about the big claim the premise, the big idea underlying the libertarian argument, is it true that we own ourselves or can we do without that idea and still of avoid what libertarians want to avoid creating a society and an account of Justice where some people can be just used for the sake of other people's welfare or even for the sake of the general good libertarians combat the utilitarian idea of using people as means for the collective happiness by saying the way to put a stop to that utilitarian\nlogic of using persons is to resort to the intuitively  powerful\nidea that we are the proprietors of our own person That's Alex and Julia and John, and Robert Nozick what are the consequences for a theory of justice and an account of rights of calling into question the idea of self-possession does it mean that we're back to utilitarianism and using people and aggregating preferences and pushing the fat man off the bridge? Nozick doesn't himself, fully develop the idea of self-possession\nhe borrows it from an earlier philosopher John Locke John Locke accounted for the rise of private property from the state of nature by a chain of reasoning very similar to the\none that Nozick and the libertarians use John Locke said private property arises because when we mix our labor with things unowned things we come to acquire a property right in those\nthings the reason? the reason is that we own our own labor and the reason for that we're the proprietors the owners of our own person and so in order to examine the moral force of the libertarian claim\nthat that we own ourselves we need to turn to the English political philosopher John Locke and examine his account of private property and self ownership and that's what we'll do next time don't miss the chance to interact online with other viewers of Justice join the conversation, take a pop quiz, watch lectures you've missed, and learn a lot more. Visit  \njusticeharvard.org,  it's the right thing to do."}, {"content": "funding for this program is provided by Additional funding provided by"}], "We Got High With Snoop Lion - Noisey Specials": [{"content": "it's not that I want to become Snoop Dog on the ray track I I want to bury Snoop Dog and become Snoop [Music] Lion hey everybody this is wber Cooper for noisy standing outside of Snoop Lion press conference for his new multimedia project reincarnated which involves a new album a new documentary and a new book [Music] for the night bingy Center where the high priest when I walked in he asked me what was my name and I said Snoop Dog and he looked me in my eyes he said no more you are bran you are the light you are the lion and from that that moment on it's like I had started to understand why I was there and we hadn't even recorded one song reincarnated is a three um step process it's basically the album a film and an amazing photo book uh that was shot by um renowned Los Angeles photographer Willie T when Ted reached out to me I'd worked with Sno for I'm a huge fan like everybody in this room um but I was playing with some of the demos from the from our new project like we played get free earlier kind of like our culture reggae records and I was that was the direction we were going into like real reggae music and uh I think when we had the team down there which is Angela Jan Moon and uh my my team Ariel and Dr Co the chemistry was amazing Diplo gave me a call like about maybe last year and was like I'm getting ready to do this project I'm really excited about it he wanted to to sing and find a new voice and um and uh you know make make good music and I was about that the music that we wrote alog together was is some of the best I've been part of and I think that the message that Snoop wants to bring is about positivity and records that that are Universal and it's not about uh politics or this direction or or that direction it's about good music and it's it's just it's a dream come true for a producer to make a record like that when I first met with Ted I actually thought what could possibly come from a meeting with snoop's manager he was very persistent he said we're going to go down to Jama this is going to be something different for Snoop I didn't know what we were signing up for I thought maybe we'll film 20 minutes and it'll be some like extra online viral assets that will go alongside the album whenever it comes out I realized after about 3 or 4 days we're making a featurelength documentary here and this is amazing so what' you think about the announcement uh actually it was very good very interesting if what was playing in the background of the trailer is what sounds like the record then it's going to be really good what you smoking on man oh man that's just California uhoh I know you already say it in the song Push I know you want to get have you going sideways I heard you smoking some crazy crazy man people smoke with you and they just like don't even know what's going on because what they do is they try to get in the fast L like see what you did you jumped in a slow Lan I like that you hit it once and gave it back a lot of like yeah you got to just smoke what strand of weed would you smoke to la la la like what would be the perfect strand to smoke when you listen to La La La it's only right that you're on the set cuz you don't want to be too wavy too you know what I mean you just want to be right man just right with some set your first record doggy style and your work with Dre on The Chronic it really exposed new audiences to hip-hop do you think that this record is going to have that same kind of of power and really you know help more people hear regay that never heard it before most definitely that's that's what I think it's going to do to the most I think more people are going to become aware of ree music who never knew what it was and never bothered to open it up to even you know give it a chance now people are going to give it a chance accept it love it and appreciate it and it's going to grow and it's going to spread around the world you know even bigger and better than it's always than than it's already done and that's what it was made for to continue to grow I'm just uh a seed that was planted that's going to try to help it grow [Music] some [Music] yeah oh yeah so when are we going to see the perm again we ever going to see the French braids I think I think the perm is being retired okay don't one of the songs that I'm just hearing a little bit of record that really touched me is the song about No Guns I know everybody's been been talking about it but I was wondering in light of you know the Dark Knight situation and stuff like like that like after you wrote that song and recorded it and you heard about that incident like how did that make you feel like what's going on through your mind with that that recent tragedy right now in context that powerful powerful song but it's like sometimes when you write you write what you feel right and it's a projection of life that's going to happen or either that has happened and it's to the point now to where I feel like when we do put this out this will reflect on that moment and make more people aware and and hopefully stop the next two or three from happening and maybe prevent it from happening and make people feel like it's not cool to have guns and put more ramifications on you know people buying guns give them more of a background check to find out what they going to do with the guns you know would I just to get them off MH no I dig it I mean that's really powerful stuff and I think that's what everybody needs to hear right now I wanted to um ask you one final question well a couple couple of questions but basically you change your name from you know Snoop Dog to Snoop Lion if if there was another animal cuz you kind of went from like you know a dog to a feline there's another animal that you could switch off to like what would it be like if there's like a third phase of the animal of the snoop snoop animals um it would have to be something underwater Boogie cuz you know I can dance under water without getting wet what's the most what's the most uh vicious animal in the in the water the shark the shark the most I'm I'm scared of sharks I think Shar yeah well that if it scares you that's what I want to be I dig it man well yo thank you so much for sitting and talking to me what up though it's your boy big Snoop DG AKA Snoop Lion and you're rocking with [Music] noisy"}], "MIT 6.S091: Introduction to Deep Reinforcement Learning (Deep RL)": [{"content": "today I'd like to overview the exciting field of deep reinforcement learning introduced overview and provide you some of the basics I think it's one of the most exciting fields in artificial intelligence it's marrying the power and the ability of deep neural networks to represent and comprehend the world with the ability to act on that understanding on that representation taking as a whole that's really what the creation of intelligent beings is understand the world and act and the exciting breakthroughs that recently have happened captivate our imagination about what's possible and that's why this is my favorite area of deep learning and artificial intelligence in general and I hope you feel the same so what is deep reinforcement learning we've talked about deep learning which is taking samples of data being able to in a supervised way compress encode the representation that data in the way that you can reason about it I would take that power and apply it to the world where sequential decisions are to be made so it's looking at problems and formulations of tasks where an agent an intelligent system has to make a sequence of decisions and the decisions that are made have an effect on the world around the agent how how do all of us any intelligent being that it's tasked with operating in the world how did he learn anything especially when you know very little in the beginning it's trial and error is the fundamental process by which reinforcement learning agents learn and the deep part of deep reinforcement learning is neural networks as using the frameworks and reinforcement learning where the neural network is doing the representation of the world based on which the actions are made and we have to take a step back when we look at the types of learning sometimes the terminology itself can confuse us to the fundamentals there are supervised learning there semi-supervised learning there's unsupervised learning there's reinforcement learning and there's this feeling that supervised learning is really the only one where you have to perform the manual annotation where you have to do the large-scale supervision that's not the case every type of machine learning is supervised learning it's supervised by a loss function or a function that tells you what's good and what's bad you know even looking at our own existence is how we humans figure out what's good and bad there's all kinds of sources direct and indirect by which our morals and ethics we figure out what's good and bad the difference we supervised and unsupervised and reinforcement learning is the source of that supervision what's implied when you say unsupervised is that the cost of human labor required to attain the supervision is low but it's never Turtles all the way down it's Turtles and then there's a human at the bottom there at some point there needs to be human intervention human input to provide what's good and what's bad and this will arise in reinforcement learning as well I have to remember that because the challenges and the exciting opportunities of reinforcement learning lie in the fact of how do we get that supervision in the most efficient way possible but supervision nevertheless is required for any system that has an input and an output that's trying to learn like a neural network does to provide an output that's good he needs somebody to say what's good and what's bad for you curious about that there's been a few books a couple written throughout the last few centuries from Socrates to Nietzsche I recommend the latter especially so let's look at supervised learning and reinforcement learning let like to propose a way to think about the difference that is illustrative and useful when we start talking about the techniques so supervised learning is taking a bunch of examples of data and learning from those examples where a ground truth provides you the compressed semantic meaning of what's in that data and from those examples one by one whether it's sequences or single samples we learn what how to then few take future such samples and interpret them reinforcement learning is teaching what we teach an agent through experience not by showing a singular sample of a data set but by putting them out into the world the distinction there the essential element of reinforcement learning then for us now we'll talk about a bunch of algorithms but the essential design step is to provide the world in which to experience the agent learns from the world the from the world it gets the dynamics of that world the physics of the world from that world that gets the rewards what's good and bad and us as designers of that agent do not just have to do the algorithm we have to do design the the world in which that agent is trying to solve a task the design of the world is the process of reinforcement learning the design of examples the annotation of examples is the world of supervised learning and the essential perhaps the most difficult element of reinforcement learning is the reward the good versus bad here a baby starts walking across the room we want to define success as a baby walking across the room and reaching the destination that's success and failure is the inability to reach that destination simple and reinforcement learning in humans the way we learn from these very few examples appear to learn from very few examples of trial and error is a mystery a beautiful mystery full of open questions it could be from the huge amount of data 230 million years worth of bipedal data there who've been walking what mammals walking ability to walk or 500 million years the ability to see having eyes so that's the the hardware side somehow genetically encoded in us is the ability to comprehend this world extremely efficiently it could be through not the hardware not the five hundred million years but the the few minutes hours days months maybe even years in the very beginning were born the ability to learn really quickly through observation to aggregate that information filter all the junk that you don't need and be able to learn really quickly through imitation learning through observation the way for walking that might mean observing others talk the idea there is if there was no other around we would never be able to learn this the fundamentals of this walking or as efficiently it's through observation and then it could be the algorithm totally not understood is the algorithm that our brain uses to learn the backpropagation that's an artificial neural networks the same kind of processes not understood in the brain that could be the key so I want you to think about that as we talk about the very trivial by comparison accomplishments and reinforcement learning and how do we take the next steps but it nevertheless is exciting to have machines that learn how to act in the world the process of learning for those who have fallen in love with artificial intelligence the process of learning is thought of as intelligence it's the ability to know very little and through experience examples interaction with the world in whatever medium whether it's data or simulation so on be able to form much richer and interesting representations of that world be able to act in that world that's that's the dream so let's look at this stack of what an age what it means to be an agent in this world from top the input to the bottom the output is the there's an environment we have to sense that environment we have just a few tools as humans have several sensory systems on cars you can have lidar camera stereo vision audio microphone networking GPS IMU sensor so on whatever robot you can think about there's a way to sense that world and you have this raw sensory data and then once you have the raw sensory data you're tasked with representing that data in such a way that you can make sense of it as opposed to all the the raw sensors and the I the cones and so on that taking just giant stream of high bandwidth information we have to be able to form higher abstractions of features based on which we can reason from edges to corners to faces and so on that's exactly what deep learning neural networks have stepped in to be able to in an automated fashion with as little human input as possible be able to form higher-order representations of that information then there is the the learning aspect building on top of the greater abstractions form through the representations be able to accomplish something useful well--there's discriminative tasks a generative task and so on based on the representation be able to make sense of the data be able to generate new data and so on from sequence the sequence to sequence the sample from Sam of the sequence and so on and so forth to actions as we'll talk about and then there is the ability to aggregate all the information has been received in the past to the useful information that's pertinent to the task at hand it's the thing the old it looks like a duck quacks like a duck swims like a duck three different data sets I'm sure there's state-of-the-art algorithms for the three image class education audio recognition video classification - activity recognition so on aggregating those three together is still an open problem and that could be the last piece again I want you to think about as we think about reinforcement learning agents how do we play how do we transfer from the game of Atari to the game of go to the game of dota to the game of a robot navigating an uncertain environment in the real world and once you have that once you sense the raw world once you have a representation of that world then we need to act which is provide actions within the constraints of the world in such a way that we believe can get us towards success the promise excitement of deep learning is is the part of the stack that converts raw data into meaningful representations the promise the dream of deeper enforcement learning is going beyond and building an agent that uses that representation and acts achieve success in the world that's super exciting the framework and the formulation reinforcement learning at its simplest is that there's an environment and there's an agent that acts in that environment the agent senses the environment by a by some observation well there's partial or complete observation of the environment and it gives the environment and action it acts in that environment and through the action the environment changes in some way and then a new observation occurs and then also as you provide they actually make the observations you receive a reward in most formulations of this of this framework this entire system has no memory that the the only thing you two could be concerned about as a state you came from the state you arrived in and the reward received the open question here is what can't be modeled in this kind of way can we model all of it from from human life to the game of go can all this be model in this way and what are is this a good way to formulate the learning problem of robotic systems in the real world in simulated world those are the open questions the environment could be fully observable or partially observable like in poker it could be single agent or multi agent Atari versus driving like deep traffic deterministic or stochastic static versus dynamic static is in chess dynamic again and driving in most real-world applications the screen versus continuous like games chess or continuous and carpal balancing a polo on a cart the challenge for RL in real world applications is that as a reminder supervised learning is teaching by example learning by example teaching from our perspective reinforcement learning is teaching by experience and the way we provide experience the reinforcement learning agents currently for the most part is through simulation or through highly constrained real-world scenarios so the challenge is in the fact that most of the successes is with systems environments that are simulated so there's two ways to then close this gap to directions of research and work one is to improve the algorithms improve the ability of the algorithm student to form policies that are transferable across all kinds of domains including the real world including especially in the real world so train and simulation transfer to the real world or is we improve the simulation in such a way that the fidelity of the simulation increased increases to the point where the gap between reality and simulation is is minimal to a degree that things learn the simulation are directly trivially transferable to the to the real world okay the major components of an RL agent an agent operates based on a strategy called the policy it sees the world it makes a decision that's a policy makes a decision how to act sees the reward sees a new state acts sees a reward she's new States and acts and this repeats forever until a terminal state the value function is the estimate of how good a state is or how good a state action pair is meaning taking an action in a particular state how good is that ability to evaluate that and then the model different from the environment from the perspective the agent so the environment has a model based on which it operates and then the agent has a representation best understanding of that model so the purpose for an RL agent in this simply formulated framework is to maximize reward the way that the reward mathematically and practically is talked about is with a discounted framework so we discount further and further future award so the reward that's farther into the future is means less to us in terms of maximization than reward that's in the near term and so why do we discount it so first a lot of it is a math trick to be able to prove certain aspects analyze certain aspects of convergence and in general on a more philosophical sense because environments either are or can be thought of a stochastic random it's very difficult to there's a degree of uncertainty which makes it difficult to really estimate the the the reward they'll be in the future because of the ripple effect of the uncertainty let's look at an example a simple one helps us understand policy's rewards actions there's a robot in the room there's 12 cells in which you can step it starts in the bottom left it tries to get rewards on the on the top right there's a plus one it's a really good thing at the top right wants to get there by walking around there's a negative 1 which is really bad you wants to avoid that Square and the choice of action is this up-down left-right for actions so you could think of there being a negative reward of point 0 4 for each step so there's a cost to each step and there's a stochastic nature to this world potentially we'll talk about both deterministic stochastic so in the in the stochastic case when you choose the action up with an 80% probability with an 80% chance you move up but with 10% chance to move left another 10 move right so that's the Catholic nature even though you try to go up you might end up in a blocks to the left into the right so for a deterministic world the optimal policy here given that we always start in the bottom left is really shortest path is you know you can't ever because there's no stochasticity you're never gonna screw up and just fall into the hole negative 1 hole that you just compute the shortest path and walk along that shortest path why shortest path because every single step hurts there's a negative a reward to it point 0 4 so shortest path is the thing that minimizes the reward shortest path to the to the plus 1 block ok let's look at it stochastic world like I mentioned the 80% up and then split to 20 10 % to left and right how does the policy change well first of all we need to have we need to have a plan for every single block in the area because you might end up there due to this the castus 'ti of the world ok the the basic addition there is that we're trying to go avoid up the closer you get to the negative one hole so just try to avoid up because up the stochastic nature of up means that you might fall into the hole with a 10% chance and given the point zero for step reward you're willing to take the long way home in some cases in order to avoid that possibility the negative one possibility now let's look at a reward for each step if it decreases to negative two it really hurts to take every step then again we go to the shortest path despite the fact that there's a stochastic nature in fact you don't really care that you step into the negative one hole because every step really hurts you just want to get home and then you can play with this reward structure right yes instead of negative 2 or negative point 0 4 you can look at negative 0.1 and you can see immediately that the structure of the policy it changes so with a higher value the higher negative reward free step immediately the urgency of the agent increases versus the less urgency the lower the negative reward and when the reward flips so it's positive the every step is a positive so the entire system which is actually quite common in reinforcement learning the entire system is full of positive rewards and so that then the optimal policy becomes the longest path is grad school taking as long as possible never reaching the destination so what lessons do we draw from robot in the room two things the environment model the dynamics is just there in the trivial example the stochastic nature the difference between 80 percent 100 percent and 50 percent the model of the world the environment has a big impact on what the optimal policy is and the reward structure most importantly the thing we can often control more in our constructs of the task we try to solve them enforcement is the what is good and what is bad and how bad is it and how good is it the reward structure is a big impact and that has a complete change like like Robert Frost say the complete change on the policy the choices the agent makes so at when you formulate a reinforcement learning framework as researchers as students what you often do is you design the environment you design the world in which the system learns even when your ultimate goal is the physical robot it does still there's a lot of work still done simulation so you design the world the parameters of that world and you also design the reward structure and it can have a transformative results slight variations in those parameters going to huge results on huge differences on the policy that's arrived and of course the example I've shown before I really love is the impact of the the changing reward structure might have unintended consequences and those consequences for real-world system can have obviously highly detrimental costs that are more than just a failed game of Atari so here is a human performing the task gate playing the game of coast runners racing around the track and so it's when you finish first and you finish fast you get a lot of points and so it's natural to then okay let's do an RL agent and then optimize this for those points and will you find out in the game is that you also get points by picking up the little green turbo things and with agent figures out is that you can actually get a lot more points even by simply focusing on the green turbos focusing on the green turbos just rotating over and over slamming into the wall fire and everything just picking it up especially because ability to pick up those turbos can avoid the terminal state at the end of finishing the race in fact finishing the race means you stop collecting positive reward so you never want to finish collected turbos and though that's a trivial example it's not actually easy to find such examples but they're out there of unintended consequences that can have highly negative detrimental effects when put in the real world we'll talk about a little bit of robotics when you put robots for wheeled ones like autonomous vehicles into the real world and you have objective functions that have to navigate difficult intersections full of pedestrians you have to form intent models those pedestrians here you see cars asserting themselves through dense intersections taking risks and within those risks that are taking by us humans will drive vehicles we have to then encode that ability to take subtle risk into into AI based control algorithms perception then you have to think about at the end of the day there's an objective function and if that objective function does not anticipate the green turbos that are to be collected and then result in some understand the consequences could have very negative effects especially in situations that involve human life that's the field of AI safety and some of the folks will talk about deep mind and open AI that are doing incredible work in RL also have groups that are working on a AI safety for a very good reason this is a problem that I believe that artificial intelligent will define some of the most impactful positive things in the 21st century but I also believe we are nowhere close to solving some of the fundamental problems of AI safety that we also need to address as we those algorithms okay examples and reinforcement learning systems all of it has to do with formulation or rewards formulation of states and actions you have the traditional the often used benchmark of a cart balancing a poll continuous so the action is the horizontal force to the cart the goal is to balance the poll so stays top and the moving cart and the reward is one in each time step if the poll is upright in the state measured by the cart by the agent is the pole angle angular speed and of course self sensing of the cart position and the horizontal velocity another example here didn't want to include the video because it's really disturbing but I do want to include the slide because it's really important to think about is by sensing the the raw pixels learning and teaching an agent to play a game of doom so the goal there is to eliminate all opponents the state is the raw game pixels the action is up/down shoot reload and so on and the positive reward is when an opponent is eliminated and negative one the agent is eliminated simple I added it here because again on the topic of AI safety we have to think about objective functions and how that translate into the world of not just autonomous vehicles but things that even more directly have harm like autonomous weapon systems and we have a lecture on this in the AGI series and on the robotics platform the manipulate object manipulation and grasping objects there's a few benchmarks there's a few interesting applications learning the problem of grabbing objects moving objects manipulating objects rotating and so on especially when those objects don't have have complicated shapes and so the goal is to pick up an object in the purely in the grasping objects allenge the state is the visual racial slurs visual visual base the raw pixels of the objects the actions is to move the arm grasp the object pick it up and obviously it's positive when the pickup is successful the reason I'm personally excited by this is because it'll finally allow us to solve the problem of the claw which has been torturing me for many years I don't know that's not at all why I'm excited by it okay and then we have to think about as we get greater and greater degree of application in the real world with robotics like cars the the main focus of my passion in terms of robotics is how do we encode some of the things that us humans encode how do we you know we have to think about our own objective function our own reward structure our own model of the environment about which we perceive and reasonable in order to then encode machines that are doing the same and I believe autonomous driving is in that category but to ask questions of ethics we have to ask questions of of risk value of human life value of efficiency money and so on all these in front of ethical questions that an autonomous vehicle unfortunately has to solve before it becomes fully autonomous so here are the key takeaways of the real-world impact of reinforcement learning agents on the deep learning side okay these neural networks that form high representation the fun part is the algorithms all the different architectures the different encoder/decoder structures all the attentions self attention recurrent Sallust Engr use all the fun architectures and the data so that and the ability to leverage different data sets in order to discriminate better than perform this Crematory tasks better than you know MIT does better than stand for that kind of thing that's the fun part the hard part is asking good questions and collecting huge amounts of data that's representative over the task that's for real world impact not cvpr publication real-world impact a huge amount of data on a deeper enforcement learning side the key challenge the fun part again is the algorithms how do we learn from data some of the stuff I'll talk about today the hard part is defining the environment defining the acts of space and the reward structure as I mentioned this is the big challenge and the hardest part is how to crack the gap between simulation in the real world the leaping lizard that's the hardest part we don't even know how to solve that transfer learning problem yet for the real world in fact the three types of reinforcement learning there's countless algorithms and there's a lot of ways to economize them but at the highest level there's model-based and there's model free model based algorithms learn the model of the world so as you interact with the world you construct your estimate of how you believe the dynamics of that world operates the nice thing about doing that is once you have a model or an estimate of a model you're able to anticipate you're able to plan into the future you're able to use the model to in a branching way predict how your actions will change the world so you can plan far into the future this is the mechanism by which you can you can do chess in the simplest form because in chess you don't even need to learn the model the models learnt is given to you chess go and so on the most important way in which they're different I think is the sample efficiency is how many examples of data are needed to be able to successfully operate in the world and so model based methods because they're constructing a model if they can are extremely simple efficient because once you have a model you can do all kinds of reasoning that doesn't require experiencing every possibility of that model you can unroll the model to see how the world changes based on your actions value based methods are ones that look to estimate the quality of states the quality of taking a certain action in the certain state so they're called off policy versus the last category that's on policy what does it mean to be off policy it means that they constantly value based agents constantly update how good is taken action in a state and they have this model of that goodness of taking action in a state and they use that to pick them optimal action they don't directly learn a policy a strategy of how to act they learn how good it is to be in a state and use that goodness information to then pick the best one and then every once in a while flip a coin in order to explore and then policy based methods our ones that directly learn a policy function so they take as input the the world representation of that world neural networks and this output a action where the action is stochastic so okay that's the range of model-based value based and policy based here's an image from open AI that I really like I encourage you to as we further explore here to look up spinning up in deeper enforcement learning from open AI here's an image that texana mises in the way that I described some of the recent developments in RL so at the very top the distinction between model free RL and model-based RL in model free RL which is what we'll focus on today there is a distinction between policy optimization so on policy methods and q-learning which is all policy methods pause optimizations methods that directly optimize the policy they'll directly learn the policy in some way and then q-learning off policy methods learn like I mentioned the value of taking a certain action in the state and from that learned that learned Q value be able to choose how to act in the world so let's look at a few sample representative approaches in this space let's start with the with the one that really was one of the first great breakthroughs from google deepmind on the deep IRL side and solving atari games dqn deep queue learning networks deep queue networks and let's take a step back and think about what cue learning is q-learning looks at the state action value function queue that estimates based on a particular policy or based on an optimal policy how good is it to take an action in this state the estimated reward if I take an action in this state and continue operating under an optimal optimal policy it gives you directly a way to say amongst all the actions I have which action should that take to maximize the reward now in the beginning you know nothing you know you don't have this value estimation you don't have this cue function so you have to learn it and you learn it with a bellman equation of updating it you take your current estimate and update it with the reward you seed received after you take an action here it's off policy and model free you don't have to have any estimate or knowledge of the world you don't have to have any policy whatsoever all you're doing is roaming about the world collecting data when you took a certain action here award you received and you're updating gradually this table where the table has state states on the y-axis and actions on the x-axis and the key part there is because you always have an estimate of what of to take an action of the value of taking that action so you can always take the optimal one but because you know very little in the beginning that optimal is going to you have no way of knowing that's good or not so there's some degree of expiration the fundamental aspect of value based methods or ami are all methods like I said it's trial and error is exploration so for value based methods that q-learning the way that's done is with the flip of a coin epsilon greedy with a flip of a coin you can choose to just take a random action and you slowly decrease epsilon to zero as your agent learns more and more and more so in the beginning you explore a lot with epsilon 1 and epsilon of zero in the end when you're just acting greedy based on the your understanding of the world as represented by the q-value function for non neural network approaches this is simply a table the Q this Q function is a table like I said on the Y State X actions and in each cell you have a reward that's at this counter reward that you estimated to be received there and as you walk around with this bellami equation you can update that table but it's a table nevertheless number of states times number of actions now if you look at any practical real-world problem and an arcade game with raw sensory input is a very crude first step towards the real world so raw sensor information this kind of value iteration and updating a table is impractical because here's for a game of break out if we look at four consecutive frames of a game of breakout size of the of the raw sensory input is 84 by 84 pixels grayscale every pixel has 256 values that's 256 to the power of whatever 84 times 84 times 4 is whatever it is it's significantly larger the number of atoms in the universe so the size of this cue table if we use the traditional approach is intractable you'll know it's to the rescue deep RL is rl+ neural networks where the neural networks is tasked with taking this in Valley based methods taking this cue table and learning a compress representation of it learning an approximator for the function from state action to the value that's what previously talked about the ability the powerful ability of neural networks to form representations from extremely high dimensional complex raw sensory information so it's simple the framework remains for the most part the same in reinforcement learning it's just that this cue function for value based methods becomes a neural network and becomes an approximator where the hope is as you navigate the world and you pick up new knowledge through the back propagating the gradient and the loss function that you're able to form a good representation of the optimal q function so using your networks with you'll know it's a good at which is function approximator x' and that's DQ 1 deep Q Network was used to have the initial incredible nice results on our K games where the input is the raw sensory pixels with a few convolutional layers for the connected layers and the output is a set of actions you know probability of taking that action and then you sample that and you choose the best action and so this simple agent whether the neural network that estimates that Q function very simple network is able to achieve superhuman performance on many of these arcade games that excited the world because it's taking raw sensory information with a pretty simple network that doesn't in the beginning understand any of the physics of the world any of the dynamics of the environment and through that intractable space the intractable state space is able to learn how to actually do pretty well the loss function for DQ n has to Q functions one is the expected the predicted Q value of a taking an action in a particular state and the other is the target against which the loss function is calculated which is what is the value that you got once you actually take in that action and once you've taken that action the way you calculate the value is by looking at the next step and choosing the max to Singh if you take the best action in the next state what is going to be the Q function so there's two estimators going on with in terms of neural networks those two forward passes here there's two Q's in this equation so in traditional DQ n that's just that's done by a single neural network with a few tricks and double DQ n that's done by two neural networks and I mentioned tricks because with this and with most of RL tricks tell a lot of the story a lot of what makes systems work is the details in in games and robotic systems in these cases the two biggest tricks for DQ n that will reappear and a lot of value based methods is experience replay so think of an agent that plays through these games as also collecting memories you collect this bank of memories that can then be replayed the power of that one of the central elements of what makes value based methods attractive is that because you're not directly estimating the policy but are learning the quality of taking an action in a particular state the you're able to then jump around through your memory and and play different aspects of that memory so learn train the network through the historical data and then the other trick simple is like I said that there is so the loss function has two queues so you're it's it's a dragon chasing its own tail it's easy for the loss function to become unstable so the training does not converge so the trick of fixing a target Network is taking one of the queues and only updating in every X steps every thousand steps and so on and taking the same kind of network it's just fixing it so for the target network that defines the loss function just keeping it fixed and only updating any regulator so you're chasing a fixed target with a loss function as opposed to a dynamic one so you can solve a lot of the Atari games with minimal effort come up with some creative solutions here break out here after 10 minutes of training on the left after a to have 2 hours of training on the right is coming up with some creative solutions again it's pretty cool because this is raw pixels right we're now like there's been a few years since this breakthrough so kind of take it for granted but I still for the most part captivated by just how beautiful it is that from the raw sensory information neural networks are able to learn to act in a way that actually supersedes humans in terms of creativity in terms of in terms of actual raw performance it's really exciting and games of simple form is the cleanest way to demonstrate that and you the the same kind of DQ and network is able to achieve superhuman performance and a bunch of different games there's improvements to this like dual DQ one again the q function can be decomposed which is useful in to the value estimate of being in that state and what's called and in future slides that we called advantage so the advantage of taking action in that state the nice thing of the advantage as a measure is that it's a measure of the action quality relative to the average action that could be taken there so if it's very useful advantage versus sort of raw reward is that if all the actions you have to take are pretty good you want to know well how much better it is in terms of optimism that's a better measure for choosing actions in a value-based sense so when you have these two estimates you have these two streams for neural networking the dueling DQ n DG QM where one estimates the value the other the advantage and that's again that dueling nature is useful for also on the there are many states in which the action is decoupled the quality of the actions is decouple from the state so many states it doesn't matter which action you take so you don't need to learn all the different complexities all the topology of different actions when you in a particular state and another one is prioritize experience for play like I said experience replay is really key to these algorithms and the thing that sinks some of the policy optimization methods and experiments replay is collecting different memories but if you just sample randomly in those memories you're now affected the sampled experiences are really affected by the frequency of those experience occurred not their importance so prioritize experience replay assigns a priority a value based on the magnitude of the temporal difference learned error so the the stuff you have learned the most from is given a higher priority and therefore you get to see through the experience replay process that that particular experience more often okay moving on to policy gradients this is on policy versus q-learning off policy policy gradient is directly optimizing the policy where the input is the raw pixels and the policy network represents the forms of representations of that environment space and as output produces a stochastic estimate a probability of the different actions here in the pong the pixels a single output that produces the probability of moving the paddle up so how do pause gradients vanilla policy grading the very basic works is you unroll the environment you play through the environment here pong moving the paddle up and down and so on collecting no rewards and only collecting reward at the very end based on whether you win or lose every single action you're taking along the way gets either punished or rewarded based on whether it led to victory or defeat this also is remarkable that this works at all because the credit assignment there's a is I mean every single thing you did along the way is averaged out it's like muddied it's the reason that policy gradient methods are more inefficient but it's still very surprising that it works at all so the pros versus DQ one the value based methods is that if the world is so messy that you can't learn a q function the nice thing about policy gradient because it's learning the policy directly that it will at least learn a pretty good policy usually in many cases faster convergence it's able to deal with stochastic policies so value based methods can out learners the gassing policies and it's much more naturally able to deal with continuous actions the cons is it's inefficient versus dqn it's it can become highly unstable as we'll talk about some solutions to this during the training process and the credit assignment so if we look at the chain of actions that lead to a positive reward some might be awesome action some may be good action some might be terrible actions but that doesn't matter as long as the death the nation was good and that's then every single action along the way gets a positive reinforcement that's the downside and there's now improvements to that advantage actor critic methods a to see combining the best of value based methods and policy base methods so having an actor two networks an actor which is policy based and that's the one that's takes the actions samples the actions from the policy Network and the critic that measures how good those actions are and the critic is value based all right so as opposed to in the policy update the first equation there the reward coming from the destination the that our war being from whether you won the game or not every single step along the way you now learn a Q value function Q s a state and action using the critic Network so you're able to now learn about the environment about evaluating your own actions at every step so you're much more sample efficient there's a synchronous from deep mind and synchronous from open AI variants of this but of the actor advantage actor critic framework but both are highly parallelizable the difference with a three C the asynchronous one is that every single agency just throw these agents operating in the environment and they're learning they're rolling out the games and getting the reward they're updating the original Network asynchronously the global network parameters asynchronously and as a result they're also operating constantly an outdated versions of that network the open AI approach that fixes this is that there's a coordinator that there's these rounds where everybody all the agents in parallel are rolling out the episode but then the coordinator waits for everybody to finish in order to make the update to the global network and then distributes all the same parameter to all the agents and so that means that every iteration starts with the same global parameters and that has really nice properties in terms of conversions and stability of the training process okay from google deepmind the deep deterministic policy gradient is combining the ideas of dqn but dealing with continuous action spaces so taking a policy network but instead of the actor actor critic framework but instead of picking a stochastic policy having the actor operator on the since the casting nature is picking the best picking a deterministic policy so it's always choosing the best action but ok with that the problem quite naturally is that when the policy is now deterministic it's able to do continuous action space but because it's termina stick it's never exploring so the way we inject exploration into the system is by adding noise either adding noise into the action space on the output or adding noise into the parameters of the network that have then that create perturbations and the actions such that the final result is that you try different kinds of things and the the scale of the noise just like well the epsilon greedy in the exploration for DQ on the scale of the noise decreases as you learn more and more so on the policy optimization side from open ai and others we'll do a lecture just on this there's been a lot of exciting work here the basic idea of optimization on policy optimization with PPO and TRP au is first of all we want to formulate reinforcement learning as purely an optimization problem and second of all if policy optimization the actions you take influences the rest of your the optimization process you have to be very careful about the actions you take in particular you have to avoid taking really bad actions when you're convergence the the training performance in general collapses so how do we do that there's the line search methods which is where gradient descent or gradient descent falls under which which is the how we train deep neural networks is you first pick a direction of the gradient and then pick the step size the problem with that is that can get you into trouble here there's a nice visualization walking along a ridge is it can it can result in you stepping off that Ridge again the collapsing of the training process the performance the trust region is is the underlying idea here for the for the policy optimization methods that first pick the step size so that constrain in various kinds of ways the the magnitude of the difference to the weights that's applied and then the direction so it placing a much higher priority not choosing bad actions that can throw you off the optimization path should actually we should take to that path and finally the on the model-based methods and we'll also talk about them in the robotics side there's a lot of interesting approaches now where deep learning is starting to be used for a model-based methods when the model has to be learned but of course when the model doesn't have to be learned it's given inherent to the game you know the model like Ingo and chess and so on out zero has really done incredible stuff so what's wise what is the model here so the way that a lot of these games are approached you know game of Go it's turn-based one person goes and then another person goes and there's this game tree at every point as a set of actions that could be taken and quickly if you look at that game tree it's it becomes you know a girl's exponentially so it becomes huge a game of go is the hugest of all in terms of because the number of choices you have is the largest and there's chess and then you know it gets the checkers and then tic-tac-toe and it's just the the degree at every step increases decreased based on the game structure and so the task for a neural network there is to learn the quality of the board it's that it's to learn which boards which game positions are most likely to result in a are most useful to explore and a result in a highly successful state so that choice of what's good to explore what's what branch is good to go down is where we can have neural network step in and without phago it was pre trained the first success that beat the world champion was pre trained on expert games then with alphago zero it was no pre training on expert systems so no imitation learning is just purely through self play through suggesting through playing itself new board positions many of these systems use Monte Carlo tree search and during the search balancing exploitation exploration so going deep on promising positions based on the estimation then you'll network or with a flip of a coin playing under play positions and so this kind of here you can think of as an intuition of looking at a board and estimating how good that board is and also estimating how good that board is likely to lead to victory down the end so as to mean just general quality and probability of leading to victory then the next step forward is alpha zero using the same similar architecture with MCTS what do you call it research but applying it to different games and applying it and competing against other engines state-of-the-art engines and go and shogi in chess and outperforming them with very few very few steps so here's this model-based approaches which are really extremely simple efficient if you can construct us such a model and in in the robotics if you can learn such a model I can be exceptionally powerful here beating the the engines which are far superior to humans already stockfish can destroy most humans on earth at the game of chess the ability through learning through through estimating the quality of a board to be able to defeat these engines is incredible and the the exciting aspect here versus engines that don't use neural networks is that the number its it really has to do with based on the neural network you explore certain positions you explore certain parts of the tree and if you look at grandmasters human players in chess they seem to explore very few moves they have a really good neural network at estimating which are the likely branches which would provide value to explore and on the other side stock fish and so on are much more brute force in their estimation for the MCTS and then alpha zero is a step towards the Grandmaster is the number of branches need to be explored as much much fewer a lot of the work is done in the representation form by the neural network it's just super exciting and then it's able to uh perform stockfish in chess it's able to outperform Elmo and shogi and it's itself in go or the previous iterations of alphago zero and so on now the challenge here the sobering truth is that majority of real world application of agents that have to act in this world perceive the world and act in this world are for the most part not based have no RL involved so the action is not learned use neural networks to perceive certain aspects of the world but ultimately the action is not is not learned from data that's true for all most of the autonomous vehicle companies are all of the autonomous vehicle companies operating today and it's true for robotic manipulation in the industrial robotics and any of the humanoid robots have to navigate in this world under uncertain conditions all the work from Boston Dynamics doesn't involve any machine learning as far as we know now that's beginning to change here with animal the the recent development where the certain aspects of the control a robotic could be learned you're trying to learn more efficient movement you're trying to learn more robust movement on top of the other controllers so it's quite exciting through RL to be able to learn some of the control dynamics here that's able to teach this particular robot to be able to get up from arbitrary positions so it's less hard coding in order to be able to deal with unexpected nishal conditions and unexpected perturbations so that's exciting there in terms of learning the control dynamics and some of the driving policy so maybe behavioral driving behavior decisions changing lanes turning and so on that if you if you were here last week heard from way moe they they're starting to use some RL in terms of the driving policy in order to especially predict the future they're trying to anticipate intent modeling predict what the pedestrians the cars are going to be based on environment that are trying to unroll what's happened recently into the future and beginning to move beyond sort of pure end to end on NVIDIA and to end learning approach of the control decisions are actually moving to RL and making long-term planning decisions but again the challenge is the the gap the leap needed to go from simulation to real-world all most the work is done from the design of the environment and the design and the reward structure and because most of that work now is in simulation we need to either develop better algorithms for transfer learning or close the distance between simulation in the real world and also we could think outside the box a little bit at the conversation with Peter bill recently one of the leading researchers in deep RL it kind of on the side quickly mentioned the the idea is that we don't need to make simulation more realistic what we could do is just create an infinite number of simulations or very large number of simulations and the naturally the regularization aspect of having all those simulations will make it so that our our reality is just another sample from those simulations and so maybe the solution isn't to create higher fidelity simulation or to create transfer learning algorithms maybe it's to build a arbitrary number of simulations so then that step towards creating a agent that work that works in the real world is a trivial one and maybe that's exactly whoever created the simulation we're living in and the multiverse that we're living in did next steps the lecture videos will have several in RL will be made all available on deep learning that MIT ID you will have several tutorials in RL on github the link is there and I really like the essay from open AI on spinning up as a deep our researcher you know if you're interested in getting into research in RL what are the steps need to take from the background of developing the mathematical background prop stat and multivariate calculus to some of the basics like it's covered last week on deep learning some the basics ideas in RL just terminology and so on some basic concepts then picking a framework tends to flow our PI torch and learn by doing i implemented guram as i mentioned today those are the core RL algorithms so implement all isms from scratch it should only take about two hundred three hundred lines of code there actually when you put it down on paper quite simple intuitive algorithms and then read papers about those algorithms that follow after looking not for the big waving performance the hand waving performance but for the tricks that were used to change these algorithms the tricks tell a lot of the story and that's the useful parts that they need to learn and iterate fast on simple benchmark environments so open the I Jim has provided a lot of easy to use environments that you can play with that you can train an agent in minutes hours as opposed to days and weeks and so iterating fast is the best way to learn these algorithms and then on the research side there's three ways to get a best paper award right two to publish and to contribute and have an impact in the research community in in RL one is improving existing approach given us a particular benchmarks there's a few benchmark datasets environments that are emerging so you want to improve on the existing approach some aspect of the convergence in the performance you can focus on an unsolved task there's certain games that just haven't been solved through their RL formulation or you can come up with a totally new problem that hasn't been addressed by RL before so with that I'd like to thank you very much tomorrow I'll hope to see you here for deep traffic Thanks you you"}], "MIT 6.S094: Deep Learning for Human-Centered Semi-Autonomous Vehicles": [{"content": "The human side of AI,\nhow do we turn this camera back in on the human, we are talking about perception, how to detect cats and dogs,\npedestrians lanes, how to steer a vehicle based on the\nexternal environment, the thing that's really fascinating and\nseverely understudied, is the human side,\nwe talked about the Tesla, we have cameras in 17 Tesla's\ndriving around Cambridge because Tesla is one of the only vehicles\nallowing you to experience in a real way, on the road,\nthe interaction between the human and the Machine, the thing that we don't have, that deep learning needs\non the human side of semi-autonomous vehicles\nand fully-autonomous vehicles is video of drivers,\nthat's what we're collecting, that's what my work is in,\nis looking at billions of video frames,\nof human beings driving 60 miles an hour plus\non the highway in their semi-autonomous Tesla, what are the things that we want\nto know about the human? If we were a deep learning therapist,\nwe\u2019d try to break apart the different things we can detect\nfrom this raw set of pixels, we can look here,\nfrom the green to red is a different detection problem, a different computer vision\ndetection problem green means it's less challenging, it's feasible,\neven under poor lighting conditions, variable pose, noisy environment,\npoor resolution, red means it's really hard\nno matter what you do, that's starting on the left\nwith face detection body pose, one of the best studied\nand one of the easier computer vision problems,\nwe have huge datasets for these, then there is micro saccades,\nthe slight tremors of the eye that happen at a rate of\na thousand times a second. All right let's look at\u2014 First, why do we even care about the human in the car? One is trust, this trust part is a\u2014\nIf you think about it, to build trust\nthe car needs to have some awareness of\nthe biological thing it's carrying inside,\nthe human inside, you assume the car\nknows about you, because you're sitting there\ncontrolling it, but if you think about it,\nalmost every single car on the road today,\nhas no sensors with which it's perceiving you,\nit knows, some cars have a pressure sensor\non the steering wheel and a pressure sensor\nor some kind of sensor detecting that you're sitting\nin the seat, that's the only thing\nit knows about you, that's it,\nso how is the car supposed to\u2014 this same car\nis driving 70 miles an hour, on the highway, autonomously,\nhow is it supposed to build trust with you\nif it doesn't perceive you? That's one of the\ncritical things here, so if I'm constantly\nadvocating something, is that we should have\na driver facing camera in every car, despite the privacy concerns, you have a camera on your phone\nand you don't have as much of a privacy concern there,\nbut despite the privacy concerns, the safety benefits are huge,\nthe trust benefits are huge. Let's start with the easy one,\ndetecting body pose, why do we care? There is a seatbelt design, there are these dummies, crash-test dummies,\nwhich we can use to design the passive\nsafety systems of our cars, and they make certain assumptions\nabout body shapes, male, female, child, body shapes,\nbut they also make assumptions about the position of\nyour body in the seat, they have the optimal position,\nthe position they assume you take, the reality is, in a Tesla,\nwhen the car is driving itself, the variability, if you remember\nthe deformable [unintelligible 00:04:44] you start doing a little bit more\nof that, you start to reach back in the back seat,\nin your purse, your bag, for your cell phone,\nthese kinds of things, that's when the crashes happen,\nwe to know how often that happens, the car needs to know\nthat you're in that position, that's critical for that\nvery serious moment when the actual crash happens, how do you do? This is deep learning class,\nthis is deep learning to the rescue, whenever you have\nthese kinds of tasks, of detecting for example\nbody poses, you're detecting points of the shoulders,\npoints of the head, five-ten points along the arms,\nthe skeleton. How do you do that? You have a CNN,\nconvolutional neural network, that takes its input image\nand takes an output, it's a regressor,\nit gives an XY position of whatever you're looking for,\nthe left shoulder, right shoulder, then you have a cascade\nof regressors they give you all of these points, they give you the shoulders,\nthe arms and so on, then you have\u2014\nthrough time on every single frame\nyou make that prediction and then you optimize, you can make certain\nassumptions about physics, your arm can't be in this place in one frame\nand then the next frame be over here,\nit moves smoothly through space\nso under those constraints you can then minimize the error-- the temporal error from frame to frame\nor you can just dump all the frames, as if there are different channels\nlike RGB is three channels, you can think of those channels\nas in time, you can dump\nall those frames together, and that's what I call\n3D convolutional neural networks, you've dumped them all together\nand then you estimate the body pose\nin all the frames at once. There are some data sets\nfor sports and we're building our own\u2014\nI don't know who that guy is\u2014 Let's fly through this a little bit,\nso what's called gaze classification, gaze is another word for glance, it's a classification problem, here's one of the TAs for this class, Not here because he's married,\nhe had to be home, I know were his priorities are at,\nthis is on camera, he should be here,\n[chuckles] There's five cameras, this is why we're recording in the Tesla. This is a Tesla vehicle, in the bottom right,\nthere's a blue icon that lights up automatically detected\nif it's operating under autopilot, that means the car is currently\ndriving itself, there's five cameras\none on the forward roadway, one on the instrument cluster,\none on the center stack, steering wheel,\nhis face, then it's a classification problem,\nyou dump the raw pixels into a convolutional neural network,\nhave six classes forward roadway, you're predicting\nwhere the person is looking, forward roadway, left, right, center stack, instrument cluster, rearview mirror,\nand you give millions of frames for every class, simple. And It does incredibly well at predicting where the driver is looking,\nthe process is the same for majority of the driver state problems\nthat have to do with the face, the face has so much information,\nwhere are you looking, emotion, drowsiness,\ndifferent degrees of frustration, I'll fly through those as well,\nbut the process is the same, there's some pre-processing,\nthis is in the wild data, there's a lot of crazy light going on,\nthere's noises, vibration from the vehicle,\nso first you have to\u2014 video stabilization\nyou have to remove all that vibration, all that noise, as best as you can,\nthere's a lot of algorithms, non-neural network algorithms, boring but they work for removing the noise,\nremoving the effects of sudden light variations and\nvibrations of the vehicle, there's the automated calibration,\nso you have to estimate the frame of the camera,\nthe position of the camera, and estimate the identity\nof the person you're looking at. The more you can specialize the network\nto the identity of the person and the identity of the car\nthe person is riding in, the better the performance for the\ndifferent driver state classification. So you personalize the network,\nyou have a background model that works on everyorne\nand you specialize each individual, this is transfer learning, you specialize each individual network\nto that one individual. There is a face frontalization, fancy name for the fact that\nno matter where they're looking, you want to transfer that face\nso the eyes, nose are the exact same position\nin the image, that way if you want to look at the eyes and you want to study the subtle\nmovement of the eyes the subtle blinking, the dynamics of the eyelid,\nthe velocity of the eyelid, it's always in the same place\nso you can really focus in remove all effects\nof any other motion of the head, and then you just\u2014\nit's the beauty of deep learning, there is some pre-processing,\nbecause this is real-world data, but you just dump the raw pixels in, you dump the raw pixels in and\npredict whatever you need. What do you need? One is emotion, You can have\u2014\nI had a study where people used a crappy and a good voice\nbased navigation system, so the crappy one\ngot them really frustrated, and they self-reported it\nas the frustrating experience or not on scale one to 10,\nthat gives us ground truth, a bunch of people to used this system, they put themselves as\nfrustrated or not, so then we can predict, we can train a Convolutional\nneural network to predict is this person frustrated or not,\nI think we've seen a video of that, turns out smiling is a strong\nindication of frustration, you can also predict\ndrowsiness in this way, gaze estimation in this way,\ncognitive load, I'll briefly look at that,\nthe process is all the same, you detect the face, you find the\nlandmark points in the face,  for the face alignment,\nface frontalization, and then you dump the raw pixels in\nfor classification, step five. You can use SVM's there or you can use what\neveryone uses now, convolutional neural networks. This is the one part where CNN's\nstill struggle to compete, is the alignment problem, this is why I talked about\nthe Cascade regressors, is finding the landmarks\non the eyebrows, the nose, the jawline, the mouth,\nthere are certain constraints there, so algorithms that can utilize those\nconstraints effectively can often perform better than \nend-to-end regressors that just don't have any concept\nof what a face is shaped like. There are huge data sets\nand we're a part of the awesome community\nthat's building those data sets for face alignment. This is the TA in its younger form, this is live in the car, the real time system predicting\nwhere they're looking, this is taking slow steps\ntowards the exciting direction that machine learning is headed,\nwhich is unsupervised learning, the less you have\nto have humans look to the data and annotate that data, the more power these machine\nlearning algorithms get,  currently supervised learning\nis what's needed, you need human beings to label\na cat and label a dog, if you can only have a\nhuman being label 1%,  one tenth of a percent\nof a data set, only the hard cases, so the machine can come\nto the human and be like, I don't know what I'm\nlooking at in these pictures, because of the partial\nlight occlusions, we're not good\nat dealing with occlusions, whether it's your own arm\nor because of light conditions, we're not good with crazy light\ndrowning out the image, this is what Google self-driving cars\nstruggle with when they're trying\nto use their vision sensors, moving out of frame, all kinds of occlusion They are really hard for computer vision algorithms, and in those cases we want a machine\nto step in and say-- and pass that image on to the human,\nbe like \"help me out with this\" and the other corner case is,\nin driving for example 90 plus percent of the time\nall you're doing is staring forward at the roadway\nthe same way, that's where the Machine shines, that's where machine automated\nannotation shines, because it's seen that face for hundreds of millions\nof frames already, in that exact position, so it can do all the hard work\nof annotation for you, it's in the transition away from those positions that it needs a little bit of help, just to make sure that this person\njust started looking away from the road to the rear view,\nand you bring those points up, so you're-- there's a\u2014\nusing optical flow, putting the optical flow\nin the convolutional neural network, you use that to predict\nwhen something has changed when something has changed you bring\nthat to the machine for annotation all of this is to build a giant\u2014 Billions of frames annotated data set,\nour ground truth, on which you train your\ndriver state algorithms, in this way you can control,\non the x-axis is the fraction of frames\nthe human has to annotate, zero percent on the Left,\nten percent on the right, and then the accuracy trade-off,\nthe more the human annotates, the higher the accuracy,\nyou approach 100% accuracy, but you can still do pretty good, this is for the gaze classification task, With an 84-- 84 fold to almost towards the magnitude reduction\nin human annotation, this is the future\nof machine learning, and hopefully one day\nno human annotation, and the result is millions of images\nlike these video frames, same thing, driver frustration,\nthis is what I was talking about, the frustrated driver\nis the one that's on the bottom, so a lot of movement\nof the eyebrows and a lot of smiling, and that's\ntrue subject after the subject, And they're Happy, the satisfied,\nI don't want to say happy, the satisfied driver is\ncold and stoic, and that's true for\nsubject after subject, because driving is a boring experience\nand you want it to stay that way Yes, question. Great, great question,\nthey're not--  Absolutely, that's a great question So these cars owned by MIT,\nthere is somebody in the back\u2014 The comment was\u2014 my emotions then have nothing to\ndo with the driving experience. Yes, let me continue that comment,\nyour emotions are often\u2014 You're an actor on the stage\nfor others with your emotion, when you're alone,\nyou might not express emotion, you're really expressing emotion\noftentimes for others, your frustration is like\n\"What the heck\" that's for the passenger,\nand that's absolutely right, so one of the cool things\nwe're doing\u2014 As I said, we now have over a billion\nvideo frames in the Tesla, We're starting to collected huge\namounts of data in the Tesla, emotion is a complex thing, in this case,  we know the ground truth,\nhow frustrated they were, in naturalistic data, when it's just\npeople driving around,  we don't know how they're\nreally feeling at the moment, we're not asking to enter an app\n\"how are you feeling right now?\" but we do know certain things,\nwe know that people sing a lot, that has to be on paper\nat some point, it's awesome,\npeople love singing, so that doesn't happen\nin this kind of data, because there's somebody\nsinging in the car, and I think the expression\nof frustration is also the same. Yes. The question is\u2014\nor the comment is that the solo data set is probably\ngoing to be very different  from a data set that's not solo, with a passenger, that's very true,\nthe tricky thing about driving  this is why it's a huge challenge\nfor self-driving cars for the external facing sensors and for the internal facing sensors\nanalyzing human behavior, is 99.9% of driving is the same thing,\nit's really boring. So finding the interesting bits\nis actually pretty complicated, so that has to do with emotion,\nthat has to do with\u2014 so singing is easy to find,\nwe can track the mouth pretty well, so when you're talking of singing\nwe can find that, but how do you find\nthe subtle expressions of emotion? It's hard, when you're solo. Cognitive load,\nthat's a fascinating thing, I mean, similar emotion\nit's a little more concrete in a sense that there's good science\nand ways to measure cognitive load, cognitive workload,\nhow occupied your mind is, mental workload\nis another term used, the window to the soul, the cognitive workload soul\nis the eyes,  so pupil\u2014 first of all the eyes move in\ntwo different ways they move in a lot of ways but \ntwo major ways is saccades, these are these ballistic movements,\nthey jump around whenever you look around the room,\nthey're actually just jumping around, when you read\nthe eyes are jumping around, Like if all of you just follow\nthis bottle with your eyes, your eyes are actually going \nto move smoothly,  a smooth pursuit. Somebody actually told me today, that probably has to do with our \nhunting background as animals, I don't know how that helps,\nlike frogs track flies really well, so you have to like\u2014\nAnyway, the point is there are smooth pursuit movements\nwhere the eyes move smoothly, and those are all indications\nof certain aspects of cognitive load, and then there are\nthese very subtle movements, which are almost imperceptible\nfor computer vision and these are micro saccades,\nthese are tremors of the eye, a work from here,\nfrom Bill Freeman, magnifying those subtle movements,\nthese are taken at 500 frames a second. So cognitive load\u2014 when the pupil, that black dot in the middle, in case you don't know what a pupil is, in the middle of the eye, when it gets larger that's an indicative\nof high cognitive load, but it also gets larger \nwhen the light is dim. So there's this complex interplay, so we can't rely in the wild outside, in the car, or just in general outdoors, using the pupil size, even though pupil size\nhas been used effectively in a lab to measure cognitive load,\nit can't be reliably used in the car, the same with blinks,\nwhen there's a high cognitive load, your blink rate decreases\nand your blink duration shortens, I think I'm just repeating\nthe same thing over and over, but you can imagine\nhow we can predict cognitive load, We extract a video of the eye. Here is the primary eye of the person\nthe system is observing, happens to be the same TA once again. We take the sequence of 100--\nit's 90 images, that's six seconds, 16 frames a second,\n15 frames a second, we dump that into a 3D\nconvolutional neural network, that means it's 90 channels,\nit's 90 frames, grayscale, and then the prediction is one of\nthree classes of cognitive load, low cognitive load, medium cognitive\nload and high cognitive load, there's ground truth for that,\nbecause we have people-- over 500 different people\ndo different tasks of various cognitive load,\nand after some frontalization again, where you see the eyes are traced\nno matter where the person looking, the image of the face is\ntransposed in such a way that the corner of the eyes remain\nalways in the same position, after the frontalization,\nwe find the eye, active appearance models,\nfind 39 points of the eyelids, the iris, and four points on the pupil. Putting all of that into a 3D CNN model, they're positioned,eye sequence on the left,\n3D CNN model in the middle, cognitive load prediction\non the right. This code by the way\nis freely available online. All you have to do,\ndump a web-cam from the video stream,\nCNN runs faster than real-time, predicts cognitive load. Same process as detecting\nthe identity of the face, same process as detecting where\nthe driver is looking, same process as detecting emotion and all of those\nrequire very little hyper parameter tuning on\nthe convolutional neural networks, they only require\nhuge amounts of data. Why do we care about detecting\nwhat the drivers doing? I think Eric has mentioned this is-- On the-- Oh man, this is the comeback of the slide, [laughter] I was criticized for this being\na very cheesy slide, in the past towards full automation, we're likely to take\ngradual steps towards that. I can't, it's enough of that,\nthis is better\u2014 Especially given that\u2014\nThis is given today, our new president,\nthis is a pickup truck country, this is a manually\ncontrolled vehicle country, for quite a little while,\nwe like control and control being given\nto somebody else, to the machine,\nwill be a gradual process, it's a gradual process of that \nmachine earning trust, and through that process,\nthe machine,  like the Tesla, like the BMW,  like the Mercedes, the Volvo, that's now playing with these ideas, it's going to need to see\nwhat the human is doing, and for that, to see what\nthe human is doing, we have billions of miles of\nforward-facing data, what we need, is billions of miles of\ndriver facing data as well. We're in the process of\ncollecting that, this is a pitch for automakers\nand everybody to buy cars that have a driver facing camera. And let me close-- I said we need a lot of data but\nI think this class has been\u2014 through your own research you'll find\nthat we're in the very early stages of discovering the power\nof deep learning, for example, recently,\n Jean [?] said that it seems that\nthe deeper the network, the better the results\nin a lot of really important cases, even though the data\nis not increasing, why does the deeper network\ngive better results? This is a mysterious thing\nwe don't understand, there's these hundreds of millions\nof parameters, from them is emerging \nsome kind of structure, some kind of representation of the\nknowledge that we're giving it. One of my favorite examples\nof this emergent concept is the Conway's Game of Life. For those of you who\nknows what this is, will probably criticize me\nfor being as cheesy as the stairway slide,\nbut I think it's such a simple and brilliant example\nof how--  Like a neuron in a neural network is a really simple computational unit, and then incredible power emerges\nwhen you combine a lot of them in a network,\nin the same way, this is called \nthe cellular automata, that's a weird pronunciation, every single cells is operating\nunder a simple rule, you can think of it as \na cell living and dying, it's filled in black when it's alive and white when it's dead,\n if it's alive and it has two or three neighbors,\nit survives to the next time, otherwise it dies, and if it has exactly three neighbors,\nand it's dead, it comes back to life,\nif it has exactly three neighbors, that's a simple rule,\nwhatever, you can just imagine,\nit's just simple\u2014 All is doing, is operating under\nthis very local process, same as a neuron. It's a\u2014\nor in the way we're currently training\nneural networks and there's this local gradient, we're optimizing over a local gradient,\nthe same local rules, and what happens\nif you run this system, operating under really local rules,\nwhat you get on the right, it's not\u2014\nAgain, you have to go home, hopefully no drugs involved,\nbut you have to open up your mind [chuckles] and see how amazing that is, because what happens is,\nit's a local computational unit, that knows very little\nabout the world, but somehow really\ncomplex patterns emerge and we don't understand why,\nin fact under different rules, incredible patterns emerge,\nand it feels like it's living creatures communicating,\nwhen you just watch it, not these examples,\nthis is the original, they get complex and interesting,\nbut even in these examples, these complex geometric\npatterns that emerge, it's incredible,\nwe don't understand why, same with neural networks,\nwe don't understand why, and we need to in order to see how\nthese networks will be able to reason. What's next?"}, {"content": "I encourage you to read\nthe deep learning book, it's available online,\ndeeplearningbook.org. As I mentioned to a few people,\nyou should-- Well, first there's a ton \nof amazing papers every day coming out on archive, I'll put these links up, but there's a lot of good \ncollections of strong papers, lists of papers, there is \nthe literally awesome list, the awesome deep learning \npapers on GitHub, it's calling itself awesome,\nbut it happens to be awesome, there is a lot of blogs,\nit's just amazing, that's how I recommend you\nlearn machine learning, on blogs,\nand if you're interested in the application of deep learning\nin the automotive space, you can come and do \nresearch in our group, just email me. Anyway, we have three winners, Jeffrey Hu, Michael Gump how  do you-- Are you here?"}, {"content": "How do you say your name?"}, {"content": "No, that's not my name\n[laughter] My name is Purna [?] Oh, I see. [?] Well, anyway here-- [applause] He achieved the stunning speed of--\nSo this is kind of incredible, I didn't know\nwhat kind of speed we were going to be able to achieve,\nI thought 73 was unbeatable, because we played with it\nfor a while and we couldn't achieve 73,\nwe design a deterministic algorithm that was able to achieve 74\nI believe, meaning like it's cheating,\nwith the cheating algorithm that got 74,\nfolks have come up with algorithms that have done\u2014\nthat had beaten 73 and then 74,\nso this is really incredible, and the other two guys\u2014\nall three of you get a free term at the Udacity\nself-driving car engineering degree, Thanks to those guys\nfor giving that award and bringing their army of brilliant\u2014 So they have people\nwho are obsessed about self-driving cars,\nand we've received over 2,000 submissions\nfor this competition, a lot of them from those guys,\nthey're just brilliant, it's really exciting to have\nsuch a big community of deep learning folks\nworking in this field, this is for the rest of eternity,\nwe're going to change this up a little bit,\nbut this is actually the three neural networks,\nthe three winning neural networks running side by side,\nyou can see the number of cars passed there,\nthe first place is on the left, second place, and third place,\nand in fact, the third place it's almost-- right now, second place \nis winning currently, but that just tells you\nthe random nature of competition, sometimes you win,\nsometimes loose. The actual evaluation process\nruns through a lot of iterations and takes the medium evaluation. With that, let me thank you \nguys so much for\u2014 Wait, we have a question\u2014 are the winning networks online? Yes. All three guys\nwrote me a note about how their networks work,\nI did not read that note, [chuckles] I'll post\u2014This tells you how\ncrazy this has been, I'll post the winning networks online, and I encourage you to\ncontinue competing and continue submitting networks. This will run for a while we're\nworking on a journal paper  for this game. We're trying to find the\noptimal solutions. Okay."}, {"content": "This is the first time\nI've ever taught a class, and the first time obviously\nteaching this class, so thank you so much\nfor being a part of it. [Applause]\nThank you to Eric, if you didn't get a shirt\nplease come back, please come down and get a shirt,\njust write your email on the note, on the on the index note. Thank you."}], "MIT 6.S094: Convolutional Neural Networks for End-to-End Learning of the Driving Task": [{"content": "Alright, welcome back everyone. Sound okay?"}, {"content": "Alright. So today we will-  We talked a little bit about neural networks, started to talk about neural networks yesterday. Today we'll continue to talk about neural networks that work with images, convolutional neural networks, and see how those types of networks can help us drive a car. If we have time we'll cover a simple illustrative case study of detecting traffic lights. The problem of detecting green, yellow, red. If we can't teach our neural networks to do that, we're in trouble, but it's a good, clear, illustrative case study of a three-class classification problem. Okay, next there's DeepTesla here looped over and over in a very short GIF. This is actually running live in a website right now. We'll show it towards the end of the lecture, this once again just like DeepTraffic is a neural network that learns to steer a vehicle based on the video of the forward road way. And once again, doing all of that in the browser using javascript. So you'll be able to train your own very network to drive using real world data. I'll explain how. We will also have a tutorial and code. Briefly described today at the end of the lecture, if there's time how to do the same thing in TensorFlow. So if you want to build a network that's bigger, deeper and you want to utilize GPUs to train that network, you want to not do it in your browser, you want to do it offline using TensorFlow and having a powerful GPU on your computer and we'll explain how to do that. Computer vision. So we talked about vanilla machine learning where there's no-  Where the size, yesterday, where the size of the input is small for the most part. The number of neurons, in the case the neural networks, is on the order of 10, 100, 1,000. When you think of images, images are a collection of pixels, one of the most iconic images from computer vision on the bottom left there is Lenna. I encourage you to Google it and figure out the story behind that image. It's quite shocking when I found out recently. So once again, computer vision is, these days, dominated by data driven approaches by machine learning where all of the same methods that are used on other types of data are used on images where the input is just a collection of pixels and pixels are numbers from 0  to 255 discrete values. So we can think exactly what we've talked about previously, you could think of images in the same exact way. It's just numbers and so we can do the same kind of thing. We could do supervised learning where you have an input image and output label. The input image here is a picture of a woman; the label might be \"woman\". On supervised learning, same thing. We'll look at that briefly as well as clustering images into categories. Again semi-supervised and reinforcement learning. In fact, the Atari games that talked about yesterday. do some pre-processing on the images. They're doing computer vision;  they're using convolutional neural networks as we'll discuss today and the pipeline for supervised learning is again the same:  there's raw data in the form of images, there's labels on those images. We perform a machine learning algorithm, performs feature extraction, it trains given the inputs and outputs on the images and the labels of those images, constructs the model and then test that model. And we get a metric and accuracy. Accuracy is the term that's used to often describe how well the model performs. The percentage. I apologise for the constant presence of cats throughout this course. I assure you this course is about driving, not cats. but images are numbers. So for us we take it for granted. We're really good at looking and converting visual perception as human beings, converting visual perception, into semantics. We see this image and we know it's a cat but a computer only sees numbers:  RGB values for a color image. There's three values for every single pixel from 0 to 255. And so given that image, we can think of two problems:  one is regression and the other is classification. Regression is when given an image we want to produce a real value of output put back. So if we have an image of the four roadway, we want to produce a value for the steering wheel angle and if you have an algorithm that's really smart, It can take any image of the forward roadway and produce the perfectly correct steering angle that drives the car safely across the United States. We'll talk about how to do that and where that fails. Classification is when the input again is an image and the output is a class label, a discrete class label. Underneath it though often is still a regression problem and once produced is a probability that this particular image belongs to a particular category. And we use a threshold to chop off the outputs associated with low probabilities and take the labels associated with high probabilities and convert it into a discrete classification. I mentioned this yesterday but it bears saying again, computer vision is hard. We, once again, take it for granted. As human beings, we're really good at dealing with all these problems. There's viewpoint variation:  the object looks wholly different in terms of the numbers behind the images in terms of the pixels when viewed from a different angle. Viewpoint variation:  objects when you're standing far away from them or up close are totally different size. We're good at detecting that there are different size. It's still the same object as human beings but that's still a really hard problem because those sizes can vary drastically. We talked about occlusions and deformations with cats; well understood problem. There's background clutter. You have to separate the object of interest from the background and given the three dimensional structure of our world. There's a lot of stuff often going on in the background:  the clutter, their inter-class variation. That's often greater than inter-class variation; meaning objects of the same type often have more variation than the objects that you're trying to separate them from. There is the hard one for driving:  illumination. Light is the way we perceive things; the reflection of light off the surface and the source of that light changes the way that object appears and we have to be robust to all of that. So the image classification pipeline is the same as I mentioned. There are categories, It's the classification problems for those categories of cat, dog, mug, hat. You have a bunch of examples, image examples of each of those categories and so the input is just those images paired with the category. And you train to map, to estimate a function that maps from the images to the categories. For all of that you need data; a lot of it."}, {"content": "There is, unfortunately, a growing number of data sets but there are still relatively small. We get excited. There are millions of images but they're not billions or trillions of images and these are, the data sets that you will see if you read academic literature most often. Mnist, the one that's been beaten to death. And then we use as well in this course the data set of handwritten digits where the categories are 0 to 9. ImageNet, one of the largest image data sets; fully labeled image data sets in the world has images with a hierarchy of categories from Word Net. And what you see there is a labeling of what image is associated with which words are present in the data set. CIFAR-10 and CIFAR-100 are tiny images that are used to prove in a very efficient and quick way offhand that your algorithm that you're trying to publish on, or trying to impress the world with, works well. It's small, it's a small data set:  CIFAR-10 means there's 10 categories. And places is a data set of natural scenes: woods, nature, city, and so on. So let's look at CIFAR-10 as a data set of 10 categories: airplane, automobile, bird, cat, and so on. They're shown there with sample images as the rose. And so let's build a classifier that's able to take images from one of these 10 categories and tell us what is shown in the image. So how do we do that? Once again, all the algorithm sees is numbers. So we have to try to have at the very core, we have to have an operator for comparing two images. So given an image and I want to save it as a cat or dog. I want to compare it to images of cats and compare it to images of dogs and see which one matches better. So there has to be a comparative operator. Okay so one way to do that is take the absolute difference between the two images pixel by pixel, take the difference between each individual pixel shown on the bottom of the slide for a 4x4 image. And then we sum that pixel-wise pixel-wise absolute difference into a single number. So if the image is totally different pixel-wise, that will be a high number. If it's the same image, the number will be 0. Oh, it's the absolute value too of the difference. And that's called L1 distance. It doesn't matter. When we speak of distance, we usually mean L2 distance. And so, if we try to-  So we can build the classifier that just uses this operator to compare it to every single image in the data set and say I'm going to pick the, I'm going to pick the category that's the closest using this comparative operator. I'm going to find-  I have a picture of a cat and I'm going to look through the dataset and find the image that's the closest to this picture and say that is the category that this picture belongs to. So if we just flip the coin and randomly pick which category an image belongs to get that accuracy, would be on average 10%. It's random. The accuracy with which our brilliant image difference algorithm that just goes through the data set and finds the closest one is 38% which is pretty good, it's way above 10%. So you can think about this operation of look into the base and finding the closest image as what's called K-Nearest Neighbors or K in that case. Meaning you find the one closest neighbor to this image that you're asking questions about and accept the label from that image. You could do the same thing increasing K. Increasing K to 2 means you take the two nearest neighbors. You find the two closest in terms of pixel-wise image difference through this particular query image and find which categories did those belong to. What's shown up top on the left is the data set we're working with:  red, green, blue. What's shown in the middle is the one nearest neighbor classifier, meaning this is how you segment the entire space of different things that you can compare. And if a point falls into any of these regions, it will be immediately associated with the nearest neighbor algorithm to belong to that image, to that region. With the five nearest neighbors, there's immediately an issue. The issue is that there is white regions. There's tie breakers where your five closest neighbors are from various categories. So it's unclear where you belong to."}, {"content": "So this is a good example of parameter tuning. You have one parameter:  K. And your task as a teacher of machine learning, you have to teach this algorithm how to do your learning for you, is to figure out that parameter. That's called \"parameter tuning\" or \"hyper-parameter tuning\" as it's called in neural networks. And so on the bottom right of the slide on the x-axis is K. As we increase it from 0 to 100 and  the y-axis is classification accuracy. It turns out that the best K for this data set is 7, 7 years neighbors. With that we get a performance of 30% human level performance and I should say that the way we get that number as we do with a lot of the machine learning pipeline process is you separate the data into the parts of days that you use for training and another part they use for testing. You're not allowed to touch the testing part."}, {"content": "That's cheating. You construct your model of the world on the training data set and you use what's called cross validation where you take a small part of the training data shown \"fold five\" there in yellow to leave that part out from the training and then use it as part of the hyper-parameter tuning. As you train, figure out with that yellow part fold five how well you're doing  and then you choose a different fold and see how well you're doing And keep playing with parameters never touching the test part. And when you're ready, you run the algorithm on a test data to see how well you really do. How will it really generalizes. Yes, question. (INAUDIBLE QUESTION) So, the question was:  \"is there a good way to- Is any good intuition behind what a good K is?\"  There are general rules for different data sets but usually you just have to run through it. Grid search, brute force."}, {"content": "Yes, question."}, {"content": "(INAUDIBLE QUESTION) (CHUCKLING) Good question."}, {"content": "Yes. (INAUDIBLE QUESTION) Yes, the question was:  \"is each pixel 1 number or 3 numbers?\" For majority of computer vision throughout its history used grayscale images so it's 1 number but RGB is 3 numbers and there's sometimes a depth value too, so it's 4 numbers. So it's- If you have a stereo vision camera that gives you the depth information of the pixels, that's a fourth and then if you stack two images together there could be 6. In general, everything we work with will be 3 numbers for a pixel. Yes, so the question:  \"as to the absolute value is just one number?\" Exactly right. So in that case, those are grayscale images. So it's not RGB images. So, you know, this algorithm is pretty good if we use the best. We optimize the hyper-parameters of this algorithm, choose K of 7, seems to work well for this particular CIFAR-10 data set. Okay, we get 30% accuracy. It's impressive, higher than 10%. Human beings perform at about 94, slightly above 94% accuracy for CIFAR-10. So given an image and it's a tiny image. I should clarify it, it's like a little icon. Given that image, human beings are able to determine accurately one of the 10 categories with 94% accuracy. And the currently state-of-the-art convolutional neural networks is ninety five, it's 95.4% accuracy and, believe it or not, it's a heated battle but the most important, the critical fact here, is it's recently surpassed humans. And certainly surpass the k-nearest neighbors algorithm. So,how does this work?"}, {"content": "Let's briefly look back. It all still boils down to this little guy:  the neuron, that sums the weights of its inputs, adds a bias, produces an output based on an activation, a smooth activation function. Yes, question."}, {"content": "(INAUDIBLE QUESTION) The question was:  \"do you take a picture of Cassie, you know it's a cat, but that's not encoded anywhere, like you have to write that down somewhere. So you have to write as a caption:  \"This is my cat.\" And then the unfortunate thing, given the internet and how woody it is, you can't trust the captions on images. because maybe you're just being clever and it's not a cat all, it's a dog dressed as a cat. Yes, question."}, {"content": "(INAUDIBLE QUESTION) Sorry. Seen as do better than what? Yes, so the question was:  \"do convolutional neural networks generally do better than nearest neighbors? There's very few problems on which neural networks don't do better, yes ,they almost always do better except when you have almost no data. So you need data. And convolutional neural networks isn't some special magical thing. It's just neural networks with some cheating up front that I'll explain, some tricks to try to reduce the size and make it capable to deal with images. So again. Yes, the input is, in this case that we looked at classifying an image of a number, as opposed to doing some fancy convolutional tricks. We just take the the entire 28x28 pixel image that's 784 pixels as the input. That's 784 neurons in the input, 15 neurons on the hidden layer and 10 neurons in the output. Now everything we'll talk about has the same exact structure. Nothing fancy. There is a forward pass through the network where you take an input image and produce an output classification and there's a backward pass through the network for Back Propagation where you adjust the weights when your prediction doesn't match the Ground Truth output. And learning just boils down to optimization; it's just optimizing a smooth function. Differentiable function; that's defined as the lost function."}, {"content": "That's usually as simple as a squared error between the true output and the one you actually got."}, {"content": "So what's the difference? What are convolutional neural networks? Convolutional neural networks take inputs that have some spatial consistency, have some meaning to the spatial- Has some spatial meaning in them like images. There's other things, you can think of the dimension of time. And you can input audio signal into a convolutional neural network. And so the input is, usually for every single layer, that's a convolutional layer, the input is a 3D volume and the output is a 3D volume. I'm simplifying because you can call it 4D too but it's 3D. There's height, width and depth. So that's an image. The height and the width is the width and the height of the image. And then the depth for grayscale image is 1; for an RGB image is 3; for a ten-frame video of greyscale images the depth is 10. It's just a volume, a three-dimensional matrix of numbers. And everything- The only thing that a convolutional layer does is take a 3D volume's input, produce a 3D volume as output and has some smooth function. Operating on the inputs, on the sum of the inputs, that may or may not be a parameter that you tune, that you try to optimize."}, {"content": "That's it."}, {"content": "So Lego pieces that you stack together in the same way as we talked about before. So what are the types of layers that a convolutional neural networks have? There's inputs. So for example a color image of 32x32 will be a volume of 32x32x3. A convolutional layer takes advantage of the spatial relationships of the input neurons and a convolutional layer, it's the same exact neuron as for fully connected network, the regular we talked about before. But it has a narrower receptive field, it's more focused, the inputs to a neuron on the convolutional layer come from a specific region from the previous layer. And the parameters on each filter, you can think of this as a filter, because you slide it across the entire image. And those parameters are shared. So supposed you've taken the-  If you think about two layers, as opposed to connecting every single pixel in the first layer to every single neuron in the following layer. You only connect the neurons in the input layer that are close to each other, to the output layer, and then you enforce the weights to be tied together spatially. And what that results in is a filter every single layer on the output, you can think of as a filter, they get excited for example for an edge and when it sees this particular kind of edge in the image, it will get excited. And it'll get excited in the top left of the image, on the top right, bottom left, bottom right. The assumption there is that a powerful feature for detecting a cat is just as important no matter where in the image it is. And this allows you to cut away a huge number of connections between neurons but it still boils down on the right, as a neuron that sums a collection of inputs and applies weights to them. The spatial arrangement of the output volume relative to the input volume is controlled by three things. The number of filters. So for every single \"filter\" you get an extra layer on the output. So if the input, let's talk about the very first layer, the input is 32x32x3. It's in RGB image of 32x32. If the number of filters is 10, then the resulting depth the resulting number of stacked channels in the output will be 10. Stride is given. is the step size of the filter that you slide along the image. Often times as just 1 or 3 and that directly reduces the size, the spatial size the width and the height, of the output image. and then there is a convenient thing that it's often done is padding. The image on the outside zeros. So that the input and the output have the same height and width. So this is a visualization of convolution. I encourage you to, kind of maybe offline, think about what's happening. It's similar to the way human vision works, crudely so, if there's any experts in the audience. So the input here on the left is a collection of numbers:  0, 1, 2. And a filter or there are two filters shown as W1- W0 and W1. Those filters shown in red, are the different weights applied in those filters. And each of the filters have a certain depth; just like the input a depth of 3. So there are three of them in each column and so, so you slide death filter along the image keeping the weights the same. this is the sharing of the weights and so your first filter you pick the weights, this is an optimization problem. you pick the weights in such a way that it fires, it gets excited, for useful features and doesn't fire for not useful features. And then there's a second filter that fires for useful features and not. And produces a signal on the output depending on a positive number, meaning there's a strong feature in that region, and negative number if there isn't but the filter is the same. This allows for a drastic reduction in the parameters and so you can deal with inputs. There are a thousand by thousand pixel image, for example, or video. There's a really powerful concept there. The spatial sharing of weights. That means there's a spatial invariance to the features you're detecting. It allows you to learn from arbitrary images so you don't have to be concerned about pre-processing the images in some clever way, you just give the raw image. There is another operation:  pooling. It's a way to reduce the size of the layers by, for example in this case, it's max pooling for taking a collection of outputs and choose x1 and summarizing those collection of pixels such that the output of the pooling operation is much smaller than the input. Because the justification there is that you don't need a high resolution. Localization of which pixel is important in the image or according to, you know, you don't need to know exactly which pixel is associated with the cat ear or a cat face. As long as you, kind of, know it's around that part and that reduces a lot of complexity in the operations."}, {"content": "Yes, question. The question was:  \"when is too much pooling, when do you stop pooling?\" So pooling is a very crude operation that doesn't have any, one thing you need to know, is it doesn't have any parameters that are learnable. So you can't learn anything clever about pooling. You're just picking, in this case max pool, so you're picking the largest number. So you're reducing the resolution, you're losing a lot of information. There's an argument that you're not, you know, losing that much information as long as you're not pooling the entire image into a single value but you're gaining training efficiency, you're gaining the memory size, reducing the size of the network. So, it's definitely a thing that people debate and it's a parameter that you play with to see what works for you. Okay, so how does this thing look like as a whole, a convolutional neural network, the input is an image there's usually a convolutional layer, there is a pooling operation, another convolutional layer, another pooling operation and so on. At the very end, if the task is classification you have a stack of convolutional layers and pooling layers. There are several fully connected layers. So, you go from those spatial convolutional operations to fully connecting every single neuron in a layer to the following layer. And you do this so that by the end, you have a collection of neurons each one is associated with a particular class. So in what we looked at yesterday is the input, is an image of a number 0 through 9. The output here would be 10  neurons. So you blow down that image with a collection of convolutional layers, with 1 or 2 or 3 fully connected layers at the end that all lead to 10 neurons and each of those neuron's job is to get fired up when it sees a particular number and for the other ones to produce a low probability. And so this kind of process is how you have the 95 percentile accuracy on the CIFAR-10 problem. This here is ImageNet data set that I mentioned. It's how you take this image of a leopard, of a container ship, and produce a probability that that is a container ship or a leopard. Also shown there are the outputs of the other nearest neurons in terms of their confidence. Now you can use the same exact operation by chopping off the fully connected layer at the end and as opposed to mapping from image to a prediction of what's contained in the image, you map from the image to another image. And you can train that image to be one that gets excited spatially, meaning it gives you a high, close to one value, for areas of the image that contain the object of interest and then a low number for areas of the image that are unlikely to contain that image. And so from this you can go on the left, an original image of a woman on a horse, to a segmented image of knowing where the woman is and where the horse is and where the background is. The same process can be done for detecting the object. So you can segment the scene into a bunch of interesting objects, candidates for interesting objects and then go through those candidates one by one and perform the same kind of classification as in the previous step where it's just an input as an image and the output as a classification. And through this process of hopping around an image, you can figure out exactly where is the best way to segment the cow out of the image. That's called object detection. Okay, so how can these magical convolutional neural networks help us in driving? This is a video of the forward road way from a data set that we'll look at, that we've collected from a Tesla. But first let me look at driving. Briefly, the general driving task from the human perspective. On average an American driver in the United States drives 10,000 miles a year. A little more for rural, a little less for urban. There is about 30,000 fatal crashes and >32,000 sometimes as high as 38,000 fatalities a year. This includes car occupants, pedestrians, bicyclists and motorcycle riders. This may be a surprising fact but in a class on self-driving cars we should remember that. So ignore the 59.9%, that's other. The most popular cars in the United States are pickup trucks:  Ford F-1 Series, Chevy Silverado, Ram. It's an important point that we're still married to our, to wanting to be in control and so one of the interesting cars that we look at and the car that is the days that we provide to the class is collected from is a Tesla. It's the one that comes at the intersection of the Ford F-150 and the cute, little Google self-driving car on the right. It's fast, it allows you to have a feeling of control but it can also drive itself for hundreds of miles on the highway, if need be. It allows you to press a button and the car takes over. It's a fascinating trade-off, of transferring control from the human to the car. It's a transfer of trust and it's a chance for us to study the psychology of human beings as they relate to machines at >60 miles an hour. In case you're not aware a little summary of human beings, where distracted things:  would like to text, use the smartphone, watch videos, groom, talk to passengers, eat, drink, texting. 169 billion texts were sent in the US every single month in 2014. On average, 5 seconds our eyes spent off the road while texting -  5 seconds. That's the opportunity for automation to step in. More than that, there's what NHTSA refers to as the 4 D's:  drunk, drugged, distracted and drowsy. Each one of those opportunity is for automation to step in. Drunk driving stands to benefit significantly from automation, perhaps. So the miles, let's look at the miles. The data. There's 3 trillion (3 million million) 3 million million miles driven every year and TESLA autopilot, our case study for this class, and as human beings is driven on full auto-pilot mode. So it's driving by itself 300 million miles as of December 2016 and the fatalities for human control vehicles is 1:90,000,000. It's about >30,000 fatalities a year and currently under TESLA auto-pilot there's one fatality. There's a lot of ways you could tear that statistic apart but it's one to think about. Already, perhaps automation results in safer driving. The thing is, we don't understand automation, because we don't have the data:  we don't have the data on the forward roadway video, we don't have the data on the driver and we just don't have that many cars on the road today that drive themselves. So we need a lot of data. We'll provide some of it to you in the class and as part of our research at MIT were collecting huge amounts of it, of cars driving themselves, and collecting that data is how we get to understanding. So talking about the data and what we'll be doing training our algorithms on, here is a Tesla Model S, Model X we've instrumented 17 of them, have collected over 5,000 hours and 70,000 miles. And I'll talk about the cameras that we've put in them. We're collecting video of the forward road way. This is a highlight of a trip from Boston to Florida of one of the people driving a Tesla. What's also shown in blue is the amount of time that autopilot was engaged:  currently 0 minutes and then it grows and grows. For prolonged periods of time, so hundreds of miles, people engage autopilot. Out of 1.3 billion miles driven a Tesla, 300,000,000 are on autopilot. You do the math whatever that is, 25%. So we are collecting data of the forward roadway, of the driver. We have 2 cameras on the driver. What we're providing with the class is epics of time of the forward roadway, for privacy considerations. Cameras used to record are your regular Webcam, the work horse of the computer vision community. The C920, and we have some special lenses on top of it. Now what's special about these webcams? Nothing that costs $70 can be that good, right? What's special about them is that they do onboard compression and allow you to collect huge amounts of data and use reasonably sized storage capacity to store that data and train your algorithms on. So what on the self-driving side do we have to work with? How do we build a self-driving car? There is these sensors:  radar, lidar, vision, audio - all looking outside helping you detect the objects in the external environment to localize yourself and so on. And there's the sensors facing inside:  visible light camera, audio again, and infrared camera to help detect peoples. So we can decompose the self-driving car task into 4 steps:  localization, answering where am I; scene understanding, using the texture of the information of the scene around, to interpret the identity of the different objects in the scene and the semantic meaning of those objects, of their movement. There's movement planning - once you figured all that out, found all the pedestrians, found all the other cars, how do I navigate through this maze, a clutter of objects in a safe and legal way. And there's driver state, how do I detect using video or other information. The video of the driver detect information about their emotional state or their distraction level. Yes, question. (INAUDIBLE QUESTION) Yes, that's the real-time figure from lidar. Lidars are sensors that provides you the 3D point cloud of the external scene. So lidar is the technology used by most folks working with self-driving cars to give you a strong Ground Truth of the objects. It's probably the best sensor we have for getting 3D information, the least noisy 3D information about the external environment. Question. So autopilot is always changing. One of the most amazing things about this vehicle is that the updates to autopilot come in the form of software. So the amount of time it's available to changes has become more conservative with time. But in this, this one of the earlier versions, and it shows, the second line in yellow, shows how often autopilot was available but not turned on. So the total driving time was 10 hours, autopilot was available 7 hours and was engaged an hour. This particular person is a responsible driver because what you see or is a more cautious driver. What you see is it's raining, autopilot is still available but- (INAUDIBLE QUESTION) the comment was that you shouldn't trust that one fatality number as an indication of safety because the drivers elect to only engage the system when it's safe to do so. It's a totally open, there's a lot bigger arguments for that number than just that one, the question is whether that's a bad thing so maybe we can trust human beings to engage, you know, despite the poorly filmed YouTube videos, despite the hype in the media, you're still a human being. riding 60 miles an hour in a metal box with your life on the line. You won't engage the system unless you know it's completely safe unless you've built up a relationship with it. It's not all the stuff you see where a person gets in the back of a Tesla and start sleeping or is playing chess, or whatever. That's all for YouTube, the reality is when it's just you in the car it's still your life on the line and so you're going to do the responsible thing unless perhaps you're a teenager and so on but that never changes no matter what you're in. Question. (INAUDIBLE QUESTION) The question was:  \"what do you need to see or sense about the external environment to be able to successfully drive? Do you need lane markings? Do you need other-   what are the landmarks based on which you do the localization and navigation?\" And that depends on the sensors. So with the Google self-driving car in sunny California, it depends on lidar in a high-resolution way, map the environment in order to be able to localize itself based on lidar. And lidar, now I don't know the details of exactly where lidar fails, but it's not good with rain, it's not good with snow, it's not good  when the environment is changing. So what snow does is it changes the visual, the appearance, the reflective texture of the surfaces around. Us human beings are still able to figure stuff out but a car that's relying heavily on lidar won't be able to localize itself using the landmarks it previously has detected because they look different now with the snow. Computer vision can help us with lanes or following a car. The two landmarks that we used in a lane is following the car in front of you or staying between two lanes. That's the nice thing about our roadways it's they're designed for human eyes. So you can use computer vision for lanes and for cars in front to follow them. And there is radar. That's a crude but a reliable source of distance information that allows you to not collide with metal objects. So all that together depending on what you want to rely on more gives you a lot of information. The question is when its messy complexity of real life occurs, how reliable it would be in the urban environment and so on. So localization-  How can deep learning help? So first, just a quick summary of visual odometry. It's using a monocular or stereo input of video images to determine your orientation in the world. The orientation, in this case, of a vehicle in the frame of the world and all you have to work with is a video of the forward roadway and with stereo you get a little extra information of how far away different objects are. And so this is where one of our speakers on Friday will talk about his expertise (SLAM) Simultaneous Localization and Mapping. This is a very well-studied and understood problem of detecting unique features in the external scene and localizing yourself based on the trajectory of those unique features. When the number of features is high enough it becomes an optimization problem. You know this particular lane moved a little bit from frame to frame you can track that information. And fuse everything together in order to be able to estimate your trajectory through the three dimensional space. You also have other sensors to help you out. You have GPS which is pretty accurate, not perfect but pretty accurate. It's another signal to help you localize yourself. You also have IMU. Accelerometer tells you your acceleration, from the gyroscope, the accelerometer, you have the six degree of freedom of movement information about how the moving object, the car, is navigating through space. So you can do that using the old school way of optimization. Given a unique set of features, like sift features, and that step involves with stereo input understorting and and rectifying the images. You have two images, from the two images compute the depth map but for every single pixel computing the best estimate of the depth of that pixel, the three dimensional position, relative to the camera then you compute, that's where you compute the disparity map, that's what that's called, from which you get the distance then you detect unique, interesting features in the scene. Sift is a popular one. It's a popular algorithm for detecting unique features and you, over time, track those features. And that tracking is what allows you through the vision alone to get information about your trajectory through three-dimensional space. You estimate that trajectory. There's a lot of assumptions, assumptions that bodies are rigid. So you have to figure out if a large object passes right in front of you, you have to figure out what that was. You have to figure out mobile objects in the scene. And those are the stationary. Or you can cheat or we'll talk about and do it using neural networks end-to-end. Now what does end-to-end mean? And this will come up a bunch of times throughout this class and today. End-to-end means, and I refer to it as cheating because it takes away a lot of the hard work of panageneric features. You take the raw input of whatever sensors. In this case, it's taking stereo input from a stereo vision cameras so two images, a sequence of two images coming from a stereo vision camera, and the output is a estimate of your trajectory through space. So it's supposed to be doing the hard work of SLAM, of detecting unique features, of localizing yourself, of tracking those features and figuring out where your trajectory is. You simply train the network. With some Ground Truth, you have form a more accurate sensor like lidar, and you train it on a set of inputs, the stereo vision inputs, and outputs is the trajectory through space. You have a separate convolutional neural networks for the velocity and for the orientation. And this works pretty well."}, {"content": "Unfortunately, not quite well and John Leonard will talk about that. SLAM is one of the places were deep learning is not being able to outperform the previous approaches. Where deep learning really helps is the scene understanding part. It's interpreting the objects in the scene. It's detecting the various parts of the scene, segmenting them and with optical flow determining their movement. So previous approaches for detecting objects like the traffic signal, the classification of detection that we have the TensorFlow tutorial for or to use car-like features or other types of features that are hard-engineered from the images. Now we can use convolutional neural networks to replace the extraction of those features. And there's TensorFlow implementation of SegNet which is taking the exact same neural network that I talked about. It's the same thing, the beauty is you just apply similar types of networks to different problems and depending on the complexity of the problem, can get quite amazing performance. In this case, we convolutionize network, meaning the output is an image, input is an image, a single monocular image. The output is a segmented image where the colors indicate your best pixel-by-pixel estimate of what object is in that part. This is not using any spatial information, it's not using any temporal information. So it's processing every single frame separately and it's able to separate the road from the trees, from the pedestrians, other cars, and so on. This is intended to lie on top of a radar / lidar type of technology that's giving you the three dimensional or stereo vision three-dimensional information about the scene. You're, sort of, painting that scene with the identity of the objects that are in it, your best estimate of it. This is something I'll talk about tomorrow is recurring neural networks and we can use recurring neural networks that work with temporal data to process video and also process audio. In this case, we can process what's shown on the bottom is  a spectrogram of audio for a wet road and a dry road. You can look at that spectrogram as an image and process it in a temporal way using recurring neural networks. Just slide it across and keep feeding it to a network. And it does incredibly well on the simple tasks, certainly of dry road versus wet road. This is important, a subtle, but very important task and there's many like it to know the road, the texture, the quality., the characteristics of the road, wetness being a critical one. When it's not raining but the road is still wet, that information is very important. Okay, so for movement planning."}, {"content": "The same kind of approach. On the right is work from one of our other speakers Sertec Karaman. The same approach we're using to solve traffic through friendly competition is the same that we can use for what Chris Gerdes does with his race cars for planning trajectories in high speed movement along complex curve. So we can solve that problem using optimization, solve the control problem using optimization, or we can use it with reinforcement learning by running tens of millions, hundreds of millions of times through that simulation of taking that curve and learning which trajectory doesn't both optimizes the speed at which you take the turn and the safety of the vehicle. Exactly the same thing that you're using for traffic."}, {"content": "And for driver state, this is what will talk about next week. It's all the fun face stuff:  eyes, face, emotion. This is with video of the driver, video of the driver's body, video the driver's face. On the left is one of the TAs in his younger days. Still looks the same."}, {"content": "There he is. So in that particular case, you're doing one of the easier problems which is one of detecting where the head and the eyes are positioned. The head and eye pose. You know it determine what's called he gaze of the driver, where the driver's looking, glance. And so, we'll talk about these problems. From the left to the right:  on the left in green are the easier problems; on the red are the harder from the computer vision aspect. So on the left is body pose, head pose. The larger the object the easier it is the detect and the orientation of it is easier to detect. And then there is pupil diameter. Detecting the pupil, the characteristics, the position, the size of the pupil. And there's micro saccade, things that happen at one millisecond frequency, the tremors of the eye. All important information to determine the state of the driver. Some are possible computer vision, some are not. This is something that we'll talk about, I think, on Thursday. Is the detection of where the driver's looking. So, this is a bunch of the cameras that we have in the Tesla. This is This is Dan driving a Tesla and detecting exactly where of one of six regions We've converted into a classification problem of left, right, rear view mirror instrument cluster center stack or forward roadway. So we have to determine out of those six categories which direction is the driver looking at. This is important for driving. We don't care exactly the X, Y, Z position of where the driver is looking at. We care that they're looking at the road or not. Are they looking at their cell phone in their lap or are they looking at the forward roadway? And we'll be able to answer that pretty effectively using convolutional neural networks. You can also look at emotion using CNNs to extract, again converting emotion, the complex world of emotion, into a binary problem of frustrated versus satisfied. This is the video of drivers interacting with a voice navigation system. If you've ever used one, you know that may be a source of frustration from folks. And so this is self reported, this is one of the hard, you know, driver emotion if you're in what's called \"Effective Computing.\"  It's the field of studying emotion from the computational side. If you work in that field, you know that the annotation side of emotion is really challenging one. So getting the Ground Truth of, well okay since this guy's smiling so can I label that as happy or he's frowning because that mean he's sad. Most effective computing folks do just that. In this case we self report ask people how frustrated they're were in a scale of 1 to 10. Dan up top reported a \"1\" for not frustrated, he's satisfied with the interaction, and the other driver reported as a \"9\" he was very frustrated with the interaction. And what you notice is there is a very cold, stoic look on Dan's face which is an indication of happiness. And in the case of frustration, the driver is smiling. So this is a sort of a good reminder that we can't trust our own human instincts. It's an engineering feature. Engineering the ground truth. We have to trust the data, trust the Ground Truth that we believe is the closest reflection of the actual semantics of what's going on in the scene. Okay, so end-to-end driving. Getting to the the project and the tutorial. So if driving is like a conversation and, thank you for someone to clarifying, that this is the Arch of Triumph in Paris in this video. If driving is like a natural language conversation, then we can think of end-to-end driving as skipping the entire Turing Test components and treating it as an end-to-end natural language generation. So what we do is we take as input the external sensors and output, the control of the vehicle. And the magic happens in the middle. We replace that entire step with a neural network. TAs told me to not include this image because it's the cheesiest we've ever seen."}, {"content": "I apologize."}, {"content": "Thank you, thank you."}, {"content": "I regret nothing. So this is to show our path to self-driving cars but it still explain a point that we have a large data set of Ground Truth. If we were to formulate the driving task to simply taking external images and producing steering commands, acceleration of braking commands, then we have a lot of Ground Truth. We have a large number of drivers on the road every day driving and, therefore, collecting our Ground Truth for us because they're an interested party in producing the steering commands that keep them alive and, therefore, if we were to record that data it becomes Ground Truth. So if it's possible to learn this, what we can do is we can collect data for the manually controlled vehicles and use that data to train an algorithm to control a self-driving vehicle. Okay, so one of the first folks who did this is Nvidia where they actually train in an external image, the image of the forward roadway. and a neural network, a convolutional network, a simple vanilla convolutional neural network I'll briefly outline: take an image in, produce a steering command out and they're able to successfully, to some degree, learn to navigate basic turns, curves and even stop or make sharp turns at a keener section. So this this now work is simple."}, {"content": "There is input on the bottom, output up top. The input is a 66x200 pixel image, RGB. Shown on the left is the raw input and then you crop it a little bit and resize it down 66x200. That's what we have in the code as well in the two versions of the code we'll provide to you. Both that runs in the browser and in TensorFlow. It has a few layers. A few convolutional layers, a few fully connected layers. And an output. This is a regression network. It's producing not a classification of cat versus dog, it's producing a steering command. How do I turn the steering wheel? That's it. The rest is magic and we train it on a human input. What we have here is a project, is an implementation of the system in ConvNetJS that runs in your browser. This is the tutorial to follow and the project to take on. So unlike the DeepTraffic game, this is reality. This is a real input from real vehicles. So you can go to this link."}, {"content": "Demo went wonderfully yesterday so let's see, maybe two for two. There's the tutorial and then the actual game, the actual simulation is on DeepTesla.JS, I apologize. Everyone is going there now, aren't they? Does it work on a phone? It does, great. Again similar structure up top is the visualization of the lost function as the network is learning and it's always training. Next is the input for the layout of the network, there's the specification of the input 200x66. There's a convolutional layer. There's a pooling layer and the output is a regression layer. A single neuron. This is a tiny version, DeepTiny, right? It's a tiny version of the Nvidia architecture and then you can visualize the operation of this network on real video. The actual wheel value that produced by the driver, by the autopilot system, is in blue and the output of the network is in white. And what's indicated by green is the cropping of the image that is then resized to produce the 66x200 input to the network. So once again, amazingly, this is running in your browser, training on real world video. So you can get in your car today input it and maybe teach a neural network to drive like you. We have the code in ConvNetJS and TensorFlow to do that and the tutorial. Well, let me briefly describe some of the work here. So the input to the network as a single image. This is for DeepTesla.JS, single image and the output is a steering wheel value between -20 and 20. That's in degrees. We record, like I said, thousands of hours but we provide publicly 10 video clips of highway driving from a Tesla. Half are driven by autopilot, half are driven by human. The wheel values extracted from a perfectly synchronized CAN, we are collecting all of the messages from CAN, which contains steering wheel value and that's synchronized to the video. We crop, extract the window."}, {"content": "The green one I mentioned."}, {"content": "And then provide that as input to the network. So this is a slight difference from DeepTraffic with the red car weaving through traffic because there is the messy reality of real world lighting conditions. And your task for the most part, in this simple steering task, is to stay inside the lane, inside the lane markings. In an end-to-end way, learn to do just that. So ConvNetJS is a javascript implementation of CNNs, of convolutional neural networks. It supports really arbitrary networks. I mean all neural networks are simple but because it runs in javascript it's not utilizing GPU. The larger the network the more it's going to be weighed down computationally. Now unlike DeepTraffic, this isn't a competition but if you are a student registered for the course you still do have to submit the code, you still have to submit your own car as part of the class. Question. So the question was the amount of data that's needed. Is there a general rules of thumb for the amount of data needed for a particular task in driving for example? It's a good question. You generally have to, like I said, neural networks are good memorizers so you have to just have every case represented in the training said that you're interested in. As much as possible, so that means, in general if you want a picture, if you want to classify the difference between cats and dogs, you want to have at least a thousand cats and a thousand dogs and they do really well. The problem with driving is twofold:  one, is that most of the time driving looks the same. And the stuff you really care about is when driving looks different. It's all the edge cases. So we're not good with neural networks is generalizing from the common case to the edge cases, to the outliers. So avoiding a crash just because you can stand the highway for thousands of hours successfully doesn't mean you can avoid a crash with somebody runs in front of you on the road and the other part with driving is the accuracy you have to achieve is really high. So for cat versus dog, No, life doesn't depend on your error. On your ability to steer a car inside of the lane."}, {"content": "You better be very close to 100% accurate. There's a box for designing the network. There's a visualization of the metrics measuring the performance of the network as it trains. There is a visualization, layer visualization, of what features the network is extracting at every convolutional layer and every fully connected layer. There is ability to restart the training. Visualize the network performing on real video. There is the input layer, the convolutional layers. The video visualization, an interesting tidbit on the bottom right is a barcode that Will has ingeniously designed. How do I clearly explain why this is so cool? It's a way to through video synchronized multiple streams of data together, so it's very easy for those who have worked with multi-modal data where there are several streams of data for them to become unsynchronized especially when a big component of training a neural network is shuffling the data. So you have to shuffle the data in clever ways so you're not overfitting any one little aspect of the video and yet maintain the data perfectly synchronized. So what he did instead doing the hard work of connecting the steering wheel and in the video is actually putting the steering on top of the video as a barcode. The final result is you can watch the network operate and over time it learns more and more to steer correctly. I'll fly through this a little bit in the interest of time just kind of summarize some of the things that you can play with in terms of tutorials and let you guys go. This is the same kind of process end-to-end driving with So we have code available on GetHub. You just put up on my GetHub and the DeepTesla. That takes in a single video or an arbitrary number of videos trains on them and produces a visualization that compares the steering wheel, the actual steering wheel and the predicted steering wheel. The steering wheel, when it agrees with the human driver or the autopilot system lighting up as green and when it disagrees, lighting up as red. Hopefully not too often."}, {"content": "Again, this is some of the details of how that's exactly done in TensorFlow. This is vanilla convolution neural networks. Specifying a bunch of layers, convolutional layers, a fully connected layer, train the model, so you iterate over the batches of images. Run the model over a test set of images and get this result. We have a tutorial on iPython Notebook into the tutorial up on this. This is perhaps the best way to get started with convolutional neural networks in terms of our class. It's looking at the simplest image classification problem, of traffic light classification. So we have these images of traffic lights. We did the hard work of detecting them for you. So now you have to figure out, you have to build the convolutional network that gets figures out the concept of color and gets excited when it sees red, yellow or green. If anyone has questions, I'll welcome those."}, {"content": "You can stay after class if you have any concerns with Docker, with TensorFlow, with how to win DeepTraffic. Just stay after class or come by Friday, 5 to 7. See you guys tomorrow."}], "MIT 6.S094: Recurrent Neural Networks for Steering Through Time": [{"content": "All right. So, we have talked about regular neural networks, fully connected neural networks, we have talked about\nconvolutional neural networks that work with images, we have talked about Reinforcement, Deeper Reinforcement Learning, where we plug in a neural network into a Reinforcement\nLearning Algorithm, when a system has to not only perceive the world but also act in it, and collect a reward. And today we will talk about, perhaps the least understood but the most exciting neural network out there, flavor of neural networks,\nis Recurrent Neural Networks. But first, for administrative stuff, there\u2019s a website. I don\u2019t know if you heard, cars.mit.edu, where you should create an account,\nif you\u2019re a registered student, that\u2019s one of the requirements. You need to have an account if you want to get credit for this, you need to submit code for DeepTrafficJS,\nand DeepTeslaJS, and for DeepTraffic, you have to have a neural network\nthat drives faster than 65mph. If you need help to achieve that speed please e-mail us. We can give you some hints. For those of you who are\nold school SNL fans, there\u2019s the Deep Thoughts\nsection now, in the profile page, where we encourage you to talk about the kinds of things that\nyou tried in DeepTraffic or any of the other DeepTesla or\nany of the work you've done as part of this class\nfor DeepLearning. Okay, we have talked about the Vanilla Neural Networks\non the left. The Vanilla Neural Network is the one where it's computing is approximating a function that maps\nfrom one input to one output. An example is mapping images to the number that is shown\nin the image. For ImageNet is mapping an image to what's the object in the image. It can be anything. In fact, Convolutional Neural Networks\ncan operate on audio, you can give it a chunk of audio,\na five second audio clip, that still counts as one input because it\u2019s fixed-size. As long as the size of the input is fixed, that's one chunk of input and as long as you have ground truth that maps that chunk of input\nto some output ground truth, that\u2019s the Vanilla Neural Network. Whether there's a fully connected\nneural network or convolutional neural network. Today we\u2019ll talk about the amazing, the mysterious Recurrent\nNeural Networks. They compute functions from one to many, from many to one, from many to many."}, {"content": "Also bidirectional. What does that mean? They take its input sequences, time series, audio, video, whenever there's a sequence of data, and that temporal dynamics that connects the data is more important than the spatial content of each individual frame. So, whenever there's\na lot of information being conveyed in a sequence, in a temporal change of whatever that type of data is, that's when you want to use\nRecurrent Neural Networks like speech, natural language, audio and the power of this is that for many of them, for a Recurrent Neural Network, where they really shine, is when the size of the input\nis variable, so you don\u2019t have a fixed chunk of data that you're putting in\nis variable input. And the same goes\nfor the output, so you can give it\na sequence of speech, several seconds of speech and then the output is a single label of whether\nthe speaker is male or female. That\u2019s many to one. You can also do many to many. Translation. You can have natural language put into the network in Spanish and the output is in English. Machine translation. That's many to many. And that many to many\ndoesn't have to be mapped directly into same sized sequences. For video, the sequence size\nmight be the same you're labeling every single frame,\nyou put in a five second clip of somebody playing basketball and you can label\nevery single frame counting the number of people\nin every single frame. That's many to many when the size of the input and\nthe size of the output is the same Yes, question? The question was, are there are any models where there's\nfeedback from output and input? That's exactly what\nRecurrent Neural Networks are. It produces output, and it copies that output and loops it back in. That's almost the definition of\na Recurrent Neural Network. There's a loop in there\nthat produces the output and also takes that output\nas input once again. There's also many to many\nwhere the sequences don't align. Like machine translation, the size of the output sequence might be  totally different\nthan the input sequence. We will look on a lot\nof cool applications; you can start a song, learn the audio of\na particular song have the Recurrent Neural Network to continue that song after\na certain period of time. So it can learn to generate sequences of audio, of natural language, of video. Okay. I know I promised not many equations, but this is so beautifully simple that we have to cover\nbackpropagation. It's also the thing that, if you're a little bit lazy and you go to the internet and start using\nthe basic tutorials of TensorFlow, you ignore how backpropagation work. At you peril."}, {"content": "You kind of assume it just works. I give it some inputs, some outputs, and it's like Lego pieces\nI can assemble them like you might have done\nwith DeepTraffic A bunch of layers put in together and then just press Train. backpropagation is the mechanism that neural networks currently-- The best mechanism we know of\nthat is used for training. So you need to understand the simple power of backpropagation, but also the dangers. Summary, I put on the top of the slide,\nthere's an input for the network that's an image, there's a bunch of neurons, all with differentiable smooth activation functions\non each neuron, and then, as you pass through those\nactivation functions, take in an input, pass it through this net of differentiable\ncompute nodes, you produce an output. In that output you also have a ground truth, the correct, the truth that you hope or you expect the network to produce. And you can look at\nthe differences between what the network actually produced and what you hoped it would produce, and that's an error. And then you backward\npropagate that error, punishing or rewarding the parameters of the network that resulted in that output Let's start with a really\nsimple example. There's a function that takes its input up on top, three variables, X, Y and Z."}, {"content": "The function does two things: it adds X and Y and then it multiplies that sum by Z. And then we can formulate\nthat as a circuit, circuit of gates, where there's a Plus gate, and a Multiplication gate. Let's take some inputs, shown in blue. Let's say it's X is negative two, Y is five and Z\nis negative four. And let's do a forward pass through the circuit to produce the output. Negative two plus five\nequals three q is that intermediate value, three. This is so simple, and so important to understand that I just want to take my time for this because everything else about neural\nnetworks just builds on these concepts The add gate produces q, in this case, is three, and three times negative\nfour is twelve. That's the output. The output of the circuit\nof this network, if you think of it as such, is negative twelve. The forward pass is shown in blue the backward pass\nwill be shown in red in a second here What we want to do, what would make us happy, what would make f happy is for the output to be\nas high possible. Negative twelve,\nso-so, it could be better. How do we teach it How do we adjust X, Y and Z, to ensure it produces a higher f makes f happier. Let's start backward, The backward pass. We'll make the gradient\non the output one, meaning we want this to increase. We want f to increase. That's how we\u00a0encode our happiness. We want it to go up by one. In order to then propagate that fact that we want the f to go up by one, we have to look at the gradient on each one of the gates. And what's a gradient? It's a partial derivative with respect to its inputs. The partial derivative of\nthe output of the gate with respect to its inputs, if you don't know what that means, is just how much does the output change when I change the inputs a little bit. What is the slope of that change\nif I increase X for the first function of addition, f of X, Y equals X plus Y. If I increase X by a little bit, what happens to f? If I increase Y by a little bit,\nwhat happens to f? Taking a partial derivative of those with respect to X and Y you just get a slope of one When you increase X, f increases linearly. Same with Y. Multiplication is a little trickier. When you increase X, f increases by Y. Do the partial derivative of f\nwith respect to X is Y, the partial derivative of f\nwith respect to Y is X. If you think about it,\nwhat happens is the gradients, when you change X, the gradient of change doesn't care about X. It cares about Y."}, {"content": "It's flipped. So we can backpropagate that one, the indication of what\nmakes X happy backward. And that's done by computing the local gradient. For q, the partial derivative\nof f with respect to q, that intermediate value, that gradient would be negative four. It will take the value of Z as I said it's the Multiplication gate, It'll\u00a0take the value of Z and assign it to the gradient. And the same for the partial derivative of f\nwith respect to Z, it will assign that to q. The value of the forward pass on the q. There's a three and a negative four\non the forward pass in blue and that's flipped. Negative four and three on the backward pass. That's the gradient. And then we continue in\nthe same exact process. But wait. What makes all of this work, is the Chain Rule. It's magical. What it allows us to do is to compute the gradient, the gradien of f with respect to\nthe inputs X, Y, Z. We don't need to construct the giant function that is the partial derivative of f\nwith respect to X, Y and Z analytically. We can do it step by step backpropagating the gradients. We can multiply\nthe gradients together as opposed to doing\nthe partial derivative of f with respect to X. We have just the intermediate, the local gradient of f with respect to q,\nand of q with respect to X, and multiply them together. So, Instead of computing gradient of that giant function X plus Y times Z, in this case is not that giant, but it gets pretty giant\nwith neural networks, we just go step by step. Look at the first function, simple addition, q equals X plus Y, and the second function,\nmultiplication, f equals q times Z. The gradient on X and Y, the partial derivative of f with respect to X and Y is computed by multiplying the gradient on the output,\nnegative four, times the gradient on the inputs, which as we talked about, when the operation is addition, that's just one. It's negative four times one. What does that mean?"}, {"content": "Let's interpret those numbers. You now have gradients on X, Y and Z the partial derivatives of F\nwith respect to X, Y, Z. That means, for X and Y is negative four,\nfor Z is three. That means, in order to\nmake f happy, we have to decrease the inputs that have\na negative gradient and increase the inputs that\nhave a positive gradient. The negatives ones are X and Y, the positive is Z."}, {"content": "Hopefully, I don't say the word \u201cBeautiful\u201d too many\ntimes in this presentation this is very simple."}, {"content": "Beautifully simple. Because this gradient\nis a local worker, it propagates for you; it has no knowledge of the broader happiness of f. It computes the greater between\nthe output and the input. And it can propagate this gradient based on, in this case f, a gradient of one but also the error. Instead of one we can have on\nthe output the error as the measure of happiness. And then we can propagate\nthat error backwards. These gates are important\nbecause we can break down almost every operation\nwe can think of that we work within neural networks into one or several gates like these. The most popular are three, which is addition, multiplication and the Max operation. For addition, the process is you take a forward pass\nthrough the network, so we have a value on every single gate, and then you take the backward pass. And through the backward pass\nyou compute those gradients. For an add gate, you equally distribute the gradients on the output to the input, when the gradient on the output\nis negative four, you equally distribute it tonegative four. And you ignore the forward pass value. That three is ignored\nwhen you backpropagate it. On the Multiply gate, it's trickier. You switch the forward pass values, if you look at f, that's a\nMultiply gate, the forward pass values are switched and multiplied by the value of\nthe gradient in the output. If it's confusing, go through\nthe slides slowly. It'll make a lot more sense."}, {"content": "Hopefully. One more gate. There's the Max gate, which takes the inputs and produces as output the value that is larger. When computing the gradient\nof the Max gate, it distributes the gradient similarly to the Add gate, but to only one,\nto only one  of the inputs; the largest one. unlike the Add gate,\npays attention to the input the input values on\nthe forward pass. All right. Lots of numbers but\nthe whole point here is, it's really simple; a neural network is just\na simple collection of these gates. You take a forward pass, you calculate some kind of function in the end, the gradient in the very end, and you propagate that back. Usually, for neural networks,\nthat's an Error function. A Loss function, Objective function, a Cost function. All the same word. That's the Sigmoid function there When you have three weights W zero, W one, W two and X, two inputs, X0, X1, that's going to be\nthe Sigmoid function. That's how you compute the output of the neuron. But then you can decompose\nthat neuron you can separate it all into just a set of gates like this Addition, multiplication, there's an exponential in there\nand division but all very similar. And you repeat the exact same process. there's five inputs, there's three weights and two inputs. X zero, X one. You take a forward pass\nthrough this circuit, in this case again, you want it to increase so that\nthe gradient of the output is one and you backpropagate that gradient of one,\u00a0to the inputs. Now in neural networks, there's a bunch of parameters that you're trying through\nthis process, modify. And you don't get to modify the inputs You get to modify the weights\nalong the way, and the biases. The inputs are fixed, the outputs are fixed, the outputs that you hope the network will produce. What you're modifying is the weights. So I get to try to adjust those weights in the direction of the gradient. That's the task of backpropagation. The main way that\nneural networks learn. As we update the weights\nand the biases to decrease the loss function. The lower the loss function the better. In this case, you have three inputs on the top left. A simple network, three inputs. Three weights on each of the inputs. There's a bias on the node, b and produces an output a, and that little symbol is indicating\na Sigmoid function. And the loss is computed as Y minus\nA squared, divided by two, where Y is the ground truth, the output that you want\nthe network to produce. And that loss function\nis backpropagating in exactly the same way that\nwe described before. The subtasks involved in this update of\nweights and biases is that the forward pass computes the network output at every neuron, and finally, the output layer, computes the error,\nthe difference between a and b, and then backward propagates\nthe gradients. Instead of one on the output, it will be the error on the output\nand you backpropagated. And then, once you know the gradient, you adjust the weights\nand the biases in the direction of the gradient. Actually, the opposite of the\ndirection of the gradient, because you want the loss to decrease. And the amount by which\nyou make that adjustment is called the Learning Rate. The learning rate can be\nthe same across the entire network or can be individual\nthrough every weight. And the process of adjusting the weights and biases is just optimization. Learning is an Optimization problem. You have an objective function,\nand you're trying to minimize it. And your variables are the parameters,\nthe weights and biases. Neural networks just happen to have tens, hundreds of thousands, millions of those parameters. So the function that you're trying\nto minimize is highly non-linear. But it boils down to\nsomething like this, you have two weights, two plots--\nor actually one weight and as you adjust it, the cost you adjust in such a way that\nminimizes the output cost. And there's a bunch of\noptimization methods for doing this. this is a convex function, You can find the local minimum. If you know about these\nkinds of terminologies, the local minimum is the same\nas the global minimum, it's not a weirdly hilly terrain where you can get stuck in. Your goal is to get to\nthe bottom of this thing and if it's really complex terrain, it will be hard to get\nto the bottom of it. This general approach\nis gradient descent, and there's a lot of different ways to\ndo a gradient descent. Various ways of adding\nrandomness into the process, so you don't get stuck into the weird crevices of the terrain. But it's messy."}, {"content": "You have to be really careful. This is the part you have\nto be aware of, when you design a network\nfor DeepTraffic and nothing is happening this might be what's happening: vanishing gradients or exploding gradients. When the partial derivatives are small, so you take\nthe Sigmoid function, the most popular for a while, activation function, the derivative is zero at the tails. When the input to the Sigmoid functions is\nreally high or really low, that derivative is going to be zero. Gradient tells on how much\nI want to adjust the weights. The gradient might be zero, and so you backpropagate that zero, a very low number, and it gets less and less as you backpropagate and so the result is that you think you don't need to\nadjust the weights at all. And when a large fraction\nof the network weights don't need to be adjusted, they don't adjust the weights. And you are not doing any learning So the learning is slow. There are some fixes to this, there are different types\nof functions. There's a piece, the ReLUs function which is the most\npopular activation function. But again, if the neurons are initialized poorly, this function might not fire. it might be zero gradient for the entire data set. Nothing that you produce as input, you run all your thousands\nof images of cats, and none of them fire at all. That's the danger here. So you have to pick both the optimization engine, the solver that you use and the activation functions\ncarefully. You can't just plug and play\nlike they're Lego's You have to be aware of the function. SGD, Stochastic Gradient Descent, that's the Vanilla\noptimization algorithm for gradient descent. For optimizing the loss function\nover the gradients And what's visualized here is, again, if you have done\nany numerical optimization, and non-linear optimization, there's the famous saddle point, that's tricky for these\nalgorithms to deal with. What happens is, it's easy\nfor them to oscillate, get stuck in that saddle and\noscillating back and forth as opposed to what they\nwant to do which is go down into-- You get so happy that you found this low point that you forget there's\na much lower point. So you get stuck with the gradient. The momentum of the gradient keeps rocking it back and forth\nwithout you going to a much greater global minimum. And there's a lot of clever\nways to solving that, the Atom optimizer is one of those. But in this case, as long as\nthe gradients don't vanish SGD, the Stochastic Gradient Descent, one of these algorithms\nwill get you there It might take a little while,\nbut it will get you there Yes, question. The question was, you're dealing with a function\nthat is not convex, how do we ensure anything about converging to anything that's reasonably good, the local optimum converges to-- The answer is, you can't. This isn't only a non-linear function it's a highly non-function The power and the beauty\nof neural networks is that it can represent these arbitrarily complex functions. It's incredible. And it can learn these\nfunctions from data But the reason people are referring to\nneural networks training as art is you're trying to play\nwith parameters that don't get stuck in\nthese local optimal. For stupid reasons\nand for clever reasons."}, {"content": "Yes, question."}, {"content": "The Question continues\non the same thread. The thing is, we're dealing\nwith functions where we don't know what\nthe global optimal is. That's the crocs of it. Everything we talked about, interpreting text, interpreting video, even driving. What's the optimal for driving?"}, {"content": "Never crashing? It sounds easy to say that, you actually have to\nformulate the world under which it defines all of those\nthings and it becomes a really non-linear objective function for which you don't know what the optimal is. That's why you keep trying and get impressed\nevery time it gets better. It is essentially the process. And you can also compare, you can compare with\nhuman-level performance. For ImageNet, who can tell the difference\nbetween cats and dogs, and top five categories, 96% of the time accuracy, and then you get impressed when a machine can do better than that. But you don't know\nwhat the best is. These videos can be watched for hours, I won't play it until I\nexplain this slide. Let's pause to reflect\non backpropagation before I go on to Recurrent\nNeural Networks. Yes, question. In this practical manner,\nhow can you tell when you're actually creating a net\nwhether you're facing the management\ngradient problem or you need to change your optimizer or you've reached a local minimum? The question was, how do you practically know when you hit the vanishing\ngradient problem? The vanishing gradient could be-- The derivative being zero\non the gradient, happens when the activation\nis exploding, like really high values and really low values. To really high values is easy."}, {"content": "Your network has just gone crazy. It produces very large values. And you can fix a lot of those things\nby just capping the activations. The values being really low, resulting in a vanishing gradient,\nare really hard to detect There's a lot of research in\ntrying to figure out how to detect these things. If you're not careful, often times you can find that, and this isn't hard to do, we're like 40 or 50 percent\nof the network, of the neurons, are dead. We will call it, for ReLU, they're dead ReLU They're not firing at all. How do you detect that? That's part of learning If they never fire you can detect that by running it through\nthe entire training set. There are a lot of tricks."}, {"content": "But that's the problem. You try to learn and then you look at the loss function and it's not converging to anything reasonable. They are going all over the place,\nor just converging very slowly. And that's an indication that\nsomething is wrong That something could be\nthe loss function is bad, that something could be\nyou already found the optimal, or that something could be\nthe vanishing gradient. And again, that's why it's an art. Certainly, at least some fraction of the neurons\nneeds to be firing. Otherwise, initialization is\nreally poorly done. Okay, to reflect on the simplicity of backpropagation and the power of it, this kind of step of backpropagating the loss function\nto the gradients locally, is the way neural networks learn. It's really the only way that we have effectively been able to to train a neural network network to learn a function. To adjusting the weights and biases, the huge number of weights and biases,\nthe parameters It's just through this optimization. It's backpropagating the error, where you have\nthe supervised ground truth. the question is whether this process, of fitting, adjusting the parameters of a highly non-linear function\nto minimize a single objective, is the way you achieve intelligence. Human-level intelligence. That's something to think about. You have to think about,\nfor driving purposes, what is the limitation\nof this approach? What's not happening? The neural network designed,\nthe architecture is not being adjusted. any of the edges, the layers,\nnothing is being evolved There are other\noptimization approaches that I think are more interesting and inspiring\nthan effective. For example, this is using soft cubes to-- This is falling out of the field of evolutionary robotics. Where you evolve the dynamics of a robot using genetic algorithms and that's These robots have been taught to, in simulation, obviously, to walk and to swim. That one is swimming. The nice thing here is that dynamics that highly non- linear space as well, that controls the dynamics of\nthis weird shaped robot with a lot of degrees of freedom, it's the same kind of thing\nas the\u00a0neural network. In fact, people have applied\ngeneric algorithms, ant colony optimization, all kinds of\nsort of nature inspire algorithms for automatizing the weights\nand the biases but they don't seem to\ncurrently work that well. It's a cool idea to\u00a0be using nature-type evolutionary\nalgorithms to evolve something that's already nature\ninspired which is neural networks. But, something to think about the backpropagation,\nwhile really simple it's kind of dumb and\nthe question is whether general intelligence reasoning\ncan be achieved with this process. All right, Recurrent Neural Networks, on the left there's an input X with weights on the input, U, there's a hidden state, hidden layer S, with weights on the edge connecting the hidden states to each other and then more weights,\nV, the on the output O. It's a really simple network,\nthere's inputs, there's hidden states, the memory of this network and there's outputs. But the fact that there's this loop where the hidden states are\nconnected to each other means that as opposed to\nproducing a single input, the network takes arbitrary\nnumbers of inputs, it just keeps taking X, one at a time and produces a sequence of Xs through time. Depending on the duration of the sequence\nyou're interested in, you can think of this network in its unrolled state. You can unroll this neural network where the inputs are in the bottom,\nXt-1, Xt, Xt+1, and same with the outputs, Ot-1, Ot, Ot+1, and it becomes like\na regular neural network, unrolled some\narbitrary number of times. The parameters, again, there's weights, there's\u00a0biases, similar to CNNs, convolutional neural networks and just like convolutional\nneural networks make certain spatial\nconsistency assumptions, the recurrent neural network assume temporal consistency\namongst the parameters, shares the parameters. That W, that U, that V, is the same for every single time step. You're learning the same parameter, no matter the duration\nof the sequence and that allows you to look at arbitrary\nlong sequences without having an\nexplosion of parameters. This process is the same exact\nprocess that's repeated base on the different variants\nthat we talk about before, in terms of inputs and outputs, one to many, many to one,\nmany to many. The backpropagation process is exactly the same as\nfor regular neural networks. It's a fancy name of\nbackpropagation through time, BPTT, but it's just backpropagation\nthrough an unrolled recurrent neural network, where the errors are on\nthe computed on the outputs, the gradients are computed, backpropagated and computed on the inputs, again, suffering for\nthe same exact problem of vanishing gradients. The problem is that the depth of these networks\ncan be arbitrary long if at any point the gradients hits a lower number, zero, becomes, that neural becomes saturated. That gradient, let's call it saturated, that gradient gets-- drives all the earlier layer to zero, so is easy to run to a problem where you're really ignoring\nthe majority of the sequence. This is just another\u00a0Python weight, sudo-called weight to look at it. Is you have the same w, remember you're sharing the weights and all the parameters\nfrom time to time, so if the weights are such WHH, if the weights are such\nthat they produce [unintelligible] they have a negative value\nthat results in the gradient that goes to zero, that propagates through the rest. That's the sudo-call for backpropagation, pass to the RNN, that WHH propagates back. You get this things with exploding and\nvanishing gradients for example, error surfaces for\na single hidden unit RNN, this is visualizing the gradient, the value of the weight,\nthe value of the bias and the error, the error could be really flat\nor could explode, both are going to lead to you not making-- either making steps that\nare too gradual or too big. It's the geometric interpretation."}, {"content": "Okay."}, {"content": "What other variants that\nwe look at, a little bit?"}, {"content": "are they [unintelligible 00:41:13]? It doesn't have to be only one way, it can be bi-directional, that could be edges going forward\nand edges going back What that's needed for is things like filling in missing,\nwhatever the data is, filling in missing elements of that data, whether that's images, or words,\nor audio. Generally, as always is the case\nin neural network, the deeper it goes, the better. That deep referring to\nthe number of layers in a single temporal instance. On the right of the slide we're stacking node in the temporal domain. Each of those layers\nhas its own set of weights, its own set of biases. These things are awesome but they need a lot of data when you add extra layers in this way. The problem is, while\nrecurrent neural network, in theory, is supposed to be able to learn\nany kind of sequence, the reality is they're not really\ngood at remembering what happened a while ago, the long-term dependency. Here's a silly example, let's think of a story about Bob, Bob is eating an apple. The apple part is generated by\nthe recurrent neural network. Your recurrent neural networks\ncan learn to generate \"apple\" because it's seen in a lot of sentences,\nwith \"Bob\" and \"eating\" and it can generate the word apple. For a longer sentence, like \"Bob likes apples, he's hungry and decided to have a snack, so now he's eating an apple\", you have to maintain the state that we're talking about Bob and we're talking about apples, through several discreet semantic sentences. That kind of long-term memory is not-- because of different effects, but vanishing gradients, it's difficult to propagate the important stuff\nthat happened a while ago in order to maintain that context in generating \"apple\", or classifying\u00a0some concept\nthat happened way down the line. When people talk about recurrent neural networks these days, they're talking about LSTMs, long-short-term memory networks so all the impressive results results on time series\nand audio and video and all that, that requires LSTMs. Again, vanilla RNNs are on top of the slide, each cell is simple, there are some hidden units, there's an input, and there's an output. Here, we used TANH\nas activation function, it's just another popular\nSigmoid type activation function. LSTMs\u00a0are more complicated, or they look more complicated but in some ways, they're more intuitive\nfor us to understand. There's a bunch of gates in each cell, we'll go through those. In yellow are different\nneural network layers, Sigmoid and TANH, are just different types\nof activation functions. TANH is an activation function that squishes the input into\nthe range of negative one to one. Sigmoid function squishes it between zero and one and that serve different purposes. There's some pointwise operations, addition, multiplication, and there's connections, data being passed from layer to layer, shown by the arrows. There's concatenation and there's\na copy operation on the output We copy, the output of each cell\nit's copied to the next cell and to the output. Let me try to make it, clarified, clarify a little bit. There's this conveyer belt going through inside of\neach individual cell and they all have, there's really\nthree steps in the conveyer belt. The first is, there is a Sigmoid function that's responsible for deciding what to forget and what to ignore, it's responsible for taking in the input, the new input, x(t), taking in the state of the previous, the output of the previous cell,\nprevious time step and deciding \"do I want to keep\nthat in my memory or not?\" and \"do I want to integrate the new input into my memory or not?\" This allows you to selective about the information\nwhich you learn. For example, there's that sentence\n\"Bob and Alice are having lunch, Bob likes apples, Alice like oranges, she is eating an orange\". Bob and Alice are having lunch, Bob likes apples, right now, if you had said\nyou have a hidden state, keeping track of the gender\nof the person we're talking about you might say that there's both genders\non the first sentence, there's male in the second sentence, female in the third sentence, and that way when you have to generate a sentence\nabout who's eating what, you'll know- you keep the gender information in order to make an\naccurate generation of text corresponding to the proper person. You have to forget certain things, like forget that Bob existed\nat that moment, you have to forget Bob likes apples but you have to remember that Alice likes oranges so you have to selectively remember\nand forget certain things that's LSTM in a nutshell. You decided what to forget,\ndecided what to remember and decided what to output\nin that cell. Zoom in a little bit,\nbecause this is pretty cool There's a state running\nthrough the cell, this conveyer belt, previous state like the gender that we're currently talking about, that's the state that you're\nkeeping track of and that's running through the cell. Then there's three Sigmoid layers outputting one, a number between the zero and one, one when you want that\ninformation to go through and zero when you\ndon't want it to go through, the conveyer belt\nthat maintains the state. First, Sigmoid function is, we decided what to forget\nand what to ignore, that's the first one, we take the input from\nthe previous time step, the input to the network on the current time step and decided, do I want to forget\nor do I want to ignore those? Then we decided which part of the state to update, what part of our memory do we have\nto update with this information and what values to insert in that update. Third step is, we perform\nthe actual update and perform the actual forgetting, that's why you have\nthe Sigmoid function, you just multiply it, when is zero is forgetting, when is one that information passes through. Finally, we produce an output from the cell, if its translation is producing an output\nin the English language where the input was\nin Spanish language and then that same output it's copied to the next cell. What can we get done with this\nkind of approach? We can look at machine translation. I guess what I'm trying to-- question. what is your representation\nof this state? Is it like a floating point or is it like a vector or what is it, exactly? The state is the activation multiplied by the weight, it's the output of the Sigmoid or\nthe TANH activations. There's a bunch of neurons\nand they're firing a number between negative one or one,\nor between zero and one, that whole's a state. It just that calling it a state\nit's sort of simplifying, but the point is that there's a bunch of numbers been constantly\nmodified by the weights and the biases, those numbers hold the state and the modification\nof those numbers is controlled by the weights and then once all of that is done, the resulting output of the recurrent neural network it's compared to the desired output and the errors are backpropagated\nto the weights. Hopefully, that makes sense. So, machine translation is one\npopular application all of it is the same, all of these networks\nthat I've talked about, they're really similar constructs. You have some inputs, whatever language that is again, German maybe,\nI think everything is German, and the output. The inputs are in one language, a set of characters composed a word in one language, there's a state being propagated and once that sentence\u00a0is over, you start, as opposed\nto collecting inputs, start producing outputs and you can output in the English language. There's a ton of great work on\nmachine translations. It's what Google is supposedly using\nfor their translator, same thing. I've show this previously but now you all know how it works, same exact thing, LSTMs generating handwritten characters, handwriting in arbitrary styles, controlling the drawing, where the input is text\nand the output is handwriting. Is again, the same kind of network with some depths here, the input is the text, the output is the control\nof the writing. Character-level text generation, this is the thing that taught us about life, the meaning of life, literary recognition and the tradition\nof ancient human reproduction. That's again, the same process, input one character at the time, what we see there is the encoding\nof the characters on the input layer, there's a hidden state, hidden layer that is keeping track\nof those activations, the outputs of the activation functions\nand every single time it's outputting its best prediction of the next character that follows. Now, on a lot of these applications you want to ignore the output until the input sentence is over and then you start\u00a0listening\nto the output, but the point is that it just\nkeeps generating text, whether is given an input or not, so you producing input is just adding, steering the recurrent neural network. You can answer questions about an image, the input you get there, you could almost arbitrary\nstack things together, you take an image as your input,\nbottom left there, put it in your convolutional neural network, and take the question. There's something call\nword embeddings, it's to broaden the representative\nmeaning of the words. \"How many books?\" is the question. You want to take the word embeddings and the image and produce your best estimate of the answer. For question of \"what color is the cat?\" it could be gray or black, it's the different LSTM flavors producing that answer. Same with counting chairs you can give an image of a chair and as the question\n\"how many chairs are there?\" And it can produce an answer of \"three\". I should say this is really hard, arbitrary question asks an arbitrary image, you are both interpreting-- you are doing natural languages processing and you're doing computer vision,\nall in one network. Same thing with\nthe image capture generation, you can detect the different objects in the scene, generate those words, stitch them together\nin syntactically correct sentences and rearrange the sentences. All of those are LSTMs, the second and the third step, the first is computer vision\ndetecting the objects, segmenting the image and\ndetecting the objects, that way you can generate\na caption that says \"a man is sitting in a chair\nwith a dog in his lap\". Again, LSTMs for video. Caption generation for video, the input, and every frame it's an image that goes into the LSTM, the input is an image and the output is a set of characters. First, you load in the video, in this case the output is on top, you encode the video into a representation\ninside the network and then you start generating words about that video. First comes the input, the encoding\nstage,  then the decoding stage. Take in the video, say a man is taking, talking, whatever and because the input and\nthe output are arbitrary, there also has to be indicators\nof the beginnings and the ends of a sentence, in this case, end of sentences. You want to know when you stop in order to generate syntactically\ncorrect sentences. that indicates the end of a sentence. You want also to be able\nto generate a period You can also, again,\nrecurrent neural networks, LSTMs here, controlling the steering of a sliding window on an image that is used to classify\nwhat is contained in that image. Here, a CNN being steered by\na recurrent neural network in order to convert this imagen into the number that's associated\nwith a house number, it's called visual attention. That visual attention\ncan be used to steer for the perception side and it can be used to steer\na network for the generation. On the right, we can generate an image as-- So the output of the network-- it's a LSTM where the output on every time step is visual, and this way you can draw numbers. Here, I mention this before, is taking in as input silent video, sequence of images and producing audio. This is an LSTM that has convolutional layers\nfor every single frame, takes images as input and produces a spectrogram, audio as output. The training set is a person hitting\nan object with a drumstick and your task is to generate,\ngiven a silent video, generate the sound that\nthe drumstick will make when in contact with that object. Medical diagnosis, that's actually-- I've listed some places\nwhere it has been really successful and pretty cool, but it's also beginning to be applied in places where can actually really help civilization, in medical applications. For medical diagnosis there's the highly spars and variable lengths sequence of information in the form of, for example, patient\nelectronic health records. So, Every time you visit a doctor, there's a test being done,\nthat information is there and you can look it as a sequence\nover a period of time and then given that data,\nthat's the input, the output is the diagnosis, a medical diagnosis, in this case, we can look at\npredicting diabetes, scoliosis, asthma and\u00a0so on, with pretty good accuracy. There's something that all of us wish we could do, is stock market prediction. You can input, for example, well first of all,\nyou can input the raw stock data, [unintelligible 01:00:30] books\nand so on, financial data, but you can also look at news articles\nfrom all over the web and take those as input as shown here, on the X axis is time, articles from different days, LSTM, once again, and produce an output\nof your prediction, binary prediction, whether\nthe stock would go up or down. Nobody has been able to\nreally successfully do this but there is a bunch of results and trying to perform above random which is how you make money, significantly above random on the prediction of\nit's going up or down? So you could buy or sell and especially when there is-- in the cases when there was crashes\nit's easier to predict, so you can predict\nan encroaching crash. These\u00a0are shown in the table, the error rates from different stocks, automotive stocks. You can also generate audio, is the exact same process\nas it generates language, you generate audio. Here's trained on a single speaker, a few hours epics of them speaking and you just learn,\nthat's raw audio of the speaker and it's learning slowly to generate [audio] Obviously, they were reading numbers. this is incredible, this is trained on a compress spectrogram\nof the audio, raw audio and is producing something that over just a few epics is producing\nsomething that sounds like words, it could do this lecture for me, I wish. This is amazing, this is raw input, raw output, all again, LSTMs, and there's a lot of work\nin voice recognition, audio recognition. You're mapping-- let me turn it up. You are mapping any kind of audio\nto a classification, you can take the audio of the road and that's the spectrogram\non the bottom there, being shown you could detect whether\nthe road is wet is wet or the road is dry. you could do the same thing for recognizing the gender\nof the speaker or recognizing many to many map of the actual words\nbeing spoken, speech recognition. This is about driving, so let's see where recurrent neural|\nnetworks apply in driving. We talked about the NVIDIA approach, the thing that actually powers\nDeepTeslaJS, it is a simple convolutional neural network, there's five convolutional layers in their approach, three fully\nconnected layers, you can add as many layers\nas you want in DeepTesla, that's a quarter of million parameters to optimize all you are taking is a single image, no temporal information,\nsingle image and producing the steering angle,\nthat's the approach, that's the DeepTesla way, taking a single imagen image and learning a regression\nof the steering angle. One of the prizes for the competition is\nthe Udacity, self-driving car engineer nanodegree for free, this thing is awesome, I encourage everyone to check it out, but they did a competition that's very similar to ours, but a very large group\nof obsessed people, they were very clever,\nthey went beyond convolutional neural networks\nof predicting steering, taking a sequence of images\nand predicting steering, what they did is, the winners, at least the first and I'll talk about\nthe second place winner tomorrow, on 3D convolutional neural networks, the first and the third place winners\nused RNNs, used LSTMs, recurrent neural networks and map a sequence of images to a sequence of steering angles. For anyone, statistically speaking, anybody here who is\nnot a computer vision person, most likely what'd you want to use,\nfor whatever application you're interested in, is RNNs, the world is full of time series data, very few of us are working on data that is no time series data, in fact, whenever it's just snapshots, you're really just reducing\nthe problem to the size that you can handle but most data in the world is time series data. This is the approach you end up using if you want to apply it\nin your own research, RNNs is the way to go. Again, what are they doing? How do you put images into a recurrent neural network? it's the same thing, you take, you have to convert\nan image into numbers in some kind of way, a powerful way of doing that\nis convolutional neural networks, so you can take either 3D convolutional\nneural networks or 2D convolutional neural networks once it takes time into\nconsideration and whatnot, process that image to extract a representation\nof that image and that becomes the input\nto the LSTM and the output at every single cell,\nat every single timestep, is a predicted steering angle, the speed of the vehicle\nand the torque that's what the first place winner did, they didn't just do the steering angle, also did the speed and torque and the sequence length\nthat they were using for training and for testing, for the input and the output, is a sequence length of 10\u00a0 did they used supervised learning or did they used reinforcement\nlearning? The question was, did they used\nsupervised learning? Yes, they were given the same thing\nas in DeepTesla, a sequence of frames\nwhere the have a sequence of steering angles, speed and torque, I think there's other information\ntoo available, there's no reinforcement\nlearning here. Question. Do you have a sense of\nhow much information is being passed,\u00a0how many\nLSTM gates are there in this problem? The question was, how many LSTM gates\nare\u00a0in this problem? This network, it's true that this diagrams kind of hide the number of parameters here,\nbut it's arbitrary just like convolutional\nneural networks are arbitrary, the size of the input is arbitrary, the size of Sigmoid function, TANH is arbitrary, so you can make it as large as you want,\nas deep as you want and the deeper and larger, the better. What these folks actually used-- the way these competitions work and I encourage you, if you're\ninterested in machine learning to participate in Kaggle, I don't know how to pronounce it,\ncompetitions where basically everyone\nis doing the same thing, you're using LSTMs or if it's one- on-one mapping, using convolutional neural network\nfully connecting networks with some clever pre-processing and the whole job is\nthat takes months and you probably,\nif you're a researcher, that's what you'd be doing\nyour own research, playing with parameters, playing with pre-processing\nof the data, playing with the different parameter\nthat controls the size of the network the learning rate, I've mentioned, this type of optimizer, all these kinds of things,\nthat's what you're playing with, using your own human intuition and you're using your-- whatever probing you can do in monitoring the performansce of the network through time. Yes? The question was, you said that there's a memory of tenth in this LCM, and I thought RNNs are\nsupposed to be arbitrary. It has to do with the training, how the network is trained. It's trained with sequences of 10. The structure is still the same,\nyou only have one cell that's\nlooping onto each other. But the question is, in what chunks, what is the size of the sequence that we should do in the training\nand then the testing. It can be arbitrary length."}, {"content": "It's just usually better\nto be consistent and have a fixed length. You're not stacking 10 cells together."}, {"content": "It's just a single cell still. The third-place winner, Team Chauffeur, used something called\ntransfer learning and it's something I don't think\nI mentioned but it's kind of implied, the amazing power of neural networks. First, you need a lot of data\nto do anything."}, {"content": "That's the cost, that's\nthe limitation in neural networks. But what you could do is, there's neural networks that have been\ntrained on very large data sets. ImageNet, Vdg Net, AlexNet, ResNet, all these networks are trained\non a huge amount of data. Those networks are trained to tell the differences between a cat and dog\nSpecific optical recognition of single images. How do I then take that network and apply it to my problem, say of driving or length detection, or medical diagnosis, or cancer or not? The beauty of neural networks, the promise of transfer learning, is that you can just take that network, chop off the final layer, the fully connected layer that maps from all those cool high-dimensional features that you\nhave learned about visual space, and as opposed to predicting cat vs. dog, you teach it to predict\ncancer or no cancer. You teach it to predict lane or no lane,\ntruck or no truck. As long as the visual space under which that network operates is similar or the data like\nif it's audio or whatever if it's similar, if the features are\nuseful then you learn, in studying the problem of\ncat vs dog deeply, you have learned actually\nhow to see the world. As you're going to apply\nthat visual knowledge, you can transfer that learning to another domain. That's the beautiful power\nof neural networks it's that they're transferable. What they did here is-- I didn't spend enough time\nlooking through the code I'm not sure which of the\ngiant nework they took but they took a giant\nconvolutional neural network, they chopped off the end layer, which produced 3000 features, and they took those 3000 features to every single image frame, and that's the Xt. They gave that as the input to LSTM. And the sequence length,\nin that case, was 50. This process is pretty similar across domains."}, {"content": "That's the beauty of it. The art of neural networks is in the-- Well\u00a0that's a good sign [chuckles], I guess I should warp it up-- The art of the neural networks is\nin the proper parameter tuning. That's the tricky part, and that's the part you can't be taught. That's experience, sadly enough. That's why they talk about Stochastic Gradient Descent SGD, That's what Geoffrey Hinton refers to as Stochastic Graduate Student Descent, meaning you just keep\nhiring graduate students to play with the hyperparameters until the problem is solved [laughter]. I have about 100+ slides on driver state, which is the thing that\nI'm most passionate about, and I think will save the best for last. I'll talk about that tomorrow. We have a guest speaker from the White House, will talk about the future\nof Artificial Intelligence from the perspective of policy, and what I would like you to do first\noff you registered students is submit the two tutorial assignments, and pick up can we just set the boxes right here\nor something? Just stop by and pick up a shirt."}, {"content": "And give us a card on the way. Thanks guys. [Applause]"}], "MIT 6.S094: Deep Reinforcement Learning": [{"content": "today we will talk about deep reinforcement learning the question we would like to explore it's to which degree we can teach systems to act to perceive and act in this world from data so let's take a step back and think of what is the full range of tasks then artificial intelligence system needs to accomplish here's the stack from top to bottom top the input bottom output the environment at the top the world that the agent is operating in sensed by sensors taking in the world outside and converting it to raw data interpretable by machines sensor data and from that raw sensor data you extract features you extract structure from that data such that you can input it make sense of it discriminate separate understand the data and as we discussed you form higher and higher order representations a hierarchy of representations based on which the machine learning techniques can then be applied once the machine learning techniques the understanding as I mentioned converts the data into features into higher order representations and into simple actionable useful information we aggregate that information into knowledge we take the pieces of knowledge extracted from the data through the machine learning techniques and to build a taxonomy a library of knowledge and with that knowledge we reason an aging estas to reason to aggregate to connect pieces of data it's seen in the recent past or the distant past to make sense of the world that's operating in and finally to make a plan of how to act in that world based on its objectives based on what it wants to accomplished as I mentioned a simple but commonly accepted definition of intelligence is a system that's able to accomplish complex goals so system that's operating in the environment in this world must have a goal must have an objective function a reward function and based on that it forms a plan and takes action and because there operates in many cases in the physical world it must have tools effectors with which it applies the actions to change something about the world that's the full stack of an artificial intelligence system that acts in the world and the question is what kind of task can such a system take on what kind of task can an artificial intelligence system learn as we understand AI today we will talk about the advancement of deeper enforcement learning approaches and some of the fascinating ways it's able to take much of the stack and treat it as an end-to-end learning problem but we look at games we look at simple formalized worlds while it's still impressive beautiful and unprecedented accomplishments it's nevertheless formal tasks can we then move beyond games and into expert tasks of medical diagnosis of design and into natural language and finally the human level tasks of emotion imagination consciousness let's once again review the stack in practicality in the tools we have the input for robots operating in the world from cars to humanoid to drones as light our camera radar GPS stereo cameras audio microphone networking for communication and the various ways to measure kinematics with IMU the raw sensory data is then processed features of form to representations are formed and multiple higher and higher order representations that's what deep learning gets us before neural networks before the advent of before the recent successes of neural networks to go deeper and therefore be able to form high order representations of the data that was done by experts by human experts today networks are able to do that that's the representation piece and on top of the representation piece the final layers these networks are able to accomplish the supervised learning tasks the generative tasks and the unsupervised clustering tasks through machine learning that's what we talked about a little in lecture one and we'll continue tomorrow and Wednesday that's supervised learning and you can think about the output of those networks as simple clean useful valuable information that's the knowledge and that knowledge can be in the form of single numbers it could be regression continuous variables it could be a sequence of numbers it can be images audio sentences text speech once that knowledge is extracted and aggregated how do we connect it in multi resolution always form hierarchies of ideas connect ideas the trivial silly example is connecting images activity recognition and audio for example if it looks like a duck quacks like a duck and swims like a duck we do not currently have approaches that effectively integrate this information to produce a higher confidence estimate that is in fact the duck and the planning piece the task of taking the sensory information fusing the sensory information and making action control and longer-term plans based on that information as we'll discuss today are more and more amenable to the learning approach to the deep learning approach but to date have been the most successful and non learning optimization based approaches like with the several of the guest speakers we have including the creator of this robot Atlas in Boston Dynamics so the question how much of the stack can be learned and to end from the input to the output we know we can learn the representation and the knowledge from the representation and to knowledge even with the kernel methods of SVM and certainly with with neural networks mapping from representation to information has been where the primary success of machine learning over the past three decades has been mapping from raw sensory data to knowledge that's where the success the automated representation learning of deep learning has been a success going straight from raw data to knowledge the open question for us today and beyond is if we can expand the red box there of what can be learned and to end from sensory data to reasoning so aggregating forming higher representations of the extracted knowledge and forming plans and acting in this world from the raw sensory data we will show the incredible fact that we're able to do CERN exactly what's shown here and to end with deeper enforcement learning on trivial tasks in a generalizable way the question is whether that can then move on to real-world tasks of autonomous vehicles of humanoid robotics and so on that's the open question so today let's talk about reinforcement learning there's three types of machine learning supervised unsupervised are the categories at the extremes in relative to the amount of human and human input that's required for supervised learning every piece of data that's used for teaching these systems is first labeled by human beings and unsupervised learning on the right is no data is labeled by human beings in between is some sparse input from humans semi-supervised learning is when only part of the data is provided by humans ground truth and the rest must be inferred generalized by the system and that's what reinforcement learning Falls reinforcement learning has shown there with the cats as I said every successful presentation must include cats they're supposed to be Pavlov's cats and ringing a bell and every time they ring a bell they're given food and they learn this process the goal of reinforcement learning is to learn from sparse reward data from learn from sparse supervised data and take advantage of the fact that in simulation or in the real world there is a temporal consistency to the world there is a temporal dynamics that follows from state to state the state through time and so you can propagate information even if the information that you're received about the the supervision the ground truth is sparse you can follow that information back through time to infer something about the reality of what happened before then even if your reward signals were weak so it's using the fact that the physical world evolves through time and some some sort of predictable way to take sparse information and generalize it over the entirety of the experience as being learned so we apply this the two problems today we'll talk about deep traffic as a methodology deep reinforcement learning so deep traffic is a competition that we ran last year and expanded significantly this year and I'll talk about some of the details and how the folks in this room can on your smart phone today or if you have a laptop training agent while I'm talking training a neural network in the browser some of the things we've added our we've added the capability we've now turned it into a multi agent deeper enforcement learning problem where you can control up to ten cars within your network perhaps less significant but pretty cool is the ability to customize the way the agent looks so you can upload and people have to an absurd degree have already begun doing so uploading different images instead of the car that's shown there as long as it maintains the dimensions shown here is a SpaceX rocket the competition is hosted on the website self-driving cars that MIT ID you slash deep traffic will return to this later the code is on github with some more information a starter code and a paper describing some of the fundamental insights that will help you win at this competition is an archive so from supervised learning in lecture one to today supervised learning we can think of as memorization of ground truth data in order to form representations that generalizes from that ground truth reinforcement learning is we can think of as a way to brute force propagate that information the sparse information through time to to assign quality reward to state that does not directly have a reward to make sense of this world when the rewards are sparse but are connected through time you can think of that as reasoning so the through time is modeled in most reinforcement learning approaches very simply that there's an agent taking an action in a state and receiving a little reward and the agent operating in an environment execute an action receives an observed state and new state and receives their reward this process continues over and over and some examples we can think of any of the video games some of which we'll talk about today like Atari breakout as the environment the agent is the paddle each action that the agent takes has an influence on the evolution of the environment and the success is measured by some reward mechanism in this case points are given by the game and every game has a different point scheme that must be converted normalized into a way that's interpreted by the system and the goal is to maximize those points maximize the reward the continuous problem of card pole by balancing the goal is to balance the pole on top of a moving cart the state is the angle the angular speed the position of horizontal velocity the actions are the horizontal force applied to the cart and the reward is one at each time step if the pole is still upright all the first-person shooters the video games is now Starcraft the strategy games in case of first-person shooter and doom what is the goal the environment is the game the goal is to eliminate all opponents the state is the raw game pixels coming in the actions is moving up down left right and so on and the reward is positive when eliminating an opponent and negative when the agent is eliminated industrial robotics been packin with a robotic arm the goal is to pick up a device from a box and put it into a container the state is the raw pixels of the real world that the robot observes the actions are the possible actions of the robot the different degrees of freedom are moving through those degrees moving the different actuators to realize of the position of the arm and the reward is positive when placing a device successfully and negative otherwise everything could be modeled in this way Markov decision process there's a state as zero action a zero and reward received a new state is achieved again action rewards state action rewards state until a terminal state is reached and the major components of reinforcement learning is a policy some kind of plan of what to do in every single state what kind of action to perform a value function a some kind of sense of what is a good state to be in of what is a good action to take in a state and sometimes a model that the agent represents the environment with some kind of sense of the environment its operating in the dynamics of that environment that's useful for making decisions about actions let's take a trivial example a grid world of three by four twelve squares we start at the bottom left and their task with walking about this world to maximize reward they're awarded at the top right is a plus 1 and a 1 square below that is a negative 1 and every step you take is a punishment or is a negative reward of 0.04 so what is the optimal policy in this world now when everything is deterministic perhaps this is the policy when you start the bottom left well because every step hurts every step has a negative reward then you want to take the shortest path to the maximum square with a maximum reward when the state space is non-deterministic as presented before with a probability of 0.8 when you choose to go up you go up but with probability 0.1 you go left and point 1 you go right unfair again much like life that would be the optimal policy what is the Keith observation here that every single state in the space must have a plan because you can't because then a non-deterministic aspect of the control you can't control where you're going to end up so you must have a plan for every place that's the policy having an action an optimal action to take in every single state now suppose we change the reward structure and for every step we take there's a negative reward is a negative 2 so it really hurts there's a high punishment for every single step we take so no matter what we always take the shortest path the optimal policy is to take the shortest path to the to the only spot on the board that doesn't result in punishment if we decrease the reward of each step to negative 0.1 the policy changes whether some extra degree of wandering encouraged and as we go further and further in lowering the punishment as before to negative 0.04 more wandering and more wandering is allowed and when we finally turn the reward into positive so every step it every step is increases the reward then there's a significant incentive to to stay on the board without ever reaching the destination kind of like college for a lot of people so the value function the way we think about the value of a state or the value of anything in the environment is the reward were likely to receive in the future and the way we see the reward were likely to receive as we discount the future award because we can't always count on it here Gama further and further out into the future more and more discounts decreases the reward the importance of the reward received and the good strategy is taking the sum of these rewards and maximizing it maximizing the scoundrel ward that's what reinforcement learning hopes to achieve and with cue learning we use any policy to estimate the value of taking an action in a state so off policy forget policy we move about the world and use the bellman equation here on the bottom to continuously update our estimate of how good a certain action is in a certain state so we don't need this this allows us to operate in a much larger state space in a much larger action space we move about this world through simulation or in the real world taking actions and updating our estimate of how good certain actions are over I'm the new state at the left is the is the updated value the old state is the starting value for the equation and we update that old state estimation with the sum of the reward received by taking action s tax action a and state us and the maximum reward that's possible to be received in the following states discounted that update is decreased with a learning rate the higher the learning rate the more value we the the faster will learn the more value we assigned to new information that's simple that's it that's Q learning the simple update rule allows us to to explore the world and as we explore get more and more information about what's good to do in this world and there's always a balance in the various problem spaces we'll discuss there's always a balance between exploration and exploitation as you form a better and better estimate of the Q function of what actions are good to take you start to get a sense of what is the best action to take but it's not a perfect sense it's still an approximation and so there's value of exploration but the better and better your estimate becomes the less and less exploration has a benefit so usually we want to explore a lot in the beginning and less and less so towards the end and when we finally release the system out into the world and wish it to operate its best then we have it operate as a greedy system always taking the optimal action according to the q2 key value function and everything I'm talking about now is permit rised and our parameters that are very important for winning the deep traffic competition which is using this very algorithm with a neural network at its core so for sin table representation of a cue function where the y-axis is state four states s one two three four and the x-axis is actions a one two three four we can think of this table as randomly initiated or initiated initialized in any kind of way that's not representative of actual reality and as we move about this world and we take actions we update this table with the bellman equation shown up top and here slides now are online you can see a simple pseudocode algorithm of how to update it how to run this bellman equation and over time the approximation becomes the optimal cue table the problem is when that cue table it becomes exponential in size when we take in raw sensory information as we do with cameras with deep crash or with deep traffic it's taking the full grid space and taking that information the raw the raw grid pixels of deep traffic and when you take the arcade games here they're taking the raw pixels of the game or when we take go the game of go when it's taking the units the the board the raw state of the board as the input the potential state space the number of possible combinations of what states it possible is extremely large larger than we can certainly hold the memory and larger that we can ever be able to accurately approximate through the bellman equation over time through simulation through the simple update of the bellman equation so this is where deep reinforcement learning comes in neural networks are really good approximate errs they're really good at exactly this task of learning this kind of cue table so as we started with supervised learning or neural networks helped us memorize patterns using supervised ground true data and we'll move to reinforcement learning that hopes to propagate outcomes to knowledge deep learning allows us to do so on much larger state spaces are much larger action spaces which means it's generalizable it's much more capable to deal with the raw stuff of sensory data which means it's much more capable to deal with the broad variation of real world applications and it does so because it's able to learn the representations as we discussed on Monday the understanding comes from converting the raw sensory information into into simple useful information based on which the action in this particular state can be taken in the same exact way so instead of the cue table instead of this cue function we plug in a neural network where the input is the state space no matter how complex and the output is a value for each of the actions that you could take input is the state output is the value of the function it's simple this is deep Q Network DQ one at the core of the success of deep mind a lot of the cool stuff you see about video games D queuing or variants of DQ and our play this is water first with a nature paper a deep mind the success came of playing the different games including Atari games how are these things trained very similar to supervised learning the bellman equation up top it takes the reward and the discounted expected reward from future states the loss function here for neural network and you'll now work learners with a loss function it takes the reward received at the current state does a forward pass through a neural network to estimate the value of the future state of the best action to take in the future state and then subtract that from the forward pass through the network for the current state in action so you take the difference between what your a Q estimator then you'll network believes the value of the current state is and what it more likely is to be based on the value of the future states that are reachable based on the actions you can take here's the algorithm input is the state output is the Q value for each action or in this diagram input is the state in action and the output is the Q value it's very similar architectures so given a transition of s a are s prime s current state taking an action receiving reward and achieving US prime state the the update is to a feed-forward pass through the network for the current state do a feed-forward pass for each of the possible actions taken in the next state and that's how we compute the two parts of the loss function and update the weights using back propagation again loss function back propagation is how the network is trained this has actually been around for much longer than the deep mind a few tricks made it made it really work experience replays the biggest one so as the games are played through simulation or if it's a physical system as it acts in the world it's actually collecting the observations into a library of experiences and that training is performed by randomly sampling the library in the past by randomly sampling the previous experiences and batches so you're not always training on the natural continuous evolution of the system you're training on randomly picked batches of those experiences that's like huge it's a it's a seems like a subtle trick but it's a really important one so the system doesn't over fit a particular evolution of this of the game of the simulation another important again subtle trick as in a lot of deep learning approaches the subtle tricks make all the difference is fixing the target network for the loss function if you notice you have to use the neural network thick the singly neural network the gqi network to estimate the value of the current state and action pair and next so using it multiple times and as you perform that operation you're updating the network which means the target function inside that loss function is always changing so you're the very nature your loss function is changing all the time as you're learning and that's a big problem for stability that can create big problems for the learning process so this little trick is to fix the network and only update it every safe thousand steps so as you train the network the the network that's used to compute the target function inside the loss function is fixed it produces a more stable computation on a loss function so the ground doesn't shift under you as you're trying to find a minimal for the loss function the loss function doesn't change in unpredictable difficult to understand ways and reward clipping which is always true with general systems that are operating it's seeking to operate in the generalized way is for very for these various games the points are different some some points are low some points are high some go positive and negative and they're all normalized to a point where the good points or the positive points are a 1 and negative points are a negative 1 that's reward clipping simplify the reward structure and because a lot of the games are 30 FPS or 60 FPS and the actions are not it's not valuable to take actions at such a high rate inside of these as particularly Atari games then you only take an action every four steps while still taking in the frames as part of the temporal window to make decisions tricks but hopefully gives you a sense of the kind of things necessary for both seminal papers like this one and for the more important accomplishment of winning deep traffic is that the tricks make all the difference here on the bottom is the circle is when the technique is used in the x1 it's not looking at replay and target takes target network and experience replay when both are used for the game of breakout River raid sea quests and Space Invaders the higher the number the better it is the more points achieved so when it gives you a sense that when replay and target both gives significant improvements in the performance of the system order of magnitude improvements two orders of magnitude for breakup and here is pseudocode of implementing dq1 the learning the key thing to notice and you can look to the slides is the the loop the while loop of playing through the games and selecting the actions to play is not part of the training it's it's part of the saving the observations the state action reward next state observation is saving them into replay memory into that library and then you sample randomly from that replay memory to then train the network based on the loss function and with probability up up top with the probability epsilon select a random action that epsilon is the probability of exploration that decreases that's something you'll see in deep traffic as well is the rate at which that exploration decreases over time through the training process you want to explore a lot first and less and less over time so this algorithm is being able to accomplish in 2015 and since a lot of incredible things things that made the AI world think that we were onto something that general AI is within reach for the first time that raw sensor information was used to create a system that acts and makes sense of the world make sense of the physics of the world enough to be able to succeed in it from very little information but these games are trivial even though there is a lot of them this dqn approach has been able to outperform a lot of the Atari games that's what's been reported on outperform the human level performance but again these games are trivial what I think and perhaps biased I'm biased but one of the greatest accomplishments of artificial intelligence in the last decade at least from the philosophical or the research perspective is alphago 0 first alphago and then alphago 0 its deepmind system that beat the best in the world in a game of go so what's the game of go it's simple I won't get into the rules but basically it's a 19 by 19 board shown on the bottom of the slide for the bottom row of the table for a board of 19 by 19 the number of legal game positions is 2 times 10 to the power of 170 it's a very large number of possible positions to consider any one time especially the game evolves the number of possible moves is huge much larger than in chess so that's why AI the community thought that this game is not solvable until 2016 when alphago used this use human expert position play to seed in a supervised way reinforcement learning approach and I'll describe in a little bit of detail and a couple of slides here to beat the best in the world and then alphago 0 that is the accomplishment of the decade for me in AI is being able to play with no training data on human expert games and beat the best in the world in an extremely complex game this is not Atari this is and this is a much higher order difficulty game and that and the quality of players that is competing in is much higher and it's able to extremely quickly here to achieve a rating that's better than alphago and better than the different variants of alphago and certainly better than the best of the human players in 21 days of self play so how does it work all of these approaches much much like the previous ones the traditional ones that are not based on deep learning are using Monte Carlo tree search MCTS which is when you have such a large state space you start at a board and you play and you choose moves with some exploitation exploration balancing choosing to explore totally new positions or to go deep in the positions you know are good until the bottom of the game is reached until the final state is reached and then you back propagate the quality of the choices you made leading to that position and in that way you learn the value of of board positions and play that's been used by the most successful go playing engines before and alphago since but you might be able to guess what's the difference with alphago verse to the previous approaches they use the neural network as the intuition quote-unquote - what are the good states what are the good next board positions to explore and the key things again the tricks make all the difference that made alphago zero work and work much better than alphago is first because there was no expert play instead of human games alphago used that very same Monte Carlo tree search algorithm MCTS to do an intelligent look ahead based on the neural network prediction of where dove the good States to take it checked that instead of human expert play it checked how good indeed are those states it's a simple look ahead action that does the ground truth that does the target correction that produces the loss function the second part is the multitask learning what's now called multitask learning is the networkers is quote-unquote two-headed in the sense that first it outputs the probability of which move to take the obvious thing and it's also producing a probability of winning and there's a few ways to combine that information and continuously train both parts of the network depending on the choice taken so you want to take the best choice in the short term and achieve the positions that are highly a slightly hood of winning for the player that's whose turn it is and another big step is that they updated from 2015 the updated of the state-of-the-art architecture which are now the architecture that one imagenet as the residual networks ResNet for imagenet those that's it and those little changes made all the difference so that takes us to deep traffic and the eight billion hours stuck in traffic America's pastime so we tried to simulate driving that behavior layer of driving so not the immediate control not the motion planning but beyond that on top on top of those control decisions the human interpretable decisions of changing lane of speeding up slowing down modeling that in a micro traffic simulation framework that's popular in traffic engineering the kind of shown here we apply deep reinforcement learning to that I'll call it deep traffic the goal is to achieve the highest average speed over a long period of time weaving in and out of traffic for students here the requirement is to follow the tutorial and achieve a speed of 65 miles an hour and if you really want to achieve a speed over 70 miles an hour which is what's acquired to win and perhaps upload your own image to make sure you look good doing it what you should do clear instructions to compete read the tutorial you can change parameters in the code box on that website cars done on mighty dad you size deep traffic click the white button that says apply code which applies the code that you write these are the parameters that you specify then you'll network it applies those parameters creates the architecture do you specify and now you have a network written in JavaScript living in the browser ready to be trained then you click the blue button that says run training and that trains the network much faster than one's actually being visualized in the browser a thousand times faster by evolving the game making decisions taking in the grid space as I'll talk about here in a second the speed limit is 80 miles an hour based on the various adjustments were made to the game reaching 80 miles an hour is certainly impossible an average and reaching some of the speeds that we've achieved last year it's much much much more difficult finally when you're happy and the training is done submit the model to competition for those super eager dedicated students you can do so every five minutes and to visualize your submission you can click the request visualization specifying the custom image and the color okay so here's the simulation speed limit 80 miles an hour cars 20 on the screen one of them is a red one in this case that's that one is controlled by a neural network its speed it's allowed the actions of speed up slow down change lanes left-right or stay exactly the same the other cars are pretty dumb they speed up slow down turn left right but they don't have a purpose in their existence they do so randomly or at least purpose has not been discovered the road the car the speed the road is a grid space an occupancy grid that specifies when it's empty it's set to a B meaning that the the grid value is whatever speed is achievable if you were inside that grid and when there's other cars that are going slow the value in that grid is the speed of that car that's the state space that's the state representation and you can choose how much what slice that state space you take in that's the input to the neural network for a visual Asian purposes you can choose normal speed or fast speed for watching the network operate and there's display options to help you build intuition about the network takes in and what space that car is operating in the default is no extra information is added then there's the learning input which visualizes exactly which part of the road the is serves as the input to the network then there is the safety system which I'll describe in a little bit which is all the parts of the road the car is not allowed to go into because it would result in a collision and that with JavaScript would be very difficult to animate and the full map here's a safety system you could think of this system as a CC basic radar ultrasonic sensors helping you avoid the obvious collisions to obviously detectable objects around you and the task for this red car for the steel Network is to move about this space is to move about the space under the constraints of the safety system the red shows all the parts of the grid it's not able to move into so the goal for the car is to not get stuck in traffic it's make big sweeping motions to avoid crowds of cars the input like DQ n is the state space the output is the value of the different actions and based on the epsilon parameter through training and through inference evaluation process you choose how much exploration you want to do these are all parameters the learning is done in the browser on your own computer utilizing only the CPU the action space there's five giving you some of the variables here perhaps you go back to the slides to look at it the brain quote unquote is the thing that takes in the state and the reward takes a four passed through the state and produce to the next action the brain is where the neural network is contained both of the training and the evaluation the learning input can be controlled in width forward length and backward length lane side number of lanes to the side that you see patches ahead as the patches ahead that you see patches behind as patches behind the you see mu this year can control the number of agents that are controlled by the neural network anywhere from one to ten and the evaluation is performed exactly the same way you have to achieve the highest average speed for the agents the very critical thing here is the agents are not aware of each other so they're not jointly jointly planning the network is trained under the joint objective of achieving the average speed for all of them but the actions are taking in a greedy way for each it's very interesting what can be learned in this way because this kinds of approaches are scalable to an arbitrary number of cars and you could imagine us plopping down the best cars from this class together and having them compete in this way the best neural networks because they're full in their greedy operation the number of networks that can concurrently operate is fully scaleable there's a lot of parameters the temporal window the layers the many layers types that can be added here's a fully connected layer with tenure ons the activation functions all of these things can be customized as specified in the tutorial the final layer a fully connected layer with output a five regression giving the value of each of the five actions and there's a lot of more specific parameters some of which have this just from gamma to epsilon to experience replay size to learning rate in temporal window the optimizer the learning rate momentum batch size l2 l1 to K for regularization and so on there's a big white button that says apply code that you press that kills all the work you've done up to this point so be careful doing it it should be doing it only at the very beginning if you happen to leave your computer running in training for several days as as folks have done the blue training button you press and it trains based on the parameters you specify and the network state gets shipped to the main simulation from time to time so the thing you see in the browser as you open up the web site is running then the same network that's being trained and regularly it updates that network so it's getting better and better even if the training takes weeks for you it's constantly updating the network you see on the left so if the car for the network that you're training is just standing in place and not moving it's probably time to restart and change the parameters maybe add a few layers to your network number of iterations is certainly an important parameter to control and the evaluation is something we've done a lot of worked on since last year to remove the degree of randomness to remove the the incentive to submit the same code over and over again to hope to produce a higher reward a higher evaluation score the method for evaluation is we collect the average speed over ten runs about 45 seconds of game each not minutes 45 simulated seconds and there is five hundreds of those and we take the median speed of the 500 runs it's done server-side so extremely difficult to cheat I urge you to try you can try it locally there's a start evaluation run but that one doesn't count that's just for you to feel better by you network that's that should produce a result that's very similar to the one we were produced on the server it's to build your own intuition and as I said we significantly reduce the influence of randomness so the the score the speed you get for the network you design should be very similar with every valuation loading is saving if the network is huge and you want to switch computers you can save the network it saves both the architecture of the network and the weights and the on the network and you can load it back in obviously when you load it in it's not saving any of the data you've already done you can't do transfer learning with javascript in the browser yet submitting your network submit model to competition and make sure you run training first otherwise it'll be initiated the way to initiate it randomly and will not do so well you can resubmit us off and you like and the highest score is what counts the coolest part is you can load your custom image specify colors and request the visualization we have not yet shown the visualization but I promise you it's going to be awesome again read the tutorial change the parameters in the code box click apply code run training everybody in this room on the way home on the train hopefully not in your car should be able to do this in the browser and then you can visualize request visualization because it's an expensive process you have to want it for us to do it because we have to run in server-side competition link is there github starter code is there and the details for those that truly want to win is in the archive paper so the question that will come up throughout is whether these reinforcement learning approaches are at all or rather if action planning control is amenable to learning certainly in the case of driving we can't do it alpha go zero did we can learn from scratch from self play because that will result in millions of crashes in order to learn to avoid the crashes unless we're working like we are deep crash on the RC car or we're working in a simulation so we can look at export data we can look at driver data which we have a lot of and learn from it's an open question whether this is applicable to date and I'll bring up two companies because they're both guest speakers deep IRL is not involved in the most successful robots operating in the real world in the case of Boston Dynamics most of the perception control and planning like in this robot does not involve learning approaches except with minimal addition on the perception side best of our knowledge and certainly the same is true with Wei MO as the speaker on Friday will talk about deep learning is used a little bit in perception on top but most of the work is done from the sensors and the optimization base the model-based approaches trajectory generation and optimizing which trajectory trajectory is best to avoid collisions deep IRL is not involved and coming back and back again the unexpected local POC is a high reward which arises in all of these situations and apply in the real world so for the cat video that's pretty short where the cats are ringing the bell and they're learning that the ring in the bell is is mapping to food I urge you to think about how that can evolve over time in unexpected ways they may not have a desirable effect where the final reward is in the form of food and the intended effect is to ring the bell that's ASAT comes in for the artificial general intelligence course in two weeks that something will explore extensively its how these reinforcement learning planning algorithms will evolve in ways they're not expected and how we can constrain them how we can design reward functions that result in safe operation so I encourage you to come to the talk on Friday at 1:00 p.m. as a reminder so 1:00 p.m."}, {"content": "not 7:00 p.m. in Stata 32 one two three and two the awesome talks in two weeks from Boston Dynamics to Ray Kurzweil and so on for AGI now tomorrow we'll talk about computer vision and psyche fuse thank you everybody [Applause]"}], "MIT 6.S094: Deep Learning for Human Sensing": [{"content": "today we will talk about how to apply the methods of deep learning to understanding the sense of the human being the focus will be on computer vision the visual aspects of a human being of course we humans express ourselves visually but also through audio voice and through text beautiful poetry and novels and so on we're not going to touch those today we're just going to focus on computer vision how we can use computer vision to extract useful actionable information from video images video of human beings in particular in the context of the car so what are the requirements for successfully applying deep learning methods in the real world so when we're talking about human sensing we're not talking about a basic face recognition of celebrity images we're talking about using computer vision deep learning methods to create systems that operate in the real world and in order for them to operate in the real world there are several things they sound simple some are much harder than they sound first and the most important here for most to less more to less critical ordered is data data is everything real world data we need a lot of real world data to form the data set on which these supervised learning methods can be trained I'll say this over and over throughout the day today data is everything that means data collection is the hardest part and the most important part we'll talk about how that data collection is carried out here in our group at MIT all the different ways to capture human beings in the driving context in the road user context pedestrians cyclists but the data it starts and ends at data the fun stuff is the algorithms but the data is what makes it all work real world data okay then once you have the data okay data isn't everything I lied because you have to actually annotate it so what do we mean by data there's raw data video audio lidar all the types of sensors we'll talk about to capture real world you wrote user interaction you have to reduce that into meaningful representative cases of what happens in that real world in driving 99% of the time driving looks the same it's the it's the 1% the interesting cases that we're interested in and what we want is algorithm to train learning algorithms on those 1% so we have to collect 100 percent we have to collect all the data and then figure out and automated semi-automated ways to find the pieces of that data that could be used to train your own networks and that a representative of the general thing kinds of things that happen in this world efficient annotation annotation isn't just about drawing bounding boxes on images of cats annotation tooling is key to unlocking real world performance systems that successfully solve some problem accomplish some goal in real world data that means designing annotation tools for a particular task annotation tools that are used for glance classification for determining where drivers are looking it's very different than annotation tools used for body pose estimation is very different than the tooling use that we use for psyche views investing thousands of dollars for the competition for this class to annotate fully scene segmentation where every pixel is colored there's needs to be tooling for each one of those elements and they're key that's HCI question that's a design question there's no deep learning there's no robotics in that question it's how do we leverage human computation human the human brain to mow effectively label images such that we can train y'all networks on them hardware in order to train these networks in order to parse the data we collect and we'll talk about we have now over five billion images of data of driving data in order to parse that you can't do it on a single machine you have to do large-scale distributed compute and large-scale distributed storage and finally the the stuff that's the most exciting that people that there's this class and many classes and much of the literature is focused on is the algorithms the deep learning algorithms the machine learning algorithms the algorithms that learn from data of course that's really exciting and important but what we find time and time again in real world systems is that as long as these algorithms learn from data so as long as this deep learning the data is what's much more important of course it's nice for the algorithms to be calibration free meaning they learn to calibrate self calibrate we don't need to have the sensors in an exact same position every time that's a very nice feature the robustness of the system is then generalizable across multiple multiple vehicles and multiple scenarios and one of the key things that comes up time again time and time again and we'll mention today is a lot of the algorithms developed in deep learning are really focused for computer vision are focused on single images now the real world is happens in both space and time and we have to have algorithms that both capture the visual characteristics but also look at the sequence of images sequence of those digital characteristics that form the temporal dynamics the physics of this world so it's nice when those algorithms are able to capture the physics of the scene the big takeaway I would like if you leave with anything today unfortunately it's that the painful boring stuff of collecting data of cleaning that data of annotating that data in order to create successful systems is much more important than good algorithms or great algorithms it's important to have good algorithms as long as you have neural networks that learn from that data okay so today I'll talk I like to talk about human imperfections and the various detection problems the pedestrian body pose glance and motion cognitive load estimation that we can use to help those humans as they operate in the driving context and finally try to continue with the idea of the vision that fully autonomous vehicles as some of our guest speakers have spoke about and sterling anis will speak about tomorrow is really far away that the humans will be an integral part of the operating cooperating with the AI systems and I will continue on on that line of thought to try to motivate why we need to continuously approach the autonomous vehicle the self-driving car paradigm in the human centered way okay first before we talk about human imperfections let's just pause and acknowledge that humans are amazing we're actually really good at a lot of things that's sometimes sort of fun to talk about how much called terrible of drivers who are how distracted we are how irrational we are but we're actually really damn good at driving here's a video of stadia our soccer player messi the best soccer player in the world obviously and the state-of-the-art robot on the right same thing well there's it's not playing but I assure you the American Ninja Warrior Casey is is uh is far superior to the DARPA humanoid robotics systems shown on the right okay so continuing and the line of thought to challenge to challenge us here that humans are amazing is you know there's record high in 2016 in the United States there was over forty thousand since uh many years it's across the forty thousand fatalities mark more than forty thousand people died in car crashes in the United States but that's in three point two trillion miles traveled so that's one fatality per eighty million miles that's one in 625 chance of dying in a car crash in your lifetime interesting side fact for anyone in the United States folks who live in Massachusetts are the least likely to die in a car crash Montana is the most likely so for every one that thinks of Boston drives is terrible maybe that adds some perspective here's a visualization of ways data across a period of a day showing you the rich blood of the city that the the traffic flow of the city the people getting from A to B and a mass scale and doing it surviving doing it okay humans are amazing but they're also flawed texting sources of distraction with a smartphone the eating the secondary tasks of talking to other passengers grooming reading using navigation system yes sometimes watching video and manually adjusting or adjusting the radio and 3,000 people were killed and 400,000 were injured in motor vehicle crashes vaulted involving distraction in 2014 distraction is a it's a very serious issue for safety texting every day more and more people text smartphones are proliferating our society 170 billion text messages are sent in the United States every month that's in 2014 you can only imagine what it is today eyes off road for five seconds is the average time your eyes off the road while texting five seconds if you're traveling 55 miles an hour in that five seconds that's enough time to cover the length of a football field so you're blindfolded you're not looking at the road in five seconds the average time of texting you're covering the entire football field eight so many things can happen in that moment of time that's distraction drunk driving 31% of traffic fatalities involve a drunk driver drunk driving 23% of nighttime drivers tested positive for a legal prescription or over-the-counter medication distracted driving as I said is a huge safety risk drowsy driving people driving tired nearly three percent of all traffic fatalities involve a drowsy driver if you are uncomfortable with videos that involve risk I urge you to look away these are videos collected by Triple A of teenagers a very large-scale naturalistic driving data set and it's capturing clips of teenagers being distracted on their smartphone [Music] once you take it in the problem we're against so in the cutting context of human imperfections we have to ask ourselves is the human centered approach to autonomy in systems autonomous vehicles that are using artificial intelligence to aid the driving task do we want to go as I mentioned a couple of lectures ago the human centered way or the full autonomy way the tempting path is towards full autonomy where we removed this imperfect flawed human from the picture altogether and focus on the robotics problem of perception and control and planning and driving policy or do we work together human and machine to improve the safety to alleviate distraction to bring drive our attention back to the road and use artificial intelligence to increase safety through collaboration human robot interaction versus removing the human completely from the picture as I've mentioned as as sterling will certainly talk about tomorrow and and rightfully so and yesterday or on Tuesday Emilio has talked about the elf four-way is grounded in literature it's grounded in common sense since in some sense it's you can count on the fact that humans the the natural flaws of human beings to over trust to misbehave to be irrational about their risk estimates will result in improper use of the technology and that leads to what I've showed before the public perception of what drivers do and semi autonomous vehicles they begin to over trust the moment the system works well they begin to over trust they begin to do stuff they're not supposed to be doing in the car taking it for granted a recent video that somebody posted this is a common sort of more practical concern that people have is while the traditional ways to ensure the physical engagement of the driver is by saying they should touch the wheel the the steering wheel every once in a while and of course there's ways to buy the need to touch the steering wheel some people hang objects like I can off of the steering wheel in this case brilliantly I have to say they shove an orange into the into the wheel to make the touch sensor fire and therefore be able to take their hands off the autopilot and that that kind of idea makes us believe that there's no way that you know humans will find a way to misuse this technology however I believe that that's not giving the technology enough credit artificial intelligence systems if are they're able to perceive the human being are also able to work with the human being and that's what I'd like to talk about today teaching cars to perceive the human being and it all starts with data it's all about data as I mentioned data is everything in these real world systems with the MIT naturalistic driving data set of 25 vehicles of which 25 and 21 and equipped with Tesla autopilot we instrument them this is what we do the data collection two cameras on the driver will see the cameras on the face capturing high-definition video of the face that's where we get the glance classification the emotion recognition cognitive load everything coming from the face that we have another camera or a fisheye that's looking at the body of the driver and that from that comes the body pose estimation hands on wheel activity recognition and then one video looking out for the full scene segmentation for all the scene perception tasks and everything is being recorded synchronized together with GPS with audio with all the can covered from the car on a single device synchronization of this data is critical so that's one road trip in the data where thousands like it traveling hundreds of miles sometimes hundreds of miles under automated control and autopilot that's the data again as I said data is everything and from this data we can both gain understanding what people do which is really important to understand how autonomy successful autonomy can be deployed in the real world and to design algorithms as for training for training the deep learning the deep neural networks in order to perform the perception tasks better twenty five beagles 21 Tesla's Model S Model X and now model three over a thousand miles collected a day every single day we have thousands of miles in the Boston Massachusetts area driving around all of that video being recorded now over five billion video frames there are several ways to look at autonomy one of the big ones is safety that's what everybody talks about how do we make these things safe but the other one is enjoyment do people actually want to use it it we can create a perfectly safe system we can create it right now we've had it for ever before even cars a car that never moves is a perfectly safe system well not perfectly but almost and but it doesn't provide a service that's valuable it doesn't provide an enjoyable driving experience so okay what about slow moving vehicles that's an open question the reality is with these Tesla vehicles and l2 systems doing automated driving people are driving 33% of miles using Tesla autopilot what does that mean that means that people are getting value from it they a large fraction of their driving is done an automated way that's value that's enjoyment the glance suffocation algorithm we'll talk about today is used as one example that we use to understand what's in this data shown with the bar graphs there and the red and the blue red is during manual driving blues during autopilot driving and we look at glance classification regions of where drivers are looking on road and off-road and if that distribution changes with automated driving or manual driving and would these glass classification methods we can determine that there's not much difference at least until you dig into the details which we haven't done and the aggregate there's not a significant difference that means people are getting value enjoying using these technologies but yet they're staying attentive or at least not attentive but physically engaged when your eyes are on the road you might not be attentive but you're at the very least physically your body's position in such a way your head is looking at the forward roadway that you're physically in position to be alert and to take in the forward roadway so they're using it and they don't over trust it and that's I think the sweet spot that human-robot interaction needs to achieve is the human gaining through experience through exploration through trial and error exploring and understanding the limitation of the system to a degree that over trust can occur that seems to be happening in this system and using the computer vision methods I'll talk about we can continue to explore how that can be achieved in other systems when the when the when the fraction of automated driving increases from 30% to 40% to 50% and so on it's all about the data and I'll I'll harp on this again the algorithms are interesting you know I will mention of course it's the same convolution neural networks it's the same networks that take in raw pixels and extract features of interest it's 3d convolutional neural networks that take into sequences of images and extract the temporal dynamics along with the visual characteristic for the individual images it's RN and zoella's TMS that use the convolutional neural networks to extract features and over time look at the dynamics and the images these are pretty basic architecture is the same kind of deep neural network architectures but they rely fundamentally and deeply on the data on real-world data so let's start where perhaps on the human sensing side it all began which is pedestrian detection decades ago to put it in con texe pedestrian detection here shown from left to right on the left is green showing the easier human sensing tasks tasks of sensing some aspect to a human being but as for your detection which is detecting the full body of a human being in an image or video is one of the easier computer vision tasks and on the right under in the red microcircuits these are the tremors of the eye or measuring the pupil diameter or measuring the cognitive load or the fine blink dynamics of the eye the velocity of the blink micro glances and I pose are much harder problems so you think body pose estimation pedestrian detection phase classification detection recognition head pose estimation all those are easier tasks anything that starts getting smaller looking at the eye and everything that start getting fine-grained there's much more difficult so we start at the easiest pedestrian detection and as the usual challenges of all of computer vision we've talked about as the various styles of appearance so the inter class variation the different possible articulations of put it of our bodies superseded only perhaps by cats but as humans are pretty flexible as well the presence of occlusion from the accessories that we wear to occluding self occlusion and including each other but that crowded scenes have a lot of humans in them and they include each other and therefore to be able to disambiguate to figure out each individual pedestrians is a very challenging problem so how do people approach this problem well there is I need to extract features from raw pixels whether that was hot cascades hog or CNN the through the decades the sliding window approach was used because the pedestrians can be small in an image or big so there's the problem of scale so you use a sliding window to detect where that pedestrian is you have a classifier that's given a single image such as this that's you're not you take that classify you slide across the image to find where all the pedestrians of scene are so you can use non neural network methods or you can use convolution neural networks for that classifier it's extremely inefficient then came along our CNN fast our CNN fast our CNN these are networks that as opposed to doing a complete sliding window approach are much more intelligent clever about generating the candidates to consider so as opposed to considering every possible position of a window different scales of the window they generate more a small subset of candidates that are more likely and finally using a CNN classify for those candidates whether there's a pedestrian or not whether the there's an object of interest or not a face or not and using that maximum suppression because there's overlapping bounding boxes to figure out what is the most likely bounding box around this pedestrian around this object that's our CNN and there's a lot of variants now with masks our CNN really the state-of-the-art localization Network mask also adds to this on top of the body box also performed segmentation there's voxel net which does three-dimensional and light our data uses localization and point clouds so it's not just using it to the images but in 3d but it's it's it's all kind of grounded in the our CNN framework ok data so we have large-scale data collection going on here in Cambridge if you've seen cameras a lidar various intersections throughout MIT we're part of that so for example here's one of the intersections to collecting about 10 hours a day instrumenting it with various sensors I'll mention but we see about 12,000 pedestrians a day across that particular intersection using 4k cameras using stereo vision cameras 360 now the insta 360 which is an 8k 360 camera gopro lidar various sizes the 64 channel of the 6 and recording this is where this is the this is where the data comes from this is from the 360 video this is from the lidar data of the same intersection this is for the 4k camcorders pointing at a different intersection and the different than capturing the entire 360 view with the vehicles approaching in the pedestrians making crossing decisions this is understanding the negotiation that pedestrian is the nonverbal negotiation that pedestrians perform and choosing to cross or not especially when they're jaywalking and everybody jaywalks especially if you're familiar with this particular intersection there's more Jay walkers than non jaywalkers it's a fascinating one and so we record everything about the driver and everything about the pedestrians again our CNN this is where it comes in is you do Bonney box detection of the pedestrians here are the vehicles as well and allows you to convert this raw data into hours of pedestrian crossing decisions and begin to interpret it that's pedestrian detection bounding box for body pose estimation is the more difficult task body pose estimation is also finding the joints the hands the elbows the shoulders the hips knees feet the landmark points in the image XY position that marked that those joints that's body pose estimation so why is that important in driving for example it's it's important to determine the vertical position or the alignment of the driver the seatbelts and the sort of the the airbag testing is always performing the seatbelt testing is performed with the dummy considering the frontal position in a standard dummy position the the greater greater degrees of automation comes more capability and flexibility for the driver to get misaligned from the standard corner dummy position and so body pose or at least upper body pose estimation allows you to determine how often these drivers get out of line from the standard position the general movement and then you can look at hands on wheel smartphone smartphone detection activity and help add context to glance estimation that which we'll talk about so some of the more traditional methods were sequential is detecting first the head and then stepping detecting the shoulders the elbows the hands the depot's holistic view which has been the very powerful successful way for multi person pose estimation is performing a regression of detecting body parts from the entire image it's not sequentially stitching bodies together it's detecting the left elbow the right elbow the hands individually it's performing that detection and then stitching everything together afterwards allowing you to deal with the crazy deformations of the body that happened the occlusions and so on because you don't need all the joints to be visible and with this cascade of pose regressors meaning these are convolutional neural networks had taken a raw image and produce an XY position of their estimate of each individual joint input as an image output is an estimate of a joint of elbow shoulder whatever one of several landmarks and then you can build on top of that every estimation zooms in on that particular area and performs a finer and finer grain estimation of the exact position of the Joye repeating it over and over and over so through this process we can do part detection and multi-person and multi-person scene that contain multiple people so we can detect the the head the neck here the hands the elbows shown in the various images on the right that don't have an understanding who the head the elbows the the hands belong to it's just performing a detection without trying to do individual person detection first and then finally connecting or not finally but next step is connecting with part affinity fields is connecting those parts together so first you detect individual parts then you connect them together and then through bipartite matching you determine which is who is that each individual body part most likely belonging to so you kind of stitch the different people together in the scene after the detection is performed with the CNN we use this approach for detecting the upper body specifically the shoulders the neck and the head eyes nose ears that is used to determine the the position of the driver relative to the standard dummy position for example looking during autopilot driving 30-minute periods we can look at on the x-axis is time and the y-axis is the position of the neck point that I pointed out in the previous slide that the the the midpoint between the two shoulders the neck is the position over time relative to where it began this is the slouching the sinking into the seat allowing the car to know that information and allowing us or the designers of safety systems and all that information is really important we can use the same body pose algorithm to from the perspective of the vehicle outside the vehicle perspective so the vehicle looking out is doing the as opposed to just plain pedestrian detection using body pose estimation again here in Kendall Square vehicles crossing observing pedestrians making crossing decisions and performing body pose estimation which allows you to then generate visualizations like this and gain understanding like this on the x-axis is time on the y-axis is on the top plot in blue is the speed of the vehicle the speed of the vehicle the ego vehicle from which the camera is observing the scene and on the bottom in green up and down as a binary value whether the Podesta when the pedestrian is not looking at the car one when the pedestrian is looking at the car so we can look at thousands of episodes like this crossing decisions nonverbal communication decisions and determine using body pose estimation the dynamics of this nonverbal here just nearby by media lab crossing there's a pedestrian approaches we can look in green there when the pedestrian glasses looks away glasses the car looks away fascinating glance behavior that happens interesting most people look away before they cross same thing here this is just an example we have thousands of these body pose estimation allows you to get this fine-grained information about the pedestrian glance behavior pedestrian body behavior hesitation glass classification one of the most important things in driving is determining where drivers are looking it if there's any sensing that I advocate and is has the most impact in the driving context is for the car to know where the driver is looking and at the very crude region level information of is the driver looking on road or off road that's what we mean by glance classification it's not the standard gaze estimation problem of X Y Z determining where the eye pose and the head pose combined to determine where the driver is looking no this is classifying two regions on road off-road or six regions on road off road left right center stack rearview mirror and instrument cluster so it's region based glance allocation not the geometric gaze estimation problem why is that important it allows you to address it as a machine learning problem it's a subtle but critical point every problem we try to solve in human sensing in driver sensing has to be learn about from data otherwise it's not it's not amenable to application in the real world we can't design systems in the lab that are deployed without learning if they involve a human it's possible to do slam localization by having really good sensors and doing localization using those sensors without much learning it's not possible to design systems that deal with lighting variability and the full variability of human behavior without being able to learn so gaze estimation the geometric approach of finding the landmarks in the face and from those landmarks determining the the Jeremie the orientation of the head and the orientation of the eyes there's no learning there outside of actually training the systems to detect the different landmarks if we convert this into a gaze classification problem shown here glass classification is when taking the raw video stream determining in post so humans are annotating this video is the driver which region the driver is looking at that's we're able to do by converting the problem into a simple variant of classification on-road off-road left-right the same can be done for pedestrians left forward right it can annotate regions of where they are looking and using that kind of classification approach determine are they looking at the cars or not are they looking away are they looking at their smartphone without doing the 3d gaze estimation again it's a subtle point but think about it if you wanted to estimate exactly where they're looking you need that ground truth you don't have that ground truth unless you there there's no in the real world data there's no way to get the information about where exactly people were looking you're only inferring so you have to convert it into a region based classification problem in order to be able to train your networks on this and the pipeline is the same the source video here the face the the 30 frames a second video coming in of the drivers face of the human face there is some degree of calibration that's required you have to determine approximately where the sensor is that's taking in the image especially for the glance classification task because its region based needs to be able to estimate where the forward roadway is where the the camera frame is relative the world frame the video stabilization and the face front elevation all the basic processing they've removed the vibration of the noise that remove the physical movement of the head that removed the shaking of the car in order to be able to determine stuff about eye movement and blink dynamics and finally with the neural networks there is nothing left except taking in the raw video of the face for the glass classification tasks and the eye for the cognitive load tasks raw pixels that's the input to these networks and the output is whatever the training data is and we'll mention each one so whether that's cognitive load glance emotion drowsiness the input is the raw pixels and the output is whatever you have data for data is everything here the face an alignment problem which is a traditional geometric approach to this problem is designing algorithms that are able to detect accurately the individual landmarks in the face and from that estimate the geometry of the head pose for the class of in version we perform the same kind of alignment or with the same kind of face detection in alignment to determine where the head is but once we have that we pass in just the raw pixels and perform the classification on that as opposed to doing the estimation its classification allowing you to perform what's shown there on the bottom is the real-time classification of where the driver is looking Road left right center stack instrument cluster and rearview mirror and as I mentioned annotation tooling is key so we have a total 5 billion video frames one and a half billion of the face that would take tens of millions of dollars to annotate just for the glass classification fully so we have to figure out what to annotate in order to trade and you'll networks to perform this task and what we annotate is the things that the network is not confident about the moments of highlighting variation the partial occlusions from the light or self occlusion and the moving out of frame the outer frame occlusions all the difficult cases going from frame to frame to frame here and the different pipeline starting at the table going at the bottom whenever the classification has a low confidence we pass it to the human it's simple we rely on the human only when the classifier is not confident and the fundamental trade-off in all of these systems is what is the accuracy we're willing to put up with here in red and blue and red is human choice decision and blue as a machine tasks in red we select the video we want to classify in blue the the the neural network performs the face detection task localizing the camera choosing what is the angle of the camera and provides a trade opportunity and percent frames it can annotate so certainly and you'll networking at a glance for the entire data set they would achieve accuracy in the case of glass classification of nine low 90% classification on the sixth glass task now if you want a higher accuracy that it will only be able to achieve that for us for a smaller fraction of frames that's the choice and then a human has to go in and perform the annotation of the frames that the algorithm was not confident about and it repeats over and over the algorithm is then trained on the frames that were annotated by the human and repeats this process over and over on the frames until everything is annotated yes yes absolutely the question was do you ever observe that the classifier is highly confident about the incorrect class yep right question was hot well then how do you how do you deal with that how do you account for that how do you account for the fact that highly confident predictions can be highly wrong yeah false positives false positives that you're really confident in there there's no at least in our experience there's no good answer for that except more more and more training data on the things you're not confident about that usually seems to deal generalize over cases we don't encounter obvious large categories of data where you're really confident about the wrong thing usually some degree of human annotation fixes most problems annotating the low the low confidence part of the data solves all incorrect issues but of course that's not always true in the general case that you can imagine a lot of scenarios whether that's not true for example one one one thing they always perform is for each individual person we usually entertain a large amount of the data manually no matter what so we have to make sure that the neural network has seen that person in the various and the various ways their face looks like with glasses with different hair with different a lighting variation so we want to manually annotate that it's overtime we're allowing the machine to do more and more of the work so what's resulting in this in the glance classification cases you can do real-time classification you can give the car information about whether the driver is looking on road or off road this is critical information for the car to understand and you want to pause for a second to realize that when you're driving a car for those our driver for those that driven any kind of car with any kind of automation it has no idea about what you're up to at all there's no it doesn't have any information about the driver except if they're touching the steering wheel or not more and more now with the GM supercruise vehicle and Tesla now has added a dryer facing camera that slowly started to think about moving towards perceiving the driver but most vehicles on the road today have no knowledge of the driver this knowledge is almost common sense and trivial for the car to have the it's common sense how important this information is where the driver is looking that's the glance classification problem and again emphasizing that we've converted it's been three decades of work on gaze estimation yet gaze estimation is doing head pose estimation so the geometric orientation of the head combining the orientation of the eyes and using that combined information to determine where the person is looking will convert that into a classification problem so the standard gaze estimation definition is not a machine learning problem classification is a machine learning problem this transformation is key emotion human emotion is a fascinating thing so the same kind of pipeline stabilization cleaning of the data raw pixels in and then the classification is emotion the problem with emotion if I may speak as an expert human not am NOT an expert in emotion is just an expert of being human is that there is a lot of ways that's a sodomize emotion to categorize emotion to define emotion whether that's for the the primary emotion of the para scale would love joy surprise anger sadness fear there's a lot of ways to mix those together to break those apart into hierarchical taxonomies and the way we think about it in the driving context at least there is a general emotion recognition task sort of I mentioned I'll mention it but it's kind of how we think about primary emotions is detecting the the broad categories of emotion of joy and anger of disgust and surprise and then there is application specific emotion recognition where you're using the facial expressions that all the various ways that we can deform our face to communicate information to determine the specific question about the interaction of the driver so I'll first for the general case these are the building blocks I mean there's there's countless ways of deforming the face that we use to communicate with each other there's 42 individual facial muscles that can be used to form those expressions one of our favorite work with is the effective SDK this is their their their task with the general emotion recognition task is taking in raw pixels and determining categories of emotion very subtleties of that emotion in the general case producing a classification of anger disgust fear surprise so on and then mapping I mean essentially what these algorithms are doing whether whether they using deep neural networks or not whether using face alignment to do the landmark detection and then tracking those landmarks over time to do the facial actions they're determined they're mapping the expressions the component their various expressions who can make with their eyebrows or their nose and mouth and eyes to map them to the emotion so I'd like to highlight one because I think it's an illustrative one for joy an expression of joy is smiling so there's an increased likelihood that you observe a smiling expression on the face when joy is experienced or vice versa if there's an increased probability of a smile there's an increased probability of emotion of joy being experienced and then joy an experience has a decreased probability likelihood of brow raising and brow following so if you see a smile that's a that's a plus for joy if you see brow raised bright for Oh brow furrow is a minus for joy that's for the general emotional recognition task that's been well studied that's sort of the core of affective computing movement from from the visual perspective again from the computer vision perspective from the application of specific perspective which were really focused on again data is everything what what are you annotating we can take here we have a large-scale data set of drivers interacting with a voice based navigation system so they're tasked with in various vehicles to enter a navigation so with they're talking to their GPS using their voice this is for depending on the vehicle depending on the system in most cases an incredibly frustrating experience so we have them perform this task and then the annotation is self-report after the task they say on a scale of 1 to 10 how frustrating was this experience and when you see on top is is the expressions detected and associated with a satisfied a person who said a a 10 on the satisfaction so a 1 in the frustration scale was perfectly satisfied with a voice based interaction on the bottom is frustrated as a believin 9 on the frustration scale so the feature the strongest there the expression remember joy smile was the strongest indicator of frustration for all our subjects that was the strongest expression smile was the thing that was always there for frustration there's other various frowning that followed and shaking the head and so on but smiles were there so that shows you the kind of clean difference between general emotion recognition tasks and the application-specific here perhaps they enjoyed an absurd moment of joy at the frustration that were experiencing you can sort of get philosophical about it but the practical nature is they were frustrated with the experience and we're using the 42 most of the face to make expressions to do classification of frustrated or not and their data does the work not the algorithms it's the annotation a quick mention for the AGI class next week for the artificial general intelligence class one of the competition's we're doing is we have a JavaScript face that's trained with a neural network to form various expressions to communicate with the observer so we're interested in creating emotion which is a nice mirror coupling of the emotional recognition problem it's gonna be super cool cognitive load we're starting to get to the eyes cognitive load is the degree to which a human being is accessing their memory or as Lawson thought how hard they're working in their mind to recollect something to think about something as cognitive load and to do a quick pause of eyes as the window to cognitive load eyes the window to the mind there's a different ways the eyes move so there's pupils the black part of the eye they can expand and and contract based on various factors including the lighting variations in the scene but they also expand and contract based on cognitive load that's a that's a strong signal they can also move around there's ballistic movement saccades when we look around eyes jump around the scene they can also do something called smooth pursuit when you and connecting to our animal past you can see a delicious meal flying by or running by that your eyes can follow it perfectly they're not jumping around so when we read a book our eyes are using saccadic movements where they jump around and when the purse muth pursuit the eye is moving perfectly smoothly those are the kinds of movements who have to work with and cognitive load can be detected by looking at various factors of the eye the blink dynamics the eye movement and the eye the pupil diameter the problem is in the real world and real world data with lighting variations everything goes out the window in terms of using pupil diameter which is the standard way to measure non-contact way to measure cognitive load in the lab when you can control lighting conditions and use infrared cameras when you can't all that goes out the window and all you have is the blink dynamics and the eye movement so neural networks to the rescue 3d convolutional neural networks in this case we take a sequences of images that I through time and use 3d convolutions as opposed to 2d convolutions on the left is everything we've talked about previous to this as 2d convolutions when the convolution filter is operating on the XY 2d image every channel is operated on by the filter individual separately 3d convolutions combine those convolve across the across multiple images across multiple channels therefore being able to learn the dynamics of the scene through time as well not just spatially temporal and data data is everything for a cognitive load we have in this case 92 drivers so how do we sort of perform the cognitive load classification task we have these drivers driving on the highway and performing the what's called the n-back task zero back one back to back and that task involves hearing numbers being read to you and then recalling those numbers one at a time so one zero back the system gives you a number seven and then you have to just say that number back seven and it keeps repeating that's easy it's supposed to be the easy task one back is when you hear number you have to remember it and then that for the next number you have to say the number previous to that so you kind of have to keep one number in your memory always and not get distracted by the new information coming up but to back you have to do that two numbers back so you have to use memory more and more went to back so cognitive load is higher and higher okay so what do we do we use face alignment face front elevation and detecting the eye closest to the camera and extract the eye region and now we have this nice raw pixels of the eye region across six seconds of video and we take that and put that in as a 3d convolutional neural network and classify simply one of three classes zero back one back and two back so we have a ton of data of people on the highway performing these tasks and back tasks and that forms the classification supervised learning training data that's it the input is 90 images it's at 15 frames a second and the output is one of three classes face fronto ization i should mention is the technique developed under for face recognition because most face recognition tasks require frontal face orientation is also what we use here to normalize everything that we can focus in on the exact blink it's taking the it's taking whatever the orientation of the face and projecting into the frontal position taking the raw pixels of the face is detecting the eye region zooming in and grabbing the eye where you find and this is where the intuition builds it it's a fascinating one what's being plotted here is the relative movement of the pupil the relative movement of the eye based on a different cognitive loads for cognitive load on the left of zero so when your mind is not that lost in thought and cognitive load of two on the right when it is lost in thought the eye moves a lot less eye is more focused on the forward roadway that's an interesting finding but it's only in aggregate and that's what the neural neural network is task would do it with extracting an a frame-by-frame basis this is a standard 3d convolutional architecture again taking in the image sequence is the input cognitive load classification is the output and classifying on the right is the accuracy that's able to achieve of 86% that's pretty cool from real-world data the idea is that you can just plop in a webcam get the video going in going into the neural network and this predicting it continued a stream from zero to two of cognitive load because every single zero want back one back to back classes are have a confidence that's associated with them so you can turn that into a real value between zero and two and when you see here's a plot of three of the people on the team here driving a car performing a task of conversation and in white showing the cognitive load frame by frame a thirty frames a second estimating the cognitive load of each of the drivers on from zero to two on the y-axis so these are high cognitive load and showing in on the bottom red and yellow of high medium cognitive load and when everybody's silent the cognitive load goes down so we can perform now with this simple neural network with the training data that we formed we can extend that to any arbitrary new data set and generalize okay those are some examples of Chania neural networks can be applied and why is this important again is while we focus on the sort of the perception tasks of using neural networks of using sensors and signal processing to determine where we are in the world where the different obstacles are informed trajectories around those obstacles we are still far away from completely solving that problem I would argue 20 plus years away the human will have to be involved and so when it's the system is not able to control when the system is not able to perceive when there's some flawed aspect about the perception or the driving policy the human has to be involved and that's where we have to know let the car know what the human is doing that's the essential element of human robot interaction the most popular car in the United States today is the Ford f-150 no automation the thing that sort of inspires us and makes us think that transportation can be fundamentally transformed is the Google self-driving mo our and although our guest speakers and all the folks work in the autonomous vehicles but if you look at it the only people who are at a mass scale or beginning to are actually injecting automation into our daily lives is the ones in between it's the Tesla's the l2 systems it's the tesla system the supercruise the audio as 90s the the vehicles that are slowly adding to some degree of automation and teaching human beings how to interact with that automation and here's again the the the path towards mass scale automation we're steering wheels removed the consideration that humans removed I believe is more than two decades away on the path to that we have to understand and create successful human robot interaction approach autonomous vehicles autonomous systems in a human centered way the mass scale integration of these systems of the human center systems like to test the vehicles a Tesla is just a small company right now the the kind of l2 technologies have not truly penetrated the the market have not penetrated that our vehicles even the Brittain the new vehicles being released today I believe that happens in the early 2020s and that's going to form the core of our algorithms that will eventually lead to the full autonomy all of that data what I mentioned with Tesla with a 32% miles being driven all of that is training data for the algorithms the edge cases arise there that's where we get all this data in our data set at MIT is 400,000 miles Tesla has a billion miles so that that's all training data on the way on the stairway to mass scale automation why is this important beautiful and fundamental to the role of AI in society I believe that self-driving cars when they're in this way are focused on a human robot interaction our personal robots they're not perception control systems tools like a Roomba performing a particular task when human life is a steak when there's a fundamental transfer between of life of a human being giving their life over to an AI system directly one on one is a transfer that is kind of a relationship that is one indicative of a personal robot this is it requires all the things of understanding communication of trust these are fascinating to understand how a human and robot can form trust enough to create a really an almost one-to-one understanding of each other's mental state learn from each other oh boy so one of my favorite movies Good Will Hunting we're in Boston Cambridge have two have two gonna regret this one this is Robin Williams speaking about human imperfections so I'd like you to take this quote and replace every time you mentioned girl with car people call those things imperfections Robin Williams is talking about his wife who passed away in the movie talking about her imperfections they call these things imperfections but they're not that's the good stuff and then we'll get to choose who we let into our weird little worlds you're not perfect sport and let me save you the suspense this girl you met she isn't perfect to you there you know what let me just the video sequences that only I know about that's what made her my wife when she had a puts on me - she all my pet dogs people call these things into fashions suffice no need to choose we learn to obviate the words in my breath explore things in suspense he has an air attack but the question is what am i perfect for each other [Music] [Music] so the approach we're taking in building the autonomous vehicle we are here at MIT in our group it's the human centered approach the autonomous vehicles they were going to release in March of 2018 in the streets of Boston those who would to help please do I will talk run a course on deep learning for understanding the humans of Chi 2018 will be going through tutorials that go far beyond the visual the convolutional neural network based detection of various aspects of the face and body would look at natural language processing voice recognition and Gans if you're going to Chi please join next week we have an incredible course that's aims to understand to begin to explore the nature of intelligence natural and artificial we have Josh Tenenbaum Ray Kurzweil Lisa Barret Nate Dubinsky looking at cognitive modeling architectures Andre karpati Stephen Wolfram Richard Moyes talking about autonomous weapon systems and AI safety mark Robert from Boston Dynamics and the amazing incredible robots I have and Ilya sutskever from open AI and myself so what next for folks register for this course you have to submit by tonight a deep traffic entry that achieves a speed of 65 miles an hour and I hope you continue to submit more that win the competition the high performer award will be given to folks the very few folks who achieved 70 miles an hour faster we will continue rolling out seg fuse having hit a few snags and invested a few thousands of dollars in the sanitation process of annotating a large-scale data set for you guys we'll continue this competition that will take us into into a submission to his nips where we'd hope to submit the results for this competition and deep crash the deeper enforcement learning these competitions will continue through May 2018 I hope you stay tuned and participate there's upcoming classes the a GI class I encourage you to come to is going to be fascinating and there's so many cool interesting ideas that we're going to explore it's gonna be awesome there's an introduction to deep learning course that I'm also part of will get a little bit more applied and get folks who are interested in the the very basic algorithms of deep learning how to get started with those hands-on and there's an awesome class that ran last year for those who took this class last year we also talked about it on the the global business of AI and robotics the slides are online I encourage you to click a link on there and register it's in the spring it's once a week and it's truly brings together a lot of cross-disciplinary folks to talk about ideas of artificial intelligence and the role of AI and robotics and society it's an awesome class and if you're interested in applying deep learning methods in the automotive space come work with us we have a lot of fascinating problems to to solve or collaborate so with that I'd like to thank everybody here everybody across the community that's been contributing we have thousands of submissions coming in for deep traffic and I'm just truly humbled by the support we've been getting and the team behind this class is incredible thank you to Nvidia Google Amazon Alexa auto live in Toyota and today we have shirts extra large extra extra large medium over there small and large over there the big and small people over here and then the medium-sized people over here so just grab it grab one and enjoy thank you very much [Applause]"}], "Nuts and Bolts of Applying Deep Learning (Andrew Ng)": [{"content": "so you know when we're uh organizing this Workshop My My co-organizers initially asked me hey Andrew end of the first day go give a Visionary talk so until uh several hours ago my talk was advertised as Visionary talk um but until but but I Was preparing for this presentation over the last several days um I tried to think what what would be the most useful information to you um and what are the things that you know you could take back to work on Monday and and do something different at your job next Monday and I thought that um Mr context right now as pet mentioned I lead BYU's AI team so team about a thousand people working on Vision speech NLP you know lots of applications of machine learning and so what I thought I'd do instead is um instead of taking the shiniest pieces of deep learning that I know I want to take the lessons that I saw at BYU that are common to so many different um academic areas as well as applications and you know autonomous cause augmented reality uh advertising uh web search um medical diagnosis with take what of the common lessons the simple powerful ideas that I've seen help drive a lot of machine learning progress at BYU and I thought I will um share those ideas of you because the patterns I see across a lot of projects I thought might be the patterns that would be most useful to you as well whatever you are working on in the next several weeks or months um so one common theme that will appear in in this presentation today is that the workflow of organizing machine learning projects feels like parts of it are changing in in the era of deep learning so for example one of the ideas I talk about is bias variance this is a super old idea right and then you know many of you maybe all of you have heard of buyers and variance but in the era of deep learning I feel like there have been some changes to the way we think about buyers and variance so we want to talk about some of these ideas which maybe aren't even deep learning per se but um have been slowly shifting as as we apply deep learning to more and more of our applications okay oh and um instead of holding all your questions until the end you know if you have a question in the middle feel free to raise your hand and well I'm very happy to take questions in the middle since this is a more maybe informal whiteboard talk right and also we want to say hi to all home viewers hi right so um you know one question that I still get asked sometimes is um and kind Andre alluded to this earlier a lot of the basic ideas of deep learning have been around for decades so why are they taking off just now right why is it that deep learning these neon networks have all know for maybe decades why why are they working so well now so I think that um the one biggest Trend in deep learning the the is is is scale that scale drives deep learning progress um and uh I think Andrea mentioned scale of data and scale of computation um and I'm just draw a picture that illustrates that concept maybe a little bit more right so if I plot a figure where on the horizontal axis I plot um the amount of data we have for a problem and on the vertic iCal axis we plot you know performance right so x-axis is the amount of spam data you've collected y AIS is how accurately can you classify spam um then if you apply you know traditional learning algorithms right what we found was that the performance often looks like it starts to Plateau after a while what was as if the older generations of learning algorithms including you know support V what logistic regression as the was as if they didn't know what to do with all the data that we finally had and what happened kind of over the last 20 years last last 10 years was with the rise of the internet rise of Mobile Rise of iot where as a society sort of marched to the right of this curve right for for for for many problems not all problems and so um with all the buzz and all the hype about deep learning in my opinion the number one reason um that deep learning algs work so well is that if you train going to call a small neuronet maybe you get slightly better performance um if you train a mediumsized neuronet right maybe get even better performance and is only if you train a large neuronet that you could train a model with the capacity to absorb all this data that we have access to that allows you to get the best as possible performance and so I feel like this is a trend that we' seen in many verticals in many application areas um couple comments one is that um this uh you know actually when I draw this picture some people ask me well does this mean a small neuronet always dominates a traditional learning algorithm and the answer is not really uh technically if you look at the small data regime if you look at the left end of this plot right um the relative ordering of these algorithms is not that well defined it depends on who's more motivated to engineer the features better right so if if you know the svm guy is more motivated to spend more time Eng doing features they might beat out the uh uh the the the neuron Network application but um uh because when you don't have much data a lot of the knowledge of the algorithm comes from hand engineering right but so but this trend is much more evident in the regime of Big Data where you just can't hand engineer enough features uh and and and the large interet combined with a lot of data tends to outperform so couple of the comments um the ification of this figure is that in order to get the best performance in order to hit that Target uh you need two things right one is you need to train a very large NE Network or reasonably large NE Network and you need um a large amount of data and so this in turn has caused pressure to train large near net Nets right build large Nets as well as get huge amounts of data so one of the other interesting Trends I've seen is that um increasingly um it I'm I'm finding that it makes sense to build an AI team as well as build a computer systems team and have the two teams kind of sit next to each other and the reason I say that is um I guess uh so let's see what so when when we started you know bu research we said our team that way other teams are also organized this way I think Peter mentioned to me that open AI also has a systems team and a and a and a machine learning team and the reason we're starting to organize our teams that way I think is that um some of the computer systems work we do right so we have an HPC team high performance team super Computing team at BYU some of the extremely specialized knowledge in HPC is just incredibly difficult for for an AI researcher to learn right some people are super smart maybe maybe Jeff Dean is smart enough to learn everything but but it's just difficult for any one human to be sufficiently expert in HPC and sufficiently expert in um uh uh in in machine learning and so we've been finding and and shubo actually one of the co-organizers is on our HPC team we've been finding that bring Talent from that Knowledge from these multiple sources multiple communities allows us to get our best performance um I want to you know you've heard a lot of present heard a lot of fantastic presentations today I want to draw one other picture which is um in my mind this is how I mentally bucket you know work in in in deep learning so this might be a useful calization right when you look at the talk you can mentally put each talk into one of these buckers I'm about to draw um but I feel like there's a lot of work on I'm G to call you know General DL General models and this would basically what the type of model that Hugo lell talked about this morning where you have you know really densely connected layers right um I guess FC right was was the so there's a huge bucket of models there um and then I think a second bucket is um sequence models so 1D sequences um and this is where I would Buck could lot the work on rnns uh you know lstms right grus um some of the attention models which I guess probably yosha r talk about tomorrow or maybe maybe maybe others maybe quas I'm not sure right um but so the 1D sequence models is another huge bucket um the third bucket is the image models um this is really 2D and maybe sometimes 3D but this is where I would tend to bucket all the work of CNN convolutional Nets and then in my mental bucket then then there's a fourth one which is the other right and this includes uh unsupervised learning you know uh uh uh the reinforcement learning right as well as lots of other creative ideas um being explored L and you like what I still find slow fature analysis B coding um U uh you know a various models kind of in the other category super exciting so it turns out that if you look across industry today um almost all the value today is driven by these three bucket right so what I mean is uh those three buckers of algorithms are you know driving causing us to have much better products right or or monetizing very well it's just incredibly useful for lots of things um in some ways I think this bucket might be the future of AI right so I find UNS supervised learning especially super exciting uh so so I'm I'm actually super excited about this as well um although I think that if you know on Monday you have a job and you're trying to like build a product or whatever the chance of you using something from one of these three buckets will be will be highest um but I definitely encourage you to contribute to research here as well right so um I said the trend one the the major Trends one of deep learning is scale um this is what I would say is maybe major Trend two of of two of two Trends this is not going to go on forever right um is I feel major Trend too is um the rise of endtoend deep learning uh for Rich especially for Rich outputs and so um end to end deep learning I'll say a little bit more in a second exactly what I mean by that but the examples I'm going to talk about are all from one of these three buckets right General DL sequence models image 2D 3D models um but let's see best Illustrated a few examples um until recently a lot of machine learning used to Output just real numbers you know so I guess in Richard's uh uh example you have Ave movie review right and then actually but I prepared totally different examples I was editing the my examples earlier to to to be more coherent with the speakers before me um but we have a movie review and then output the sentiment you know is this a positive or A negative movie review um or you might have an image right and then you want to do uh image nit object recognition you know so this would be a01 output this might be a integer from 1 to 1,00 but so until recently a lot of machine learning was about out putting a single number maybe a real number maybe an integer um and I think the the the number two major Trend that I'm really excited about is um enter and de learning algorithms that can output much more complex things than numbers and so one example that you've seen is a image captioning where instead of taking an image and saying this is a cat you can now take an image and output you know an entire string of texts using RNN to generate that sequence so I guess uh what um Andre who spoke just now I think Oro vendal uh uh shoe at BYU right a whole bunch of people have have have worked on this problem um one of the things that I guess uh my my my collaborator Adam coats will talk about tomorrow uh maybe Quark as well not sure is um speech recognition where you take as input audio and you directly output you know the text transcript right and so um when we first propose using this kind of ENT in architecture to do speech recognition this was very controversial we're building my work of Alex Graves uh but the idea of actually putting this in the production speech system was very very controversial when we first you know said we wanted to do this but I think the whole Community is coming around to this point of view more recently um or you know machine translation say go from English to French right soas qu others uh working on there a lot of teams now um or you know given the parameters um synthesize a brand new image right and and and you saw some examples of image synthesis so I feel like the the the second major trend of of of deep learning that that I find very exciting and and I mean this allowing us to build you know transformative things that we just couldn't build three or four years ago has this trend toward not just learning algorithms an output not just a number that can output very complicated things like a sentence or caption or French sentence or image or or or or or let the recent wavenet paper output audio right so I think this is a maybe the second um major Trend so um despite all the excitement um about endtoend deep learning um I think that end to end deep learning you know sadly is not the solution to everything um I want to give you some rules of thumb for deciding when to use what is exactly an learning and when to use it and when not to use it so was moving the second bullet and we'll go through these so the trend toward end to end deep learning has been um this idea that instead of engineering a lot of intermediate representations maybe you can go directly from your Ro input to whatever you want to predict right so for example actually a take I'm going to use speech as a recurring example uh so for speech recognition um previously one used to go from the audio to you know hand engineered features like mfccs or something and then maybe extract phon names right um and then eventually you try to generate the transcript um oh for those of you that aren't sure what a phone name is so uh if you look at the word listen to the word cat and the word kick the sound right is the same sound and so pH names are this uh um basic units of sound such as c as a pH name and is um hypothesized by linguist to be the basic unit of sound so C would be the maybe the three pH names that make up the word cat right so traditional speech systems used to used to do this uh and I think 2011 leang and Jeff Hinton um made a lot of progress in speech recognition by saying we can use deep learning to do this first step um but the end to end approach to this would be to say let's forget about phes let's just have a neuronet right input the audio and output the transcript um so it turns out that in some problems this's endtoend approach so one end is the input the other end is the output so the phrase end to end deep learning refers to uh just having a neuronet or you know like a learning algorithm directly go from input output that's that's what n to end means um this ENT end formula uh is I think it makes for what great PR uh and and it's actually very simple but it only works sometimes um and actually maybe maybe say this interesting story you know this end to-end story we really upset a lot of people um when we were doing this work I guess I guess I used to go around and say I think PHS are a fantasy of linguists um and we should do away with them and I still remember there was a meeting at Stanford and some of you know who it was there was a linguist kind of yelling at me in public for saying that so maybe maybe I should not H we turned out to be right yeah so all right um so let's see um but the the the Ares heel of a lot of deep learning is that you need tons of label data right so if this is your X and that's your y then for endtoend deep learning to work you need a ton of label you know input output data X comma y so to take an example where um um where you know one may or may not consider ENT deep learning um this is a problem I learned about just last week from ctis langas and and Doin who's in the audience I think of uh imagine you want to use um X-ray pictures of your hand in order to predict the child's age right so this is a real thing you know doctors actually care to look at an x-ray of your of a child's hand in order to predict the the age of the child so um boy let me draw an x-ray image right so this is you know the child's hand so these are the bones right I guess this is why I'm not a doctor okay so that's a hand and and and you see the bones um and so more traditional algorithm my input an image and then first you know extract the bones so first figure out oh there's a bone here there's a bone here there's a bone here and then maybe measure the length of these bones right um so really I'm going to say bone lengths and then maybe has some formula like some regression average some simple thing to go from the bone length to estimate the age of the child right so this is a non-end to-end approach to trying to solve this problem an interent approach would be to take an image and then you know run a convet or whatever and just try to Output the age of a child and I think this is one example of a problem where um it's very challenging to get end to end deep learning to work because you just don't have enough data you just don't have enough X-rays of children's hands annotated with dat ages and instead where we see deep learning coming in is in this step right to use go from image to to figure out where the bones are use deep learning for that but the advantage of this non-end architecture is it allows you to hand engineer in more information about the system such as how bone lengths map age right which which you can kind of get tables about um there are a lot of examples like this and I think one of the unfortunate things about deep learning is that um let's see uh you know you can for for for suitably sexy values of X and Y you could almost always train a model and publish a paper but that doesn't always mean that you know it's actually a good idea Peter I see yeah I see yeah I see yes that's true yes Pet's poting out that in practice you could um uh if this is a fixed function f right you could back propop all the way from the age all the way back to the image yeah that's a good idea actually who was it just said you better do it quickly yeah um Let me give a couple other examples uh uh that where where it might be harder to backdrop all the way through right so here here's an example um take self-driving cars you know most teams are using an architecture where you input an image what's in front of the car let's say and then you you know detect other cars right uh and then and and maybe use the image detect pedestrians right self-driving cars are obviously more complex than this right uh but then now that you know where the other cars and where the posss are relative to your car you then have a planning algorithm uh uh to then you know come up with a trajectory right and then now that you know um what's the trajectory that you want your car to drive through um you could then you know compute the steering direction right let's say and so um this is actually the architecture that most self-driving car teams are using um and you know that have been interesting approaches to to say well I'm going to input an image and I'll put a steering direction right and I think this is an example of where um at least with today's data technology I'd be very is about the second approach and I think if you have enough data the second approach will work and you could even prove a theorem you know showing that it will work I think but um I don't know that anyone today has enough data to make the second approach really really work well right and and I think kind of Peter made a great comment just now and I think you know some of these components will be incredibly complicated you know like this could be a pop Planet ex explicit search and you could actually design a really complicated powerp plan and generic the trajectory and your ability to hand code that still has a lot of value right so this is one thing to watch out for um I have seen project teams say I can get X I can get y I'm G to train deep learning um but unless you actually have the data you know some of these things make for great demos if if you cherry pick the examples but but it can be challenging to um get to work at scale I I should say for self-driving CS this debate is still open I'm I'm cautious about this I don't think is this I don't think this will necessarily fail I just think the data needed to do this will be will be really immense so I I'd be very cautious about and and right now but it might work if you have enough data um so you know one of the themes that comes up in machine learning really if you're work on a machine learning project one thing that'll often come up is um you will you know develop a learning system uh train it maybe doesn't work as well as you're hoping yet and the question is is what do you do next right this is a very common part of a machine learning you know research or a machine learning engineer's life which is you know you you train a model doesn't do what you want it to yet so what do you do next right this happens us all the time um and you face a lot of choices you could collect more data maybe you want to train it longer maybe you want a different neuron Network architecture maybe you want to try regularization maybe you know bigger model for some more gpus so you have a lot of decisions and I think that um a lot of the skill of a machine learning researcher machine learning engineer is knowing how to make these decisions right and and and the difference in performance and whether you you know do you train a bigger model or do you try regularization your skill at picking these decisions will have a huge impact on how rapidly um uh you can make progress on actual machine learning problem so um I want to talk a bit about bias and variance since that's one of the most basic you know Concepts in machine learning and I feel like it's evolving slightly in the era of of of deep learning so to use a as a motiving example um let's say the goal is to build a human level right uh Speech system right speech recognition system okay so um what we would typically do especially in Academia is we'll get a data set you know here's my data set a lot of examples and then we Shuffle it and we randomly split it into 7030 train tests or maybe or maybe 70% train you know 15% Dev and uh 15% test right we oh and uh some people use the term validation set but I'm I'm just use the dep set or stand for development set means the same thing as validation set okay so it's pretty common um and so what we would what what what I encourage you to do if you aren't already is to measure the following things um human level error so let actually let me illustrate an example let's say that on your deel uh uh let's say that um on your death set you know human level error is uh 1% error um let's say that your training set error is um use 5% and let's say that your def set error really very de set is appr proxy for test set except you tune to the dev set right is um you know 6% d okay so this is one of the most basic this this is really a a step in developing a learning Al that I encourage you to do if you aren't already to figure out what are these three numbers because these three numbers um really helps in terms of telling you what to do next so in this example um you see that you're doing much worse than human level performance um and so you see that there's a huge gap here from 1% to 5% and I'm going to call this you know right the bias of your learning algorithm um and for the statisticians in the room I'm using the terms buys and variance informally and doesn't correspond exactly to the way they're defined in textbooks but I find these useful concepts for for for deciding how to make progress on your problem um and so I would say that you know in this example you have a high bias class by try training a bigger model maybe try training longer we come back to this in a second um for a different example you know so this is one example uh for a different example if human level error is 1% and uh training set error with 2% right and death set error was 6% then you know you really have a high what variance problem right like an overfitting problem and this tells you this really tells you what to do what to try right try adding regularization or try um uh uh or try early stopping or um or or or even better we get more data um and then there's also really a third case which is if you have a 1% human level error um I'm going to say 6% death set error oh actually let me say 5% death set error and 10% um excuse me 5% training error and 10% death set error and in this case you have high bias and high variance right um so so I guess yeah High buys and high VAR you know like sucks for you right um so I feel like that when I talk to applied machine learning teams there's one really simple workflow um that is enough to help you make a lot of decisions about what you should be doing on your machine learning application um and by if if you're wondering why I'm talking about this and what this has to do with deepy I'll come back to this in a second right does this change in Era deep learning but uh uh I feel like this is you know almost a workflow like almost a a flow chart right right which is first ask yourself um is your training error high oh and I hope I'm writing big enough that people can see if if you have a trouble reading let me know and I'll and I'll read it back out right but first I ask you know are you even doing well in your training set um and and and if your training error is high then you know you have high bias and so your standard tactics like train a bigger model just train a bigger NE Network um or maybe try training longer you know make sure that your optimization algorithm is is doing a good enough job um and then there's also this magical one which is a new model architecture which is a hard one right um come back to that in a second okay and then you kind of keep doing that until you're doing well at least on your training set once you're at least doing well on your training set so your training error is no longer high so no training error is not unacceptably High um we then ask you know is your death error high right and if the answer is yes then um well if your dep set error is high then you have a high variance problem you have an overfitting problem and so you know the solutions are try to get more data right or add regularization or try a new model architecture right and then until and and you kind of keep doing this until your uh dep set error is is is is no is I guess until both you're doing well on your training set and on your death set and then you know hopefully right you're done so I think one of the um one of the nice things about this era of deep learning is that no matter it's kind of no the way you're stuck with modern deep learning tools we have a clear path for making progress in a way that was not true or at least was much less true in the era before deep learning which is in particular no matter what your problem is overfitting or underfitting uh really high buys or high Varian or maybe both right you always have at least one action you can take which is bigger model or more data so you could so so so in the Deep learning era relative to say the logistic regession era the svm era it feels like we more often have a way out of whatever problem we're stuck in um and so I feel like these days people talk less about buyers variance trade-off you might have heard that term buyers variance trade-off underfitting versus overfitting and the reason we talked a lot about that in the past was because a lot of the moves available to us like tuning regularization that really traded off buyers and variance so it was like a you know zero something right you you could improve one but that makes the other one worse but in the era of deep learning really one of the reasons I think deep learning has been so powerful is that the coupling between buyers and variance can be weaker and we now have tools we now have better tools to you know reduce buyers without increasing variance or reduce variance without increasing buyers and really the bigger the the the big one is really you can always train a bigger model bigger neuron Network in a way that was harder to do when you're training logistic regression is to come up with more and more features right that was just harder to do um so let's see one of the um and I'm I'm going to add more to this diagram at the bottom in a second okay um one of the effects of uh this maybe this and and and by the way I've been surprised I mean honestly um this new model architecture that's really hard right it takes a lot of experience but but even if you aren't super experienced with you know a variety of deep learning models the things in the blue boxes you can often do those and that would drive a lot of progress right but if you have experience with you know how to tune a confet versus a resonet versus Whatever by all means try those things as well definitely encourage you to keep mastering those as well but this dumb formula of more data bigger bigger model more data is enough to do very well on a lot of problems so um let's see uh so bigger model puts pressure on you know systems which is why we we have high performance Computing team um more data has has led to another interesting um set of Investments so uh with you know I guess a lot of us have always what needed that had this insatiable hunger for data we use you know trout sourcing for labeling um uh we try to come with all sorts of clever ways to come to to to get data um one one area that that I'm seeing more and more activity in right it feels a little bit nent but I'm seeing a lot of activity in is um automatic data synthesis right um let's see and so here's what I mean you know once upon a time people used the hand engineer features and there was a lot of skill in hand engineering the features of you know like the CIF or the hog or whatever to feed into svm um automatic data synthesis is this little area that is small but feels like it's growing where there is some hand engineering needed but I'm seeing quite a lot of progress in multiple problems is enabl by hand engineering uh synthetic data in order to feed into the giant mole of your neuron Network right so let me best Illustrated a couple examples um one of the easy ones is OCR so so let's say you want to train a um optical character recognition system and actually I've been surprised that by do this has tons of users actually this is one of my most useful apis that I you right um if you imagine firing up Microsoft Word um and uh downloading a random picture off the Internet then choose a random Microsoft Word font choose a random word in English dictionary and just type the English word into Microsoft Word in a random font and paste that on top you know like a transparent background on top of a random image off the internet then you just synthesize a training example for OCR right um and so this gives you access to essentially unlimited amounts of data it turns out that the simple idea I just described won't work in its natural form you actually need to do a lot of tuning to blur the synthesize text with the background to make sure the color contrast matches your training distribution so found it in practice can be a lot of work to find you and how you synthesize data but I've seen in many verticals um I'll give a few examples if you do that engineering work and sadly it's painful engineering you could actually get a lot of progress actually actually ta Wang uh who was a a student here at Stanford um uh the effect I saw was he engineered this for months with very little progress and then suddenly he got the parameters right and he had huge amounts of data and was able to build one of the best OCR systems in the world at that time right um other examples speech recognition right uh one of the most powerful ideas uh for building a effective speech system is if you take clean audio you know a clean relatively noises audio and take random background sounds and just synthesize what that person's voice would sound like in the presence of that background noise right and this turns out to work remarkably well so if you recall a lot of car noise what the inside of your car sounds like and record a lot of clean audio of someone speaking in a quiet environment um the mathematical operation is actually addition it's superposition of sound but you basically add the two waveforms together and then you get an audio clip that sounds like that person talking in the car and you feed this your learning algorithm and so this has a dramatic effect in in terms of amplifying the training set for speech recognition and has a huge effect can have a we found a huge effect on um performance um and then also NLP you know here here's here's one example actually done by some Stanford students which is um using entend deep learning to do grammar correction so input a ungrammatical English sentence you know maybe written by non-native speaker right and can you automatically have a have a I guess attention RNN input an ungrammatical sentence and correct the grammar just edit the sentence for me um and it turns out that you can synthesize huge amounts of this type of data automatically and so that'll be another example where data synthesis um works very well um and oh and I think uh uh video games in RL right really one of the um well let me just games broadly right one of the most powerful um uh applications of RL deep RL these days is video games and I think if you think supervised learning has an insatable hunger for data wait till you work on AO algorithms right I think the the hunger for data is even greater but when you play video games the advantage of that is you can synthesize almost infinite amounts of data to to feed this even greater more right even greater need that our ARS have um so just one note of caution data synthesis has a lot of limits um I'll tell you one other story um you know let's say you want to recognize cars right uh there are a lot of video games um I need to play more video games what's a video game with cause in it oh GTA Grand Theft Auto right so there a bunch of cars in Grand Theft Auto why we just take pictures of cars from Grand Theft Auto and you can synthesize lots of cars lots of orientations there and paste that give that as training data um it turns out that's difficult to do because from the human perceptual system there might be 20 cars in a game but it looks great to you because you can't tell if there 20 cars in the game or a thousand cars in a game right and so there are situations where the synthetic data set looks great to you because 20 cars in a video game is plenty it turns out uh you don't need a 100 different calls for the human to think it looks realistic but from perspective of learning algorithm this is very impoverished very very poor data set so so I think so so so a lot to be to be sorted out for data synthesis um for those you that work in companies one one practice I would strongly recommend is to have a unified data warehouse right um so what I mean is that if your teams if your you know engineer teams your research teams are going around trying to accumulate the data from lots of different organizations in your company that's just going to be a pain it's going to be slow so um at buo you know our our policy is um it's not your data is a company's data and if it's user data it goes into my user data warehouse uh we we we should have a discussion about user access rights privacy and who can access what data but at BYU I felt very strongly so we we mandate this data needs to come into one loog it's a logical warehous right so it's physically distributed across loss of data censes but they should be in one system and what we should discuss is access rights but what we should not discuss is whether or not to bring together data into as unified a data warehouse as possible and so this is another practice that I found um makes uh access the data just much smoother and allows you know teams to to to to drive performance so really if if if your boss ask you tell them that I said like build a unified data warehouse right so um I want to take the uh train test you know bias variance picture and refine it it turns out that this idea of a 7030 split right train test or whatever this was common in um machine learning kind of in the past when you know frankly most of us an Academia were working on relatively small data sets right and so I know there used to be this thing called the UC Irvine repository for machine learning data sets you know by today's this amazing results at the time but by today standards is quite small and so you download the data set shuffle the data set and you have you know train Dev test and whatever um in today in production machine learning today is much more common for your train and your test distributions to come from different distributions right and and and this creates new problems and new ways of thinking about bu and VAR so let me sure talk about that um so actually here's a concrete example and this is a real example from Buu right what builds a very effective speech recognition system and then recently actually actually quite some time back now we wanted to launch a new product that uses speech recognition um we wanted a speech enabled rear viiew mirror right so you know if you have a car that doesn't have a built-in GPS unit right uh we wanted this is a real product in China we want to let you take out your rearview mirror and put a new you know AI power speech part rearview mirror because it's an easier uh uh like a off the market installation so you can speak to rearview mirror and say dear Rew mirror you know navigate me to whatever right so this is a real product um so so so how do you build a speech recognition system for this incar speech enable rear view mirror um so this is our status right we have you know let's call it 50,000 hours of data from of speech recognition data from all sorts of places right a lot of data we bought some user data that that that we have permission to use but a lot of data collected from all sorts of places but not your incar rear viiew mirror scenario right and then our product managers can go around and you know through quite a lot of work for this example I'm going to say let's say they collect 10 hours more of data from exactly the rear view mirror scenario right so you know install this thing in the car get drive around talk to it you collect 10 hours of data from exactly the distribution that you want to test on so the question is what do you do now right do you throw this 50,000 hours of data away because it's not from the distribution one or or or can you use it in some way um in the older pre deep learning days people used to build very separate models it was more common to build one speech model for rearview mirrror one model model for the maps voice query one model for search one model and in the era of deep learning it's becoming more and more common to just power all the data into one model and let the model sorted out and so long as your model is big enough you could usually do this um and if you do little Tech if you get the features right you could usually pile all the data into one model uh and often see gains butly usually not see any losses but the question is given this data set you know how do you split this into train dep test right so here's one thing you could do which is call this your training set call this your dep set and call this your test set right um turns out this is a bad idea I would not do this and so one of the best practices with with' derived is um make sure your development set and test sets are from the same distribution right I've been finding that this is one of the tips that really boost the effectiveness of a machine learning team um so in particular I would make this the training set and then of my 10 hours let me expand this a little bit right much smaller data set maybe five hours def five hours of tests and the reason for this is um uh your team will be working to tune things on the death set right and the last thing you want is if they spend three months working on the death set and then realize when they finally tested that the test is totally different a lot of work is wasted so I think to make an analogy you know having different dep and test set distributions is a bit like if I tell you hey everyone let's go north right and then a few hours later when when all of you are in Oakland I say where are you wait I want you to be in San Francisco and you go what why' you tell me to go north tell me to go to San Francisco right and so I think having depth and test set be from the same distribution is one of the ideas that I found really optimizes the team's efficiency because it you know the development set which is what your team is going to be tuning as algorithms to that is really the problem specification right and you problem specification tells them to go here but you actually want them to go there you're going to waste a lot of effort um and so when possible having Deen tests from the same distribution which it isn't always there there there's some cavas but when is reason well to do so um this really improves the the the the um the team's efficiency um and another thing is once you specify the de set that's like your problem specification right uh once you start the test set that's your problem specification your team might go and collect more training data or change the training set or synthesize more training set but but you know you shouldn't change the test set if the test set is is is your problem specification right so um so in practice what I actually recommend is splitting a training set as follows um your training set cover a small part of this let me just say 20 hours of data to form I'm going to call this the um training def set train dasde set but that's basically a development set that's from the same distribution as your training Set uh and then you have your depth set and your test set right so these are what you actually from the distribution you actually care about and these you have your training set $50,000 of all sorts of data and maybe we aren't even entirely sure what data this is uh but split off just a small part of this so I guess this is now what 49980 hours and 20 hours um and then here's the generalization of the bias variance concept um actually let me use this board and and but has say the the um the fact that training and test sets don't match is one of the problems that um Academia doesn't study much there's some work on domain adaptation there is some literature on it but it turns out that when you train and test on different distributions you know it it sometimes it's just random is a little bit luck whether you generalize well to a totally different test set so that's made it hard to study systematically which is why I think um Academia has not studied this particular problem as much as I feel it is important for to to those of us building production systems um but there is some work but but not no no no very widely deployed Solutions yet would be would my sense um but so I think our best practice is if if you now generalize what I was describing just now to the following which is um measure human level performance measure your training set performance measure your training death performance measure your death set performance and measure your test set performance right so now you have kind of five numbers so to take an example let's say human level is 1% error um and I'm going to use very obvious examples for illustration if your training set performance is 10% you know and this is 10.1% right uh 10.1% you know 10.2% right in this example then it's quite clear that you have a huge gap between human level performance and training set performance and so you have a huge bias right uh and and and so kind of use the the the bias fixing types of um uh uh Solutions um and then um there just one example I want to well and so I find that the machine learning one of the most useful things is to look at the aggregate error of your system which in this case you know is your depth set your tested era and then to break down the components to to figure out how much of what eror comes from where so you know where to focus your attention so this accumulation of errors this difference here this is maybe 9% bias which is a lot so I would work on the bias reduction techniques uh this Gap here right this is kind of um really the variance this Gap here is due to your train test distribution mismatch um and this is overfitting of Dev okay right um so just to be really concrete um here's an example where you have high train test error mismatch right which is if human level performance is 1% % your training error is you know 2% uh your training death is 2.1% and then on your death Set uh the error suddenly jumps to 10% right so this would sorry my my my my x-axis doesn't perfectly line up but if there's a huge gap here then I would say you have a huge train test set mismatch problem okay um and so at this basic level of analysis what you know this formula for machine learning instead of Dev I would replace this with train Dev right and then in the rest of this uh really recipe for machine learning um I would then ask um is your death error high if yes then you have a train test mismatch problem and there the solution would be to try to get more data uh that's similar to test set right or maybe a data synthesis or data augmentation you know try to tweak your training set to make it look more like your test set um and then there's always this kind of a uh Hail Mary I guess which is you know new architecture right um and then finally just to finish this up you know that that that's not that much more uh finally uh uh there's this yeah well and then hopefully if you're done uh uh hopefully your test set error will be will be good and if if you're doing well your death set but not your test set it means you've overit your death set so just get some more death set data right actually I'll just write this I guess test set error y right and if yes then just get more depth data okay and then done sorry if this is not too legible what I wrote here is uh if your dep set error is not high but your test set error is high it means you've overfit your dep set so just get more test set get more depth set data okay um so one of the um effects I've seen is bias and variance is it sounds so simple but it's actually much diffic much more difficult to apply in practice than it sounds when I talk about it or or on text right so some tips for a lot of problems just calculate these numbers and this can help drive your analysis in terms of deciding what to do um yeah and and I find that it takes surprisingly long to really Gro to really understand bu and variance deeply but I find that people that understand buys and variance deeply are often able to drive very rapid progress in in in machine learning applications right and and I know it's much sexier to show you some cool new network architecture and I don't know and and and and just this really helps our teams make rapid progress on things um so you know there's one thing I I I kind of snuck in here without making it explicit which is that in this whole analysis we were benchmarking against human level performance right so there another Trend another thing that that that has been differenced uh again you know I'm looking across a lot of projects I've seen in many areas and trying to pull out the common Trends but I find that comparing to human level performance is a much more common theme now than several years ago right with with I guess Andre being the uh the the human level Benchmark for image net uh um and and and really by do we compare our speech system to human level performance and try to exceed it and so on so why is that um it turns out that so why why why is human level performance right such a such a common theme in in applied deep learning um it turns out that if um this the x-axis is time as in you know how long you've been working on a project and the y- axis is accuracy right if this is human level performance you know like human level accuracy or human level performance on some task you find that for a lot of projects your teams will make rapid progress you know up until they get to human level performance and then often it will maybe surpass human level performance a bit and then progress often gets much harder after that right but this is a common pattern I see in a lot of problems um so there multiple reasons why this is the case I'm I'm curious like why why why why do you think this is the case any any guesses yeah cool labels are coming from humans the labs are oh cool yep labels coming from humans anything else all right cool anything else oh interesting Ox small out the human brain yeah I don't know maybe I I think the the the the distance from neuronet to human brains is very far so that one I would uh I see human capacity this from similar yeah kind of yeah all close yeah just okay board I see see right cool that's one more and then I'll just oh be satisfied okay cool you're satisfied and bought I guess on two sides of the coin I guess all right so oh defens human man yeah yeah cool so so let let me let me let me uh I think there there all all all you know lots of great answers um I think that there there there are several good reasons for this type of effect um one of them is that um there is for a lot of problems there is some theoretical limit of performance right if if you know some fraction of data is just noisy in speech recognition a lot of audio CPS are just noisy uh someone picked up a phone and you know they're in a rock console or something and it's just impossible to figure out what on Earth they were saying right or some images you know are just so blurry just impossible to figure out what dis is so there is some upper limit theoretical limits of performance um called the optimal error rate right and and the basian will will call this the base rate right but really there is some theoretical Optimum where even if you had the best possible function you know with best possible parameters it cannot do better than that because the input is just noisy and sometimes impossible to label so it turns out that um humans are pretty good at a lot of the tasks we do not all but humans actually pretty good at speech recognition pretty good at computer vision and so you know by the time you surpass human level accuracy there might not be a lot of room right to go to go further up so that's kind of one reason as just humans are pretty good um other reasons I think a couple people said right um and and it turns out that um so long as you're still worse than humans uh you have better levs to make progress right um so you know while while worse than humans um right have good ways uh to make progress and so some of those ways are right a couple of you mentioned this you can get labels from humans right um You can also carry out error analysis and error analysis just means look your death set look the examples your Al got wrong and see you know see if the humans have any insight into why a human thought this is a c AR thought it was a dog or why a human you know recognized this utterance correctly but your system just mistr transcribed this um and then I think another reason is that it's easier to estimate um buas variance effects right and here's what I mean um so let's see to take another confute example let's say that uh you let's say that you're working on some image recognition task right if I tell you that um uh your training error is 8% um and your death error is 10% right well should you work on you know bias reduction techniques that you should work on variance reduction techniques is actually very unclear right if I tell you that humans get 7.5% then you're pretty close on the trading being said to human and you would think you have more of a variance problem if I tell you humans can get 1% 1% error then you know that even on the training side you're doing way worse than humans and so well you should build a bigger Network or something right so this piece of information about where humans are and and I think of humans as a proxy as an approximation for the Bas error rate for the optimal error rate this piece of information really tells you where you should focus your effort and therefore increases the efficiency of your team but once you surpass human level efficiency I mean if if if even humans you know got um a 30% error right then then is is it's just slightly tougher so that's is another thing that that that becomes harder to do that you no longer have a proxy for estimating the base error rate to decide how to improve performance right um so you know there definitely lots of problems where surpass human level performance and keep getting better and better but I find that uh uh a lot of the I find that my life building deep learning applications is often easier until we surpass human level performance which is much better tools and after we surpass human level performance um well actually you one the details what we usually try to do is try to find subsets of data where we still do worse than humans so find let's say so for example right now we surpass human level performance for speech accuracy of for short audio clips taken out of context but we find for example we're still way worse than humans on one particular type of accented speech then even if we are much better than humans in the aggregate if we find what much worse than humans on the subset of data then all these levers still can apply but this kind of an advanced topic maybe where you segment the training center and analyze sub separate subsets of training Cent yeah yeah I see actually you know that's a wonderful question I want to ask a related Qui question to everyone in the audience and we going come back to to to what Alex just said right so um given everything we just said um I have another quiz for you right um I'm going to pose a question uh write down four choices and then ask you to raise your hand to to to to vote what you think is the right answer okay so um I talked about you know how the concept of human level accuracy is useful for driving machine learning progress right so um how do you define human level performance right so here's good example um I'm spend a lot of time working on AI Healthcare so a lot of medical examples in my head right now but let's say that you want to do medical imaging for medical diagnosis you know so read medical images tell your patient a certain disease or not right so um so medical example so my question to you is how do you define human level performance um Choice a is um you know a typical human so non-doctor right let's say that the error rate at Reading a certain type of medical image is 3% right choice B is a typical doctor let's say a typical doctor makes 1% error um or I can find an expert doctor and let's say an expert doctor Mak 0.7% error or I can find a team of expert doctors and what I mean is if I find a team of expert doctors and have a team look at every image and debate and discuss and have them come to you know the team's best guess of what's happening to this patient let's say I can get 0.5% error so think for a few seconds I'll ask you to vote by by by raising your hands which of these is the most useful definition of human level error if you want to use this to drive the performance of your oper okay so who thinks Choice a raise your hand oh sure uh uh uh yeah don't worry about ease of obtaining this data yeah right so which is the most useful definition Choice a who anyone just a couple people choice B who thinks uses Cool like a fifth Choice C exper doctus another fifth Choice D oh cool wow interesting all right so so I'll tell you that um I think that for the purpose of driving machine learning progress I think uh ignoring the cost of collecting data was a great question um I would find this definition the most useful um because I think that um a lot of what we're trying to use human level performance as a proxy for is the base rate is really the optimal error rate right and and really to measure the Baseline level of noise in your data um and so you know if a team of human doctors can get 0.5% then you know that the mathematic optimal error rate has got to be 0.5% or maybe even a little bit better um and so for the purpose of using this number to drive all these decisions such as um estimate bias and variance right uh uh that definition gives you the best you know estimate of bias right um uh because you know that the base error rate is is 0.5 or lower um in practice because of the cost of you know getting labels and so on in practice you know I would fully expect teams to use this definition uh and and and by the way publishing papers is different than um the goal of publishing papers is different than the goal of actually you know building the best possible product right so for the purpose of publishing papers people like to say oh we're better than the human level so for that I guess using this definition would be what many people do um uh and and and if you actually trying to collect data you know there'll be some tearing where right get a typical doctor to label example if they arure hire an expert doctor if they still unsure then find you know so so for the purpose of data collection you you other processes but for the mathematical analysis I would tend to use 0.5 as as as as my definition for that number question the back oh is it possible that team of expert doctors does worse than a single doctor I don't know I I I had to ask the doctors in the audience know all right um all right just just I just two more pages and wrap up um so you know one of the reasons I think in the era of deep learning we uh refer to human level performance much more frankly is because um for a lot of these toss we are approaching human level performance right so when computer vision accuracy you know when when I guess maybe to continue this example right um if you know when your training set accuracy in computer vision was you know 30% and your death error was like 35% then it didn't really matter if human level performance was 1% or 2% or 3% it didn't affect your decision that much because you're just so clearly far so far from base rate but now as really more and more deep learning systems are approaching human levels performance on lot these TS measuring human level performance uh actually gives you very useful information to to to drive decision making and so honestly for a lot of the teams I work with when I meet with them a very common piece of advice is he's going to figure out what is human level performance and and they didn't spend some time to have humans labor and get that number because that number is useful for for for for driving some of these decisions so um just two last things and then we'll finish um you know one question I get asked a lot is um what can AI do really what can deep learning do right um and and I guess maybe passion a company you often you know with the rise of AI I feel like um uh maybe this is again a company thing um in silic Valley we've developed pretty good workflows for Designing products in the desktop era and in the mobile era right so with processes like draw a wireframe the designer draws a wireframe excuse me the the the product manager draws a wireframe the designer does the visual design or something or they work together and then the program implements so we have well-defined workflows for how to design you know typical apps like the Facebook app or the Snapchat app or whatever we sort of know how to design we have workflows established and companies to design stuff like that in the era of AI um I feel like we don't have good processes yet for Designing AI products so for example how should a product manager specify you know I don't know a self-driving C how do you specify the product definition how does a product manager specify what level of accuracy is needed for my cat detector is like how how how so today in Silicon Valley with AI working better and better um I find us inventing new processes in order to design AI product right processes that really didn't exist before but one of the questions I often get asked partially sometimes at product people some business people is what can AI do because when a product manager is trying to design a new thing you know it's nice we can help them know what they can design and what they can design there's no way we can build right so so so so when I so so I want to give you some rules of thumb that are far from perfect but that I found useful for thinking about what AI can do oh oh before I tell you the rules I use um here's one of the rules of thumb that a product manager I know was using which is he says assume that AI can do absolutely anything right and and and and this actually wasn't terrible it actually led to some good results but but I want I want to but I want to give you some some some more Nuance uh uh ways of communicating about modern deep learning um in in in in in these sorts of organizations you know one is um anything that a person a typical person can do in less than one seconds right and I know this rule is far from perfect there a lot of counter examples of this but this is one of the rules I found useful which is that if it's a task that a normal person can do with less than one second of thinking there's a very good chance we can automate it with deep learning so so you know given a piece of given a picture tell me if the face in this picture is smiling or frowning you don't need to think for more than a second so yes we can build deep loading systems and do that really well right um or speech recognition you know like uh listen to this audio clip what did they say you don't need to think for that long less than a second so this is really a lot of the perception work uh uh in computer vision speech um that uh deep learning is working on this rule of thumb works less well NLP I think because humans just take time to vext bit but we found um right now at BYU we're a bunch of product managers looking around for tasks that humans can do in less than one second uh to try to automate them so this been highly thought but but still useful R of thumb um question I see yeah yeah actually great question I feel like a lot of the value of deep learning a lot a lot of the the the concrete short-term applications um a lot of them have been um trying to automate things that people can do uh really especially people can do in a very short time and and this feeds into all the advantages you know when when you're trying to automate something that the human can already do um oh I see oh that's inter observation oh if a human can label in less than a second you can get a lot of data yeah that's observation cool yeah right um and then I think another one the the other huge bucket of deep learning applications that I've seen create tons of value is um uh predicting outcome of the next uh in sequence of events right um but so you know if there's something that happens over and over such as you know maybe not super inspiring we show a user an act right that happens a lot uh uh and and the user clicks on it or doesn't click on it with tons of data to predict if the user will click on the next app probably most lucrative application AI de leading today or you know by do we run a food delivery service so we're seen a lot of data of if you order food from this restaurant to go to this destination at this time of day how long does it take we've seen that a ton of times very good at predicting if you order food how long will take to to to to send this food to you so I feel like I don't know I you know deep learning does so much stuff so I've struggled a bit to come up with simple rules explained to to Really to product managers right how to design around it I found these two rules useful even though I know these are clearly highly FAA and there are many many counter examples right um so I think let's see um say it's exciting find for deep learning because I think it's letting us do a lot of interesting things it's also causing us to rethink how we organize a companies like build a systems team next an AI team how we the work for for process for for for for a product so I think there's a lot of excitement going on um the last thing I want to do is um you know I found that the number one question I get asked is um uh how do you build a career in machine learning right and I think um you know when I when I did a Reddit ask me anything a Reddit AMA that was one of the questions that was asked even today a few people came up to me and said you know taking a machine learning course the machine learning cero or something else um what advice do you have for building a career in machine learning I have to admit I I don't have an amazing answer to that but since I get asked that so often and because I really want to think what would be the most useful content to you I I I thought I'll at least attempt an answer even though it is maybe not a great one right so this is the last thing I had uh at the start which is the kind of personal advice um you know I think that um I was asking myself this same question uh uh uh like a couple months ago right which is you know after you've taken a machine learning course um what's the next step for um developing your machine learning career and at that time I thought um the best thing would be if you attend deep learning school so so so Sammy Peter and I got together to do this I hope um this is really part of motivation um and then and then beyond that right what what are the things that that that really help um so I do have had actually I think all of our organizations we've had quite a lot of people want to move from non-machine learning into machine learning and when I look at the career paths um you know one common thing is after taking these courses to work on a project by yourself right I've seen I have a lot of respect for kago a lot of people actually pass in kago and learn from the blogs there and then and then become better and better at it um but I want to share with you one other thing I haven't really shared oh by the way almost everything I talked about today is is is new content that I've never presented before right so so I I don't know as I hope it worked okay thank you thank you so I want to share of you really the the I want to think of is a PhD student process right which is you know a lot of um uh uh people really when I was teaching full-time at Stanford a lot of people joined Stanford and ask me you know how do I become a machine learning researcher how do I have my own ideas on how to push the bleeding edge of machine learning and um whether you know you're working robotics or machine learning or or something else right there's one PhD student process that I find has been incredibly reliable um and um and and I'm going to say it and you may or may not trust it but I've seen this work so Rel livly so many times that I hope you take my word for it that this process reliably turns non-machine learning researchers into you know I very good machine learning researchers which is um and there's no magic really read a lot of papers and work on replicating results right and I think that the human brain is a remarkable device you know people often ask me how do you have new ideas and I find that um if you read enough papers and replicate enough results you will have new ideas on how to push for this daily art right I I I don't know how the I don't really I don't know how the human brain works but I've seen this be an incredibly reliable process read enough papers and you know between 20 and 50 papers later and it's not one or two it's more like 20 or maybe 50 you will start to have your own ideas and this has been see see sami's nodding his head this is an incredibly reliable process right and then my other piece of advice is um so sometimes people ask me what work in AI is like and I think some people have this picture that when we work on AI you know at BYU or Google open AI or whatever I think some people have this picture of us hanging out in these um Airy you know well-lit rooms with natural plant in the background and we're all standing in front of a whiteboard discussing the future of humanity right and all of you know working on AI is not like that frankly almost all we do is Dirty Work right so one place that I've seen people get tripped up is when they think working on AI is that future of humanity stuff and shy away from the dirty work um and Dirty Work means anything from going on The Intern internet and downloading data and cleaning data or downloading a piece of code and tuning parameters to see what happens or debugging your stack Trace to figure out why this silly thing you know overflowed or optimizing the database or hacking a GPU kernel to make it faster um or reading a paper and struggling to replicate the result um at the end a lot of what we do comes down to Dirty Work and yes there are moments of inspiration but I've seen people really stall if they refuse to get into the dirty work so my advice to you is um and and actually another another place I've seen people stall is if they only do dirty work then then you can become great at data cleaning but but not also not become better and better at having your own moments of inspiration so one of the most reliable formulas I've seen is really if you do both of these you know dig into the Dirty Work like if if your if your if your team needs you to do some dirty work just go and do it but in parallel read a lot of papers and I think the combination of these two is the most reliable formula I've seen for producing great researches right so um I want to close with uh uh uh uh uh uh just one more story about this and I guess some of you may have heard me talk about the the the the Saturday story right but um for those of you that want to advance your career and machine learning um you know next weekend you have a choice right um next weekend you can either stay at home and watch TV uh or or or or or or you could do this right and it turns out this is much harder and then no short-term rewards are doing this right if next weekend I think this weekend you guys are all doing great um um but next weekend if you spend next weekend studying reading papers refering results there are no short-term rewards if you go to work the following Monday your boss doesn't know what you did your peers didn't know what you did no one's going to patch you on the back and say good job you spend all weekend studying um and realistically after working really really hard next weekend you're not actually that much better you're barely any better at your job so there's pretty much no reward for working really really hot all the next weekend um but I think the secret to to to to advancing your career is this if you do this not just for one weekend but do this for weekend after weekend for a year you will become really good at this in fact almost every well everyone I've worked with at Stanford that that that that was close and became great at at at this you know everyone actually including me on a gr we all spent late nights you know hunched over like a neuronet tuning hyper parameters trying to figure out why it wasn't working and it was that process of doing this not just one weekend but weekend after weekend that um that that allow all of us really to to to our brains neuron networks to learn the patterns that that that taught us how to do this um so I hope that you know even after this weekend you keep on uh spending the time to keep learning because I promise that if you do this for long enough you will become really really good at Deep learning um so just to wrap up you know I'm super excited about AI uh been making this analogy that AI is the new electricity right and and what I mean is that just as a 100 years ago um electricity transformed industry after industry right electricity transformed your agriculture manufacturing Transportation Communications um I feel like those of you that are familiar with AI are now in a amazing position to guard and transform not just one industry but potentially a ton of Industries so um I guess at at at at BYU I have a fun job trying to transform not just one industry but multiple Industries but um I see that uh you know it's very rare in the history of in in in human history where one person where someone like you can gain the skills and do the work to have such a huge impact on society um I think in Silicon value the phrase change the world is overused right you know every every stand fit undergrass says I want to change the world but for those of you that work in AI I think that the path from what you do to actually having a big impact on a lot of people and helping a lot of people in transportation and healthare and Logistics and whatever is actually becoming clearer and clearer so so I hope that all of you will you know uh uh uh keep working hard even after this weekend and and go do a bunch of cool stuff for Humanity thank you [Applause] thank you thank you do we make any announcement Sho we're running super late so I'll be around later in F okay so let's break for today and look forward to seeing everyone tomorrow thank you"}], "Deep Learning State of the Art (2019) - MIT": [{"content": "The thing I would very much like to talk about today is\u00a0the state of the art in deep learning. Here we stand in 2019 really at the height of some of the great accomplishments that have happened. But also stand\u00a0at the beginning. And it's up to us to define where this incredible data-driven technology takes us. And so I'd like to talk a little bit about the breakthroughs that happened in 2017 and 2018 that take us to this point. So this lecture is not on the state of the art results on main machine learning benchmarks. So the various image classification and object detection or the NLP benchmarks or the GAN benchmarks. This isn't about the cutting edge algorithm that's available on github that performs best on a particular benchmark. This is about ideas ideas and developments that are at the cutting edge of what defines this exciting field of deep learning. And so I'd like to go through a bunch of different areas that I think they're really exciting. Of course this is also not a lecture that's complete There's other things that may be totally missing that happened in 2017-18 that are particularly exciting to people here and people beyond. For example medical applications of deep learning is something I totally don't touch on. And protein folding and all kinds of applications that there has been some exciting developments from deep mind and so on that don't touch on. So forgive me if your favorite developments are missing but hopefully this encompasses some of the really fundamental things that have happened both on the theory side and the application side and then the community side of all of us being able to work together on this and these kinds of technologies. I think 2018 in terms of deep learning is the year of natural language processing. Many have described this year as the ImageNet moment. In 2012 for computer vision when AlexNet was the first neural network that really gave that big jump\u00a0in performance. And computer vision it started to inspire people what's possible with deep learning with purely learning based methods. In the same way there's been a series of developments from 2016-17 led up to 18 with a development of BERT that has made\u00a0on benchmarks and in our ability to apply\u00a0NLP to solve various NLP tasks, natural language processing tasks a total leap. So let's tell the story of what takes us there."}, {"content": "There's a few developments. I've mentioned a little bit on Monday about the encoder decoder or recurrent neural networks. So this idea of recurrent neural networks encode sequences of data and\u00a0output something, output either a single prediction or another sequence. When the input sequence and the output sequence are not the same, necessarily the same size, they're like in machine translation we have to translate from one language to another the encoder decoder architecture takes the following process. It takes in the sequence of words or the sequence of samples as the input and uses the recurrent units whether LSTM, GRU and beyond and encodes that sentence into a single vector. So forms an embedding of that sentence of what it represent, representation of that sentence. And then feeds that representation in the decoder recurrent neural network that then generates the sequence of words that form the sentence in the language that's being translated to. So first you encode by taking the sequence and mapping it to a fixed size vector representation. And then you decode by taking that fixed size vector representation and unrolling it\u00a0into the sentence that can be of different length than the input sentence. Okay that's the encoder-decoder structure for recurrent neural networks has been very effective for machine translation and dealing with arbitrary length input sequences, arbitrary length output sequences. Next step attention. What is attention? Well it's the next step beyond it's an improvement on the the encoder-decoder architecture. It allows the, it provides a mechanism that allows to look back at the input sequence. So suppose to saying that you have a sequence that's the input sentence and that all gets collapsed into a single vector representation. You're allowed to look back at the particular samples from the input sequence as part of the decoding process. That's attention and you can also learn which aspects are important for which aspects of the decoding process, which aspects the input sequence are important to the output sequence. Visualize in another way and there's a few visualizations here."}, {"content": "They're quite incredible that are done by Jay Alammar. I highly recommend you follow the links and look at the further details of these visualizations of attention. So if we look at neural machine translation the encoder RNN takes a sequence of words and throughout, after every sequence forms a set of hidden representations,\u00a0hidden state that captures the representation of the worlds that followed. And those sets of hidden representations as opposed to being collapsed to a single fixed size vector, are then all pushed forward to the decoder. That are then used by the decoder to translate but in a selective way. Where the decoder here visualized on the y-axis the input language and on the X the output language the decoder weighs the different parts of the input sequence differently in order to determine how to best translate generate the word that forms a translation in the full output sentence. Okay that's attention, allowing expanding the encoder-decoder architecture to allow for\u00a0selective attention to the input sequence as opposed to collapsing everything down into fixed representation. Okay next step self-attention. In the encoding process allowing the encoder to also selectively look informing the hidden representations at other parts of the input sequence in order to form those representations. It\u00a0allows you to determine for certain words. What are the important relevant aspects of the input sequence that can help you encode that word the best? So it improves the encoder process by allowing it to look at the entirety of the context. That's self-attention. Building a transformer. It's using the self attention mechanism in the encoder to form these sets of representations on the input sequence. And then as part of the decoding process follow the same but in reverse with a bunch of self-attention that's\u00a0able to look back again. So it's self attention on the encoder attention on the decoder and that's where the magic, that's where the entirety magic is. That's able to capture the rich context of the input sequence in order to generate in the contextual way the output sequence. So let's take a step back then and look at what is critical to natural language in order to be able to reason about words, construct a language model and be able to reason about the words in order to classify a sentence or translate a sentence or compare two sentences and so on. There the sentences are collections of words or characters and those characters and words have to have an efficient representation that's meaningful for that kind of understanding. And that's what the process of embedding is. We talked a little bit about it on Monday. And so the traditional Word2Vec\u00a0 process of embedding is you use some kind of\u00a0trick in an unsupervised way to map words into into a compressed representation. So language modeling is the process of determining which words follow each other usually. So one way you can use it as in a skip gram model taking a huge datasets of words you know, there's writing all over the place taking those datasets and feeding a neural network that in a supervised way looks at which words are usually follow\u00a0the input. So the input is a word\u00a0the output is which word are statistically likely to follow that word. And the same with the preceding word. And doing this kind of unsupervised learning if you throw away the output and the input and just taking the hidden representation form in the middle that's how you form this compressed embedding a meaningful representation\u00a0that when two words are related in a language modeling sense, two words that are related they're going to be in that representation close to each other. And when they're totally unrelated have nothing to do\u00a0with each other they're far away ELMo is the approach of using bi-directional L STMs to learn that representation. And what bi-directional, bi-directionally? So looking not just the sequence that let up to the word but in both directions the sequence that following, the sequence that before. And that allows you to learn the rich full context of the word. In learning the rich full\u00a0context of the word you're forming representations that are much better able to represent the statistical language model behind the kind of corpus of language that you're you're looking at. And this has taken a big leap in ability to then that for further algorithms then with the language model a reasoning about\u00a0doing things like sentence classification, sentence comparison, so on."}, {"content": "Translation that representation is much more effective for working with language. The idea of the OpenAI transformer is the next step forward is taking the the same transformer that I mentioned previously. The encoder with self-attention decoder with attention looking back at the input\u00a0sequence. And using, taking the language learned by the decoder and using that as a language model and then chopping off layers and training in a specific on a specific language tasks like sentence classification. Now BERT is the thing that did the big leap in performance. With the transformer formulation there is always there's no bi-directional element. There is, it's always moving forward. So the encoding step and the decoding step with BERT is it's richly bi-directional it takes in the full sequence of the sentence and masks out some percentage of the words, 15% of the words. 15% of the samples of tokens from the sequence. And tasks the entire encoding self-attention mechanism to predict the words that are missing. That construct and then you stack a ton of them together. A ton of those encoders self-attention feed-forward network, self attention feed forward network together. And that allows you to learn the rich context of the language to then at the end perform all kinds of tasks. You can create first of all, like Elmo and like Word2Vec, create rich contextual embeddings. Take a set of words and represent them\u00a0in the space that's very efficient to reason with. You can do language classification, you can do settings pair classification, you can do the similarity of two sentences, multiple choice question answering, general question answering, tagging of sentences. okay I'll link it on that one a little bit too long. but it is also the one I'm really excited about and really if there's a breakthrough this year is been it's thanks to BERT. The other thing I'm very excited about is totally jumping away from the new rips, the theory, those kind of academic developments and deep learning and into the world of applied deep learning. So Tesla has a system called Autopilot where the hardware version 2 of that system is a newer\u00a0 implementation of the NVIDIA Drive PX 2 system which runs a ton of neural networks. There's 8 cameras on the car and a variant of the inception network is now taking in all a cameras at different resolutions as input and performing various tasks, like drivable area segmentation, like object detection and some basic localization tasks. So you have now a huge fleet of vehicles where it's\u00a0not engineers some I'm sure engineers but it's really regular consumers, people that have purchased the car have no understanding in many cases of what neural networks limitations the capabilities are so on. Now it has a neural network is controlling the well being has its decisions,\u00a0its perceptions and the control decisions based on those perceptions are controlling the life of a human being. And that to me is one of the great breakthroughs of 17 and 18. In terms of the development\u00a0of what AI can do in a practical sense in impacting the world. And so one billion miles over 1 billion miles have been driven in Autopilot. Now there's two types of systems in currently operating in Tesla's. .There's hardware version 1,\u00a0hardware version 2. Hardware version 1 was Intel Mobileye monocular camera perception system. As far as we know that was not using a neural network. And it was a fix system. That wasn't learning, at least online learning in the Tesla's. The other is hardware version 2 and it's about half and half now in terms of the miles driven. The hardware version 2 has a neural network that's always learning. There's weekly updates. It's always improving the model shipping new weights and so on. That's the exciting set of breakthroughs in terms of AutoML, the dream of automating some aspects or all aspects or many aspects as possible of the machine learning process where you can just drop in a dataset that you're working on and the system will automatically determine all the parameters from the details of the architectures, the size are the architecture, the different modules and then architecture the hyper parameters use for training the architecture running that they're doing the inference everything. All is done for you. All you just feed it is data So that's been the success of the neural architecture search in 16 and 17. And there's been a few ideas with Google AutoML that's really trying to almost create an API we just drop in data set. And it's using reinforcement learning and recurrent neural networks to given a few modules, stitch them together in such a way where the objective function is optimizing the\u00a0performance of the overall system. And they've showed a lot of exciting results. Google showed and others that outperform state of art systems both in terms of efficiency and in terms of accuracy. Now in 18 there've been a few improvements on this direction and one of them is a AdaNet where it's now using the same reinforcement learning AutoML formulation to build ensembles\u00a0on your network. So in many cases state-of-the-art performance can be achieved by as opposed to taking a single architecture, is building up a multitude and ensemble a collection of architectures. And that's what is doing here is given candidate architectures, stitching them together to form an ensemble to get state-of-the-art performance. Now that state of the art performance is not a leap a breakthrough leap forward but it's nevertheless a step forward. And it's a very exciting field that's going to be receiving more and more attention. There's an area of machine learning\u00a0that's heavily under studied and\u00a0I think it's extremely exciting area. And if you look at 2012 with AlexNet achieving the breakthrough performance of showing what deep learning networks are capable of. From that point, from 2012 to today there's been non-stop extremely active developments of different architectures that even on just ImageNet alone on doing the image classification task have\u00a0improved performance\u00a0over and over and over with totally new ideas. Now on the other side on the data side there's been very few ideas about how to do data augmentation. So data augmentation is the process of, you know, it's what kids always do when you learn about an object right? You look at an object and you kind of like twist it around is is taking the raw data and messing it in such a way that it can give you much richer representation of what this can this data can look like in other forms in other contexts in the real world. There's been very few developments I think still and there's this AutoAugment is just a step a tiny step into that direction that I hope that we as a community invest a lot of effort in. So what AutoAugment does? As it says, ok, so there's these data augmentation methods like translating the image, sharing the image, doing color manipulation like color inversion. Let's take those as basic actions you can take and then use reinforcement learning and an RNN again construct to stitch those actions together in such a way\u00a0that can augment data like an ImageNet, you train on the data, it gets\u00a0state-of-the-art performance. So mess with the data in a way that optimizes the way you mess with the data."}, {"content": "So. And then they've also showed that given that the set of data augmentation policies that are learned to optimize for example for ImageNet given the some kind of architecture you can take that learn the set of policies for data augmentation and apply it to a totally different dataset. So there's the process of transfer learning. So what is transfer learning? We talked about transfer learning, you have a neural network that learns to do cat versus dog or no learns to do a\u00a0thousand class classification problem on image. And then you transfer, you chop off few layers and you transfer on the task of your own dataset of cat versus dog. What you're transferring is the weights that are learned on the ImageNet classification task. And now you're then fine-tuning those weights on the specific, personal cat vs. dog dataset you have."}, {"content": "Now you can do the same thing here. You can transfer as part of the transfer learning process, take the data augmentation policies learned on ImageNet, and transfer those. You can transfer both the weights and the policies. That's a really super exciting idea I think."}, {"content": "It wasn't quite demonstrated extremely well here in terms of performance, so it got an improvement in performance and so on, but any kind of inspired an idea that's something that we need to really think about. How to augment data in an interesting way such that given just a few samples of data? We can generate huge data sets in a way that you\u00a0can then form meaningful complex rich representations from. I think that's really exciting in one of the ways that you break open the problem of how do we learn a lot from a little. Training deep neural networks with synthetic data. This also really an exciting topic that a few groups but especially NVIDIA invested a lot in. Here's a from a CVPR2018 probably my favorite work on this topic is they really went crazy and said ok let's mess with synthetic data in every way we could possibly can. So on the left there're shown a set of backgrounds then there's also a set of artificial objects and you have a car or some kind of object that you're trying to classify. So let's take that car and mess with it with every way possible. Apply lighting variation to whatever way possible, rotate everything that is crazy so what NVIDIA is really good at is creating realistic scenes. And they said okay let's create realistic scenes but let's also go away aboveboard and not do realistic at all."}, {"content": "Do things that can't possibly happen in reality. And so generally these huge datasets I\u00a0want to train and again achieve quite interesting quite a quite good performance on image classification. Of course they're trying to apply\u00a0\u00a0to ImageNet and so on these kinds of tasks, you're not going to outperform networks that were trained on ImageNet. But they show that with just a small sample from from those real images they can fine tune this network train on synthetic images, totally fake images to achieve state of the art performance. Again another way to generate, to get, to learn a\u00a0lot for very little by generating fake worlds synthetically. The process of annotation which for supervised learning is what you need to do in order to train the network, you need to be able to provide ground truth, you need to be able to label whatever the entity that is being learned. And so for image classification that's saying what is going on in the image. And part of that was done on ImageNet by doing a Google search for creating candidates. Now saying what's going on in the image is a pretty easy tasks. Then there is the object detection task of detecting the boundary box. And so saying drawing the actual boundary box is a little bit more difficult but\u00a0it's a couple of clicks and so on. Then if we take the finals the probably one of the higher complexity tasks of perception of image understanding is segmentation. It's actually drawing either pixel level or polygons the outline of particular object. Now if you have to annotate that that's extremely costly. So the work with Polygon-RNN is to use recurrent neural networks to make suggestions for polygons. It's really interesting. There's a few tricks to form these high-resolution polygons. So the idea is it drops in a single point you draw a boundary box around an object. You use convolutional neural networks to drop the first point. And then use recurrent neural networks to draw around it. And the performance is really good There's a few tricks and this tool is available online. It's a really interesting idea again the\u00a0dream with AutoML is to remove the human from the picture as much as possible. With data augmentation remove the human from the picture as much as possible for a menial data. Automate the boring stuff and in this case the act of drawing a polygon tried to automated as much as possible. The interesting other dimension along which deep\u00a0learning is recently being trying to be optimized is how do we make deep learning accessible. Fast, cheap, accessible. So the DAWNBench from Stanford the benchmark the DAWNBench benchmark from Stanford asked formulated an interesting competition, which got a lot of attention and a lot of progress. It's saying if we want to achieve 93% accuracy on ImageNet and 94% on CIFAR10, let's now compete, that's like the requirement, let's now compete how you can do it in the least amount of time and for the least amount of dollars. Do the training in the least amount of time and the training in the least amount of dollars like literally dollars you are allowed to spend to do this."}, {"content": "And fast AI you know it's a renegade awesome renegade group of deep learning researchers have been able to train on ImageNet in 3 hours. So this is for training process for 25 bucks. So training a network that achieves 93% accuracy for 25 bucks, and 94% accuracy for 26 cents on CIFAR10. So the key idea that they were playing with is quite simple. But really boils down to messing with the learning rate throughout the process of training. So the learning rate is how much you based on the loss function based on the error the neural network observes, how much do you adjust the weights. So they found that if they crank up the\u00a0learning rate while decreasing the momentum, which is a parameter of the optimization process, and they do it that jointly they're able to make the network learn really fast. That's really exciting and the benchmark itself is also really exciting because that's exactly for people sitting in this room that opens up the door to doing all kinds of\u00a0fundamental deep learning problems without the resources of Google DeepMind or OpenAI or Facebook or so on, without computational resources. That's important for academia that's important for independent researchers and so on."}, {"content": "So GANs. There's been a lot of work on generative adversarial neural networks. And in some ways there has not been breakthrough ideas in GANs for quite a bit. And I think began from Google DeepMind an ability to generate incredibly high-resolution images. And it's the same GAN technique, so in terms of breakthroughs and innovations\u00a0but scaled. So the increase the model capacity and increase the the batch size the number of images that are fed that are fed to the network. It produces incredible images I encourage you to go online and and look at them It's hard to believe that they're generated. So that was 2018 for GANs was a year of scaling and parameter tuning as opposed to breakthrough new ideas. Video-to-Video Synthesis. This work is from NVIDIA is looking at the problem so there's been a lot of work on general going from image to image. So from a particular image generating another image. So whether it's colorizing an image or just to traditionally define GANs. The idea with video to video synthesis that a few people have been working on but NVIDIA took a good step forward is to make the video to make the temporal consistency the temporal dynamics part of the optimization process. So make it look not jumpy. So if you look here at the comparison the for this particular. So the input is the labels on the top left and the output of the of the NVIDIA approach is on the bottom right. See it's temper it's very temporarily consistent. If you look at the image to image mapping that's that state the pix2pixHD. It's very jumpy, it's not temporally consistent at all."}, {"content": "And there's some naive approaches for trying to maintain temporal consistency."}, {"content": "That's in the bottom left. So you can apply this to all kinds of tasks all kinds of video to video mapping. Here is mapping it to face edges. Edge detection on faces mapping it to faces. Generating faces from just edges. You can look at body pose to actual images. As an input to the network you can take the pose of the person and generate the\u00a0\u00a0video of the person. Okay semantic segmentation. The problem of perception, so if began with AlexNet and ImageNet has been further and further developments where the input, the problem is of basic image classification, where the input is an image and the output is a classification was going on in that image and the fundamental architecture can be reused for more complex tasks like detection like segmentation and so on, interpreting what's going on in the image. So these large networks from VGGNet, GoogLeNet, ResNet, SENet, DenseNet all these\u00a0networks are forming rich representations that can then be used for all kinds of tasks whether that task is object detection. This here shown is the region based methods where the neural network is tasked the convolutional layers make region proposals."}, {"content": "So much of candidates to be considered. And then there's a step that's determining what's in those different regions and forming boundary boxes around them in a for-loop way. And then there is the one-shot method single-shot method where in a single pass all of the boundary boxes in their classes generated. And there has been a tremendous amount of work in the space of object detection. Some are single shot method, some are region based methods. And there's been a lot of exciting work but not more not I\u00a0would say breakthrough ideas. And then we take it to the highest level of perception which is semantic segmentation. There's also been a lot of work there the state of the art performance is at least for the open source systems is DeepLabv3+ on the PASCAL VOC challenge. So semantic segmentation and catch it all up started 2014 with fully convolution neural networks. Chopping off the fully connected layers and then outputting the heatmap very grainy very low resolution. Then improving that was SegNet performing maxpooling with a breakthrough idea that's reused in a lot of cases is Dilated Convolution, Atrous convolutions having some spacing which increases the field of view of the convolutional filter. The key idea behind DeepLabv3 that is the state of the art is the multi-scale processing. Without increasing the parameters the multi scale is achieved by the \"atrous rate\" So taking those atrous convolutions and increasing the spacing. And you can think of the increasing that spacing by enlarging the model's field of view. And so you can consider all these different scales of processing and looking at the at the layers of features. So allowing you to be able to grasp the greater context as part of the upsampling deconvolutional step. And that's what's produced in the state of art performances and that's where we have the tutorial on github\u00a0showing this DeepLab architecture trained on CityScapes. CityScapes is a driving segmentation data set that is one of the most commonly used for the task of driving scene segmentation. Okay on the deep reinforcement learning for."}, {"content": "So this is touching a bit a bit on the 2017. But i think the excitement really settled in 2018 as the work from Google and from OpenAI, DeepMind. So it started in DQN paper from Google DeepMind where they beat a bunch of a bunch of Atari games achieving superhuman performance with deep reinforcement learning methods. That are taking in just the raw pixels of the game, so the same kind of architecture is able to learn how to beat these, how to beat these games. Super exciting idea that kind of has echoes of what general intelligence is. Taking in the raw raw information and being able to understand the game, the sort of physics of the game sufficient to be able to beat it. Then in 2016 AlphaGo with some supervision and some playing against itself, self play, some supervised learning on expert\u00a0world champ players and some self play where it plays against itself was able to beat the top of the world champion at Go. And then 2017 AlphaGo Zero a specialized version of Alpha Zero was able to beat the AlphaGo with just a few days of training. and zero supervision from expert games. So through the process of self play again this is kind of getting the human out of the picture more and more and more which is why Alpha Zero is probably\u00a0or this AlphaGo Zero was the demonstration of the cleanest demonstration of all the nice progress in deep reinforcement learning. I think if we look at the history of AI when you're sitting on a porch hundred years from now sort of reminiscing back Alpha Zero will be a thing that people will remember as an interesting moment in time, as a key moment in time. And Alpha Zero was applied in 2017 to beat. Alpha Zero paper was in 2017 and it was this year played StockFish in chess which is the best engine, chess playing engines is able to beat it with just four hours of training of course the four hours this caveat. Because four hours for Google DeepMind is highly distributed training. So it's not four hours for an undergraduate student sitting in their dorm room. But meaning it was able to self play to very\u00a0quickly learn to beat the state of the art chess engine. And learned to beat the state of the art Shogi engine Elmo. And the interesting thing here is you know with perfect information games like chess you have a tree and you have all the decisions you could possibly make and so the farther along you look at along that tree presumably the better you do. That's how DeepBlue beat Kasparov in the 90s is you just look as far as possible in a down the tree to determine which is the action is the most optimal. If you look at the way human grandmasters think it certainly doesn't feel like they're like looking down a tree. There's something like creative intuition there's something like you can see\u00a0the patterns in the board, you can do a few calculations but really it's an order of hundreds. It's not on the order of millions or billions which is kind of the the StockFish the state of the art chess engine approach. And Alpha Zero is moving closer and closer closer towards the human\u00a0grandmaster\u00a0concerning very few future moves. It's able through the neural network estimator that's\u00a0estimating the quality of the move and\u00a0the quality of the different, the current quality of the board and and the quality of the moves that follow. It's able to do much much less look ahead. So the neural network learns the fundamental information just like when a grandmaster looks at a board they can tell how good that is. So that's again interesting, it's a step towards at least echoes of what human intelligence is in this very structured formal constrained world of chess and go and shogi. And then there's the other side of the world that's messy. It's still games. It's still constrained in that way but OpenAI has taken on the challenge of playing games that are much messier\u00a0to have this resemblance of the real world and the fact that you have to do teamwork, you have to look at long time horizons with huge amounts of imperfect information, hidden information, uncertainty. So within that world they've taken on the\u00a0challenge of a popular game Dota 2."}, {"content": "On the human side of that there's the competition the international hosted every year where you know in 2018 the winning team gets 11 million dollars. So it's a very popular very active competition has been going on for a few years. They've been improving and it achieved a lot of interesting milestones in 2017. Their 1v1 bot beat the top professional Dota 2 player. The way you achieve great things is as you try. And in 2018 they tried to go 5v5. The OpenAI team lost two games a go against the top Dota 2 players at the 2018 international. And of course their ranking here the MMR ranking in Dota 2 has been increasing over and over but there's a lot of challenges here that make it extremely difficult. To beat the human players and this is, you know, in every story rocky or whatever you think about losing is essential element of a story that leads to then a movie in a book and the greatness. So you better believe that they're coming back next year."}, {"content": "And there's going to be a lot\u00a0of exciting developments there. It also, Dota 2 and this particular video game makes it currently this really two games that have the public eye in terms of AI taking on his benchmarks. So we saw go incredible accomplishment What's next? So last year the associate were the best paper in Europe's. There was the heads up Texas No Limit Hold'em AI was able to beat the top level players was completely current well not completely but currently\u00a0out of reach is the general not heads up one versus one but the general team Texas No Limit Hold'em here you go. And on the gaming side this dream of\u00a0Dota 2 now that's the benchmark that everybody's targeting. And it's actually incredibly difficult one and some people think would be a long time before we can win. And on the more practical side of things\u00a0the 2018, start in 2017 has been a year of of the frameworks growing up of maturing and creating ecosystems around them. With TensorFlow with the history there dating back a few years has really with TensorFlow 1.0\u00a0as come to be sort of a mature framework PyTorch 1.0 came out 2018 is matured as well. And now the really exciting developments\u00a0in the TensorFlow with the eager execution\u00a0and beyond that's coming out TensorFlow 2.0 in in 2019. So really those two players have made incredible leaps in standardizing deep learning. In the fact that a lot of the ideas I talked about today and Monday and we'll keep talking about are all have a github repository with implementations in TensorFlow and PyTorch. Making extremely accessible and that's really exciting. it's probably best to quote Geoff Hinton the \"Godfather\" of deep learning, one of the key people behind backpropagation said recently on backpropagation is \"My view is throw it all away and start\u00a0again\" His believes backpropagation is totally broken and an idea that has ancient and it needs to be completely revolutionized and the practical protocol for doing that\u00a0is he said the future depends on some graduate student who's deeply suspicious of everything I've said that's probably a good way\u00a0to end the discussion\u00a0about what the state of the art in deep learning holds because everything we're doing is fundamentally based on ideas from the 60s and the 80s and really in terms of new ideas, there has not been many new ideas especially the state of the art results that I've mentioned are all based on fundamentally, on stochastic gradient descent and backpropagation. It's ripe for totally new ideas. So it's up to us to define the real breakthroughs and the real state of the art 2019 and beyond. So that I'd like to thank you and the stuff is on the website deeplearning.mit.edu."}], "7. Category Selectivity, Controversies, and MVPA": [{"content": "all right so i'm going to finish up some of the things that i talked about with experimental design last time and then we're going to get on and talk about category selective regions in the cortex which of course we've been talking about in various ways all along but i'll raise some general controversies about that some alternative views from the kind of one that i've been foisting on you and what i consider to be some of the strongest most important evidence against the view that i've been putting forth here and then we'll talk about decoding signals from brains okay that's the agenda here we go okay so last time i had you guys work in groups to think about experimental design because really most decisions about experimental design once you know the bare basics of the measure measurement methods they're just applying common sense thinking about what it's like for the subject how are you going to get the data you need so in terms of what exact conditions to run in any experiment i talked about the idea of a minimal pair this kind of platonic ideal of the perfect contrast which never exists in reality but that you aspire toward so ideally you want two conditions that are identical except for the one little thing that you're interested in okay and you don't want to have other things that co-vary with that thing you're manipulating other than the thing you're interested in and that's the crux of the matter in experimental design okay you guys talked about what kind of tasks have subjects do in the scanner there's a trade-off between kind of doing the most natural thing which is they're just lying there and stimuli come visual auditory whatever versus the fact that subjects might fall asleep if they have nothing to do and if they fall asleep you won't know and that's not good so it's sometimes better to have a task to keep them awake and to tell you that they're awake a key important point don't have one task for one stimulus condition and a different task for a different stimulus condition if you did that would be a sorry confound exactly that would be a confound okay don't do that um we talked about baseline conditions um so for example in a vision experiment staring at a dot or a cross is a kind of as as far as you can go in turning off your visual system why would you want to bother with that um well it's sometimes useful um to have that kind of baseline because we want we sometimes want to look not just at a difference between two conditions remember one condition alone in mri tells you not a damn thing all we can see is differences but even just two conditions showing you a difference that's something but it can be ambiguous so for example if you had a situation like this where there was a response in some brain region to the red condition here in the green condition there they're just two numbers that's all you have uh that is different that's kind of meh you know there's a difference but meh right but if you have a good baseline and you really know that zero is zero um or as close to zero as you can get and now imagine if zero was here that'd be like wow that's a really strong effect and especially in neuroscience where we care a lot as you may have noticed about selectivity about how much more we get a response in one condition than another and cell activities are usually more interesting as a ratio than as a difference as i'm illustrating here and so you can't get a ratio unless you have a third condition usually a baseline all right a few other things we talked about how you allocate subjects to conditions you could have all your subjects do you know one half of the subjects do the face condition for an hour in the scanner another half of your subjects do the object condition for an hour in the scanner that's no good we don't want to do that we want to within subjects design we want all the conditions within a subject whenever we can do that why well my best analogy to this is suppose we decided to grade your assignments as follows a third of the class is going to be graded only by heather this third of the class is going to be graded only by dana across the whole semester you guys are heather people you guys are dana people you guys are anya people is that fair no that's dumb what if heather's a hard ass and she is kind of a hard ass right [Laughter] not that you guys aren't they're they're all the pretty tough crew there i stand here just waiting for the gong to go wrong and you guys should do that i'm sure i've already said wrong things and you know it so next time sound the gong and correct me anyway that wouldn't be fair in grading exams and neither is a good and experimental design so for all the same reasons that you guys can hopefully get an intuition here you want to have all the conditions within a person because maybe one person's brain just activates more than another person's brain maybe this person had more coffee coffee increases your bold response we give away free espresso beans chocolate espresso beans before scans in my lab to increase the mri response okay all of that do designs within subjects whenever possible okay how do you allocate conditions to runs these kind of subsets of a whole hour-long experiment where you scan people for maybe five minutes at a time and give them a break and another five minutes well the same logic applies imagine you're in a scanner for an hour you're getting sleepy you're getting bored you're thinking about other things you're kind of not on the ball those things change over slow periods of time and so you want to get all those conditions together within a run just as you want to get conditions together within a subject whenever possible okay okay and so then we didn't really get into this and i think you did in your groups but how do we stick all these conditions together within a run do we clump them together in a batch or we do we interleave them and i think most of you guys realize that there's a there's this deep set of trade-offs there um and so you know here's a block what's sometimes called the block design where you clump a condition a whole bunch of trials with one condition then a whole bunch of trials of another with in this case some kind of baseline in between right versus a mixed interleaved condition which is called event related for uninteresting historical reasons um and if it's event related you can have it slow or fast okay so why what what are the why wouldn't you um what are the reasons okay what are the reasons to do this rather than that many of you guys came up with this last time so nothing earth sorry minion lights on biases yeah yeah what kind of biases in a blocked experiment they might be biased by what they've been looking for yeah all kinds of biases like consider this trial here in a yellow condition well you just did a bunch of yellow trials so maybe your yellow system is adapted out or something or biased somehow but you also know that the next one's going to be yellow and there's all that previous stuff and anticipatory stuff all on top of the actual effect of a single yellow trial yeah was that what you were going to say is yeah all of those things the effects of recent history doing the same thing and anticipation of the future all on top of what actually happens in this trial okay so those are not deal killers but they're you know things to be aware of so those are reasons why you might want to go with this condition or this condition why wouldn't you always do this alternate the order and not alternate randomize the order of conditions over time um and bunch them in together why is that not always a great idea people do that sometimes it's not a terrible idea but there are things to keep in mind here what's the challenge with that yeah one possible challenge is that the bold response has like a 10 second window so it doesn't describe delete exactly so these the bold responses here are going to be massively on top of each other that's why people sometimes do this it's like okay we'll have a random order and we'll put a big chunk of time in between but if you have to stick 10 seconds in between trials your subject is going to fall asleep and you're wasting you're spending all that expensive scan time you know not collecting enough trials right so there's you know none of these is right or wrong they're right or wrong in different conditions okay so as okay am i saying it right okay um as i mentioned the challenge here let me just give you my crude depiction of this so let's suppose you have a this is time a series of trials with a house a dot a face a dot a dot i don't know where that i want to face the house etc and each of those trials is one second long okay well let's imagine the response in the fusiform face area to that first house you get some kind of middling low response that's going to take many seconds to peak okay let's look at the response to this face well it's going to be higher and it's going to peak out there okay and so then you can look at the response of each of these things right and so you get this whole series of bold responses from each of those different trials okay but now here's the problem what we observe when we measure the response of a little voxel a little three-dimensional pixel in the brain is the sum of all of that something like this it'll be higher than that but some big blurry sum of all that so now we want to go backwards from observing this to seeing the difference between that and that and that's a problem okay so that's not great but here's the crazy thing it's not impossible it's not impossible because by weird mysterious to me still kind of unfathomable um physiological mechanisms these things add up approximately linearly it's really counterintuitive who would think a big sloppy biological system with many different causal steps could produce something that is approximately linear but it does and because they add up linearly if you have enough trials you can take this thing and recover that and that okay we're not going to go through the math of it it's just basically addition it's like solving for like you know it's it's solving for um you know multiple equations because you have all these different time points did everybody get the gist of the idea that even if you're observing something really slowly varying and weakly varying because it's massively blurred you could in principle with enough trials go backwards and solve for that and that everybody get that idea okay so what that means is it's a bit of an uphill battle to do a fast event related thing like you can't just look at the response you have to actually do a lot of math and you may or may not have enough trials to pull it out right but under some circumstances where you really need things to be interleaved you can pull that off okay all right so that's what i just said blah blah blah okay a few other design things that i didn't really talk about in detail one i've mentioned glancingly but i wanted to be more explicit about it this whole idea that we've talked about a few times of defining a region of the brain that we're going to look at with a uh with a localizer scan okay with functional mri we talked about that with the case of characterizing face areas go run a face versus object scan find the face area in that subject and then do new experiments and test it right or when you guys proposed your snake experiments you said first localize a candidate snake specific region with snakes versus non-snakes and then do repeated tests in that region that you found in each subject why do we have to do all that within each subject you don't technically have to lots of people don't but the reason i think it's important and the reason we do it in my lab and all of my intellectual descendants do that and lots of other people do too the reason we do that is that that region is not in exactly the same place in each subject okay so i have a dopey analogy brains are physically different from one person to the next if we scan you guys just anatomically and look at the structure of your brains your brains are as different from each other as your faces are that is you all have the same basic structure the same major lobes and sulcide just as you all have eyes and nose and mouth but they're in slightly different positions and that's just the anatomy the function on top of that is even more variable okay so uh it's like trying to align faces right so no matter if you have a bunch of photographs of faces and you try to align them on top of each other and superimpose them even if you have a few degrees of stretch you can't do it perfectly you'll get some kind of mess like this right they just they're different so they don't perfectly superimpose right well it's the same deal with brains you try to align them perfectly from one person to the next but they're physically different they do not perfectly superimpose okay so but you know so now imagine that this is totally crazy analogy but it's best i could come up with suppose you're a dermatologist and you're interested in skin cancers that arise in the upper lip what could happen there's more sunlight hitting the upper lip whatever okay so now you can take a whole and you're studying photographs to try to see how many people have it or something like that so you could take a whole bunch of photographs and you could just say okay i'm going to look right there it's usually going to be the upper lip but it's not always going to be the upper lip and so you're really throwing away a lot of information by choosing the wrong location for this person down here you missed it right you're looking at the wrong thing okay so in the same way if you want to study that region you've got to find it on each individual photograph and similarly if you want to study the fusiform face area or the snake area which doesn't exist but whatever um you gotta go find that thing in that person individually otherwise you're really blurring your data just as those data are blurred there make sense okay all right um good okay different topic about design these are just kind of different topics i couldn't find a good segues so far we have been talking about the most rudimentary simple possible experimental design that means two conditions faces on and objects snakes and non-snakes moving or stationary whatever two conditions where you contrast and you look in the brain is there a higher response to a than b okay nothing wrong with that you can get pretty far with this but first of all of course we can have more than two conditions so you can have one factor in this case stimulus category with many different conditions right aces bodies objects scenes whatever right okay so that's not rocket science we've just added a few more conditions of the same factor your factor is the you know the dimension you're varying in this case it's stimulus type okay but we could get fancy and we could have four conditions that are two factors varied orthogonally like this okay this is sometimes called a two by two design uh we're going to vary one thing on this axis and another thing on this axis okay why would we want to do that well let's look at an example now let's suppose that you were going to compare faces to objects in this case chairs but beyond just those two conditions of comparing the response in the brain when people are looking at faces versus objects we could now ask does a response in the brain to faces and objects depend on whether you're paying attention to the faces and objects what if you're paying attention to something else what if we have little colored letters right in the middle of the display and they're changing rapidly over time and your task is to monitor for a repetition of a letter a one-back task and it's going really fast so it's very demanding you're just looking at those letters they're flashing up a little two b's bum you hit a button boom it's like very demanding okay the information hitting your retina is still coming in from the face because the little letter is tiny it's not hiding much of the face what do you think if you're doing the letter task do you think you'll still get a response in the fusiform face area when the face comes up and will it be higher than when the chairs come up any intuitions yes talk to me about that it should be because i think what we've learned is the signals once it hits the medium and so still coming in yeah will it be just as high what do you think no i don't think it'd be as out but it doesn't since your response that's like higher than effort everybody see how this is kind of an interesting question right the machinery is the same all the feed forward stuff is the same you can't when i tell you just now you're doing the letter task now you're doing the face task when you switch to the letter task the wiring in your brain doesn't change all the same wiring is there that's it's a stimulus is still hitting your retina it's still going up the system so it becomes interesting to ask how could it be different right would it be different all right i just want you all in the grip of this is a question that we might ask so how could we ask this question um well um we can do as i just said we can have subjects in one case do their standard object task look for repetitions of fa of con consecutive repetitions of a face or of a chair we have all different kinds of chairs but every once in a while two in a row are the same okay um or we could have this other task where they're monitoring for letter repetitions so does everybody get this two by two design on one factor we're varying the stimulus is it faces or objects and on the um faces or objects those are the two conditions it's just terminology okay um and on the other factor we're varying um tasks are you doing the the face object task or the letter task yeah ben is it okay so what is it that this task was like what conclusions to allow you to draw the simpler customer good question good question anybody have an intuition here you mean other than just doing that never mind the letters yes exactly exactly the right question what do you guys what do you think is there any reason to do this does anybody care about this what would it tell us yeah i forget your name lauren yeah the effect of attention on perception yeah yeah so if we want to know not just is there some bit that responds more to faces and objects we've been doing that for weeks enough already right we know there is okay now we want to know does it matter what you're paying attention to is that thing like a just like a is it like a little machine that's going to do its thing no matter what or do you the perceiver have any control over it here's another version of that question you guys can all sit there and look bright-eyed and bushy-tailed and look at me and smile and nod and think about whatever you want to think about and i won't know you could be bored out of your mind thinking about you know what you did last night whatever and i won't know and that's great i mean isn't that nice that we human beings are not trapped by the stimulus that's in front of us at any moment instead we can control our mental processes to some degree right and if you choose to think about something else you go for it you have good judgment that is fine it happens to me all the time you have that ability i have that ability not really when i'm lecturing i kind of have to stay on task that's why it's exhausting but anyway um but you know we are not trapped we are not completely controlled by the sensory world impinging on us and that's a good thing and so if you wanted to find out about how that works and study how well we can control our own mental processes you would do something like this make sense okay all right okay so this design enables us to ask a whole bunch of things one does a response in some region or voxel or wherever we're looking depend on stimulus category okay this is what we've been talking about for a couple weeks now that by to do that you could just say okay is there an overall higher response to these two conditions than those two conditions you wouldn't worry about tasks you say overall is there a bit that likes faces more than objects okay everybody got that that's one thing that's sort of what we've been doing so far is just comparing two levels of one factor that's called a main effect okay in this case a manifest effect of the factor stimulus type all right or we could ask a different question does the response of a region of the brain depend on attention so overall never mind whether it's faces or objects there's like photographs flashing up there does it matter if you're paying attention to those photographs or paying attention to something else okay so for that we compare the average of these two versus the average of those two that would be a main effect of task make sense it's just terminology but it's important to see that we can ask these different questions of a two by two design okay ready with me anybody want to ask me something this one this main effect isn't a very interesting one it's kind of a weird one but you could you could do it right okay um okay so that's yeah main effect of attention or task okay now we could ask as someone else said a moment ago was that you lauren yes if we want to know does the effect of stimulus category depend on attention that's what a two by two design is that is that kind of question that a two by two design enables you to ask so to ask that question really what we would do is essentially look at this row and then that row and then we compare them so we might say how much higher of a response you get than for faces and objects and we get some number in that cell sorry when you're paying attention to them and how much would you get when you're not paying attention to them you're paying attention to the letters and then we could say oh what is it you know how selective is the face response when it's attended versus unattended in other words how do the response to stimuli depend on task okay it's not rocket science but it's important to see how this humble little two by two enables you to ask these very different questions so this question of how the effect of one factor depends on the level you're at with the other factor is called an interaction okay um and it's often like the most interesting kind of question to ask of any kind of data whether it's mri or anything else you could think of it as a difference of differences right or more directly how the effect of one factor depends on the level of the other factor okay in this case the terminology would be we'd be looking at an interaction of stimulus category by task make sense everybody with the program about how this question is different than the two different main effect questions okay to get some practice with this i'm going to have you guys come up here and draw some data okay so we're going to consider um okay we're going to just to get experience with main effects and interactions we're going to consider a main effect of factor x which is an overall effect of x i the difference between condition one versus condition two within x and we're going to consider interactions of factor x and factor y that is how um how the effect of x depends on y and vice versa okay so i'm going to have you guys draw data i need my first volunteer this is not hard uh how do i put this thing up i forgot to check if i have red and black pens hopefully i do if you don't volunteer i'm gonna pick randomly and that could be worse it's not too awful is it carrie unfortunately i remember your name so what up here um okay so um you got an easy one uh this doesn't write very well but it will do okay this is your red pen that's your black pen um okay so we have here the response in red or orange will be the attended case we're looking at a response in the fusiform face area a possible response in this case a pretty unlikely one but never mind so the attended one and there's the unattended one and there's response to objects and faces and what i want you to draw is a pattern of data in which there's no main effect of stimulus type no main effect of attention and no interaction of stimulus type by attention so just put you're going to draw four dots you can do x's and o's or whatever okay so no effect of the stimulus so that means it doesn't matter if what's the base or option uh-huh exactly so i guess you could do that for one to go do that for the attended task first so do that in red you have to really lean on it oh it worked for me sorry we'll have the extremely counterintuitive thing of this is the tension there we go here you go okay perfect no main effect of stimulus type good okay now we've got no main effect of attention so take the blue pen so this is like and no interaction no effect of attention relative to attention no attention that's right no no main effective attention means no difference for attended and unattended okay but stimulus type is important no no we're still it's all the same we're drawing all the same situation yeah exactly it's a little bit of a there you go beautiful nicely done carrie okay so that's kind of a dopey case well done you can sit down yeah okay so we're just starting basic here okay that's what it looks like if you have no main effects and no interactions everything's the same okay all right that's not going to happen if you're in the fusiform face area if you get that there's something wrong with your scan or something went way wrong okay but we're just flushing out the logical possibilities okay i need the next volunteer who's going to do a main effect of stimulus type no main effect of attention and no interaction of stimulus type by attention yes come on up here is it what's your name sorry aquali yes right um great so go ahead and draw that for me i'm just gonna clarify that this what do we do this is unintent wait a minute yeah unattended here okay here you go there's a main effect assuming it's probably easiest if you start yeah start with the tendon there's a main effect of stimulus type great you're in the ffa the faces are going to be higher than the objects and main effect of stimulus type says you're going to get a difference good beautiful well done make sense everyone thank you kwiley um that make sense everyone okay so what would this mean if you got this okay quality you're not quite done so you get that what's that telling you um it tells you that uh it responds to the stimulus but the the attention doesn't make any difference yeah the the the selectivity you get doesn't depend on attention in this case again these are all we're just making up data right we're just considering the different ways the data could come out and what they would tell us everybody got that okay now the plot is going to thicken a little bit now we're going to have a main effect of stimulus and main effective attention and no interaction of stimulus by attention it's going to come up here satalia one up here here you go beautiful thank you everybody see how this is a main effective stimulus type faces are higher than objects a main effect of attention attended is higher than unattended but no interaction the effective stimulus type is the same at each level yeah just something that made it was unclear is the does the tension usually affect the selectivity or the average response these are great questions right now we're just considering the logical possibilities okay we will talk about that later yeah it's a good question you should be wondering yeah okay so um talia tell us if you found that what would that mean um so because like the difference in effect between like intended and unintended like objects and faces is the same like that does show that like a tension like plays an effect and the stimulus vision effect but there's like no interaction between them because like the difference is the same it's like there's these two different things there's face selectivity and then there's just a big like overall if you're looking at stuff you get higher responses and if you're looking at the letters yeah exactly all right one more i need a volunteer david that's not a volunteer i realize it's different than a volunteer but okay so draw me a case where you have a main effect of stimulus a main effect of attention and an interaction of stimulus by attention yeah beautiful so here we have um oh wait actually hang on hang on hang on uh wait a second you've got a main effect of stimulus actually you don't have the main effect of stimulus here did i get rid of that yeah you got rid of that now you have the main effect of attention wait maybe i said oh maybe i told it maybe i said it wrong oh yes you didn't have a okay wait a second oh yeah you're right i think i screwed you up here okay we want a main effect of stimulus yeah yeah and then well let's let's just if we move it a little bit like that exactly okay so don't go away um does everybody see how this is a main effect of stimulus those guys are higher than those guys a main effect of attention the grease got green guys are higher than the blue guys but an interaction like that difference is bigger than that difference okay now don't go away david if you got that what would you conclude about the fusiform case here if you got those data well the ffa if it was like this it depends if not only does it depend on attention but it depends on attention more than uh maybe the object uh detection doesn't depend on attention so much that's right that's what your data show is that the the response to faces is more strongly affected by attention than the response to objects but another way of saying the same thing is to say that the selectivity is greater when you're attending than when you're not attending make sense or the differential response is greater okay great thank you everybody got these basic ideas okay they're pretty rudimentary i don't want to insult your intelligence but i i really i've found that people often don't get main effects in interactions and they're often really the crux of an interesting design is an interaction and keeping it straight from the main effects sometimes takes a little doing okay so let's consider what is the key sign of an interaction oh well we already have a case where often people draw an interaction where the lines cross but they don't need to cross david just showed you a nice interaction where the lines don't cross okay all right okay moving on that was all leftovers that's bad planning oh sorry what oh yes put the thing up good point or down thank you chris um okay let's talk about category selective regions of the visual cortex we've been talking about these all along but it's time to get a little more critical um so first i've been talking about how there's a patch in there that responds pretty selectively to faces there's a patch out there on the lateral surface it responds pretty selectively to bodies and we haven't mentioned it much but next week you'll hear more than you want to hear about a patch smack in the middle there that responds selectively to images of scenes okay so you just look at that and it's really damn near impossible not to wonder what else is lurking in there right what else is in there uh and of course we we wondered that many years ago me and paul downing who did the um the body area paper he was my postdoc at the time and we said well let's just scan people looking at 20 different categories of objects and we put in all kind of silly stuff in there i'm phobic about snakes so i wanted snakes he's phobic about spiders we compromised in our creepiest condition threw them both in there it was kind of sloppy but we had food and plants because we figured those are biologically important we had you know weapons because those aren't tools because those are you know those are important in other ways we had flowers because steve pinker has this line in one of his books saying that a flower is a veritable microfiche of biologically relevant information he hypothesized based on that that people might have special purpose neural machinery for flowers sounded like a crock to me but it's an empirical question so we threw flowers in there for steve pinker okay um and uh and so then we scan people looking at all of these things and we replicated in every subject the uh the existence of selective regions for places faces and bodies and we didn't find anything else none of these other categories produced clear whopping selectivities in systematic regions of the kind that you see in every subject for faces places and bodies now i hasten to say that there are lots of ways with any method to not see something that's actually there you might not have enough statistical power to see it it might be that there's a whole bunch of neurons that do that but they're scattered all over the brain and so they're spatially interleaved with neurons that do other things in which case mri will never see it there are big black holes in mri images where there are artifacts and you can't see anything and if the soul was right there we wouldn't have discovered it yet because we can't see it in our mri images not that i know what the contrast is for the soul you could work on that do you have a question ty yeah i'm just curious did you try it on like cracks yes and we will get to that later and there is absolutely a specialized region for text and we'll talk about that in a few weeks yeah we didn't in this experiment but we and lots of others have in other cases um okay so um so don't take this too seriously my main point is just that you don't find a little patch of brain for any damn thing you test mostly you don't find it right there is some disagreement in the field about the case of tools and hands there are many reports that if you look at pictures of tools or look at pictures of hands you can get a nice little selective blob i have looked at both of those many times i don't see it i don't know what everyone else is on about i'm confused about that i just leave that as in play i don't know but with that exception there's good agreement that faces places and bodies everyone replicates and most of these others no one replicates and so in particular nobody reports selective patches of brain that respond selectively to cars chairs food or lots of other things we have tested snakes by the way and not found anything at least in the cortex so what does that mean that implies connoisseur that some categories are special in the brain okay at least at this crude grain that we can see with functional mri and that seems pretty interesting and important yes i have a nice question about places did you um distinguish between newly made places and naturals we'll get into all of that in excruciating detail next week yeah it doesn't really make much of a difference it likes all of those things yeah um okay so i've been going around for 20 years saying see these these these categories are really special in the brain and the mind and that's what we're getting from this and that's deep and fundamental it's telling something us something about you know who we are as human beings or whatever sometimes i go off the deep end with huge claims okay but not everybody buys this and so what i want to do is allude briefly to the general kinds of ways you could argue against this and then talk in some detail about one main one okay so ongoing controversies this view here is highly caricaturized and this is actually not right right the brain doesn't have completely discreet little regions it's a mucky biological system and if you actually look at the part the face selective regions they have ratty edges and little kind of archipelagos of you know sub-blobs and stuff it's kind of a bit of a mess right there's a general cluster in that vicinity in most subjects but it isn't always a discrete blob unless you blur your data you take any any data and blur it enough it looks nice and clean but if you want to know the actual native form in the brain on blurred it's kind of mucky okay so one could react to that in different ways my reaction to that is like what do you expect it's a biological system does it really need to be perfectly you know perfectly oval shaped with a perfectly sharp edge i don't really care if it if it's interleaved with other stuff around the edges but people react different ways and one kind of important alternative view is look how do we know these that these are really you know things in the brain i'm talking about them as things you know pieces parts of brain and mind right and you know maybe they're just kind of peaks in a broader landscape of responses across the cortex that are fluctuating and empirically that's true there isn't just like one butte and then nothing else in the cortex around it there's some kind of profile right so it's a bit of a judgment call how excited you want to be about a big peak in a fluctuating background yeah and so there's much discussion about that is it really just a peak in a broader spatial organization and if so what is that broader spatial organization all about right it just pushes that question back it says we're wrong to think about discrete things but that still leaves many mysteries about what that continuous gradient is okay so that's kind of one line of response which i think is completely legitimate um any sort of version of that it kind of blurs into this next view which we've talked about a little bit and that is to what extent can these things if i'm calling them things be accounted for just by their perceptual features so we've grappled with that in a number of ways so far one of the first things we asked about the face area is is it just responding to curvy stuff right or round things or whatever right and so there are many lines of work where me and many other people have asked that question and for the most part the answer seems to be there's somewhat you know there's some featural selectivities in these regions but probably not enough to account for their category selectivity but that that one too was still in play and there's this dude in english in england who publishes like several papers a year saying like you know no this thing isn't category selective it's just that um i was going to assign i'm going to try to assign one of his papers to you because i want you to expose you to alternate views but i haven't yet um i haven't yet taught you the key methods you need for that paper anyway so there's room for debate in that question as well then there's just a continuum of okay exactly how selective are these regions like okay i'm excited if a face area responds like this to faces and like that to objects but hey it responds like that to objects is that selective enough you know so there's a lot of debate about what that means okay so there's a lot of room to push back on the simple-minded story i've been serving up to you guys but what i want to do next is talk about what i take to be the most smart and serious challenge which is somewhat different from all of these okay and this comes from a guy up at dartmouth named jim hacksby who published the paper that was assigned for today and i intended for you to like struggle with it a little bit and try to understand it but if you didn't understand it fully i'm going to talk about it here and hopefully that'll make it more intelligible okay so here's the big idea that hacks be there's many ideas in that paper but the part of it that's most relevant to us for now is the following even if the fusiform face area responds weakly to chairs and cars for in contrast with strong response to faces that doesn't mean that it doesn't hold information about chairs and cars okay so all along i've been just talking about one dimension does it respond like this or like that and that's gotten us pretty far but the essence of hacksby's idea is that we should care not just about the overall mean response we should ask if there's information present in the pattern of response across voxels okay and his point is that even if there's a low mean response you could still have information in the pattern across voxels even if it averages to some low number okay and that pattern of information could enable you to distinguish different categories all right so let's get very particular so how exactly would you tell so here's what hacksby did essentially or here's my here's the subset of the assigned paper that's relevant to the current question if we want to know does the fusiform face area hold information about cars and chairs thereby arguing against its selectivity for for faces right i mean we should care about information in the brain not just magnitude of response right if the brain is an information processing system we care what information the parts contain not just house how much the neurons are firing okay all right so if we want to know this here's what you can do here's a version of what hacksbee did you scan subjects while they're looking at chairs and cars you've localized the fusiform face area so you know where it is okay so now you get the response this is highly schematic this is an idealized version of the cortical surface remember the cortex is a surface so we can mathematically unfold it and look at the magnitude of response of each voxel in the ffa ffa isn't square but we're idealizing it here okay everybody get how that could be a pattern of response across voxels in the ffa when the subject looks at chairs okay and maybe you have some other pattern when the subject is looking at cars now certainly if if the pattern when they're looking at faces all of these bars would be much higher but our point is that even if these are low they're different across voxels okay so that's step one so then what hacksb says is you do the same thing in the same subject you do it again hopefully in the same scanning session and you get another pattern like this and this okay now here's the key question if there is systematic uh if those patterns are systematic for chairs and systematically different for cars then there is information in that region about the difference between chairs and cars okay chairs and cars aren't faces so that's an important challenge to my story about how that region only does faces okay so how do you measure that well there's lots of ways um haxby's is the lowest tech and most intuitive he just says let's look at the similarity of this pattern to that pattern repeated measures on cars sorry chairs same subject chairs on the even runs and chairs on the odd runs by the way why do you split your data like this rather than like this okay he does eight runs we could take the first half of the runs put those data here in the second half and put them over there or we could take the data like this and take even runs and odd runs why is even an odd better than first half second half yeah uh i guess it doesn't allow like the subjects to get used to like one particular one particular thing one after another well they're doing the same thing it's all the same data it's just how you analyze it i'm not sure i think it's probably easier to compare between one time and one face and the other it is you can actually do it either way it's like you scan these eight runs here they are you can do that i don't know if you can see what i'm doing here with my whole crew or you can do this why is this better than this yeah as well um yeah maybe they fell asleep halfway through the scan okay then if you do like this the odd and even are going to be better compared to each other than first half second half right makes sense okay it's another version of why you do things within subjects it's the same kind of argument yeah okay so he splits into even and odd and so you ask how similar are they within a category within chairs and within cars you get two different correlation values just how similar are those patterns you get an r value and we compare that with how similar the patterns are between chairs even to cars odd and chairs and cars even to chairs odd okay and so the key question you ask if there's information about chairs and cars in this pattern of responses then the correlations will be higher within category than between category in other words two different times you scan looking at chairs those patterns are more similar than chairs are to cars make sense i mean it's pretty it's pretty basic but it's one of these things that's simple and yet subtle at the same time does everybody get this okay so you just do these repeated measures and you look at these pattern of correlations and if the the patterns are more similar or more correlated within a category than between categories then you have information in that pattern that enables you to distinguish those categories yeah okay so that's what hacksbee did um yes so what was this information doubles so it would be difficult to look at nothing really um well wait a second oh that's the same okay that's essentially like this it's just that since we're going from even to odd with the win within case we're going to go even to odd in the between case you could have done it this way but then yeah okay okay so um that's the method what does hacks be find well you guys should all look at the paper some more so you get a sense of it it's actually really nicely written even though it's dense those science papers are very dense but basically here's what happened so in that paper he says yes he can distinguish between cars and chairs in the ffa and therefore to quote from his paper regions such as the ffa notice the square scare quotes he's put in there to diss me i i hear you i hear you jim okay regions such as the ffa are not dedicated to representing only human faces rather they're part of a more extended representation for all objects them's fighting words right everybody see how this is a serious challenge with a very elegant method okay so when i first read that paper it's like huh okay i'm paying attention but he didn't do everything right i didn't like the way he defined the ffa i found a million reasons to dis it and i ran my own version and in my paper that we published we did we could not discriminate those we said you can we can okay you did it wrong we did it right then a few years later jim publishes a paper with a collaborator in which they reanalyze their old data and said actually you really can't discriminate it very well it was significantly above chance but really lousy and so they concluded preferred regions for faces and houses that is regions that respond preferentially to faces or houses are not well suited to object classifications that do not involve phases in houses respectively but i didn't get to gloat because right about the same time we were redoing our experiments at higher resolution and actually we could distinguish two different non-faces in the fusiform face area so that was like the little drama that unfolded and so the current status is um yes like you really can discriminate two different non-faced categories within the fusiform face area um even if you do it right even if i do it right and i don't want that result and i do it right i can get that result okay so that's true empirically the ability to discriminate is is feeble it's not very strong but it's significantly greater than chance so does that mean i'm toast and i wasted the last few weeks telling you guys a bunch of bs that has been disproven and i should not have been telling you yeah david isn't it it's kind of like saying that you could use a vending machine like a clock and then asking the question then what is this thing for he said well it's obviously the office clock that's a great a great analogy i love that absolutely absolutely so now to me the central question and here's another another example that i think is exactly like that but but even more on point and that is that there are deep nets that people have trained on faces vgg face it's really good at face recognition it has only ever seen faces it has only been trained on faces that is all it's about and if you feed it chairs or whatever i have chairs and cars it can discriminate between chairs and cars so even if you have this perfect representation that's only been trained on faces that has only evolved if it evolved we'll get to that later to deal with faces it can still give you a somewhat different response to chairs and cars and that doesn't mean that that's what it's doing right so i think this is a really important um challenge but i think centrally crucially what we really need to be thinking about maybe quilly has a contribution yeah so like if it's only been trained on faces and you feed it and share um like what's it out for them um okay so you know it's just it's just a bunch of feed-forward layers that are connected with you know boatloads of units at each thing and connected in the systematic pattern and once you train it up you can feed it any stimulus and you can collect the response at the top okay so even though it is designed for and only been trained on faces you can feed it non-faces and get the response out this at the top and see but that is not the not the category not not the top layer where it says that's joe or that's bob but just before that layer there's a whole bunch of units that have some representation distributed across units you can take that and try to read it out and ask if there's information there okay i'm not giving you all the details of how you do that but hopefully you can get at least suggest and later in the semester katherine dobbs is going to tell you more about how you do all this kind of stuff okay i spent a lot of time in the last last few weeks talking about a key difference between two different kinds of methods one set of methods that allows this kind of inference and another set of methods that allows that kind of inference i'm trying to give you guys a clue here um actually what i'm going to do is let you percolate on this i don't think this is obvious i worried about this for years i think there are many answers to it it's not cut and dried i will say i have already presented to you at least two different lines of work that argue that provide an important counter argument to this one of the people who gave me crappy teaching evaluations last year said she told us about counter arguments and then made us tell her how they could in fact after all be consistent with her data i thought that was weird i was just i was just trying to teach people to think about data but anyway i won't make you do that because somebody didn't like that before but you can think about it and we'll talk later and actually i'm gonna i it's actually good to think about and we will come back to it um but i want to get on with the rest okay i mean i mention all this because it is an important challenge yeah and i'm wondering if like objects are not processed in ffa they must be processed somewhere else totally so something else totally i had a whole piece of this lecture on that and then i thought for once i'm not going to go over my time so i'm not going to talk about that but um yeah there are there there's remember there's all those other bits of cortex i've just identified a few particular ones there's lots of cortex in between and the simple statement is there's a lot of nearby cortex near the ffa in the ppa that seems to respond generically to object shape and the first pass guess is that there's like a general purpose visual machine in there in addition to some more specialized ones but i'm going to not say more at the moment and i'll just say actually if you read it you may read it in papers it's sometimes called lo or loc that's kind of shape selective region which is arguably the kind of generic let's process everything else system okay only if it's clarification questions okay ask it no i was just wondering which came first this world called transcripts sorry this work or oh ah good question uh the transcranial stuff has actually been going on for a long time but the relevant kind that i talked to you about is more recent and you're right it is one of the very strong answers to this kind of critique there's several actually i've told you about three so far answers to this but think about it okay so um okay so what we're going to do now is talk about not just this particular use of this method to ask a serious question about the selectivity of regions in the ventral visual pathway now what i'm going to do is argue that actually i think i just said all of this what what hacksbee has given us is also a method to ask what information is present in this little patch of the brain and that's an awesome thing so let's go on and talk about that let's talk about neural decoding with functional mri so that was an instance of it but i'm going to cash it out in another way more generally so let's take the case where there's a person with a patch of their brain and a pattern of response across fossils in that patch of their brain when they look at some stimulus let's suppose you're given this and you want to know what was that person looking at to produce that pattern right what was the stimulus out in the world that produced that pattern can you do that so more generally can you read the mind with functional mri or maybe a little more honestly can you at least tell what the person saw from their pattern of brain response okay everybody get the question here okay how can we try this well they're all variations of that hacksbee method that i just told you about okay but let's walk through this so the first thing you need is you have this pattern and you're trying to figure out what stimulus produced that pattern in this and this person's in that part of this person's brain well you need a decoder you need to know what those voxels respond like when they look at different things where you know the answer okay so what you do is you scan the subject on a bunch of different conditions to get your decoder and then you can take your unknown data and compare it to those decoder data okay so in particular you have to train your decoder so you scan the person looking at say shoes and you get pattern you scan them looking at cats and you get a pattern maybe you scan them looking at five ten a hundred other things probably not a hundred you don't have enough scan time but some number of things and so now you know you know this is how those voxels respond when the person looks at shoes and this is how those voxels respond when they look at cats okay now you test your decoder with your mystery pattern now you have your mystery unknown pattern you want to know was that shoes or cats okay well you can just look what is it more similar to all the methods are versions of that they're just fancy mathematical versions of that so what do you think that pattern what produced that pattern shoes it's more similar to the shoe pattern exactly you guys just did neural decoding okay so that's exactly how you do this there are all kinds of ways of doing this from just saying is this more correlated with that than that that's hacksby's version or you can put a whole big fancy machine learning rigmarole in there to do pattern classification because that is after all what machine learning is so awesome at is pattern classification and this is just a straightforward pattern classification task train on these test on that is that is that sort of intuitive what we're doing here okay so that's the agenda that's the logic of how we do this um and so does that work well a little bit but you don't have to worry uh because at least at the moment um because there are a million ways about 10 years ago i was getting called up by um legal types all the time because are there are people going to use people going to detect lies with functional mri and i thought this was a total crack and i was going around giving talks on all the reasons why nobody has to worry that um they're going to be compelled to testify by having being shoved in a scanner and have their brains read i mean it's not a totally stupid thing to worry about but lest anybody uh i don't think this will happen but lest anybody try to read your mind against your will while you're in an mri scanner you can totally foil it in any number of ways one move your head two if they've got your head bolted down move your tongue you totally mess up your whole signal if you move your tongue okay three do mental arithmetic you can totally shut down whatever they're trying to do if you think about something else anyway so we don't need to worry about it it's not good for insidious kind of legal efforts but it is pretty good for science sometimes okay so there's lots of versions of neural decoding with functional mri so we've been talking so far about decoding functional mri patterns of response across voxels um that's called mvpa multiple voxel pattern analysis you don't need to memorize that but when you see mvpa in a paper this is what it's talking about okay but you can also do it with lots of other kinds of neural data oh sorry within mvpa you can ask it of a particular roi in the brain region of interest like v1 or the face area or the body area or something else but you can also apply it to the whole damn pile of data from the whole brain and say can i tell what this person is thinking by looking at their whole brain okay beyond functional mri you can apply it to lots of other kinds of data so you can do monkey neurophysiology as we discussed briefly last time where you have actual firing rates from individual neurons and you can look at the response acro you know the response of each stimulus class to each neuron in a region of the brain and you can do the same deal running a pattern classifier or a simple correlation method on the pattern of response across neurons rather than voxels everybody see how that's sort of the same deal just better okay or you can do magnetoencephalography as we talked about stick your head in the big expensive hair dryer collect magnetic signals from all around the head 300 channels and now those magnetic signals are changing over time so the cool thing about neural decoding with with meg is you can say okay let's take the data from just exactly 80 milliseconds after the stimulus flashed on and let's ask what can you decode then what can you decode at 100 milliseconds 120 milliseconds you can see the growth of information over time as neural information processing proceeds by by running the decoder separately at each time point okay i'm going to try to squeeze into a future lecture more talk about that because i think it's cool and we're doing a lot of it in my lab right now does everybody get the gist of this at least okay okay so that gives you the time course of information extraction okay similarly there's lots of different decoding methods you can use as i mentioned the kind of simple low-tech hax-b style correlations or you can use something called linear support vector machines or various other kinds of fancy machine learning math okay to to to do those classifiers okay let's take do i have time to do this i'm going to skip this yeah we're going to skip that it's cool but we're going to cut to the oh i don't know we'll do it all we've got time all right um okay so pointed now that i waste all that time deciding whether we had time okay we're going to compare how well this works when you do it on mri versus how well it works when you do it on neurons and monkey brains okay so um so there was a beautiful paper a few years ago that looked at this so the question is here are these face patches and monkeys that i told you about and that david leopold will be talking about at four o'clock today and so question is this particular one am one of the nice face patches up there these guys wanted to know what information is represented up there in face patch am is there information about different individual face identities can you use it to decode which face the monkey saw okay and so they did this experiment two ways one they did monkey neurophysiology they recorded from 167 different individual neurons in that region and for each neuron they measured its response to five different faces okay in another condition they popped the very same monkeys in the scanner and they scanned them with functional mri and they did the same experiment and they measured the magnitude of response of each of 100 voxels in that same patch of brain in that same monkey and they got the mri response to each of those hundred voxels and for each voxel to each of those five phases everybody get that this is asking the same question how well can you decode face identity from individual neurons or from functional mri in the same animal and the answer is damn depressing the answer is you can decode identity really well from neurophysiology and you can't do it worth a damn with functional mri big bummer yeah so that's a drag it's just what it is presumably remember each mri voxel has hundreds of thousands of neurons in it so the real miracle is that we ever see anything at all and when we can't see the neural code with the resolution that we need to to tell whether it's got information about face identity that's just because we're averaging over so many neurons okay that was my lament at the end of the lecture um on monday that there are so many limitations in um human methods and here's one of the key ones okay um what are the implications it sucks anyway okay i want to get one more idea out uh and that is yeah to fmri or does it also translate to vdgs oeg is much worse much worse oh my god yeah yeah um yeah the only thing that might be better someday is intra cranial recording but even there you usually don't get enough electrodes so you need these very rare cases where you have very high density grids of intracranial electrodes that some surgeon has decided by chance to put on a part of the region a part of the brain where you happen to have hypotheses and you happen to be incredibly lucky to test your your hypothesis and that's very rare did you have a question clearly no okay um okay so i've been talking about neural decoding and that's a way of asking what information is present in this batch of neurons or this bunch of voxels and that's a really deep question to ask for cognitive science because we're interested in information processing and we want to know what's represented in each region it's really the crux of the matter in cognitive neuroscience but we can also use it to ask in a richer way about the nature of that information in each region okay so suppose we want to know what exactly is represented there we want to know not just that it can distinguish shoes from cats okay that's okay but suppose we want to know how is it doing shoes versus cats does it just know for example the shoes are elongated this way and cats are roundish and that's all it's using to do its classification in other words it's not really shoes and cats it's this versus that or something right if we want to know how abstract those representations are or how invariant they are to variations in viewing conditions then we can do the following cool thing we can train the decoder on one set of stimuli and test on a different kind of stimuli okay so for example we can ask are those representations of shoes or are there representations of shoes that are invariant to for example color and viewpoint chosen just because that was the nice shoe i could find my was searching hour ago okay so if we train on these and test on that is that going to work is it going to know that this is the same kind of thing as that if it does what have we learned about that shoe representation yeah it's kind of generalizable it's very generalizable yeah different perspective totally totally it's not just this it's something closer to shoeness we don't know exactly how far it is that until we test more conditions but exactly we've shown that it's really abstract and generalizable that makes it more useful that makes it more cognitively interesting we could even go off the deep end and say okay is it the concept of a shoe we could scan people reading the word shoe and ask is that going to work okay anja's doing experiments like that there's various people looking at this kind of thing um and so you can ask at any level how general or invariant is that representation okay so neural decoders are not just like gimmicks to try to say oh i can see and for mec and read out you know what this person saw there are powerful methods in science to characterize mental representations and to characterize how abstract they are you"}], "4. Cognitive Neuroscience Methods I": [{"content": "all right let's get started so today we're going to talk at some length about what i mean by this idea of mars computational theory level of analysis it's a way of asking questions about mind and brain and we're going to talk about that in the case of color vision and that's going to take a while we'll go down and do the demo we'll come back and talk about color vision and how we think about it at the level of computational theory and why that matters for mind and brain and then we're going to start in the second half a whole session on which is going to roll into next class on the methods we can use in cognitive neuroscience to understand the human brain and we'll illustrate those with a case of face perception and we'll talk about computational theory light very briefly a face perception what you can learn from behavioral studies and what you can learn from functional mri and then we'll go on and do other methods next time everybody with the program all right so to back up a little the biggest theme addressed in this course the big question we're trying to understand in this field is how does the brain give rise to the mind okay that's really what we're in it for that's why there's lots of cognitive science we're trying to understand how the mind emerges from this physical object and so for the last few lectures you've been learning some stuff about the physical basis of the brain what it actually looks like some of you guys got to touch it i hope you thought that was half as awesome as i did and we got a sense of the basic physicality of the brain and some of its major parts but now the agenda is how are we going to explain how this physical object gives rise to something like the mind and the first problem you encounter is what is a mind anyway i drew it as a weird big amorphous cloud because it's just not obvious how you think about minds right it feels like one of those things like could you even have a science of the mind like what is mine it's all kind of nervous making right um and so our field of cognitive science over the last few decades has come up with this framework for how we can think about minds and this isn't even a theory it's more meta than that it's a framework for thinking about what a mind is and the framework is the idea that the mind is a set of computations that extract representations okay now that's pretty abstract you can think of a representation in your mind as anything from a percept like i see i see motion right now or i see color and as you learned before you might see motion even if there uh isn't actually motion in the stimulus but that representation of motion in your head that percept that's that's a kind of mental representation or if you're thinking you know why is nancy going through this really basic stuff she's insulting our intelligence if you know something like that is going on in the background as i'm lecturing that's a thought that's a mental representation of a sort or if you're thinking oh my god it's after 11 and i'm not going to get to eat until 12 30 i'm going to starve you know whatever thoughts are going through your head those are mental representations too right and so the question is here how do we think about those and so this idea that mental mental processes our computations and mental contents are representations implies that ideally in the long run if we really understood minds we'd be able to write the code to do everything that minds do right and that code would work in some sense in the same way now that's a tall order mostly we can't do that yet like not even close a few little cases in perception kind of sort of maybe but mostly we can't do that yet but that's the goal that's the aspiration and so question is how do we even get off the ground trying to launch this enterprise of coming up with an actual precise computational theory of what minds do and the first step to that is by thinking about what is computed and why and so that is the crux of david mar's big idea right the brief reading assignment that i gave you guys that from mar and he's talking about how do we think about minds and brains step number one what is computed and why so we're going to focus on that for a bit here and let's take vision for example you start with a world out there that sends light into your eyes that's my icon of a retina that blue thing in the back the back of your eyes sends an image onto your eye and then some magic happens and then you know what you're looking at okay so that's what we're trying to understand what goes on in there in a sense what is the code that goes on in here that they takes this as an input and delivers that as an output okay more specifically we can ask as we did in the last couple of lectures let's take the case of visual motion so suppose you're seeing a display like this like something in front of you somebody jumps on a beach like that and there's visual motion information what are the kinds of things so that's your input what are the kinds of outputs you might get from that well to understand that we need to know what is computed and why so what is computed well lots of things you might see the presence of motion you might see the presence of a person actually you can detect people just from their pattern of motion if we should have done this at that demo write me a note to think about that next time if we stuck little tiny leds on each of my joints and we're in a totally black room and i jumped around and all you could see was those dots moving you would see that it was a person it would be trivially obvious so motion can give you lots of information aside from something's moving and what direction is it moving you can see someone's jumping that also comes from the information about motion you can infer something about the health of this person or even their mood so there's a huge range of kinds of information we glean from even a pretty simple stimulus attribute like motion and so we're going to understand how do we perceive motion we first need to get organized about what's the input and which of those outputs are we talking about and probably the code that goes on in between in your head or in a computer program if you ever figured out how to do that will be quite different for each of those things but that's the way you need to be thinking about mines okay what are the inputs what are the outputs and then as soon as you pose that challenge like okay let's say it's just moving dots and you're trying to tell if that's a person think about what is the code you'd write just these moving dots how the hell are you going to go from that to detecting if those dots are on the joints of a person who's moving around versus on something else that's how you think what are the computational challenges involved okay and i'm not going to ever ask you guys to write that code we're just going to consider it as a thought enterprise to kind of see what the problem is that the brain is facing that it's solving okay and so mars big idea is this whole business of thinking about what is computed and why what the inputs and outputs are and what the computational challenges are getting from those inputs to those outputs that all of that is a prerequisite for thinking about minds or brains okay we can't understand what brains are doing until we first think about this that's why i'm carrying on about this at some length and mar writes so beautifully that i'm just going to read some of my favorite paragraphs because um paraphrasing beautiful prose is a sin so mars says trying to understand perception by studying only neurons is like trying to understand bird flight by studying only feathers it just can't be done to understand bird flight you need to understand aerodynamics only then can one make sense of the structure of feathers and the shape of wings similarly you can't reach an understanding of why neurons in the visual system behave the way they do just by studying their anatomy and physiology okay you have to understand the problem that's being solved okay further he says the nature of the computations that underlie perception depends more on the computational problems that have to be solved than on the particular hardware in which their solutions are implemented so he's basically saying we could have a theory of any aspect of perception that would be essentially the same theory whether you write it in code and put it in a computer or whether it's being implemented in a brain yeah mar was many things he was a he was a visionary a visionary who studied vision a truly brilliant guy with a very strong engineering background and this is you know now pervading the whole field of cognitive science that people take an engineering approach to understanding minds and brains to try to really understand how they work okay so to better understand this we're going to now consider the case of color vision and so in this case we start with color in the world that sends images onto the back of your retina some magic happens and we get a bunch of information out so the question we're going to consider is what do we use color for okay and we're going to use the same strategy we used in the edgerton center of trying to understand some of the things that that we use color for by experiencing perception without color okay what are the outputs okay so to do that we're going to head over right now to the imaging center and we're going to have a cool demo by rosalesa so if it's going to be faster to leave your stuff here i don't know maybe we should yeah yeah we'll lock the room okay um yeah how long are we going to be today 10 minutes something like that and i need everyone to boogie because there's a lot of stuff i want to get through today so let's go all right so what do we use color for when we have it it's not a trick question supposed to be really obvious now yeah what's your name chardon hi uh do you think it was booty yeah yeah choosing which what else related to that but different yeah yeah yeah like what what did you notice that you could identify better but besides identifying and choosing what else much more generally bringing things into our awareness like with the reds in particular the strawberries yeah like do you find them easier to find no much harder oh yeah right harder without the light exactly what else yeah like driving like you need to have color to know the traffic lights totally totally that's a modern invention but a really important one what else are we in general are we very general or like whatever what do we use color for i mean we use it to like figure out like what's what to eat because it's like one of the strawberries isn't actually a strawberry so yeah i use color too uh-huh and the bananas did anybody notice sometimes it's hard to tell yeah point in the bag say more totally did you feel like people's faces looked a little sickly absolutely absolutely okay so this is just to show you that a lot of a lot of computational theory starts with sort of common sense of just reasoning what do we use this stuff for it helps to not have it just to reveal what we use it for but you guys have just reinvented the the key insights and early field of color vision okay so standard story is to find fruit like if you ask yourself how many berries are here take a moment get a mental tally how many berries okay ready now how many berries okay you see more and in fact there's a long literature showing that um primates who have uh three cone colors we're not going to go through all the physiological basis of cones and stuff like that but they have richer color vision because the number of different color receptors in their retina they're better at finding berries and in fact a paper came out a couple years ago where they studied wild macaques on an island off of puerto rico called cayo santiago and the macaques there have a natural variation genetically where some of them have two photo two color photoreceptors instead of three okay and in fact they followed them around and the monkeys that have three photoreceptors types are better at finding fruit than the ones that have only two okay so that story that's just been a story for a long time turns out it's true and also as you guys have already said to not just find things but identify properties like you can probably tell whether you'd want to eat those bananas on the bottom maybe not it's hard to tell on the top which ones you'd like and yet that's all you need to know okay so these are just a few of the ways that we use color and why it's important but there is a very big problem now that we try to think figure out okay what is the code that goes between the wavelength of light hitting your retina and trying to figure out what color is that thing so here's the problem we want to determine a property of the object of its surface properties its color right that's a material property of that thing but all we have so here's a thing we'll call that reflectance it's a property of wavelength but you can think of it as for now just a single number it's a property of that surface but all we have is the light coming from that object to our eyes that's called luminance i'm not going to test you in these particular words but you should get the idea okay so that's what we have that's our input but here's the problem the light that's coming off the object is a function not just of the object but of the nature of the light that's shining on the object that's called the illuminate so the problem is we have this equation this light coming from the object to our eyes is the product of the properties of the surface and the incident light okay and our problem is we have to solve for l i'm sorry we have to solve for r the property of the object given l what is r that's a problem okay that's kind of like if i said a times b is 48 please solve for a and b okay that's known in the field as an ill-posed or underdetermined problem we don't have enough information to uniquely solve this okay that's a very very deep problem in perception and a lot of cognition we are often in fact most of the time in this boat okay so the implications are when we want to infer reflectance of the property of the object from l we must bring in other information right we must be able to make we must have some way to make guesses about i about the light shining on that object okay so the big point is many many inferences in perception and cognition are ill-posed in exactly this way all right and so here are two other examples of ill-posed problems in perception in shape perception you have a similar situation you have stuff in the world that's making an image on the on the back of your eyes okay that's optics what we're trying to do as perceivers is reason backwards from that image what object in the world caused that image on my retina that's sometimes called inverse optics because you're trying to reason the opposite way that's basically what we're doing in vision so here's a problem like it's a crappy diagram but if you can see here there's three very different surface shapes here that are all casting the same image for example on a retina you could do this with cardboard and cast it with a shadow does everybody get what this shows here what that means is if you start with this and you have to reason backwards to the shape that caused it that's an ill-posed problem big time it could be any of those things this information doesn't constrain it does everybody see that problem okay so that's another ill-posed problem here's a totally different example of an ill pose problem that's that's big in cognition when you when you learn the meaning of a word especially as an infant trying to learn language the classic example the philosophers like god knows why philosophers like weird stuff but never mind um somebody points to that and says gav a guy and your job is to figure out what does gavagai mean okay so gavagai could mean all kinds of different things it could just mean rabbit if you already have a concept of a rabbit it could mean fur it could mean ears it could mean motion if the rabbit is jumping around or in the example the philosopher's love it could mean undetached rabbit parts weird but anyway philosophers like that kind of thing anyway the point is it's ill-posed we don't know from this what is the correct meaning of the word does everybody see how this underdetermines the correct meaning of the word we don't have enough information to solve it okay so um yeah so there's a there's a whole literature on the extra assumptions that infants bring to bear to constrain that problem so they can make a damn good guess about what the actual meaning of the word is okay the whole big literature quite fascinating okay but for now i just want you to understand what an ill-posed problem is and why it's central to understanding perception and cognition okay so back to the case of color as i said the big point is that lots of inferences including determining the reflectance of an object are imposed and so we have to bring in assumptions and knowledge from other places from our knowledge of the statistics and the physics of the world our knowledge of particular objects all kinds of other things must be brought to bear okay so all of that again is considering the problem of color vision at the level of mars computational theory notice we haven't made any measurements yet we've just thought about light and optics and what the problem is and what we use it for okay all this stuff you know what what is extracted and why are the reflectance of an object useful for characterizing objects and finding them what cues are available only l and that's a problem uh because it's ill-posed okay next question so obviously we get around and we can we can figure out what colors are which what are the other sources of information that we might use in principle and that humans do use in practice okay um and so all of that kind of stuff has been done without making any measurements we're just thinking about the problem itself okay all right um so next uh mars other levels of analysis algorithm and representation and hardware are more standard ones you will have encountered which is why i'm making a big deal of computational theory it's really his major novel contribution but it's better understood by contrast with these so at the level of algorithm and representation this is like what is the code that you would write to solve that problem right and so we could ask how does the system do what it does can we write the code to do it and what assumptions and computations and representations would be entailed so how would we find out how humans do this well one of the ways is a slightly more organized version of what you guys just did and that's called psychophysics psychophysics just means showing people stuff and asking them what they see or playing them sounds and asking them what they hear you can do it in very sophisticated formalized ways or you can do it like we just did talk to us about what the world looks like okay usually psychophysics means a slightly more organized version okay so here's an example in fact it's a cool demo also from rosa and so what i'm going to do is i'm going to show you a bunch of pictures of cars and your task is going to be to shout out loud as fast as you can the color of the car okay they're going to appear on the screen everyone ready as fast as you can shout it out loud here we go what color okay interesting okay here's another one uh-huh interesting ready here we go here's another one okay here's another one ah you guys caught on to that pretty fast okay so um good job um nice consensus although i noticed a little bit of transition there which is very interesting um but here's the thing all of those cars are the exact same color the body of the car is the exact same in all of them and if you don't believe it here's i'm going to occlude everything except for a patch okay here we go boom they're all gray i know it's awesome it's rosa that's awesome not me i just had to bum this because it's so awesome okay so rosa spent months designing these stimuli to make a particular test particular ideas about vision but the basic demo is simple and straightforward you can get the point here okay so what's going on here what's going on here is that you guys the algorithm running in your head that's trying to figure out what is the color of that car is trying to solve the ill-posed problem and it's using other information than just the luminance of light coming from the object it's using information from the rest of the object it's making inferences about l the luminance the light hitting the object okay and in particular when you look at that picture up there what is the color of light shining on that car yeah right officially known as teal in the field but some of you shouted out green first because that's what you saw first is the color of light okay what's the color of light hitting that car yeah purple magenta here yeah and over there yeah yellow orange yeah okay so basically what your visual system did is look quickly figure out the color of the incident light l and use that to solve the otherwise ill pose problem of solving for r the color of the car and in this case this demo shows that if you just change the color of the illuminant light and hold constant the actual wavelengths coming from that patch you can radically change the perceived color of the car everyone got that okay yeah if i ran this to a computer yeah asked to get the the intensity of the pixel at like on the hood of the car there it would it would not correspond to yellow across one degree uh well it depends what you're asking the computer exactly if you hold up a spectrophotometer that's just going to measure the wavelength of light they're all gray right there on top of those cars they're all the exact same neutral gray that's just the raw physical light coming from that patch okay but if you coded up the computer to do something smart and you coded it up to take other cues from the image try to figure out what l is and therefore solve for r you might be able to get it to do the right thing i just mean just like you look at the pixels like in the matrix like the color on the car would it be what yellow is great they're all great so that's what that's what i was trying to show you here is that in fact they are actually gray right that's the cars are underneath there and you can see they're all exactly the same and they're gray and there's no color in it okay everyone got that all right okay so all of that is a little baby example of psychophysics what we do at the level of trying to understand the algorithms and representations extracted by the mind to try to figure out what are these strategies that we use to to solve problems about the visual world okay and so behavior or psychophysics or seeing as you just did can reveal those assumptions and reveal some of the tricks that we're using in the human visual system to solve those ill-posed problems okay so in this case it was assumptions about the illuminant that enabled us to infer the reflectance from the luminance okay the third level mar talks about is the level of hardware implementation in the case of brains that's neurons and brains and so we won't cover this in any detail here but there's lots and lots of work on the brain basis of color vision we'll mention it briefly next time so this is some of rose's work showing those little blue patches on the side of the monkey brain that are involved in color vision and some work that rosa did in my lab showing the bottom surface of the human brain with a very similar organization with those little blue patches in there that are particularly sensitive to color so you can study brain regions that do that if it's a monkey you can stick electrodes in there and record from individual neurons and see what they code for and you can really tackle at multiple levels the hardware hardware neural basis of color vision and brains as well okay so the big general point is we need lots of levels of analysis to understand a problem like color vision okay and so accordingly we need lots of methods to understand those things all right so what i want to do next is now launch into this this whole thing about the different methods that we can use in the field in this part of the lecture we'll go on to next time but let's get going everybody good with this so far all right um so we're going to use the case of face perception to think about the different kinds of questions and different levels of analysis and face perception so let me start by saying why face perception not just that i've worked on it for 20 years although i'll admit that's relevant there's lots of other good reasons beyond that why we should care about face perception so i don't have a demo that enables me to kind of put you in a situation where you can see everything but faces that would be cool and informative if we could do that but failing that i can tell you about somebody who's in that situation and this is a guy named jacob jacob hodes so this is a picture of him recently i met him around a decade ago when he was a freshman at swarthmore and he sent me an email and he said i've just learned about face perception and the phenomenon of prosopagnosia the fact that some people have a specific deficit in face recognition and it explains everything in my life and i want to meet you and i said because he knew i worked on face perception i said that's awesome i would love to meet you but i got to tell you i'm not going to be able to help so if you're interested in chatting please please come by um but i don't want you to feel like i'm going to be able to do anything useful he said no i don't care i just want to i want to understand the science so he comes by and by the way one of the one of the things that people have wondered for a while is are people who have particular problems with face recognition are they just socially weird are they just like bizarre like maybe a little bit on the spectrum they don't pay attention to faces and so they don't get them very well and so forth um or can they be like totally normal in every other respect except for just face perception and so i was very interested i'd only emailed with this guy and when he showed up in my office within about you know 15 seconds it's like this is like the nicest normalest kid you could ever meet such a nice guy so normal socially adept smart thoughtful lovely lovely person so i chatted with him for a long time and he told me he was then halfway through he grew up in lynn massachusetts and he went off to swarthmore his freshman year and he had been having a really rough time of it because in his hometown he was with the same group of kids all the way from first grade through high school and so in fact he he just can't recognize faces at all never could when he was a little kid his mom used to drive him to the practice field and they would sit there and come up with cues about this is how you tell that's johnny he's got this weird thing about us here and this is how you tell that's bobby and they would like practice and practice um and so he developed these clues to be able to figure out who was who in his small little cohort of kids that he knew um you know all the way through high school then he goes off to college and it's all these new people and he's screwed and he said to me that he was just devastated because he would go to a party and he would meet someone and think wow this is a really nice person you know they they i would really like to be this person's friend but he would realize he would have no way to find that person again and so the point he's like you know you don't want it like it's kind of like oversharing to say when you've met somebody for 10 minutes like by the way i'm not going to be able to find you you have to find me it's like you just don't want to have to go there yet right so there's all kinds of things that would make it a real drag to not be able to recognize other faces and now having said all of that i'll say that a surprisingly large percent of the population is in jacob's situation about two percent of the population it will be unsurprising if there are one or two of you in here and if there is you can tell me later i'd love to scan you um but um uh about two percent of the population has routinely fails to recognize family members people they know really well right um and so and interestingly this is completely uncorrelated with iq or with any other perceptual ability your ability to read or recognize scenes or anything else yeah that's the kind of thing where you either have it or don't have it oh good question no it's a it's a it's a gradation so the two percent of the bottom are not like this two percent who are really screwed and everyone else is up here it's a hugely wide distribution and the point is that the bottom end of that distribution is really really bad like they just can't do it at all similarly the top end of that perspec distribution is weirdly good they are so good at face recognition that they have to hide it socially because otherwise people feel creeped out like for example as one of those people they're called super recognizers a bunch of them have been hired by um by investigation services in in london recently as part of their kind of crime solving unit those people are so good that um that one of them said to me we scanned a few of these people one of them said you know if i if i if i you know she recounted this event where she's um standing in line waiting for movie tickets and she realizes that the person in front of her in line was sitting at the next table over at a cafe four years before she says if i share this information with that person they'll be creeped out so i've just learned to keep it to myself but i know that was the same person right so there's a huge spread you had a question a while back patient um is that so like for example jacob looking at a person could describe that absolutely he knows that it's a face he can tell if they're male or female he can tell if they're happy or sad um it looks like a face to him he just doesn't look different than anyone else yeah is there any difference like okay like for example my father he can tell faces in person just fine but like when he watches videos of people he just cannot like he cannot recognize faces at all so is there any like difference there are lots of cues i mean that's a very interesting exercise to think about what are the cues that you have in person right you have all kinds of other things first of all there's lots of constraining information the person you're looking at there are all kinds of things you know about where you are and who that might be that help right um so yeah there's many different cues to face recognition that might be engaged here so my point is just that um face recognition matters like you can get by if you can't do it but it sucks it's really hard okay okay so mort yes questions no they see the structure of a face they see a proper face if the eye was in the wrong place they would know they absolutely know the structure of the face it just looks they all look kind of the same by the way there's a we don't have time to talk about this in any detail but there's a well-known effect that probably many of you guys have experienced which is called the other race effect and that is the fact that they all look the same whoever they are if you have less experience looking at that group of people you're less well able to tell them apart okay i have this problem teaching all the time i grew up in a rural lilywhite community my face recognition is not so good to begin with and it's really not good for non-caucasian faces it's embarrassing as hell it feels disrespectful i hate it you know i fault myself but actually it's just a fact of the perceptual system your perceptual system is tuned to the statistics of its input and um and it's not so plastic later in life um and so um a way to simulate a version that some of you may have experienced is whatever race of faces you have less experience with if you find those people hard to distinguish it's not that you can't tell it's a face it's not that you could tell that you would be able to tell if the nose was in the wrong place it's just hard to tell one person from another so it's a lot like that i really need to get going so i'll take one more question and go wait could you like kind of use an analogy it's like being able to tell people apart by like their hands or something like to the point that like you just like you know you can't really tell people apart by like their hands usually so is that kind of how people feel like it's just looking at a body that's all you had yeah yeah probably probably yeah and there is by the way an interesting literature you show people photographs of their own hand and a bunch of other hands people can't pick out their own hand from so yeah you're right we're not so good at that um okay i'm going to go ahead if you guys are interested i could post there's some there's a whole fascinating literature here but actually i got dinged last year for talking about face recognition too much and prosopagnosia we all heard about in the 900 in 900. so i took most of that out and now you guys are asking me so i don't know what the right thing is but i'm going to go on and i will put some optional readings online especially if you send me an email and tell me to do that okay so point is faces matter a lot they matter you know for the quality of life they're important because they convey a huge amount of information not just the identity of the person but also their age sex mood race direction of attention so if i'm lecturing like this right now and i start doing that you guys are going to wonder what the hell's going on over there yeah i saw a few heads turn i'm just doing a little demo here right we're very attuned to where other people are looking okay so there's just one of many different social cues we get from faces they're just an incredibly rich bunch of information in a face um we read in aspects of people's personality from the shape of their face even though it's been shown with some interesting recent studies there's absolutely nothing you can infer about a person's personality from the shape of their face we all do it and we do it in systematic ways another reason this is important and faces are some of the most common stimuli that we see in daily life starting from infancy where i think about 40 percent of waking time there's a face right in front of an infant's eyes and probably these abilities to extract all this information have been important throughout um our primate ancestry so that's just to say there's a big space of face perception and now we're going to focus in on just face recognition telling who that person is all right so what questions do we want to answer about face recognition well a whole bunch of them and what methods do we want to use so let's start with some basic questions about face recognition well first as usual we want to know what is the structure of the problem in face recognition what are the inputs what are the outputs why is it hard right just as we've been doing for motion and color that's mars computational theory level we want to know how does face recognition actually work in humans what computations go on what representations are extracted and is that answer different do we are we running different code in our heads when we recognize faces from when we recognize toasters and apples and dogs okay another facet of that do we have a totally different system for face recognition from the recognition of all those other things if so then we might want different theories of how face recognition works from our theories of how object recognition works how quickly do we detect and recognize faces that'll help constrain what kinds of computations might be going on and of course how was face recognition actually implemented in neurons and brains so those are just some of the big wide open questions we want to answer so now let's consider what are our tools for considering these things and you guys should all know what tools are available for thinking at the level of mars computational theory basically just thinking right you can collect some images too but basically to understand this we just think so for example um as i keep saying at the level of mars computational theory we want to know what is the problem to be solved what is the input what is the output how might you go from that input to that output okay so for example here's a stimulus that might hit a retina and then some magic happens and then you just say julia okay so we want to know what's going on in that magic okay and if a different image hits your retina you go oh brad that is i wouldn't i'm live in a cave but i barely get out of the lab but i understand that these are people most people recognize that's why i use them that's a question what goes on here in the middle um and your first thought is well duh easy we could just make a template a kind of store the pixels that match that image and take the incoming image and see if it exactly matches and that's going to work great right no why not louder yeah yeah absolutely that's not going to work at all and the problem is that we don't just have one picture of julia that we can match there are loads of loads of totally different kinds of pictures of julia all of which we look at and immediately go julia no problem okay and so that means what what is it that we're doing in our heads if we're storing templates we have to store a lot of them okay so um all those differences in the images so we could memorize lots of templates well that has long been taken as like the reductio out absurdum like that's the ridiculous hypothesis how could that be how could there be room in here to store lots of templates of each person um and furthermore how would that work for people we don't know the other idea which is very vague right now is that well maybe we extract something that's that's common across all of those maybe something like the distance between the eyes something about the shape of the mouth of other kinds of properties that might be invariant across those images that is that you could come you could pull out that information from any of those images okay it's sounding very vague because it is vague nobody knows what those would be but the idea is maybe there's some image invariant properties of a face you can get from here that you can then store and use to recognize faces okay so now we can to think about this we can step back and say okay how is this done in machines so machine face recognition didn't work well at all until very recently okay and then all of a sudden a couple years ago as i said here's another paper from the different one that i showed you before this one is vgg face one of the major deep net systems for face recognition it's widely used there was another one the year before all of this since 2014 2015 hugely cited widely influential they're on all your smartphones boom it all just happened like nearly overnight okay with with the availability of lots of images to train deep nets so now these things are extremely effective um and accurate and so in some sense those networks are possible models of what we're doing in our heads when we recognize faces it doesn't mean we do it in the same way but it's a possibility it's a hypothesis we could test okay yeah what is the current state of the literature surrounding getting other information from people's faces like moods lots lots they're like simple you know there's like conferences and um machine vision competitions on extracting you know personality properties mood properties every possible thing you can imagine this is like a huge a lot of people care about a huge field in computer vision and there's also a huge field in cognitive science asking what humans pull from success oh god others would know that better than me i bet it's pretty damn good a lot of it yeah yeah i mean these things are suddenly extremely effective yeah okay and there will be by the way later in the course my postdoc katharina dobbs who knows that literature much better than i do we'll talk about deep nets and their application in human cognitive neuroscience and she knows a lot about the various networks that process face information okay so this is progress now we have some kind of computational model trouble is nobody really has a intuitive understanding of what vggg face is actually doing like you know how to train one up there it is but how do we don't really understand what it's doing and further we have no idea if what it's doing is anything like what humans are doing okay so it's progress that we have a model now that we didn't have like five years ago um but we still have all these questions open okay so on this first question what do we want to know what we've discovered at the level of mar computational theory is a if not the central challenge and face recognition is a huge variation across images right which you know just by thinking about it or trying to write the code okay so um oh i'm just barely able i'm going to race along and anja's going to tell me in five minutes to switch okay um so i want to talk just a little bit about behavioral data i'll run out of time and we'll roll this in last time because i want to include functional mri because you guys need it for the assignment okay so how are we going to figure out what humans represent about faces okay so here we are we consider this possibility that one way to solve this problem is by essentially memorizing lots of templates for each person another possibility is this kind of vague and kuwait idea that maybe there's some abstract representation that'll be the same across all of those how are we going to figure out which humans do well if we're really memorizing lots of templates for each person and that's how we recognize them in all their different guises that wouldn't work for people we didn't know that is you you wouldn't be able to take two different photographs of the same person and know if it's the same person or not right because you could only do this by memorizing everybody get that idea whereas whatever this other idea is it should work somewhat for novel individuals you don't already know here are two photographs same person or different person so now let's ask can humans do this do we store lots of templates for individuals or can we do something more abstract well if we can store if we simply deal with this problem by storing lots of templates for each individual maybe not literally pixel templates but some kind of literal some kind of snapshot then the key test is we shouldn't be able to do this matching task if we don't know that person everybody get the logic here okay so let's try it so this paper a few years ago jenkins at all asked that question so here's what they did they collected a whole bunch of photographs of dutch politicians with multiple images of each politician okay then they gave them to people on cards and they said there are multiple images of each person and i'm not going to tell you how many different politicians are in this deck just sort them in piles so there's a different pile for each person okay i'm going to show you a low-tech version of this i'm going to show you a whole bunch of pictures all in one array and you guys are going to try to figure out how many people are there okay everybody ready i'm just going to leave it up for a few seconds it's going to be lots of pictures your task is how many different individuals are depicted here here we go okay write down your best guess just kind of look around you know okay everybody got a guess okay write down your guess okay how many people think there are over 10 different individuals there one okay how many people think over five yeah probably half of you how many people think over three most of you they're two what does that mean that means you can't do it that means you can't match different images of the same person if you don't know that person pretty surprising isn't it we think we're so awesome at face recognition because most of the time what we're doing is recognizing people we know people we've seen in all different viewpoints and here arrangements and stuff if you haven't see if you don't have lots of opportunity to store all those things and it's a novel face we're really bad at that okay yeah but there's a constraint of time yeah yeah i was trying to make the demo work but you know the way okay so the way they do this task people have unlimited time and they're just kind of sorting them the mean number of piles that people made in this experiment was seven and a half correct answers too okay okay now you might say well maybe those are shitty photographs right okay so here's the control those are dutch politicians they then did the same experiment on dutch people who look at that photograph and in about two seconds say two duh okay so if you know there's nothing wrong with those photographs it's just a matter of whether you know those people or not okay so the point of all of this is that this crazy story that in fact what a lot of what we're doing i'm sort of simplifying here but a lot of what we're doing in face recognition a lot of the way we deal with all this image variability is not that we have some very abstract fancy high-level um representation of each individual face we just have lots of experience with faces and we use that so that if we have a novel face that we don't have all that experience with we're not so good at it i'm going to run out of time so i'll take one question and go on um how do they control for you know the issue you said about like if you don't have experience with like certain races yeah i'm sure whenever you do face recognition experiments you make sure that you know if your dominant subject pool is caucasian you have caucasian faces or whatever yeah if unless it's something you don't understand i'm going to hang around after class you can ask me questions there or you have to if you have to go you can email me because i really want to get through this next bit okay okay so um okay so there we are with that so what this suggests kind of sort of is that whatever we're doing it's something that benefits enormously from lots and lots of experience with that individual maybe it's not literal memorization of actual pixel-like snapshots but it's something more like that than anybody would have guessed before this experiment okay okay all right i'm gonna skip this awesome stuff here okay um okay so uh the the the benefits of actually gonna come back and do that slide next time too we're gonna cut straight to functional mri i'm sorry about this but i just really want you guys to have this background in case you don't you probably do but um so functional mri another cool method in cognitive neuroscience and how would it be useful here okay so first what is it functional mri is the same as regular mri that's in ten probably tens of thousands of hospitals around the world the big advances in functional mri were when some physicists in the early 90s figured out how to take those images really fast and how to make images that reflect not just the density of tissue but the activity of neurons at each point in the brain okay that was big stuff okay early 1990s and so the reason it's a big deal it is the best highest spatial resolution method for making pictures of human brain function non-invasively that means without opening up the head all right so that's an important thing that's why there's lots and lots of papers on it that's why we're going to spend a lot of time on it the bare basics are that the functional mri signal that's used is called the bold signal that stands for blood oxygenation level dependent signal okay what that means is this basic signal uh is blood flow and so the way it works is if a bunch of neurons some place in your brain start firing a lot that's metabolically expensive to make all those neural neurons fire um and so you have to send more blood to that part of the brain so it's just like if you go for a run the muscles in your legs need more blood delivered to them to supply them metabolically for that increased activity and so the blood flow increase to your leg muscles will increase okay well similarly the blood flow increases to active parts of the brain now the weird part of it is that for reasons nobody completely understands the blood flow increase more than compensates for the oxygen use so the signal is actually backwards active parts of the brain have less not more deoxygenated hemoglobin compared to oxygenated hemoglobin and the relevance of that is that oxygenated hemoglobin and deoxygenated hemoglobin are magnetically different in the way that the mri signal can see so the basic signal you're looking at is how much oxygen is there in the blood in that part of the brain and hence how much blood flow went there and hence how much neural activity was there did that sort of make sense i'm not going to test you on which is paramagnetic and which is diamagnetic i never remember i couldn't care less but you should know what the basic signal is right it's a magnetic difference that results from oxygenation differences that result from blood flow differences that result from neural activity more oxygenated and because it over compensates for oxygen for for the metabolic use of the neurons the active parts that you see with an mri signal have more oxygenated hemoglobin right okay all right so that's the basic signal and because that's the basic signal there's a bunch of things we can tell already so first of all um i'm just going to am i going to do this i'm going to skip over this it doesn't really matter because it's all based on blood flow one it's extremely indirect neural activity blood flow change over compensation different at magnetic response mri image right so you would think with all those different steps that you would get a really weird non-linear messy crappy signal out the other end and it is one of the major challenges of my personal atheism but actually you get a damn good signal out the other end and it's pretty linear with neural activity which seems like kind of a freaking miracle given how indirect it is okay but that has empowered this whole huge field to discover cool things about the organization of the brain okay nonetheless are many caveats because it's blood flow the signal is limited in spatial resolution down to people fight about this but around a millimeter there are cowboys in the field who think that they can get less than a millimeter maybe i don't know it's debated uh and the temporal resolution is terrible blood flow changes take a long time think about it you start running how long does it take before the blood flow increases to your calves well if you're really fit it's probably fast but still going to take a few seconds takes about six seconds for those blood flow changes in the brain after neural activity and it happens over a big sloppy chunk of time and so you cannot you don't have much temporal resolution with functional mri does that make sense okay um okay the because it's this very indirect signal that also means that we get it when we get a change in the mri signal we don't exactly know what's causing it is it synaptic activity is it actual neural firing is it one cell inhibiting another is it a cell making protein you know i mean it could be any of these things right so we don't know and that's a problem um and another problem is the number you get out is just the intensity of the detection of deoxyhemoglobin it doesn't translate directly into an absolute amount of neural activity the consequence of that is all you can do is compare two conditions you can never say there was this exact amount of metabolic activity right there you can only say it was more in this condition than that condition okay all right so those are the major caveats nonetheless we can discover some cool stuff okay so let's suppose to get back to face recognition you wanted to know is face recognition a different problem in the brain from object recognition right if if it was you might want to write different code to try to understand it from the code you're writing writing for object recognition it's something you'd kind of want to know okay so here's an experiment i did god 20 years ago anyway simplest possible thing so it's an easiest way i can explain to you the bare bones of a simple mri experiment you pop the subject in the scanner you scan their head continuously for about five minutes well they look at a bunch of faces for 20 seconds they stare at a dot they look at a bunch of objects they stare at a dot okay five minute experiment you're scanning them that whole time and then you ask of each three-dimensional pixel or voxel in their brain whether the signal was higher in that voxel while the subject was looking at faces than while they were looking at objects okay and when you do that you get a blob i've outlined it in green here but there's a little blob there this is a slice through the brain like this that blob is right in here on the bottom of the brain and the statistics are telling us that the mri signal is higher during the face epochs than the object apex everybody with me here which implies very indirectly that the neural activity of that region was higher when this person was looking at faces than when they were looking at objects okay now whenever you see a blob like that really you want to see the data that went into it so here's mine this is now the raw average mri signal intensity in that bit of brain over the five minutes of the scan you can see the signals higher when that person is looking at face in that region when the person is looking at faces these bars here than when they're looking at objects there everyone get that that's what the stats are telling us this is just the reality check of the data that produced those stats okay so now in fact you can see something like that in pretty much every normal person i could pop any of you in the scanner and in 10 minutes we'd find yours okay um now here's the key question does this so far let's suppose you find this in anyone you do all the stats you like it's as robust as you could possibly want do these data alone tell us that that region is specifically responsive to faces no why it not just like that certain arrangement of um features or it could be reacting to the light in terms of reflecting off good keep going what else yes you could do yeah then it might still be faces but it would be different if it's human faces versus any faces we kind of want to know right the code would be different yeah the face is a part of something absolutely where the object is the whole thing what else just objects are simpler or maybe just easier maybe it's just hard to distinguish one face from another and so you need more blood flow it's just really what that thing is that's a generic object recognition system but it has a harder time distinguishing faces from each other because they're so similar so there's more activity everybody get that okay what else i'm going to go two minutes over so if people have to leave if that's okay i'll try not to go more than two minutes over what else yeah yeah as i just said there's all this stuff we get from a face not just who is it but you know are they healthy what mood are they in are they where they look and all that stuff okay so what you guys just did this is just basic common sense but it's also the essence of scientific reasoning and we'll do a lot of that in this class and the crux of the matter is here's some data here's an inference and so your job is to think is there any other is there any way that inference might not follow from those data how else might we account for those data okay you guys just did that beautifully okay so the essence of good science is whenever you see some data and an inference ask yourself how might that inference be wrong how else might we account for those data okay so that's what you guys just did i had previously made a list of other things that might mean it could respond to anything human you would said any kind of face but it could also be just anything human maybe a response to hands any body part anything we pay more attention to anything that has curves in it or any of the suggestions you guys made okay so the crux of the matter and how you do a good functional mri experiment or make a strong claim about a part of the brain based on functional mri is to take all these alternative accounts seriously and so as just one example what we did in our very first paper is say okay there's lots of alternative accounts let's try to tackle a bunch of them so we scan people looking at now three-quarter views of faces and hands and we made them press a button whenever two consecutive hands were the same that's called a one-back task or whenever two consecutive faces are the same by design that task is harder on the hands than the faces so we were forcing our subjects to pay more attention to the hands than the faces okay and what we found is you get the same blob still responding more to faces than hands and so the idea is by showing that we've ruled out every one of those things it's not just any human body part doesn't go to hands oh so anything human it's not just any body part it's not anything we paid attention to because we made them pay more attention to the hands it's not anything with curvy outline okay and so that's just a little you know tiny example of how you can proceed in a systematic way to try to analyze what is actually driving this region of the brain you come up with a hypothesis and then you think of alternatives to the data and you come up with more hypotheses and then you think of ways to test them and we'll do a lot of that in here okay that's what i just said um and i'll just say that there's lots of data since then that region of the brain is actually extremely uh very much prefers faces um and it's present in everyone and next time we will talk about um uh the fact that that looks like it's suggesting that we have a different system for face recognition for than object recognition but there's a lot we haven't yet nailed the case and you guys should all think about what remains okay thank you sorry i was racing there i will hang out if you guys have questions"}], "2. Neuroanatomy": [{"content": "NANCY KANWISHER: So seeing\nwhere animals are going, so you can avoid them if\nthey're coming after you or so you can catch them if\nyou're going after them, right? One of the arguably\nuniquely human abilities is precision throwing, right? No other animal can do that. That's a very human thing. Although, visual motion is\nshared with lots of ability to see motion is shared\nwith lots of animals. What else did you notice? What else seemed funny or harder\nto discern with stop motion? Yeah? AUDIENCE: We care about small\ndetails like [INAUDIBLE] to understand what\nthe person is seeing. NANCY KANWISHER: Yeah. Yeah, so I was\nmaking notes to self. I haven't done that demo before. But in future, it would\nbe really good to have the audio quality terrible. Because if the audio\nquality is terrible, you would lean more\non lip reading. And we might have noticed more. But it's really hard to\ndo that probably even at relatively fast flicker rates\nbecause that motion information is important. Absolutely."}, {"content": "What else? How about beyond\njust lip reading? What else did you notice about\nthe faces, mine or Jim's? Could you-- yeah? AUDIENCE: They were static. So it was kind of hard\nto tell like emotion because a lot of the\nways we express emotion is very nuanced. NANCY KANWISHER: Exactly. Exactly. Facial expressions\nare incredibly subtle. Like little\nmicroexpressions flicker across the face in a tenth\nof a second and go away, and you guys detect them. Like we're very, very\nsensitive to those things. Sometimes if you see somebody\nin a hallway and, for a moment, there's an expression that\nflickers across their face and then they give\nyou a normal smile, but you can tell\nfrom that expression that actually they\ndidn't want to see you, for whatever reason, right? We catch those things. We're really, really\ngood at catching those little\nfleeting expressions. And those probably have to\ndo with not just sampling with fine temporal frequency\nbut probably seeing the direction of motion of\neach little part of the face. OK?"}, {"content": "OK, so this is just\ncommon sense reasoning about what we might\nhave motion for. OK? And so you guys got all the\nthings that I had in mind. OK, so now the next question,\njust kind of thought question, speculation question, given\nthese many different things that make motion important\nto us, biologically, ecologically, in\nour daily lives, maybe that's important\nenough that we might allocate special brain\nmachinery to processing motion. What do you think? Important enough? Could you get by if you lived\nin a strobe world all the time? Could you survive just fine?"}, {"content": "Hard to say, right?"}, {"content": "Might be hard. I mean, we probably don't need\nto go hunting down predators. But you walk across\nVassar Street. And there's some pretty\ndangerous predators coming down Vassar Street\nin the way of cars, right? You need to know\nwhere they're going and whether you can\ncross in front of them. So it's actually pretty\nhard to live life without being able\nto see motion. And I'll tell you about a woman\nwho has that experience later in the lecture."}, {"content": "OK, next question,\njust think about this. I'm not going to test\nyou on it or anything. It's not the topic\nof this course. But it's a perspective\nyou should take. Imagine that this\nwere a CS course and I gave you a\nsegment of video. And your task was to\nwrite some code that takes that video input\nand says whether objects are moving in that movie or\nsays which objects are moving or how much they're moving or\nwhat direction they're moving. What kind of code\nwould you have to write to take that video input\nto try to figure that out? OK, so just think about that. We're not going to be\nwriting code in this class. But a lot of what\nwe're going to be doing is thinking about,\nhow do you take this kind of perceptual\ninput and come out with that kind of\nperceptual inference? And what kinds of\ncomputations would have to go on in between whether\nthose computations are going on in code that you guys write\nor in a piece of brain that's doing that computation? And thinking about how\nyou might write the code gives you really\nimportant insights about what the brain\nmight be doing. OK?"}, {"content": "All right, so that's the\npoint of all of that. The Marr reading talks\nabout all of this. And the key point we're\ntrying to get here is that you can't\nunderstand perception without thinking about what\neach perceptual inference is necessary for ecologically\nin daily lives and about the computational\nchallenges involved in making that inference. OK?"}, {"content": "So we'll get back to all\nthat next week and beyond. But meanwhile, here's\nthe agenda for today. So here's the agenda. We just did the demo. We're now going to skip and do\nsome neuroanatomy, absolutely bare basics. Because on Wednesday, we\nhave this amazing opportunity to have one of the most famous\nneuroscientists in the world do a dissection of\na real human brain right here right\nin front of you. It's going to be awesome. And I don't want to\nwaste that opportunity or embarrass ourselves\nby having people not know the bare basics. So we're going to\ndo the bare basics. It's all stuff you should\nknow from 900 and 901. And I'm going to\nwhip through it fast, so we can get to more\ninteresting stuff and get back to visual motion. OK? That's the agenda. All right, so some\nabsolute bare basics of the brain, the human brain\ncontains about 100 billion, 10 to the 11th neurons. And that's a very big number. That's such a big number it's\napproximately Jeff Bezos' worth. Well, it was until Mackenzie\ngot into the picture."}, {"content": "So we'll see. No, you don't need to\nremember this number. Just know it's a\nreally big number. Basics of a neuron,\nhere's a neuron. A neuron is a cell like\nany other cell in the body. It's got a cell body\nand a nucleus, just like any other\ncell in your body. But the thing that's\ndistinctive about a neuron is it has a big long\nprocess called an axon. It's got a bunch of dendrites,\nthe little processes, the little thingies\nnear the cell body. And out at the tip of the axon,\nthat's your classic neuron. Many neurons have\na myelin sheath, a layer of rolled up fat\naround the axon made up of other cells. That makes the axon conduct\nneural signals faster. OK, you should know all that."}, {"content": "I'm not trying to insult\nyour intelligence. I'm just trying to make sure\neverybody's with the program here. OK, so you have thousands\nof synapses on each neuron. And that means you have-- to\nput it technically-- a shitload of synapses in your brain. OK? Another important point, the\nbrain runs on a mere 20 watts. And if you're not impressed\nwith that, reflect on the fact that IBM's Watson\nruns on 20,000 watts. So one of the cool things\nabout the human brain is not just all\nthe awesome stuff that we can do that\nstill no computer can do, that I talked about\nlast time, but also how incredibly\nenergetically efficiently we do it with our human brains. So most of this course is\ngoing to talk about the cortex. That's all the stuff on\nthe outside of the brain. That's that sheet\nwrapping around the outside of the brain,\nthat folded outer surface. It's approximately the size\nand area of a large pizza. But there are lots of\nother important bits too."}, {"content": "And I'm going to just\ndo whirlwind tour of those other bits now. OK, so you can\nthink of the brain as composed of four major\nkinds of components. Deep down in the\nbottom of the brain, you have the brain stem, where\nthe spinal cord comes in here. And the rest of the\nbrain is up there. And the brain stem\nis right down here. And the cerebellum, this\nlittle cauliflower like thing that sits out right back there. And in the middle\nof the brain, you have the limbic system\nwith a whole bunch of subcortical regions. And we'll talk about a\nfew of those in a moment. And you have white matter,\nall the cables and connections that go from one part of\nthe brain to another part. This is an actual\ndissected human brain. And all those kind of\nweird fibrous things are bundles of axons connecting\nremote parts of the brain to each other. You can see them in\ngross dissection. OK? And of course, you\nhave the cortex. OK, so these are just four\nmajor things to think about. And before we spend the\nrest of the course on that, we're going to do just\na teeny little bit on the other major bits. OK, and I'm going fast."}, {"content": "So just stop me if any\nof this isn't clear. All right, so the reason\nwe're doing this in part is that, with a\ndissection of a brain, some of the main\nthings you see are those subcortical\nstructures, right? And so even though the course\nis going to focus on the cortex, each little different bit of\nthe cortex to the naked eye looks like any other\nbit of the cortex. It's the subcortical stuff\nthat looks different, right? So that's why we're doing this. OK, bare basics\non the brain stem, you can think of it\nas a bunch of relays in here, different centers that\nconnect information coming up from the spinal cord and send\nit through into the cerebellum. So it's, in many ways, the most\nprimitive part of the brain. That means it's\nshared with animals that branched off\nfrom us very far back in mammalian evolution. But it's also essential to life. OK? So you can get by with\nmost of your cortex gone. Like you may not\nhave a lot of fun. You may not really\nknow what's going on. But you will stay alive. But you can't get by without\nyour brain stem, right? It controls all kinds of basic\ncrucial bodily functions, like breathing, consciousness,\ntemperature regulation, et cetera. So it's not interesting\ncognitively. But it's crucial for life. Cerebellum, this\nbeautiful thing here, it's basically involved\nin motor coordination. But from there on out,\nthere's a huge debate about its possible\nrole in cognition. And so there's lots of\nbrain-imaging studies where people find that\nthe cerebellum is engaged in all kinds of\nthings from aspects of perception up through aspects\nof language understanding. You can find activations\nin brain-imaging studies. Nonetheless, the best\nguess is that you actually don't need a cerebellum\nfor any of this. So if anybody's\ninterested, I'm going to actually try to\nremember to put it up as an optional\nreading on the site. There's a recent\narticle in The Atlantic or The New Yorker about a\nkid who had no cerebellum. And he learned to\nwalk late and slow. Nobody knew what\nhis problem was. But he learned to do\npretty much everything. Like he's pretty much fine. His motor coordination\nisn't great, but he's fine. Yeah? AUDIENCE: How would you\ndefine the consciousness in this context? NANCY KANWISHER: Oh,\nthat's a good question. And it's a big question. And it's a question that\nnobody knows how to answer, not just me. So Christof Koch,\nwho does more work on the neural basis\nof consciousness than just about\nanybody, has been going around saying,\nfor about 15 years, we must not get stuck on\na premature definition of consciousness\nbecause we don't know what that thing is that\nwe're trying to understand. So I'll hide behind Christof's\nparry of that question and say we'll talk about\nit later in the course. But there are many\ndifferent ways of defining it from the\ndifference between being awake versus asleep, which is\nsome of the functions that go on here, the difference\nbetween being knocked out and completely unconscious\nunder general anesthesia, which is different\nfrom being asleep. Those kind of states\nof consciousness are regulated, in\npart, in here, yeah. OK, so you can get by\nwithout a cerebellum. But it's not recommended. Moving right along, all\nthose subcortical bits, we're just going to talk about three\nof the most important ones, the thalamus, this\nbig guy right smack in the middle of the brain,\nvery large structure, the hippocampus,\nand the amygdala. OK, let's talk\nabout the thalamus. Think about the thalamus\nas a Grand Central Station of the brain, OK,\nwith all of these connections going to all those\nparts of cortex coming in and out of\nthe thalamus like that. OK? So one of the key things\nabout the thalamus is that most of the\nincoming sensory information goes by way of the thalamus\nen route to the cortex. OK? So if you start with\nyour ear, there's sensory endings in\nyour ear that we'll talk about later in the term. And they send neurons into\nthis, the thalamus here, this yellow thing, through\na bunch of different stages. They make a stop\nin the thalamus. And then they come up\nhere to this green patch, which is auditory cortex. OK? Similarly,\nsomatosensory endings, touch sensors in\nyour skin that enable you to feel when\nyou're being touched come in through the skin. And they make a stop\nin the thalamus. And then they go up to\nsomatosensory cortex up there. OK? Similarly, visual signals\nthat come in from your eyes make a stop in the thalamus and\nthen go up to visual cortex. OK, what's the name of the\nstructure in the thalamus that those axons\nmake a synapse in? Coming up from the eyes,\nyou make a synapse here. And you go up to visual cortex. AUDIENCE: LGN. NANCY KANWISHER: LGN, perfect. What does it stand for? AUDIENCE: Lateral\ngeniculate nucleus. NANCY KANWISHER: Perfect. OK, you should know that. This is review from 900, 901. OK, yes?"}, {"content": "Sorry. OK, which sensory modality does\nnot go through the thalamus en route to cortex\nbetween the sensory nerve endings and the cortex? Sorry? AUDIENCE: Olfactory. NANCY KANWISHER: Yes. Yes."}, {"content": "You guys are on the ball. Yes, olfactory system is\nthe one sensory modality that doesn't make a\nstop in the cortex. You can sort of see that here. From the nose, it goes straight\nup into olfactory cortex right there. All right, so that's\nthe standard view of the thalamus is this\nkind of like relay station where all the external sensory\ninformation comes in there, makes a stop, and then\ngoes up to cortex. OK? That's my thalamus act. Boom. Like that, right?"}, {"content": "OK. But, increasingly,\nthere's evidence that the thalamus is much\nmore than a relay station. And why would you bother\nwith a relay anyway? Kind of doesn't mean anything. Kind of means like\nwe don't know what's going on here because\nyou wouldn't just make a synapse for no reason, right? OK, and so the\nfirst thing to note, is there are lots\nof connections that go back down the other way? There are 10 times\nas many connections that go from primary\nvisual cortex right here in me, right\nhere in this guy in red, there are 10 times as many\nthat go backwards down to the thalamus as go forwards. That's mind blowing, right? Information comes from the\neyes up into the brain. What the hell are those things\ndoing going backwards, OK? Well, they're doing all\nkinds of interesting things. So that's the first indication\nthat the thalamus isn't just relaying stuff in a\nstupid, passive way. And the second\nwhole line of work, which many people\nare working on, but I think some of the most\nawesome work on this topic is done by our own Mike\nHalassa in this department. And he does these\nincredible studies that you can do in mice with\nthese spectacular methods that we can't use in humans,\nwhere he can really take apart the circuit and\nmagnificent detail. And he's showing\nthat the thalamus is involved in all kinds\nof high-level cognitive computations in mice. It's really stunning work. When the mice have to switch\nfrom doing one task to another, the thalamus plays a key role in\ngating the flow of information from one cortical\nregion to another, OK? All right, moving along,\nthe hippocampus, I you guys all learned about this. The number one gripe\nin this department as we learn about\nH.M. in every course. So that's going to happen here. But it's going to\nlast about 20 seconds. So here goes. That's a normal slice\nof the brain like this. Here's the hippocampus\non either side. It's like a whole curled up deal\nright there and right there. And here is H.M.'s brain,\nthe famous H.M., who had surgery to remove his\nhippocampus on both sides, and completely lost his episodic\nmemory for anything that happened after his surgery. OK? You all remember that, right? If anybody hasn't heard\nof H.M., send me an email. And I'll give you some\nbackground reading. OK, so very loosely,\nthe hippocampus involved both in this kind\nof long-term episodic memory that H.M. lost. And it also plays a\nkey role in navigation, which we'll talk about in\ngreat detail in a few weeks. And I just want to say\nthat some cases are even more extreme than H.M. So there's a case of\nLonni Sue Johnson. And I am trying to\nget you guys a video. And I didn't get it in time."}, {"content": "But I'll show it to you later in\nthe term if you're interested. Lonni Sue Johnson\nhad a viral infection that went up into her brain. She was an extremely\naccomplished person. She did illustrations on\nthe cover of The New Yorker. She was a pilot. She had her own\nfarm in which she raised lots of stuff, a\nvery smart, interesting, multitalented woman, who\nhad this terrible tragedy of getting viral\nencephalitis at I don't know what\nage, but middle age. And she now does not remember\na single event in her life. She's smart. She's funny. Her personality\nis totally intact. She can answer questions. She can paint. She can do all kinds of things. But she does not remember\na single event in her life. That's pretty astonishing. Reflect on what it means\nto have the sense of self if you don't remember\nanything in your life. Yeah? AUDIENCE: Can she\nremember her name? NANCY KANWISHER:\nThat's a good question. I'm not sure she. Might know her-- yes,\nshe does know her name. Actually, it is\nevident in this video. But the video, well, so\nshe doesn't remember. At one point in this\nvideo, she's asked, were you ever married? And she's lovely and sweet and\ngentle and kind of low key. And she's like, you know,\njust don't remember. I might have been. I might have been. She was married for 10 years. So that's the hippocampus. Important. You don't want to lose that one. Yeah? AUDIENCE: About H.M.,\nif the hippocampus is used in long-term memory,\nwhy is it that it being removed caused him to not form memories? NANCY KANWISHER: Well, so\nlong-term memory means-- it's a vague term. It means the formation\nand retrieval of memories that are\ngoing to last a long time. So in H.M.'s case, he can\naccess a lot of the memories from before his injury. In Lonni Sue's case,\nshe can't do even that. OK? All right, the\namygdala, OK, amygdala is a Greek word\nthat means almond. Because the amygdala is the\nsize and shape of an almond. And so just for fun, we're\npassing around some almonds, my favorite kind. Have some almonds\nand pass them around. All right, OK, so\nthe amygdala is involved in experiencing\nand recognizing emotions, especially fear. The simple statement that you\nshould remember about what the amygdala does is just\nremember the four F's. You guys all know about the\nfour F's, fighting, fleeing, feeding, and mating. OK, patient SM lost her\namygdala on both sides. OK? She cannot experience fear. She doesn't recognize\nfear on facial expressions of other people. And she doesn't\nexperience fear herself. OK? And so that's the\nstriking piece of evidence on what the amygdala does. Her face recognition is\nnormal, recognizing identities. Her IQ is normal. She's overly trusting\nof other people. OK? OK, so that's all\nyou need to know about the amygdala for now. OK, let's talk about white\nmatter, just brief review. Here's a kind of tunnel\nthrough a piece of cortex. OK, so my brain cortex is\nwrapping around like that. If we took a piece like\nthis, just took a segment out like that, this is the\noutside of the brain up there. Cortex runs like this. And gray matter is the\nstuff on the outer surface that's full of cell bodies, OK? White matter are the\naxons, the processes that come out of\nthose cell bodies and travel elsewhere\nin the brain. OK? Everybody clear on that? OK, so we got gray matter up\nhere and white matter down there, mostly myelinated axons\nthat have that layer of fat to make them conduct fast. And so you'll see bundles of\nwhite matter in the dissection. And so here's an\nactual photograph of the slice through a brain. So all that white stuff\nup there is white matter. OK, and so you might\nsay, well, that's just a big bunch of wires. Who cares about that? That's a good question. But actually, the wires\nare pretty damn interesting and pretty fundamental. And so I'll just give\nyou a few reasons. And you don't need to\nmemorize every one of these. I'm trying to give you a gist\nof why we might care about this. And then there will be a whole\nother lecture on networks and connectivity\nlater in the course. Well, first of all, white matter\nis 45% of the human brain, OK? So it takes up a lot of space,\nall those wires connecting one bit to another bit. And I would say we cannot\npossibly understand the cortex and how it works or any little\npiece of it without knowing the connectivity of each\npiece to each other bit of the cortex, right? Imagine trying to understand\na computer or a circuit without being able to see the\nconnections between the bits. Like it would drive you crazy. That's the situation we're\nin now in human cognitive neuroscience. It, frankly, drives me insane. But that's where we are. Next thing, the\nlong-range connectivity of each little bit of cortex,\nsome little bit right there in my brain, is\nconnected to some bunch of other remote\nregions in my brain. And that particular\nset of connections is distinctive for\nthat patch of cortex. So you can think of it as\na connectivity fingerprint of a patch of cortex. OK, so one of the ways that\nthe different bits differ from each other is by\nway of their connectivity fingerprints. And I'm going to skip\nthe rest of these because we're going to\nget back to them later."}, {"content": "And I'm going to\nrun out of time. And I'm going to assign the\nTAs to sound the gong at 12:15. OK?"}, {"content": "Good. All right, now we're\nup to the cortex. This is really,\nlaughably, shallow. But whatever, that's\nwhat we're doing here. So here's this cortex. And as I mentioned,\nit's a whole big sheet. And the different bits look\nreally similar if you just look at them or slice them up. So how are we\ngoing to figure out how this thing is organized? Well, OK, now we're up\nhere talking about cortex. All right, let's start\nwith the easy parts, which you've already seen. You've already\nseen this up here. These colored bits, visual\ncortex, auditory cortex, somatosensory cortex, gustatory\ntaste cortex, those bits are like the easy\nparts of cortex. Those are called\nprimary sensory regions. There's also motor cortex right\nin front of sensory cortex. So those are the\nprimary regions. They're primary in\nthe sense of this is the first place that\nsensory information lands up at the cortex coming up\nfrom the senses, right? OK, and all of that input is\nwired through what structure? AUDIENCE: Thalamus. NANCY KANWISHER: Yes. Thank you. So how are these\nregions organized? Well, they have maps. Every one of these\nregions has a map. And each of them has a\nmap of a different thing. So let's start\nwith visual cortex, and we're going to\ntalk about the map that lives in visual cortex. But the prior condition\nfor understanding that map is to understand the concept\nof receptive field, which you should know. So I'm going to whip\nthrough it quickly. OK, so here is how\nyou map the receptive field as a property of an\nindividual cell in a brain. OK? So the classic way in\nanimal neuroscience is you place an\nelectrode in the brain next to a neuron in\nmonkey visual cortex. OK? So here's this monkey. He's got an electrode\nright in his brain right next to a neuron\nin visual cortex. And every time that neuron\nfires, you get a spike. You hear a spike. OK, now you train the monkey\nto stare at a fixation spot without moving its eyes. OK, I can do this with\nhumans without training you. I can just tell you, look\nat the tip of my nose. OK, so keep your eyes\non the tip of my nose. I can see if you're\nlooking elsewhere. So look at the tip of my nose. OK? OK, so you train a\nmonkey to do that. That takes a few months. And then they can do that. And then while recording\nfrom neurons in his brain, you put stimuli over here,\nput a flash over there or a flash over here or a flash\nover here or a flash over here. OK, you can stop\nlooking at my nose. It's not all that fabulous\na nose, I realize. OK, so a receptive field is\nthe place in the visual world that makes a given neuron fire. OK? So if there's a\nneuron in your brain that responds to a flash here\nbut not a flash here or here or here or here, the\nreceptive field of that neuron is right there. Everybody got that idea? OK, so in visual\ncortex, neurons have restricted receptive fields. They don't respond to anything\nanywhere in the visual field. They respond to a\nparticular place in space. OK, if that's confusing\nat all, ask a question."}, {"content": "Because it will come\nup again and again. All right, so that's what\nthe rest of this slide says, what I just said. Blah, blah, blah. It doesn't matter. That's a receptive field. Different visual neurons have\ndifferent receptive fields for different parts of space. Now here comes the\nimportant idea. In visual cortex,\ntwo neurons that are next to each\nother in visual cortex have nearby receptive fields. OK? So that's the\nconcept of retinotopy or the map in visual cortex. So you basically have a\nmap of the visual world in your visual cortex because\nthere's this systematic layout just like you have\nin your retina. In your retina, visual\ninformation comes in. And because of optics,\ndifferent parts of your retina respond to different\nparts of the image. But that information is\npropagated back through the LGN up to primary visual\ncortex where you still have a map of the visual space\nup in primary visual cortex. OK? So that map is called\nretinotopic in visual cortex because it's oriented\nlike the retina. And so here's a particularly\nkind of gruesome but very literal depiction of this\nproperty of retinotopy in a monkey brain. This is an experiment done\nvery long ago by Roger Tootell. And what he did was he used\na method called deoxyglucose. And so what deoxyglucose\nis a molecule that's a whole lot like glucose. But it's got one little\nchange in the molecule, which means it gets stuck\non the metabolic chain. And so it gets taken up by cells\nthat want to take up glucose. And then it gets stuck in\nthere and can't be broken down. So it builds up in cells that\nare metabolically active. OK? So you can put a\nlittle radioactive tracer on deoxyglucose, inject\nit into a person or an animal. And what happens is it builds\nup with this radioactive tag on all the cells\nthat were active. Make sense? OK, so Tootell did an\nexperiment where he had the monkey fixate on a spot. And he presented\nthis stimulus here. So the monkey's\nfixating right there. And this stimulus is\nflashing on and off. He injects the radioactive\ndeoxyglucose into the monkey while the monkey's\nlooking at this. And then, I'm sorry to say, he\nkilled the monkey, rolled out visual cortex into a sheet. And there it is. And you can see the\nbullseye pattern that the monkey was looking\nat across the surface of visual cortex. Does everybody get that? OK, so that shows\nyou very literally what a retinotopic\nmap is in the brain. It's just like the map of the\nvisual world in the retina. But there it is up in\nthe back of the brain. And humans have this too. OK? And so this can be shown in\nhumans with functional MRI. We'll talk later more about\nthe methods of functional MRI. But here's a very\nhigh-resolution functional MRI experiment done by some\npeople over MGH Charlestown. By the way, when I\nhave names on slides, it's just because, in science,\nwe don't get paid that much. And so our credit for our cool\ndata is kind of all we have. And so I can't stand to\ntalk about other people's cool experiments without\ngiving them credit. I do not expect you\nto learn the names. It's just my little\npersonal tic that I need to have their name\nthere to give them credit, even though you don't\nknow who they are. OK. OK, so what this guy\nJohn Polimeni did was show human subjects\nthis stimulus here. They were fixating right there. And the stimulus is\nflickering with the dots kind of dancing around. And then he looked on\nthe back in visual cortex on the surface of the brain,\nand he sees an M there. It's the same stimulus. It's just flipped\nupside down, which is not deep or interesting. The cortex has to be\noriented one way or another. The brain doesn't care whether\nyou turn it around, right? And your map of visual\nspace is upside down in the back of the head. And you see that M. Does\neverybody get how that also shows retinotopic\nproperties in the brain in human visual cortex? OK. All right, so the key\nidea of retinotopy is that adjacent parts\nof the visual field are mapped to adjacent\nparts of the cortex. All right, OK, a little bit of\nterminology just because people are fast and loose\nwith these things. I've already referred to V1\nand primary visual cortex. It's also sometimes\ncalled striate cortex. It's all the same thing. It's the part of\nthe visual cortex where the information first\ncomes up from the LGN right back here. So in me, it's right there. Most of it is in the space\nbetween the two hemispheres. But a little bit\nsticks out on the side. So in this person, that\nyellowy orange stuff, that's primary\nvisual cortex, which is the same as V1\nand striate cortex. OK?"}, {"content": "That's just terminology. All right, just as we have\nmaps for visual space, we have maps for touch space. And so you've probably\nseen this diagram here of the map of touch space going\nacross somatosensory cortex like this. So this is a picture\nof a slice like that, showing you which parts of the\nbody are mapped out to which parts of space. And you can see that\nparticularly important parts of the body get\nbigger bits of cortex. Yeah? OK, just as we have visual\nmaps and touch maps, we have auditory maps\nin auditory cortex, which is right on the top of\nthe temporal lobe right in here. And what's mapped out\nin auditory cortex is auditory frequency,\nhigh versus low versus high\nfrequencies of sound. And so you see that here's a\npiece of auditory cortex in one subject, showing\nyou regions that respond to high frequencies, low\nfrequencies, high frequencies. Here it is another\nsubject, high, low, high, another subject,\nhigh, low, high. OK, so the point of all of this\nis that primary somatosensory cortex has maps. Everybody clear on this? The different sensory modalities\nmap different dimensions. OK, so what about\nthe rest of cortex? Like you can see,\nmost of the cortex is not primary sensory cortex. Is the rest of cortex just mush? Or are there separate bits\nlike primary sensory areas? And if so, do those\nother bits have maps? And if so, what\nare those maps of? OK?"}, {"content": "We just took you\nfrom 100 years ago to the cutting edge of the field\nis asking this question in lots of different ways right now."}, {"content": "OK? OK, let's back up and ask,\nwhat counts as a cortical area anyway? I just posited that these\nprimary sensory regions count as distinct things. They're like the things, right? They're separate\nthings in the brain. OK? And if for no other reason,\nthen they get direct input from the thalamus, right? OK, but let's back up\nand ask, what exactly is a cortical area? And we're going to\nconsider this question by considering the three\nkey criteria for what counts as a cortical area. OK, the first one is that\nthat region of cortex is distinct from its\nneighbors in function. Neurons there fire in\nresponse to something different from the neurons\nin the neighboring region. OK, that's very vague right now. But we'll illustrate that. The next one is-- I mentioned this before--\neach distinct region of cortex has a different\nset of connections to other parts of the brain. It has a distinct\nconnectivity fingerprint. OK? And the third thing is,\nfor at least some regions of the cortex, they're\nphysically different. If you slice them up and stain\nthem and look at them really carefully, they\nmight look a little different than other\nbits of the cortex. OK? So those are three of\nthe key criteria that have been used to say, this bit\nof cortex, it's a thing, right? It's distinct, right? OK, so let's look at\nthe classic example beyond those primary regions. Those are the most\nclassic regions. Those are the primary regions\nwe've already talked about. Those are the ones nobody\nwould fight you on that. This one is next in line. Nobody would fight\nyou if you say, visual area MT, that's an area. Well, they might."}, {"content": "But most people wouldn't. OK, and then from there on out,\nit's all fighting all the time. OK, so let's talk\nabout visual area MT. It's a little patch of the\ncortex in a monkey brain. This is a side view\nof a monkey brain. And in this human brain, it's\nthat little patch right there. OK, so this region\nmeets all the criteria to be a distinct visual area. So how do we know this? Well, we know this from lots\nand lots of different methods. So I'm going to whip through\na few of those to give you a gist of how we\ncan find evidence that that region is\ndistinct in functional connectivity and the physical\nstuff, sometimes called cytoarchitecture. OK? All right, function,\nhow would we know that region has\na different function? Well, one way,\nthe classic way is to record from individual\nneurons in monkey brains. So if you stick a neuron\ninto monkey visual cortex while the monkey is\nlooking at the stimulus that I'll show you\nin a second, you'll hear the responses of\nan individual neuron. Each click will be the response\nof an individual neuron to the stimulus. So let's play this thing, except\nit's not making any sound. Chris, can you help me? Oh, right."}, {"content": "Duh. That part, OK, see when the\nbar of light moves this way, it makes a lot of firing and\nnot when it moves the other way? Let's watch it for a second. Watch the bar move again. See? It responds less\nwhen it's moving in a different direction. Everybody got that? What is this area\nright there called? Yeah, this area right\nhere in the middle. AUDIENCE: [INAUDIBLE] NANCY KANWISHER: Exactly. That's the receptive field. That's the part of visual space\nthat makes this neuron fire. OK, this neuron also has a\nproperty called direction. It's sensitive to\nmotion, as you see. But it's also specific to\nspecific directions of motion. Everybody see that? OK, so that's a\ndirection-selective neuron in monkey area MT. And here's a way of showing,\nwith data, what you guys just saw. This is a map of\ndifferent directions in polar coordinates. And this shows you how much-- this is a single cell\nbeing described here. This is the direction\nselectivity of that cell, showing you that when\nthe stimulus moves in this direction, you\nget a lot of firing. When it moves in this\ndirection, you get less firing. And can everybody see how this\nplot shows you the direction selectivity of that cell? Make sense?"}, {"content": "Right. OK, so that shows you what\nyou just saw in the movie. So this is one way to establish\nthe function of visual area MT is stick electrodes in\nthere and record directly from them when a monkey looks\nat different kinds of stimuli. And you see direction\nselectivity when you do that. OK, further, if you actually\ndo this systematically, moving across next door\nbits of monkey area MT, what you find is that,\nas we said before, nearby bits of cortex respond\nto similar things, in this case, to similar directions of motion. So here's a little diagram. As you move across the cortex,\nyou see a systematic change in the direction\nselectivity of neurons as you move across the cortex. So in MT, we have a map\nof direction preference, just as we had a map\nof spatial location in primary visual cortex. Make sense? OK, now because those neurons\nare clustered like that-- I forget what my next point was. No."}, {"content": "Never mind."}, {"content": "We'll get that in a second. OK, what about humans? OK, so here's a monkey brain. Here's a neuron\nin a monkey brain. What about humans? Can we record from\nsingle neurons in humans? What do you think?"}, {"content": "Do we ever get to do that? Yeah? AUDIENCE: Like neurosurgeons. NANCY KANWISHER: Yeah. Yeah. Neurosurgeons,\nvery occasionally, enable us to record\nfrom individual neurons in human brains. It's the most awesome data ever. Of course, we only do it\nwhen the neurosurgeons have decided, for\nclinical reasons, to put electrodes\nin human brains. They need to do this to map\nout epilepsy before surgery. And sometimes those\npatients are super nice and say, yes, I'll\nlook at your stimuli or listen to your stimuli while\nyou record from my neurons. And then we get the\nmost awesome data ever. But it's very, very rare. I don't know of any\ndata where people have reported individual\nneurons in area MT in humans. Yeah? AUDIENCE: So how\npowerful should an fMRI be to be able to record\nsuch information? NANCY KANWISHER: Oh,\nwe're getting there. OK, so given that\nwe, very rarely, get to record from\nindividual neurons in humans and we want to more\ngenerally if there is an MT in humans, what do we do? We pop subjects\nin an MRI scanner. And we show them moving\ndots or stationary dots. And we scan them\nwith functional MRI. We'll go through the\ndetails of how this works more in future lectures. But what you see,\nbasically, is this is a slice through\nthe brain like this. And you see this region\nright here responds more to the moving dots. This is the response. This is time here. This is when the moving\ndots are on high response. And then when it switches\nto stationary dots, the response drops. OK, so with functional\nMRI, you can also find the visual area empty\nby the higher response to moving than stationary dots. Does that make\nsense, more or less?"}, {"content": "I mean, I'm not giving\nyou any of the details. But for now, they\ndon't really matter."}, {"content": "OK, so that's cool. But does that tell us\nthat neurons in human MT are specific for the\ndirection of motion? Yes? AUDIENCE: Are the moving dots\nmoving to a specific location? NANCY KANWISHER: They're\nmoving in all the directions you see here. No, it doesn't. It tells us it's sensitive\nto the presence of motion but not the direction of motion. OK? So if we want to really know,\nis human MT like monkey MT or is this really human\nMT, we want to know, are the neurons in there not\njust responsive to motion but are neurons specific\nfor particular directions of motion, OK? So how would we do that? OK, well, there's lots\nof ways of doing that. But actually, one of\nthe charming things is you can do that\nwithout an MRI scanner. That is it won't\ntell you whether it's MT you're looking at. But we can ask the question\nof whether your brains have neurons that are tuned\nfor particular directions. So for this demo, I want you\nto fixate right in the center. And do not move your\neyes from that dot. And I'm going to keep\ntalking for a while, while you keep fixating\nright on that dot. And so what I'm\ngoing to show you is something called\nan after effect. This is also known as the\npsychophysicist's electrode. Psychophysicists are people\nwho just measure behavior. And from behavior,\nthey can infer how individual neurons work. And that is about as\nawesome as it gets. That's much more impressive\nthan just recording from the damn neuron. Inferring from\nvery indirect data how the neuron works from\nbehavior, now, that is pretty-- oops. OK, sorry. Look directly at my face. You see anything? I didn't see it stop. OK, we're going\nto-- oh, here we go. Oh, right. OK, just fixate on\nthe center again. Sorry. I forgot this guy\nwas going to stop. So keep looking at the center. And then when it\nstops in a little bit, then keep your eyes\nright on that dot. And you can see what happens. AUDIENCE: [INAUDIBLE] NANCY KANWISHER:\nOh, that's right. Good point. Yes, right now,\nit's alternating. Nothing's going to happen."}, {"content": "But that's OK. We're going to have\nthe whole experience. Keep fixating on the dot. It's good the TAs\nare on the ball. OK, fixate on the dot. Anybody see anything? Not really."}, {"content": "That's OK. You're not supposed to. That's the control condition. It was alternating directions. OK? So I think it's going\nto start moving again. I'm not sure. Let's go back. Let's just start it again. OK, I'm sorry I blew\nit the first time."}, {"content": "But let's just get this right. OK, fixate on the center\nand just keep your eyes right on that center. So this one, it's\nnot alternating. And it's going to do this\nfor around 30 seconds. And so the whole point of\nthis is a way with behavior to ask the question\nof whether you have neurons in your brain\ntuned to specific directions of motion. And something as low-tech\nand simple as an aftereffect can tell you that."}, {"content": "Keep looking. Did you guys see anything? What did you see? What happened? AUDIENCE: It wasn't\nmoving exactly [INAUDIBLE] NANCY KANWISHER: Uh huh. Well, it actually should-- well, now it's doing\nsomething else. But it should shrink at the end. Did you guys see it shrink? OK, so that's an after effect. And the simple\nversion of the story is that you are tiring\nout your neurons that are sensitive to outward\nmotion while you stare at all that outward motion. And after you kind of burn\nthem out and exhaust them, then when you look at\nsomething stationary, it looks like it's going inward. OK? And the general idea is\nyou have pools of neuron-- the easiest way to\naccount for that is you have pools of neurons tuned\nfor different directions. And that's why, if you\ntire out one batch, you have a net signal\nin the other direction. Does that make sense? This is all very relevant\nto your assignment which is due tomorrow night at 6:00. This phenomenon was used in the\nscanner for that experiment. You can think about how you\nwould use this phenomenon to ask whether there's direction\nselectivity, not just responses to motion, in human MT. Yeah? AUDIENCE: I'm just a\nlittle bit confused. So even when an image\nis completely still, like even if you're\nnot detecting motion, those neurons are still firing? NANCY KANWISHER:\nThat's a good question."}, {"content": "But most likely,\nthe simple cases-- this may have not worked\nbeautifully, in part, because I screwed it up and\ndidn't notice when it stopped. But if it works well, you should\nget a pretty powerful sense that after you see it\nexpanding, then when it's still, it should seem to\nbe contracting. So when that happens-- the reading assigned for\ntoday, tomorrow night tells you what\nhappens in your brain during that time when you are\nlooking at stationary stimuli but experiencing motion. So there's no motion\nin the stimulus. But there's motion\nin your percept. OK?"}, {"content": "So that's the question."}, {"content": "All right? So read the paper and find out."}, {"content": "Yeah? All right, so all of that tells\nus just that there are neurons someplace in your brain that\nare sensitive to the direction of motion. It doesn't tell us that\nthey're in MT in particular. But the assigned reading\nwill talk about that. OK? Right, a further\nbit of evidence is remember I said how, in\nmonkeys, next door bits in MT have similar\ndirection selectivity. That means you can also\ninject an electrical signal in a little patch of MT and\ngive the monkey a net percept of a direction of motion. OK? If all the neurons were\nscrambled around spatially, so that there was no clustering\nof neurons sensitive to, say, this direction of\nmotion, then stimulation wouldn't do anything. But if you train a\nmonkey to tell you what direction of\nmotion he's seeing and you show him just random\ndots that aren't moving in any direction and you\nstimulate one little patch, it'll tell you the\ndirection of motion of the neurons in\nthat little patch. And that is much more\npowerful evidence that that region is not\nonly responsive to motion but causally involved in\nyour perception of motion. OK? I'm a little obsessed with this\ndistinction between recording responses and\nestablishing causality. So we'll go over this\nin more detail later. But I want you to start\ngetting used to that idea. Another way to test the causal\nrole of area MT in motion is with patients with\nbrain damage in area MT. So there's one\nfamous patient who had brain damage\nright there, which is right where MT usually is. And she could not see motion. And she reports\nall kinds of things like difficulty crossing the\nstreet, difficulty catching balls, difficulty\npouring water into a cup, OK, just as you\nguys saw earlier. That's called\nakinetopsia, right? Kinetics, motion. A, not motion, right? Opsia, eyes. OK. All right, so I started\nwith these criteria for what makes something\na distinct area. And one piece of\nevidence is function. And I just give\nyou a whole bunch of different kinds of\nevidence for distinct function and visual area MT,\nthat it's specifically involved in motion processing. And the two other criteria,\nwhich are getting short shrift, but I'll just toss them off."}, {"content": "And we'll return to them. One is the distinct\nconnectivity of that region. OK, so you may have seen\nthis horrific wiring diagram of visual cortex in monkeys. I think it comes up in like\nhalf the talks in classes in my field. This is the one down here. And so there's lots and lots\nof different visual areas. And there's a whole\nfancy wiring diagram. And smack in the middle of this\ndiagram, that's visual area MT. And if you blow this\nup and stare at it, you'll see that MT has a\nparticular set of connections to other visual\nregions in cortex. And its particular\nset of connections are different from\nthe connections of any of those other regions. It's part of its connectivity\nfingerprint or signature. And that's another piece of\nevidence that it's a thing. OK? It's not just another like\namorphous bit of cortex. It's a particular\nthing in the brain. And finally, you might\nwonder, is that bit of cortex physically different? Are the cells in\nthere different? Are the layers of cortex\ndifferent in any way? And you may remember,\nfrom probably 900, about Brodmann areas. Like this dude\nKorbinian Brodmann sliced up lots of dead\nbrains, looked at them under a microscope,\nand argued that there were 52 different\nparts just from what it looked like if you slice\nthem up under a microscope. OK? So we called those\nBrodmann areas. And area 17, this\nprimary visual cortex, comes from Brodmann's\nterminology. And so he argued that there-- he thought these were\ndistinct organs in the brain. And he even inferred the\nspecific histological differentiation of\nthe cortical areas proves irrefutably their\nspecific functional differentiation. Well, it doesn't."}, {"content": "But never mind. Kind of sounded good. Anyway, that was his idea. And these kinds\nof distinct, kind of cellular, physical,\nanatomical differences are very salient for\nprimary cortical areas for vision and audition\nand touch and motor cortex. But they're much muckier\nfor lots of other areas. One important exception,\nwhich is why we chose this, is area MT. And so I'll end in one minute. But just to tell you\nwhere this is going, this is a flattened piece\nof monkey cortex rolled out like with a baking roller. No. I don't know. Something like that. So here's monkey cortex. And there's V1 and V2. And it's a big mess. But that big dark blob,\nthis bit of cortex is stained with something\ncalled cytochrome oxidase. And that indicates\nmetabolic activity. MT neurons are very highly\nmetabolically active. And so here's a map\nof visual cortex. And that exactly is area MT. So area MT actually\nis histologically or cytoarchitectonically\ndifferent from its neighbors and fits all of the criteria\nfor a cortical area. OK?"}, {"content": "I went one minute over. I realize I threw out\na lot of terminology. I don't want you to\nmemorize too much. So I made a list of\nthe kinds of things that you should understand\nfrom this lecture, the things that I think are important."}], "1. Introduction to the Human Brain": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] NANCY KANWISHER: All right. It's 11:05. I'm going to try to start\npromptly at 11:05 each time. So welcome. Is everybody psyched? I'm psyched. This is 913, the Human Brain. I'm Nancy Kanwisher. I'm the prof for this class. And lest, you were wondering, I\nhave a brain, and there it is. That's me, with some\nbits colored in that you will learn about in this class. OK. What I'm going to\ndo today is I'm going to tell you a brief\nstory for around 10 minutes. And then I'm going to\ntalk about the why, how, and what studying the human\nbrain, why it's a cool thing to do, how you do it,\nand what in particular we're going to\nlearn about in here, and then we'll do some mechanics\nand details of the course, and allocation of\ngrades, and all that. It's on the syllabus anyway. Cool? That's the agenda. All right. So let's start with that story. And for this, I'm\ngoing to sit up here. The story isn't\nthat long, but it has a lot of interesting\nlittle weird bits. So I have cue cards\nto remind myself of all the bits I want\nto remember to say. So you can put away your\nphones and your computers. And you don't need\nto take notes."}, {"content": "This is just a story. It's going to foreshadow a lot\nof the themes in the course, but it's not stuff you're\ngoing to be tested on. OK. So this is a true\nstory, and I've changed only a few\ntiny little bits to protect the identity\nof the people involved. But otherwise, it's an\nabsolutely true story. It's a story about a\nscary medical situation that happened to a friend\nof mine a few years ago. But at the same\ntime, it's a story about the nature\nof the human mind, about the organization\nof the human brain. And it's also a story\nabout the ability or lack thereof to recover\nafter brain damage. It's also incidentally a story\nabout resilience, privilege, expertise, and all\nof those things that are characteristic of many\npeople in Cambridge society, not so relevant for the course,\nbut, all right, here goes. So a few years ago,\na friend of mine was staying over at\nmy house in Cambridge en route to a conference\nin a nearby state. And this guy, I'll call him\nBob, was a close friend of mine. I'd known him for\nyears and years. We talked regularly. We went on hiking\ntrips together. We were pretty close. So he's en route\nto this conference. He's staying over at my\nhouse the night before. The plan was for him to get\nup early the next morning and drive to the conference. So we hung out the night\nbefore and chatted. And the next morning, he's\nsleeping in the next room over from mine. And early in the morning,\nI hear some shuffling. I think yep, OK, Bob is\npacking to leave and thank, God, I don't need to get up. I'm only dimly awake. And so I'm not paying\nthat much attention. Shuffle, shuffle, shuffle\nin the background. And then I hear a crash. And I think, what\nthe hell is that? And I get up and I go\ninto the next room. And Bob is lying on\nthe floor, not moving. I say, Bob, and\nthere's no answer. And then I shout, Bob,\nand there's no answer. And then I dialed 911. While we were sitting there\nwaiting for the ambulance to arrive, Bob\nstarts to wake up. And he's very woozy,\nbut he's alive. And he's making a\nlittle bit of sense. And he can't figure\nout what's going on, and neither can I. And so\nwe're talking and chatting, and he's making a\nlittle more sense, but we still don't\nknow what's happening. So then the ambulance\narrives incredibly fast. I felt like three minutes, boom. There's three EMTs\nrushing in the front door, rushing up to the\nroom where Bob was. And they take all his vitals. And they can't find\nanything wrong. And so they're really casual. I guess they confront stuff\nlike this all the time. I don't. Bob doesn't, but they're\nvery calm about it. And they're saying,\nwell, go take him to the hospital or not. And I was like, I think we need\nto know what just happened, even though we seems OK. We kind of need to know\nwhat this is all about. Don't you think? They're like, yeah, you\ncould take him to the ER. And I said, well, do we need\nto waste ambulance resources, or do you think it's safe if I\ndrive him myself, since there's a hospital not far away? They say you could\ndrive him yourself. So I drive Bob to the\nMount Auburn Hospital ER, which is like less than\na mile from my house. And we do the usual\nER thing, which is mostly waiting, and\nwaiting, and waiting, but various docs come by. And they take all these tests."}, {"content": "And they take all these\nhistory questions, and it goes on and on. And basically, they're\njust not finding anything. So after about an\nhour or two of this, they're still doing tests. They don't want to quite\nlet him go yet, because they don't know what happened. Everybody's calm about it. I figure, OK, fine,\nI got work to do. And I tell, Bob, text\nme throughout the day, and I'll come get you whenever\nthey're ready to release you. And so I go into work, but\njust before I go into work, a thought flashes through my\nmind, and I say to the ER, doc you should\ncheck Bob's brain. And the reason that thought\nflashed through my mind is that actually I had\nbeen worrying about Bob for a number of years. And I hadn't really-- it hadn't quite\nregistered consciously, It was kind of too horrifying a\nthought for me to really allow myself to realize I was\nworried about Bob's brain, but I was worried about\na very particular thing and that is that\nBob had been showing these weird signs\nthat he often got lost and didn't\nknow where he was. And on the one hand, this\njust didn't make any sense, because he was fine\nin every other way, but it was really\npretty striking. So one time, I was\nover at Bob's house with some other friends of ours. And the friend\nasked, Bob, how do we get-- how do I drive from\nyour house into Cambridge? And Bob said, well, you go\nto the end of the driveway, and you turn left. My friend and I looked at\neach other like, Bob, what? And Bob thinks about\nit for a minute, yeah, end of the driveway, turn left. I just had this like\nsinking feeling of dread in the pit of my stomach, but\nwe sort of made light of it, and made fun of\nit, and it went by. It was like, no, you turn right,\nand we gave the directions. Another time a friend\nof mine was driving with Bob in Bob's hometown. And notice that\nlike Bob didn't seem to know how to\nget to the grocery store in his\nhometown, where he'd lived for a really\nlong time, a trip he'd made hundreds of times. Another time, I was at\na conference in Germany. And I saw there are\nthese arrays of posters of people presenting usually\npretty dry scientific things. And out of the corner of my\nI see the title of a poster and it says navigational\ndeficits colon, an early sign of Alzheimer's. And I saw that,\nand I just saw ah, and I just kind of\nsuppress the thought. I thought, oh my God,\nBob, wasn't that old. I know Alzheimer's can\nvery rarely strike early. I didn't want to\nthink about it, but it was like rattling around\nin the back of back of my consciousness. So there had been\nthese signs, but as I say, it didn't make sense,\nbecause Bob was holding down a very high-powered job. He was writing beautiful prose. He was the life of every\nparty he was at witty, funny. Everybody's like favorite\nlife of the party. So how could that be? It just didn't make sense\nthat there would be anything wrong with Bob's brain. So I managed for a few\nyears to notice these signs and ignore them and\nnot pay any attention. So the killer thing is, I\nshould have known better. My research for the last 20\nyears has been on the very fact that there are different\nparts of the brain that do different things. And one of the\ncorollaries of that is you can have a\nproblem with one of those parts and the other\nparts can work just fine. And so I, if anyone,\nshould have realized, yes, there's something really\nwrong with Bob's navigation abilities. And the fact that\nhe's smart, and witty, and funny and holding\ndown a high powered job doesn't mean there isn't\nsomething wrong with his brain, with a part of his brain. But I didn't realize that. But then, as I'm leaving the\nER, theyit kind of all clicked. And I said to the ER doc,\nyou better check his brain. I thought Bob was out of\nearshot when I said that. He heard it. He's like what?"}, {"content": "I was like, oh, never mind. Anyway, the ER doc with\nthe kind of confidence that only docs can muster\nsaid, no, not a brain thing. This is a heart thing, which\nwasn't exactly reassuring, but I set aside\nthe brain thought."}, {"content": "And I went off to work. So throughout the day, I\ntexted with Bob a few times. Things seem to be fine. They've done more tests. They weren't finding anything. We just got calmer\nand calmer about it. I guess sometimes weird stuff\nhappens, and you just move on. But then that night\naround 7:00 or 8:00 at night, I was over\nat a friend's house, and the phone rang. And it was Bob. I picked it up and Bob\nsays, get over here. They found something\nin my brain. So I ran out of the\nhouse, grabbed my phone. And as I'm driving to\nthe Mount Auburn ER, I called my trusty lab\ntech, an amazing guy, who keeps track of all kinds of\nthings much better than I do, and I said, I remember\nthat we scanned Bob a bunch of years ago for a\nregular experiment in my lab. And I don't remember the date. I don't remember anything about\nit, but dig around in the files and see if you\ncan figure it out. It might be useful\nto have that scan. So by the time I get\nto the ER, my lab tech has already texted me back\nand said found the scans. I'm putting them in\na Dropbox for you. So I go into the ER, and\nthere's Bob and the ER doc. And Bob says to me,\ndo you want to see it? The ER doc or the\nradiologist has already shown Bob the\npicture of his brain. And so they take me in there."}, {"content": "And I look at it. And I gulped. There was a thing\nthe size of a lime smack in the middle\nof his brain. Pretty terrifying. So this lime in the\nmiddle of Bob's brain was right next to a\nregion that my lab had studied in great detail. In fact, my lab had discovered\nthat a brain region right next to where that line was\nlocated was specifically involved in navigation. How could I not have\nput all this together? But I didn't until that moment\nI thought, of course, of course, there's a thing\nin his brain right next to the parahippocampal\nplace area, which I discovered, and a nearby related region\ncalled retrosplenial cortex, of course. And how the hell could\nI not have known? But I didn't know. In that earlier work, it had\nbeen nearly 20 years ago, I had a postdoc named\nRussell Epstein. And Russell was a\ncomputer vision guy. And he wanted to understand\nhow we see by writing code to duplicate the algorithms\nthat he thought go on in the human brain when we\nunderstand visual images. And that's a very\nrespectable cool line of work, which we'll learn\na little bit about in here. And Russell was\nreally a coding guy. At the time, we were just\nstarting doing brain imaging, but Russell was like\npooh poohing it all. It's like the flash in the pan."}, {"content": "It's going to go by. It's trashy. So you guys get nice\nblobs on the brain. I'm not having any of it. And I kept saying, Russell,\nyou need to get a job. Just do one experiment so\nyou can show in your job talk that you can do brain imaging. It might help you. You don't need to\ndo a lot of it."}, {"content": "Just do one dumb experiment. Russell was interested in how\nwe recognize scenes, not just objects, and faces, and words,\nbut how do we know where we are and how do we recognize if the\nscene as a city, or a beach, or whatever it is? I said, OK, Russell,\nwe'll just scan people, looking at pictures\nof scenes, and looking at other kinds of pictures. And we'll just kind\nof see if there's any part of the brain that\nresponds a lot to scenes. It really was not\nwell thought out. This is not how you\nshould do an experiment. It shouldn't be based on\npolitical calculations, lack of theory, any of the above. But the fact is that's why\nwe did that experiment. Russell needed to be able to\nshow a brain image in his job talk. So we scan some people\nlooking at scenes. And the results\nknocked our socks off. We found a part of the brain\nthat responds very selectively when you look at\nimages of scenes, not when you look at\nfaces, objects, words, or pretty much anything else. And so we'll learn more about\nthat later in the course. We called it the\nparahippocampal place area. And that launched a whole\nmajor line of work in my lab and now dozens of other\nlabs around the world. Backtrack-- we'd already\nfound that region. And here's this\nlime in my friend Bob's brain, sitting right next\nto the parahippocampal place area. Then I remembered, let's\nlook at the scans from my lab from a few years\nago in Bob's brain. I fiddled around and managed\nto download the files. And there it was. You could see that same blob. But in the scans\nfrom a few years before, it was much smaller. It was the size of a grape. That told us a bunch of things. Most importantly, it told us\nthis thing is growing really slowly. And that was hugely important,\nbecause brain tumors are very bad news. And they usually\ngrow really fast. And the fact that it\ngrew really slowly told us that this was not one\nof the kind of worst, most invasive, most horrible ones. It was clearly a problem. It was big. But at least it wasn't\ngrowing hugely fast. But how poignant that there\nwas in my own damn data, and I hadn't seen it\nin my friend's brain. Well, I'm not a radiologist. I'm a basic researcher. And I didn't look,\nand I didn't see it. Indeed, the next\nday, the docs told us that they thought this was\nmeningioma, not cancer. Who knew that you could have\ntumors that weren't cancer? But you can. And they still need to come\nout, if they're big enough. And that's very serious. But it's not as bad as having\na cancer in your brain. As we're collecting\ninformation, the next day, I'm hanging out in\nthe hospital room. And there was an amusing moment\nwhen one of the residents came by. And he's taking the\nhistory and asking all of the basic questions. And I said kind of\nsheepishly-- because you don't want to seem like you\nknow more than the residents. And in fact, I didn't\nreally know more, but I just thought I'd\nprovide a little information. And I said, he's actually had\nsymptoms for a bunch of years, and there's a\nregion of the brain nearby that I've actually\nstudied a little bit. And the resident says,\nlike, we know who you are. So much for my trying\nto stay under the radar. That afternoon, I talked to a\nneurosurgeon friend of mine, because I figured,\nOK, we need advice. We need help. And the neurosurgeon\nfriend said, quote-- it got\nbranded in my brain-- she said, \"it is of\nparamount importance that you find the\nbest neurosurgeon. It's the difference between\nwhether Bob dies on the table or goes on to live\na normal life.\" This is the privilege\npart of the story. I'm not that well connected,\nbut I'm a little bit connected."}, {"content": "And I kind of dug around,\nand did what I could. And we spent a couple\nof weeks, and we found the best neurosurgeon. And the night\nbefore the surgery, Bob is staying over at my\nhouse, because the surgery was in a Boston hospital. And I thought, I've been\ndancing around this for years, but now it's all\nout in the open. We know there's a problem. And I'm going to test him. I'm going to find out\nwhat the hell's going on. This is, after all, one\nof the basic forms of data that we collect\nin my field-- that is, testing people with\nproblems in their brain to try to figure out\nwhat things they can do and what things they can't do. It's a way of figuring out\nwhat the basic components of the mind and brain are. It's actually the oldest, most\nvenerable method in our field, and it's still a\nhugely important one. So I thought, what the hell. So I said, OK, Bob, draw me\na sketch map of the floor plan of your house. Bob takes a few minutes\nand he draws this thing. And it was shocking. There weren't even-- the rooms\nin a rectilinearly arranged house, they weren't\neven aligned. There was, like,\na soup of lines. There was no organization\nfrom one room to the next. And Bob kind of realized,\nthis isn't right, is it? But he didn't know\nhow to fix it. And he said he just\ncouldn't visualize what it looked like\nto be in his house, and so he couldn't\ndraw the floor plan. And I thought, OK, he hasn't\nbeen there in a couple of days. So I gave him another\npiece of paper and I said, OK, draw the\nfloor plan of my house, where you are right now. Bob took a couple of minutes\nand delivered a similar mess. He couldn't even imagine\nthe layout of the room next to him, that he'd been\nin a few minutes before. And then, trying to channel\nmy inner neuropsychologist, I thought OK. Gave him another\npiece of paper and I said, OK, Bob, draw a bicycle. Why did I choose a bicycle? Because it's a\nmulti-part object that has a bunch of\ndifferent bits that have a particular\nrelationship to each other, just as the rooms\nin a house have a particular spatial\nrelationship to each other. And I wanted to know, is\nhis problem specifically about places, or is it about\nany complex, multi-part thing that you have to remember\nthe relationships to? Bob is no artist,\nto put it mildly. But his bicycle was clearly\nrecognizable as a bicycle. It had the two wheels in\nthe right relationship, and it had all of\nthe basic parts in roughly the right place. I then had him draw a lobster,\nanother multi-part object. And also, his lobster\nwas not beautiful, but had everything\nin the right place. That's very telling he had\na specific problem in-- I don't know-- imagining,\nreproducing, remembering? It's not totally clear. The arrangements\nof parts in a room, but not the arrangements\nof parts in an object. And we'll get back to\nthat more in a few weeks."}, {"content": "What do I want to say here? I said all of that. The next day, Bob has\nan 11-hour surgery. Major, hardcore,\nextreme neurosurgery. Remove a huge piece of bone\nfrom the back of your head, pull apart the hemispheres\nof the brain like this, go in multiple inches\nand remove a lime. Holy crap, right? Said lime was right\nnear the vein of Galen. Galen lived, what, a couple\nof thousand years ago? The fact that there's\na vein of Galen means it's a big-ass\nvein-- the kind of vein that even Galen would\nhave found with dissection 2,000 years ago. This lime was all wrapped\naround and interleaved with the vein of Galen. Not good. But because we found\nthe best neurosurgeon, and because we have\nextreme privilege and all of the possible\nmedical resources and expertise you could\npossibly hope for, Bob sailed through the surgery. And an hour after the\nsurgery, I'm chatting with him and he's making sense. Amazing, right? And literally, two days\nlater, they sent him home. And a few days after\nthat, he's back at work. No problem."}, {"content": "Totally fine. But now we get to the question\nyou're probably thinking about. What about his\nnavigational abilities? The sad answer\nis, nothing doing. None of it came back at all. Thank god for iPhones. If Bob lived 30 years ago, he\nwouldn't be able to function. But he goes everywhere\nusing his iPhone GPS-- everywhere. And this fact that\nhe didn't recover his navigational\nabilities is consistent with the whole\nliterature that we'll consider later in the course-- that, often-- not\nalways, but often, if you have brain\ndamage, especially to some of these\nvery specialized circuits that we'll talk\nabout, you don't recover later. If the damage is early, you may\nwell recover-- early in life, you may well recover. Children have much more\nplastic brains that can adjust after brain damage. Adults, not so good. Bob's doing fine. That's my story. Any thoughts or questions?"}, {"content": "Yeah? AUDIENCE: Can he tell the\ndifference between right to left [INAUDIBLE]? NANCY KANWISHER: Yes. Yes."}, {"content": "And it's very interesting. There are many of his\nspatial abilities that are absolutely intact, and yet\nthe ones related to navigation are not. Yeah? AUDIENCE: Can he drive? NANCY KANWISHER:\nYeah, no problem. But he's always looking at his\ndamn phone to get directions, or to listen to the\nGPS directions system. Driving is no problem. It's another kind of\nleft-right-- the immediate spatial orientation abilities\nare absolutely fine. But knowing, where am I now,\nand how would I get there from here, is blitzed."}, {"content": "Other questions? Yeah? AUDIENCE: Can he\nrecognize familiar places? NANCY KANWISHER: Great question. Yes, he can recognize\nfamiliar places. What he can't do is,\nhe can say, oh, right, that's the front of\nour house, or that's such-and-such cafe\nthat's near our house. What he can't do\nis say, which way would you turn from\nthere to go home? AUDIENCE: Can he can he string\ntogether multiple [INAUDIBLE]?? NANCY KANWISHER: Great question. Great question."}, {"content": "A little bit. He can navigate a\nlittle bit with his GPS. And because he's\nlearned certain routes as a series of almost\nverbal commands-- if you're here, turn right,\nthen there, nur, nur, nur, nur. That whole kind of thing."}, {"content": "It's not what any of\nyou guys could do. If you guys are driving\naround in Cambridge or walking around campus-- remember when they blocked off\nthis whole middle of campus a couple of years ago? It was so irritating. I would like go there,\nand it's like, oh god, they've blocked it off. I can't get over to lobby 7. Well, you immediately come\nup with an alternate route. It's like, OK, I guess we're\ngoing to have to do this. You come up with\nan alternate route. This is a normal\nnavigation system can do. Bob can't do that at all. He's like, route blocked? No idea."}, {"content": "Get out the phone."}, {"content": "Yeah? AUDIENCE: Is he good at\nestimating distances? Does he know something is\na certain number of miles away, or? NANCY KANWISHER: Yes. Yes, he is. And that's very interesting."}, {"content": "But that seems to be kind\nof a different thing. You could think about all of\nthe different kinds of cues you have for distance beyond\nyour kind of literal navigation skills. Yeah?"}, {"content": "AUDIENCE: [INAUDIBLE]? NANCY KANWISHER: A little bit. A couple of minutes, yes. The next day-- I mean, it would be\nkind of like this thing. It's like, I sort of vaguely\nremember that when I was here, I turned right, so I'd\nbetter do that again. Yes, did you have question? AUDIENCE: Can he navigate\nwithin buildings? NANCY KANWISHER:\nNo, not very well. And this is a problem, because\niPhones don't usually-- yeah. New hotels, big problem. Finding the bathroom down\nthe hall, or the front door in a hotel, big problem. Yeah. I mean, these are\nproblems you can-- you can come up\nwith workarounds. It's not life-threatening, but\nit's extremely inconvenient. Yeah? AUDIENCE: Is it the case that\nthose navigational skills that develop long-term, like a\nlong time ago are stronger? So he has a harder\ntime developing-- for example, you said\nnew hotels are a problem. But if it is places that are\nmore familiar, like his home, is it easier for\nhim to navigate? NANCY KANWISHER: It's\na great question. And you might\nthink that the kind of navigational maps you laid\ndown long ago would be intact. So is it just that you\ncan't learn new ones? It's a great question."}, {"content": "The answer is kind of\ncomplicated in this case. For routes that he's memorized-- there's a whole different\nsystem for knowing a route, and really having an\nabstract knowledge of a place that enables you to\ndevise a new route if something is blocked on that route. For highly over-learned\nroutes, he's OK. He remembers the [INAUDIBLE]. It's like a memorized\nmotor sequence. You do A, and then B,\nand then C, and then D. He's OK with those, with\nroutes he learned long ago. But he is not good at coming\nup with a new route in a place that he learned long ago. We'll take one last question. AUDIENCE: Does he\nhave conscious access to past knowledge\nthat [INAUDIBLE] And does he have conscious\nknowledge that [INAUDIBLE]?? NANCY KANWISHER: No, he knows-- well, he knows,\nbecause when he tries to figure out which way\nto head, he has no idea. He's extremely aware of\nit, and very articulate on precisely what happens. What he says is, if he's\nlooking at a place-- here's something he says. He's looking at a place. He knows where he\nis, because there's all kinds of other\nbits of information that tell you where you\nare, because you intended to go there, and the relevant\nthings are happening, and all. So he knows where he is. And it looks familiar. If he tries to imagine\nwhat's behind him, he says that he starts to get it\nand it just kind of vaporizes. He just can't hang on to it. He can't kind of construct\na stable mental image of nearby places. I don't know exactly\nwhat that means, but he's very articulate,\nand can report what happens-- what he experiences\nwhen he tries to access this kind of information. What you guys-- we'll go on. But what I want to say\nis, what you guys just did is exactly what\nwe do in my field. We try to take a mental\nability and tease it apart and say, is it exactly\nthis or is it exactly that? And you guys all just\ndid it beautifully. A lot of what we\ndo in my field is kind of this common-sense\nparsing of mental abilities. What is a particular\nmental ability-- how does it relate\nto some other one? Are these things separable ? Can you lose one\nand not the other? Do they live in different\nparts of the brain, et cetera? All right."}, {"content": "That's the story. I'm going to cache out some\nof the particular themes that came out from the story that\nwill echo through this course. And the first and\nmost obvious one is, the brain isn't just\na big bunch of mush. It has structure. It has organization. The different bits\ndo different things. Importantly, when Bob had\nthis big lime in his head, he didn't just get\na little bit stupid. No. His IQ, if he'd take an IQ\ntest, would be unchanged. He lost a very specific\nmental ability. And that is fascinating,\nbut it's also good news for science. Because often, when you try to\nunderstand a complicated thing, a great way to make progress\nis to first figure out what the parts are, and then\nlater try to figure out, how does each\nindividual part work and how do they work together? But if there's part\nstructure, there's at least a place to start. Second theme is that\nsome parts of the brain do extremely specific things. Not all of them. Some of them are\nquite general, and are engaged in lots of\ndifferent mental processes. But some are\nremarkably specific. We'll talk a lot about that. Third big theme. The organization of the\nbrain echoes the architecture of the mind. And I would say, the\nfundamental pieces of the brain are telling us what are\nfundamental parts of the mind. And that's why\nI'm in this field. That's what I think is cool. The brain is just\na bunch of cells. It's a physical thing. Who cares about\na physical thing? The reason we care about it is,\nthat's where our mind lives. And if we study\nthat physical thing, we can learn something\nabout our minds. And that's pretty\ncosmic, I think. The point of all of\nthis kind of work is not to say, oh, that mental\nprocess is here, not there. Who cares?"}, {"content": "I don't really care. I mean, at some point, you\nneed to have a ballpark sense. You need to know to\nstudy the things. But the interesting\nquestion is not where these things\nare in the brain, but which mental processes\nhave their own specialized machinery, and why those? Another important theme. How do brains change? Bob didn't recover\nafter his brain damage, in that very particular\nmental function that he lost. If all of that had happened\nwhen he was five years old, he probably would have. How do brains change\nover normal development? How do they change from\nlearning and experience? How do they change after injury? And the final theme\nechoed in that story is, there are lots and\nlots of different ways to study the brain. There are the simple\nbehavioral observations. Bob can't navigate, but\nhe can do everything else. OK, that's really deep and\ninformative-- low-tech, but really powerful. The anatomical brain\nimages that showed where the lime was\nin Bob's brain, that gives you another\nkind of information. What's the physical\nstructure of the brain? The functional\nimages that we had done in my lab to discover the\nparahippocampal place area, and the studies of what\nmental abilities are preserved and which are lost\nin people who have alterations of their brain. Those are just a\nfew of the kinds of methods in our\nfield, each of which tells us about a different\nkind of thing about the brain. Those are the themes I\nwas trying to get at here. Let's move on to the\nwhy, how, and what of exploring the brain. I'm going to assign the TAs\nto get me to shut up at-- let's see. We're supposed to\nend at 5 minutes before the end of\nclass, is that right? Is that the MIT tradition? OK, so at-- oh, my,\nshockingly soon-- 11:45, you're going to-- AUDIENCE: [INAUDIBLE] NANCY KANWISHER: Oh,\ngreat, thank you. Thank you. This is one of the many\nthings TAs are for. They pick up the hundreds\nof typos and \"mindos\" and all of that. Excellent."}, {"content": "I'm thinking, how the hell\ndid I so mis-time this? Thank you, Heather. OK, good."}, {"content": "We'll go on. Why should we study the brain? First, most obvious\nreason, know thyself. Know what this thing is\nthat's operating in our heads. This is who you\nare, is your brain. There are lots of very fine and\nimportant organs in the body, but the brain is special. So, a heart is important. You'd die without it. But it's the brain\nthat's your identity. There's a reason that\nsurgeons do heart transplants. That makes sense. Something wrong with your heart,\nyou need another heart, OK. But why don't they\ndo brain transplants? That wouldn't make sense. If there's something\nwrong with my brain, it doesn't make sense to\ntake someone else's brain and put it in here, because\nthen I'd be that other person. It doesn't make sense, because\nthe brain is who you are. So the brain is really special. It's not just another organ. That's why, a few years ago, we\nhad the decade of the brain-- not the decade of the pancreas,\nor the liver, or the kidney. People need to\nstudy these things. They need to know\nhow to fix them. They're important. But they're not as\ncosmic as the brain. Second reason why we\nshould understand brains, and that is to understand the\nlimits of human knowledge. The more we understand\nabout the human mind, the more we can\nactually evaluate how good our knowledge is. Are there things that we\nmight not be able to think? Possible through\nscientific theories we might not be able\nto understand, ever? You can think of\nstudying the mind as a kind of empirical\nepistemology, a way to actually know\nabout the knower so we can figure out how\ngood the knowledge is in that knower. That's another reason. A third reason is to advance AI. Up until a few years ago, I\nused to give lectures on vision, and they would all start\nwith some version of this. You guys all have amazing\nvisual abilities in the back of your brain that does vision. You can do all of\nthis incredible stuff that no machine can touch. Hats off to you. You have an amazing\nvisual system back here, and those guys in AI-- it is mostly guys. Guys, gals, whatever. Those people in AI\ncould only dream of coming up with\nalgorithms as good as the one that's running\nin the back of your head. You can't quite start the\nlectures that way anymore. If any of you have\nbeen living in a cave and not heard about\ndeep nets, there's been a massive revolution. And all of a sudden,\ndeep nets are doing things that are really\nclose to human abilities, particularly in vision. For example, in visual\nobject recognition, machines were way far\nbehind human vision until very recently, especially\nwhen this paper here came out-- was published in 2012. First author, Krizhevsky."}, {"content": "It has now been cited an\nastonishing 33,000 times. Actually made this slide\na couple of weeks ago. It's probably been cited\n36,000 times by now. You could look it up on\nGoogle Scholar and find out. That is a huge\nnumber of citations. The influence of this\npaper is ginormous. Probably half of you have\nalready heard about this paper. Raise your hand if you've\nheard about this paper. Oh, OK."}, {"content": "All right. Major, big news. What's so important\nabout this paper? Well, they trained-- as,\nprobably, most of you know-- they trained a deep net\non the over 1 million images in ImageNet, a massive\ncomputer database of images. And they basically taught\nit to do object recognition. And it performed\nmuch more accurately than any previous system, and\nit approaches human abilities. This is major. This is a radical\nchange in the situation that we were in five years ago. Things have changed radically. Just as an example,\nhere's one of the figures from that seminal paper. Here is one of the\nimages from ImageNet that AlexNet, this trained\nnetwork, was tested on. And the correct answer,\naccording to ImageNet, is that that's a mite. And here's what AlexNet says. Its number one first\nanswer is mite, and its second,\nthird, fourth answers are black widow,\ncockroach, et cetera. Pretty damn good. The mite is even sticking\noff the edge of the frame, and it gets it. Container ship. First choice, container ship. Pretty good. Second choice makes sense. Lifeboat. Not bad. Look at that-- motor scooter. I can barely even see the\nmotor scooter in there, but AlexNet, awesome. Right? Leopard. Awesome. Even when AlexNet\nmakes a mistake, the mistake is totally\nunderstandable. Like, according to ImageNet,\nthat is a picture of a grille, and AlexNet calls\nit a convertible. I'm siding with\nAlexNet on this one. This, the correct\nanswer is mushroom, and AlexNet says agaric. I had to look that up. It's a particular\nkind of mushroom. This one's pretty funny. ImageNet says that's\npictures of cherry. There's cherries\nin the foreground. But AlexNet says dalmatian. I'm siding with AlexNet on this. And Madagascar cat, et cetera. Pretty amazing."}, {"content": "And nothing even close to\nthis was possible before 2012. This is very recent history,\nand it has totally shaken up the field in lots of ways. That's been transformative\nnot just for computer science, but it's also been\ntransformative for cognitive science\nand neuroscience. Because now, we have\nalgorithms-- like, here's this deep net,\nand it does this thing. That's a possible theory\nof how humans do it. It's a possible,\ncomputationally precise theory of what's going on in here. And we didn't use to\nhave those, and now we have those for a\nnumber of domains. And that's shaking up the field. There will be a whole\nlecture on deep nets and how you can use them\nto think about minds and brains toward the end of\nthe course-- guest lecture by my postdoc Katharina Dobbs. And we'll hear more about that. But let's first\nstep back a second and say, OK, do they really\nperform as well as humans, even on just object recognition? Well, what if we tested it\non images not in ImageNet? ImageNet is a pretty good test\nbecause these things, as you can see, are highly variable. They have backgrounds. They're complicated. They're real-world images. But they were photographs taken\nby people in a particular way, with a particular goal. And most of the photographs\nyou take, you throw out. They don't end up in ImageNet. ImageNet is a weird little\nidiosyncratic subset of the kind of visual\nexperience that we have. So would this really generalize? It so happens that Boris\nKatz and Andrei Barbu, across the street in\nCSAIL, have been doing some very interesting studies. This stuff isn't published\nyet, but I got their permission to tell you about this\ncool stuff they're doing. And they're saying,\nhey, let's test AlexNet and other similar\ndeep nets since then on a more Realistic, harder version\nof object recognition that's more characteristic\nof what humans do. They're generating this\nhuge data set of stimuli that they crowdsource. Workers on Mechanical\nTurk go on there and create images for them. They get instructions\nlike, hold an object in this particular\nlocation, or at this angle, or move it here, and\nsend us the images. They are getting, I think,\nhundreds of thousands of images to test this on. And they're much more\nvariable in the location of the object in the image, and\nits orientation, and so forth. For example, you\nguys have no problem telling what that\nthing is, but it's a slightly atypical example. Likewise, what's the\nobject on the floor there? You can tell what\nit is, but it's a slightly atypical example. What Boris and\nAndrei are finding is that human\nperformance is still pretty good on these\nimages, but the deep nets are terrible at this stuff. ResNet, one of the\nmore recent ones, drops from 71% correct\non ImageNet to around 25% correct on these images. And the other similar,\nfancy, more recent networks, do similarly badly. On the one hand,\nAI, the deep nets, are awesome and transformative. No question about it. But on the other hand,\ndespite all the hype, they're still not quite like\nhuman object recognition. They're a whole lot closer\nthan they used to be, but they're not really there. And more generally, what\nabout harder problems, like image\nunderstanding-- not just labeling and classification,\nbut understanding what's going on in the image? You guys have probably\nseen image captioning bots. There are lots of\nthese around now. This kind of hit\nthe scene in 2016, when Google AI came out\nwith a captioning algorithm. And of course, right\naround the same time, Microsoft had a\ncaptioning algorithm. And let's see how they do."}, {"content": "This is an example. You give this algorithm\nthis picture here, and it says, that's a dinosaur\non top of a surfboard. That's pretty damn good, right? OK, wow. Let's look more generally,\nhow well this thing works at other examples. It looks at this\nand it says, that's a group of people on the\nfield playing football. Like, wow."}, {"content": "OK. A snow-covered field. Pretty good. Liu Shiwen and Ding Ning\nposing for a picture. I don't know, but\nthese things are very good at face recognition. That's probably exactly\nthose two people. A car parked in a parking lot. Pretty good. A large ship in the water. Pretty good. A clock tower lit up at night. Awesome, right? A vintage photo of a pond. Well, the vintage part. I don't know where the pond is. There's a little water in there. I don't know. Not way off. A group of people\nthat are standing in the grass near a bridge. Not really. There's grass. There's a bridge, sort of. There's people. But not really, right? A group of people\nstanding on top of a boat. Definitely not. A building with a cake. What? A person holding a cell phone. Not. A group of stuffed animals. I love this one. A necklace made of bananas. Wow. We've really landed\non Mars here. A sign sitting on the grass. Talk about missing the boat. Now, look at this\npicture for a second. Just figure out\nwhat's going on here. Takes a couple of seconds. Everyone got it?"}, {"content": "There's a lot going on here. This algorithm\nsays, I think it's a group of people standing next\nto a man in a suit and tie. And the algorithm is\ncorrect, but the algorithm has profoundly missed the boat. I'm channeling--\nactually, I stole these slides from\nJosh Tenenbaum."}, {"content": "But let me channel\nhim for a moment and say what his big\nidea is, which I think is really important. And that is that both\nhumans and deep nets are very good at pattern\nrecognition-- pattern classification. This is a cat, or a dog,\nor a car, or a toaster. What they're not good at-- what humans are good at,\nbut the deep nets are not, is building models to\nunderstand the world. When you look at\nthis picture, there are all kinds of things\nthat are crucial for really understanding, at a deep\nlevel, what's going on in here."}, {"content": "We need to know\nwhy some people-- what some people here know,\nbut the guy on the scale does not know. Namely, even if\nyou don't recognize that that's James Comey-- I think it is-- here's Obama with his\nfoot on the scale. You need to know that\npeople find it embarrassing if they weigh too much. You need to know that he can't\nsee that Obama's doing it. You need to know\nthat they can see it, even though he can't, and that's\nkind of the essence of humor. There's just a whole universe\nof rich structural information going in here that is\npart of what it means to understand this picture. And no deep net is even close\nto doing that kind of thing. Bottom line of all this is-- or let me just go\non more generally-- AI systems can't\nnavigate new situations, infer what others believe,\nuse language to communicate, write poetry and music\nto express how they feel, or create math to\nbuild bridges, devices, and lifesaving medicines. That's a quote from our\nleader, Jim DiCarlo, head of this department,\npublished in Wired a year ago in a beautiful\narticle on the limitations of deep nets. But more generally,\nthe point is that, yes, AI is taking a massive leap now. We're right in the middle of\nit, and it's super exciting, and it's helpful to neuroscience\nand cognitive science. But AI has a lot to\nlearn from us too-- a lot to learn from\nwhat's going on in here, and how this thing works\nthat those AI systems still can't touch. All of that was my third\nreason for studying-- we're still in the, why are\nwe studying the human brain? The fourth reason to\nstudy the human brain is the one most\ncompelling to me, and that is that it is\njust simply the greatest intellectual quest of all time. We could fight about cosmology."}, {"content": "I'm not going to fight with\nyou about anything else. I don't think\nthere's any contest. It's the greatest intellectual\nquest of all time. And that's why I'm\nin it, and that's why I hope it'll be fun for you. That was the why. How are we going to\nstudy the human brain? Here's this thing. How are we going to\nfigure out how it works? Kind of daunting,\nnot totally obvious. The first thing to\nrealize is that there are lots of levels of\norganization in this thing, and hence, lots of\nways of studying it. We could look at molecules\nand their interactions. Lots of people in\nthis building do that. We could look at properties\nof individual neurons. We could look at\ncircuits of neurons interacting with each other. We could look at\nentire brain regions and what their functions are. We could look at networks\nof multiple brain regions interacting with each other. All of those things\nare possible."}, {"content": "But actually, what we're\ngoing to do in the course is none of those\nthings in particular. Instead, we're going to ask a\nsomewhat different question. And that question is,\nhow does the brain give rise to the mind? And to understand\nthat question, we're going to do more at this level,\nand less at the upper level. To answer this question, we\nneed to start with the mind. We need to-- if we're\ngoing to understand, how does this thing produce a\nmind, we need to first figure out, what is a mind? What do we know about minds? We need to start with the\nvarious mental functions that minds carry out-- things\nlike perception, vision, hearing, aspects of cognition,\nlike understanding language, thinking about people, thinking\nabout things, et cetera. For each mental function,\nwhat we're going to do in here is start by trying to\nunderstand how it works in minds as well as we can, or what it is\nthat we're trying to understand that minds can do. What is computed and how? And then we're going to\nlook at its brain basis and try to figure out\nwhat we can figure out about how that mental function\nis implemented in a brain. The first question we'll\nask for all of these domains is, is there specialized\nmachinery to do that thing? And then we'll ask,\nwhat information is represented in the\nrelevant parts of the brain, and when is that information\nrepresented, and how? How are we going to\nanswer those questions? Well, there's lots and lots\nof methods in our field. The first set of methods-- if\nwe want to understand minds, the first set of methods\nare the basic stuff of cognitive science,\npsychophysics. That means showing\npeople visual stimuli, or playing them\nsounds, and asking them what they see or hear. Nice and low tech,\nbut lots has been learned from those methods. You collect reaction\ntime and accuracy, and it's amazing\nhow much you can learn from these methods\nthat have been around for a hundred years or more. Perceptual illusions are\nsimilarly very informative about how minds work. Now, let me say an important\nthing that arises here. Last year was the first\ntime I taught this course, and I would say it went so-so. I'm aiming for it to be\nmuch better this year. And one of the ways\nI'm trying to do that is to be responsive\nto the student evals I got last\nyear, which were not fabulous across the board. Hurt my feelings badly. But once I got over myself, I\ndecided to just listen to them and try to fix it. And one way to fix it is\nto be honest with you today about what this course\nis going to cover. In my evals, student\n50458, bless them, offered this comment. \"This class was not\nsold in the correct way. It should not be\ncalled the Human Brain, because it was basically\njust a cognitive science, not a brain class. I expect it to learn\nvery different material.\" I don't know who\nthis student is. I wish I could\napologize to them. But I will say to you,\nsorry, student 50458-- sorry I didn't make that clear. The fundamental the\nreason the brain is cool is that gives rise to the mind. And that means that studying\nthe biological properties of the brain without considering\nthe mental functions it implements it would\nbe kind of like trying to study the physical\nproperties of a book without considering the\nmeaning of its text. We're going to\nspend a lot of time doing cognitive science in here. And if you had a different\nimpression, sorry about that. But that's what\nwe're doing here. How are we going to answer this? Lots of cognitive science. How are we going to\nlook at the brain basis? Well, we're going to look at\nneuropsychology patients-- people like Bob who\nhave damage to the brain and what functions get\npreserved and lost. We'll look at a lot of\nstudies with functional MRI. Neurophysiology,\nwhere you can record from individual neurons\nin animal brains, and in rare cases,\neven in human brains-- under clinical\nsituations where they need to have electrodes in their\nbrain anyway for neurosurgery. We will look at EEG recorded\nfrom electrodes on the scalp and MEG recording\nfrom magnetic fields from squids placed\nnext to the scalp. We'll look at\nconnectivity measures with a method called diffusion\ntractography, et cetera. Lots of methods. Which mental functions\nwill we cover? Well, to tell you\nabout that, I need to tell you about the\nhuge progress that has happened in our field\nin the last 20 years. All of this is quite recent."}, {"content": "Let's back up to 1990. Here is approximately what we\nknew about the organization of the human brain in 1990. The black ovals\nare the bits that are primary sensory and motor\nregions that have been known for a long time, even by 1990. And the colored\nbits are the bits where we had some idea\nthat face recognition might go on somewhere in the\nback end of the bottom of the right hemisphere\nbecause of people who had damage back there and\nlost their face recognition ability-- sometimes, preserving\ntheir ability to visually recognize words\nand scenes and objects, only losing their ability\nto recognize faces. The language\nregions we had known about for nearly 200 years,\nfrom Broca and Wernicke and others, who had studied\npatients with damage in those regions and noted\nthat they had problems with language function. And similarly, many\npeople had reported that if you have damage up\nhere in the parietal lobes, you sometimes lose\nyour ability to direct your attention to different\nplaces in the visual scene. That was approximately\nwhat was known in 1990. And here's what we know now. We now know, thanks\nlargely to functional MRI, that for dozens of regions in\nthe brain, in every one of you, we have a pretty good idea of\nthe function of that region. This is major progress. This is a kind of rough\nsketch of the organization of the human mind and\nbrain that we have now, that we didn't\nhave 20 years ago. And that's awesome. That has made possible\na lot of progress, building with other methods. What we'll study\nin this course is, we'll focus on those\nmental functions where the brain bases\nare best understood. And that will include things\nlike the visual perception of color, shape, and motion,\nvisual recognition of faces, places, bodies, and words-- and scenes. Didn't make it on the slide. Oh, yes, it did. Perceiving scenes\nand navigating. Understanding numbers. Yes, there's a whole\nlot about the brain basis of understanding numbers. Perceiving speech\nand perceiving music. Understanding language. Understanding other\npeople and their minds. Those are the kinds of\ntopics where there's been a lot of progress recently\nin understanding the brain basis of those mental functions. Those are the ones\nwe'll focus on. And that means there's going\nto be a lot on perception, high-level vision and\nhigh-level audition, because that's one where a\nlot of progress has been made, and it's also a\nlot of the cortex. As I mentioned a moment ago,\nthe whole back part your brain does vision, construed broadly. Some people might say,\nwell, why is she spending all of this time in vision? Well, it's a big part\nof what your brain does. We are very visual animals. So we'll spend a lot\nof time on vision. For each of these functions,\nwe will ask, to what extent is this mental\nfunction implemented in its own specialized\nbrain machinery? Are there multiple\ndifferent brain regions that carry out that function? What does each one do?"}, {"content": "Is there a division\nof labor between those different regions? How does that system\narise in development? Does it have homologues\nin other species? Are these things uniquely\nhuman, or which of them are? And also, along\nthe way, other side cool questions\nthat will come up. What, if anything, is special\nabout the human brain? How come we are taking over--\nand largely destroying-- the planet, and other\nspecies are not? Besides destroying\nthe planet, we're doing some other cool things,\nlike inventing science, and engineering, and medicine,\nand architecture, and poetry, and literature, and\nall of these other-- and music-- all of these\nother awesome things that other species aren't doing. How come our brains are doing\nthat and other species aren't? Where does knowledge come from? You guys know all of this stuff. How much of that stuff was wired\nin at birth and how much of it did you get from experience? How much can our minds and\nbrains change over time? Can we go study a new thing\nand get a whole new brain region for that thing? Can we change the basic\nstructure just by training, or after brain damage? Can we think without language? How many of you have\nwondered about that question?"}, {"content": "Yeah, really basic question. Anya is answering it. Anya and some others. But Anya is doing a lot\nto answer that question. There are actually\nempirical answers to these long-standing,\ndeep questions that everyone wonders about. That's pretty cool. Somebody back there asked a\nwhile ago about awareness. Can we think, perceive,\nunderstand without awareness? How much can go on in\nthe basement of the brain when we don't even know\nwhat's going on down there? We'll consider all of\nthese other cool questions. There's a bunch of things we\nwon't cover in this course for various reasons, that could\nhave been in here and just aren't. There's only so much time. Motor control. It's really important to know\nhow you do things like pick up objects and plan actions. And we're just\nnot covering that. Something had to go. Subcortical function. This is a very\ncorticocentric course. Most of the course will\ndeal with the cortex. That's where most of conscious\nthinking and reasoning and cognition happens. There's a lot of good stuff down\nin the basement of the brain, and it's going to get\npretty short shrift. Not for any good reason-- just what it is. Decision-making."}, {"content": "Important field, not getting\nmuch coverage in here. Importantly,\ncircuit-level mechanisms-- explanations of cognition. If you think that we're going\nto understand not only what it means to understand\nthe meaning of a sentence, but that I'm going\nto give you a wiring diagram of the neurons that\nimplement that function, sorry to be the\nbearer of bad news, but nobody has a\nfreaking clue how you could get a bunch\nof neurons to understand the meaning of a sentence. That's exciting. That means there's a field\nfor you guys to waltz into. And probably, in your\nlifetimes, people will start to\ncrack these things. But just to know what\nwe're headed into, rarely, for almost no\nhigh-level mental functions, do we have anything\nlike a wiring diagram-level understanding\nof any perceptual or cognitive function. That's not in the\ncards for this course, because it doesn't\nexist in the field. For that kind of\nthing, there are cases where you can make progress. You can understand, say,\nfear conditioning in a mouse. Those circuits are\nbeing like cracked wide open by people in this building,\npeople all around the world, with spectacular precision. They know the specific classes\nof neurons, their connectivity. They know every damn\nthing about them. But it's like, how does a mouse\nlearn that this thing is-- to be afraid of this thing? OK, that's important. But for more complex aspects\nof cognition in humans, we can't usually have that kind\nof circuit-level understanding. Lots of other things that\nwill get short shrift. Memory, not for any good reason. I mean, there's\na lot of coverage of memory in 900 and 901,\nand it's just somehow off a blind spot\nfor understanding-- for knowing how to talk\ninterestingly about memory. So I'm not going to give you\na boring lecture on memory. Instead, I'm not going to\ngive you any lecture on memory until I learn how to talk\nabout it interestingly. Reinforcement learning\nand reward systems. I'm going to try to\npull some of that in, but it's not going to\nbe a major focus, even though it's a really\nimportant part of cognition. Attention."}, {"content": "There might be some at the end. How many of you have taken 900? Looks like a little over a half. How many have taken 901? Yeah, a little over half. OK, good. If you have, great. Good for you. This course is designed as\na tier two course for people who have taken 900 or 901. If you haven't,\nyou're probably OK, but you might need to\ndo a little extra work. I've already posted online, and\nin the syllabus, information about, actually, a\nlecture I gave a year ago on some of the background\nstuff that is no longer taught in this course. People hated it\nwhen I taught them stuff they'd already\nencountered before, so I'm trying to minimize that. That's a backup for\nthose of you who haven't taken these courses. If you're worried about this,\nchat with me afterwards. I think it will\nbe OK, just count on doing a little bit of\nextra work-- not much. For those of us\nwho have taken it, there's going to be a\nlittle bit of overlap. It's simply impossible\nto have zero overlap. I mean, what does John Gabrieli\nin 900 and Mark Bear in 901 do? They survey the\nwhole broad field, and they pick the coolest\nstuff out of every little bit, and they teach it to you,\nexactly as they should. But that means that when I\ncome along and try to say, I'm going to do a more intensive\ncoverage of the coolest things, there's going to be a\nteeny bit of overlap. But I'll try to not\nmake it too much-- just because the coolest\nstuff is the coolest stuff. Also, the spin and the\ngoals of this course are quite different\nfrom both 900 and 901. You will have to memorize\na few things, but not much. My real goal in this\ncourse is to have you understand\nthings, not memorize a sea of disjointed facts. A little more on the goals. Really, what I want you\nto get out of this course is to appreciate the big\nquestions in the field and what is at stake\ntheoretically in each. I want you to understand the\nmethods in human cognitive neuroscience, what\neach one can tell you, what it can't, how different\ncombinations of methods Can work synergistically and\ncomplementarily to answer different facets of a question. I do want you to gain some\nactual knowledge about some of the domains of\ncognition where we've learned a bunch,\nboth at the cognitive level and the brain level-- things like face\nrecognition, navigation, language understanding,\nmusic, stuff like that. And crucially, I\nwant you guys to be able to read current\npapers in the field. If you look in the syllabus,\nthe first few papers are, like, 20\nyears old, but it's going to accelerate quickly\nand you'll be reading papers-- I'm trying to choose\nmostly papers published in the last year or two. I'm trying to take you\nstraight to the cutting edge of the field. Yeah? AUDIENCE: Are the papers\ngoing to be straight out of research labs, or are\nthey going to be, like, the annual review [INAUDIBLE]? NANCY KANWISHER: No, straight\nout of research labs. You're going to\nread the real deal, not someone else's blurry,\nthey just read the abstracts and put in some stuff\nin the review article. No, you're going to\nread the actual paper. That's the whole deal."}, {"content": "Those are the goals. Good."}, {"content": "A few things. Why no textbook? This field is moving\ntoo fast for a textbook. Plus, I have strong\nopinions, and I don't like any of the textbooks. Any textbook is out of date. We're going to be reading hot\nstuff that's hot off the press, and so that's not in\nthe textbooks yet. And so we're skipping\nthat, and you're going to go straight to\noriginal research articles. There will be occasional\nreview articles where relevant, but mostly, part of the\nagenda of this course is to teach you to be not\nafraid of and able to read current articles in the field. All right."}, {"content": "You've all been\nwaiting for this. Details on the grading. Pretty standard. Midterm, 25% of the class-- of the grade. Final, 25%. It will be cumulative,\nbut weighted toward the second half. There's going to be a lot\nof reading and writing assignments, approximately\ntwo papers to read per week. And for, usually, one of\nthose papers per week, you will have a very short\nwritten assignment in which, usually, I ask a few simple\nquestions and maybe one paragraph-level think question. The essence of\nthese tasks is not the written assignment itself. The essence of the task is\nto understand the paper. If you understood the\npaper as you read it, then you should be able to\nanswer those questions pretty straightforwardly. And let me just say\nthat understanding a scientific paper\nis not trivial. When I write a scientific\npaper, right in my area, where I have all of the\nbackground, it takes me hours-- hours. It may be five pages. It still takes me hours. It's just how it is. So when I assign a paper and you\nsay, oh, it's only three pages, I could do that in 20 minutes. Oh, no, you can't. No, you can't. And that's part of what I\nwant you to learn how to do, is how to really\nread and understand the scientific paper. Allocate the time it\ntakes to really get it."}, {"content": "That's a big part of\nthe agenda in this task. All of the stuff-- the assignments and the\nsubmission of the assignments-- will all happen on Stellar. Your first written\nresponse to a paper is due February 12 at\n6:00 PM on Stellar. But there are other readings\nthat are assigned before that. A note about the schedule. I struggled a lot trying to\nboth have the assignments happen when you had already learned\nenough in lectures to know how to do it, but have it close\nenough to the topic at hand so it didn't seem, like,\nno longer relevant. It's hard to do both\nof those things. So the compromise is,\nall of the assignments are due at 6:00 PM the\nnight before the class in which they're assigned. If you see that it's\nassigned on the 13th-- if it's listed on the lecture\nfor the 13th, check carefully. It's probably due\nthe night of the-- I'm getting this\nwrong-- the 12th. The night before. And that's so that we and\nthe TAs can look at it, figure out what you understood,\nwhat you didn't, and how to incorporate and\nexplain whatever you didn't get in the next lecture. All right. Quizzes. I haven't done this before. New thing I'm going to try. There are going to be\nabout eight of these. They're going to be very brief. They're going to happen at\nthe end of class, in class. And you will do them on\nyour computer or your iPhone using Google Forms. If anybody doesn't have\na computer or an iPhone they can bring to class\nthe days of those quizzes, let us know after class and\nwe'll come up with a solution. And the idea of\nthese is not to fish out an obscure fact that was in\none of the reading assignments and ding you on it. I'm not interested in that. The goal of this is just\nto keep you up to date, keep you doing the readings,\nkeep you up with the material. And if you basically\nare understanding what you're reading and understanding\nthe lecture material-- maybe you glance at\nit briefly before-- you should do fine\non the quizzes. They're just kind\nof reality checks for us to know what people\nare getting and not. First quiz is February\n20, blah, blah. There is one longer\nwritten assignment that is not due with\nthe usual schedule, with all of the other\nthings, to do near the end. And in that one,\nyou will actually design an experiment\nin a particular area. And that will be-- I don't know yet-- three to\nfive pages, something like that. We'll give you more\ndetails on exactly how you want to organize this. And it will be very\nspecific-- like, state your exact\nhypothesis, state your exact experimental\ndesign, et cetera. And you'll get practice with\nthose things in advance. Those are the grading\nand requirements. And this is the-- you have this\nall in the syllabus in front of you. This is the lineup of topics. But very briefly, let me try to\ngive you the arc of the class. So this is the introduction. Next time, we're going\nto do just a teeny bit of neuroanatomy. There will be a teeny bit of\noverlap with 900 and 901 there. I'm going to whip through\nit in very superficial form. I'm doing that largely because\non the following class, we have an amazing\nprivilege, which is that one of the greatest\nneuroscientists alive today, Ann Graybiel's, will be doing\nan actual brain dissection, right here in this class,\nright in front of you. It's going to be awesome."}, {"content": "I can't wait. It's an incredible privilege. It will be a real human\nbrain, and you guys will be-- Ann will be here with\nall her apparatus, and you guys will\nbe clustered around. And if it's this\nmany, god help us, but we'll figure out\nhow to make it work. I may-- let me just say, if\nthere are listeners in here, I may have to tell\nlisteners they can't come, because very sensitive about\nnot having too many people. Stay tuned on that."}, {"content": "I haven't quite decided yet. It depends how many people\nare taking the class. But it's going to be amazing. And I want to remind\nyou of just some basics so you're not asking her,\nlike, what is the hippocampus? I should all know that, but\nwe'll just do bare basics. And then we'll have\nthe dissection. That will be great. And also, another\nthing to say is, I mentioned that the subcortical\nregions are going to get short shrift in this class. That's true. But a lot of what you\nsee in the dissection is the subcortical stuff. Cortex is great but, it\nkind of all looks the same. You kind of can't say,\noh, that's this region. That's the other region. Well, you can, but it\ndoesn't look any different from any other region. That's where the subcortical\nstuff will happen. Then I'm going to do\na couple of lectures that focus on high-level vision,\nperceiving motion, and color, and shape, and faces,\nand scenes, and bodies, and stuff like that. And we will use those both\nto teach you that content, and also to teach you vast\narray of methods in this field. We will then have a\nlecture on the kind of debates about\nthe organization of visual cortex in humans. I have a particular view. I'm very fond of views\nthat some patches of cortex are very, very\nfunctionally specific. Not everyone believes that."}, {"content": "So I have assigned\nreadings of people who have different views,\nand we will consider that. I will try to expose you\nto the alternate views and tell you why I'm teaching--\nwhy I still believe mine, but why other smart people\nbelieve different things. We will then move up the\nsystem from perception, and we will spend two meetings\ntalking about scene perception and navigation. You got a hint about what\nan interesting area this is from the story of Bob. We'll consider more\nwhat we've learned from studies of patients\nwith brain damage, from functional MRI, from\nphysiology in animals, from cognitive science, from\nthe whole glorious menagerie of methods to\nunderstand navigation. It's a really fascinating area. In the two lectures after that,\nwe'll consider development. How do you wire up a brain? How much is present at birth? What is specified in the genes? What is learned? And a lot of that will focus\non the navigation system and the face system,\nsimply because that's where there's a lot known. We'll consider\nsome other things, but those are two\nareas where there's super exciting work from just\nthe last three or four years. That's what we'll\nfocus on there. I'm then going to do a lecture\non brains in blind people. How are they different?"}, {"content": "How are they the same? What does that tell us? And then you have the midterm. Then we're going to move\non and consider number. How do you like instantly\nknow that that's three fingers and that's two\nwithout having to do anything all that complicated? And if I had 25 fingers\nand held them up, you would immediately get a\nsense that it was about 25. You might not know\nif it was 22 or 28, but you would know\nit was about 25. And there are\nparticular brain regions that compute that for you. And we will consider\nall of that. And there's a very rich\narray of information from studies of\ninfant cognition, from animal behavior, from brain\nimaging, from brain damage, from single-unit physiology, and\nfrom computation, all of which inform our\nunderstanding of number. Those are my favorite\nlectures, where we can take one\ndomain of cognition and inform it with\nall of the methods. And numbers are a\nreally great example. Then we'll talk a\nlittle bit about-- one of my TAS said,\ncall it neuroeconomics. That will sound good. But actually, what\nI'm going to try to do is sort of neuroeconomics. But it will be about pleasure,\nand pain, and reward, and how we think\nabout those things. And then that's down to April 3. Just as a side note,\nall of these things are things that are pretty\nsimilar between humans and-- at least primates. And some of them are\nshared with rodents. And most of the\nthings after that are things that are\nreally uniquely human. We'll be really moving away,\nwith less available animal literature to inform the\nstuff we're looking at, because animals can't\ndo these things. And so necessarily far from the\ndetails of individual neurons and circuits, but\nthere's still lots cool that can be said about\nhow you understand speech, how you appreciate music. There will be a guest\nlecture, just for fun, on brain-machine interface\nby Michael Cohen, who's working in my lab\nnow, and who has a great lecture on this topic. Then we'll spend a couple\nof lectures on language-- how you understand\nand produce language, and what the relevant\nbrain regions are, what we know about\nit from cognition, and lots of other methods-- and what the relationship is\nbetween language and thought. Then we'll think about how\nwe think about other people. This is called theory of mind-- how I can look out\nat this lecture and try to evaluate from\nyour facial expression. Are they bored, sleepy,\noverworked, fascinated, excited? All of this kind of\nstuff that all of us do moment-to-moment\nin any conversation, and that, yes, lecturers\nare doing all of the time, even if I know that you\nguys have too much work, and that's why\nyou're sleepy, and I shouldn't take it personally. I'm still noticing. Anyway, then we'll go on\nand consider brain networks. Of course, brain\nfunction doesn't happen in just a single region,\neven if we spend a lot of time studying individual regions. There's considerable\nwork trying to figure out which sets of regions\nwork together, and how could we discover that,\nand what are those broader networks of brain regions? And then on May 6,\nyou will have turned in your longer\nwritten assignment designing your own experiment. And then on May 6, we will\nwork together in groups to refine those experiments\nand really hash out the details so you actually know how\nto design an experiment. And then we will have this\nguest lecture from my postdoc, Katherina Dobbs, on deep nets\nand what they can tell us about cognition and brains. And then we'll talk about\nattention and awareness. And then I'm not\ntotally sure what we're going do in\nthe last class, but what I'm voting for is\nthat the amazing TAs each give a short talk on the\ncool stuff they're doing. But that's under discussion. OK, that's the arc of the class. Questions? All clear? Great. Well, if I have\nfive more minutes, maybe I'll do one\nother little thing. Let me try this. You asked-- I'm going to try\nto learn everybody's names, but I'm not doing that\nyet, because some of you might not show up and I will\nhave wasted a whole piece of my brain encoding it. I'm just kidding. But anyway, I remember\nthat you asked, are you going to read current papers? Yes, it is-- and you're right. It's daunting. But let me just say a little\nbit about how to read papers. This is not a stats course, and\nwe haven't prerequisited stats. Neither is it a course\non the physics of MRI. There will be parts\nof every MRI paper that have a lot of gobbledygook. We scanned with this\nscanning procedure. We used this kind of scanner and\nthis kind of blah, blah, blah. Lots of gobbledygook."}, {"content": "You guys don't need\nto worry about that. About the stats, it's\nkind of a judgment call. Everyone in here should have an\nidea of what a P level means, and I hope, a sense of what\na T-test is and an ANOVA. If you don't, I should\nprobably tell you that offline, because that's pretty basic. And what a correlation is. Beyond that, just use your\nintuitions about those things. And this is not of course\nabout understanding the details of the stats\nin each experiment. There just isn't room to cover\nall that in the substance of the studies, as well. When you read a paper-- for example, here's a paper-- a very old paper. You come across this,\nand it was like, OK, here are all these words. And it goes on for 20 pages. And how do you even dig in? Well, the way to dig in\nis to start by saying, what question is being\nasked in this paper? If the paper is\nwell written, you'll be able to find that\nin the abstract. Blah, blah, blah, to study\nthe effect of face inversion on the human fusiform face area. We'll talk about\nthat more later. But if you fish\nthrough the abstract, you should be able to find\nwhat question is being asked. And it's the first thing\nyou should figure out about a paper. You don't necessarily\nread a paper start to-- beginning through the end. I think it's better to start\nwith this list of questions in your head and look for the\nanswers to those questions. Second question. What did they find? If the abstract is\nwell written, you can find that in the\nabstract as well. Signal intensity from\nthe fusiform face area was reduced when grayscale faces\nwere presented upside down. Kind of boring, but there it is."}, {"content": "That's the finding\nof this paper. What is the interpretation? In other words, who cares?"}, {"content": "Why-- who cares about this? If you look in here,\nin the abstract, FFA responds to\nfaces per se rather than to the low-level\nfeatures present in faces. We'll talk more about\nwhat that means."}, {"content": "You guys have an assignment\nabout that-- probably, several assignments about\nthat kind of question. Next question you want to\nask yourself is, what is the design of this experiment? Often, for this, you have\nto go beyond the abstract. And I should say, for even\nthese earlier questions, sometimes you won't find\nthem in the abstract. That just means the abstract\nis not well written. But that exists. To get the design-- like, what exactly did they do? Usually, you have to fit\nin what exactly was done, and how were the data analyzed? You need to fish farther. You need to fish around\nother parts of the paper. And of course, all\nof those questions-- I just said, what question-- I circled this part. But there are many\nlevels to one question. You can get more on, why is that\ninverted question important? You look through, usually, in\nthe introduction to the paper. Does the FFA respond\nto faces per se, or to a confounding\nvisual feature which tends to be present in faces? Second, is it true that\ninverted faces cannot engage face-specific mechanisms? Blah, blah, blah."}, {"content": "That gives you a\nlittle more background on what the question is. There are different\nlevels of depth. These are all things\nyou want to be looking for when you read a paper. What exactly was done? We measured MRI\nresponses in the FFA to upright and inverted faces. I don't expect you to\nunderstand all of this."}, {"content": "These are just giving\nyou, schematically, how you proceed when\nyou're reading a paper. More on the interpretation,\nor who cares? This result would show that\nface-specific mechanisms are engaged only or predominantly\nby upright faces, blah, blah, blah. You can fish through\nfor those things."}, {"content": "The point is to have those\nquestions in your head when you read a paper. It's much more easy and\nengaging to read something if you have an agenda\nwhen you read it. Your agenda, in reading\nscientific papers, is to answer those\nquestions for yourself. More stuff. What was the design and logic? Often, that's deep\nin the methods. You have to fish\naround and find it. There will be some set of\nconditions and designs. We'll talk more about\nall this kind of stuff."}, {"content": "What exactly was done,\nblah, blah, more details. And this is an example of\nthe kind of gobbledygook that you can ignore. Subjects were scanned on\na 1 and 1/2 T scanner. And there are all these-- here's an example of\nsaid gobbledygook."}, {"content": "You can ignore\nthis, in this class. Every method will have\ndifferent kinds of gobbledygook. This is MRI gobbledygook. You can ignore it."}, {"content": "It matters a lot, but not here."}, {"content": "What else? How are the data analyzed? If you look in the-- sometimes, there's a data\nanalysis section, or a results section, or a methods\nsection, that will tell you. You can find that,\nfigure it out. What was the finding? Here's more on the finding. Again, you just fish\nthrough for these things. The point is just, when\nyou're reading a paper, it's not necessarily-- what I do is, I read the\ntitle, I read the abstract. And then I start answering\nthose questions for myself. And sometimes, at that point,\nI'm skipping to figures. I'm skipping to methods. Any of that is fine. Don't feel like you need\nto understand each word, especially deep in the methods. I don't know. Was that helpful at all? We'll try it, and you guys\nwill give me feedback, and if it works, great. And if not, we'll do more\non how to read papers. All right, it's 12:25. See you on Monday."}], "8. Navigation I": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] NANCY KANWISHER: Here's\nthe agenda for today. As usual, a bunch of\nannouncements in red. Assignment 4 was graded. There will be comments showing\nup online on Stellar soon on any of you who didn't get\na near-perfect score on it. And I'll also be going over a\nlittle bit of it in a moment. And then once we do\nthat, we're going to talk about navigation--\nhow we know where we are, and how to get from here\nto someplace else, which is much more awesome than it\nsounds at first, as you will see. OK."}, {"content": "So quick review. OK. So what was the key point? Why did I assign the Haxby 2001\narticle for you guys to read? It presents this\nimportant challenge to the functional specificity\nof the face area and the place area. What was that challenge? What was Haxby's key point? Yes, Isabel. AUDIENCE: Well, he\nwas just attacked-- it just has a preference\nfor rectilinear and not seeing if it's\nactual scanning for. It's not truly detecting\nwhether it's a face or not. NANCY KANWISHER: Yeah. He wasn't worrying about\nrectilinearity so much back then. But his point was that\nwe shouldn't care just about the overall magnitude\nof response of a region. Like, OK, it's nice\nif the face area responds like this to face,\nbut isn't like that to objects. But even if it responds low and\nthe same to cars and chairs, it might still have information\nto enable you to distinguish cars from chairs if the pattern\nof response across boxes in that region was stably\ndifferent for cars and chairs. OK?"}, {"content": "That's really key. We'll go over it at\na few more points. But that's essential, right? A lot of the details that\nI'm going to teach you that go by in\nclass don't matter, but I really want you guys\nto understand the PPA. And that's the nub of it."}, {"content": "OK? So the idea is that\nselective-- his claim is that selective regions,\nlike the face area, contain information about\nnon-preferred stimuli. That is, like, non-faces\nfor the face area, or non-places for\nthe place area. And because they\ncontain information, those regions don't care only\nabout their preferred category. So why does Kanwisher\nget off saying the FFA is only about faces and\nthe PPA is only about places if we can see information about\nother things in those regions? OK. That's a really\nimportant critique. That's why we're\nspending time on it. OK?"}, {"content": "OK. Next, what kind\nof empirical data might be an answer\nto Haxby's challenge? I presented at least\nthree different kinds of data that can address this\nand say, hey, wait a minute. You know, you have a point,\nbut what kind of data could speak to that\nand respond to Haxby? We didn't actually talk about\nthis explicitly in class, but think about it. Here's the claim he makes. What might we say, right? So that's empirically true. Like, you look in the FFA. Even in my own data, I\ncan distinguish chairs from shoes a little\nteeny bit in the FFA. OK? So that empirical claim is true. Why might it\nnonetheless be the case that the face area is really\nonly about face recognition? What other data have\nyou heard in here that might make you think that? Yes, Ben. AUDIENCE: Because\nit's the presence-- NANCY KANWISHER: Speak up. AUDIENCE: Sorry. The presence of low-level\nstimuli that are generally in faces, but can also be sparse\non chairs and cars in context. NANCY KANWISHER: Absolutely. So yeah, put another\nway, even if you had a perfect coder for faces-- like take your best deep net\nfor face recognition, VGG face-- it can distinguish chairs\nand shoes too, right? The features that you\nuse to represent faces will slightly discriminate\nbetween other non-face objects. So the fact that we can see\nthat information in itself isn't strong evidence\nthat that region isn't selective for face perception. Absolutely."}, {"content": "What else? Yeah, OK. AUDIENCE: Like transcranial\nmagnetic stimulation? When you stimulate\nthe epithelial and you look at it\nface it affects it, but when you are like\nlooking at other objects, the effect is no longer. NANCY KANWISHER: Exactly. And so what does\nthat tell you about-- OK, so there's\npattern information in there about other\nthings beyond faces. But? Apparently it's not used, right? Now with every bit of evidence,\nyou can always argue back. People would say, well,\nTMS, those effects are tiny. Maybe there isn't and\nwe didn't have power to detect it, blah,\nblah, blah, blah. But at least,\nabsolutely you're right. TMS argues against them. What else? Or at least is a way to argue\nagainst it-- and the Pitcher paper that I assigned\nand other papers that we've talked about in\nhere provide some evidence that actually, at least the\noccipital face area really is only causally involved\nin face perception even if there's information\nin there about other things. What else?"}, {"content": "What other methods\ncan address this?"}, {"content": "Yeah. AUDIENCE: That is\npretty new simulation, and even when you're pressing\nhand against your face, you can perceive faces in it. NANCY KANWISHER: Exactly."}, {"content": "Exactly. So these are both\ncausal tests, right? OK, there's\ninformation in there. But is it causally\nused in behavior? TMS suggests not. The little bit of direct\nintracranial stimulation data that I showed you also suggests\nthe causal effects when you stimulate that region are\nspecific to face perception, again suggesting that\neven if there's pattern information in there,\nit's not doing anything important because\nwe can mess it up and nothing happens to the\nperception of things that aren't faces. Absolutely."}, {"content": "What else? We talked about it very\nbriefly a few weeks ago."}, {"content": "Yeah. AUDIENCE: So if you\nremove the [INAUDIBLE],, it just completely\nmakes a person incapable of perceiving faces. That is causing-- NANCY KANWISHER: Yes, but\nthe crucial way-- yes, but the crucial way\nto address Haxby would be what further\naspect of that? Yes. And by the way, we don't\nremove the area in humans, but occasionally,\nwe find a human who had a lesion there due to a\nstroke and then we study them. AUDIENCE: So they're still\nable to do other categories. NANCY KANWISHER: Exactly."}, {"content": "Exactly. So all three lines of evidence\nfrom studies of prosopagnosia, electrical stimulation directly\non the brain, and TMS, all can provide evidence\nto various degrees. Again, one can\nquibble about each of these particular studies. But all of those suggests that\neven though there's information in the pattern,\nHaxby's right-- there's information in there about\nother things that aren't faces. The only causal effects when\nyou mess up with that region are on faces, not\non other things. That suggests that\npattern information is what they sometimes say\nin philosophical circles is \"epiphenomenal.\" That is, it's just not related\nto behavior and perception. Make sense? OK, moving along,\nhow can we then use Haxby's method\nto not just engage in this little fight about the\nFFA and how specific it is, but to harness this method and\nask other interesting questions from functional MRI data. How can we use it to find out,\nfor example, does the place area discriminate, say, beach\nscenes from city scenes? We want to know what's\nrepresented in there. How could we use this\nmethod to find out? Yes, Jimmy. AUDIENCE: If I do what\nHaxby kind of did, and try the decoder, and see if\nthe decoder could decide and differentiate between\nthe city and or like an acre of shade. NANCY KANWISHER: Exactly. Exactly. So we talked about\ndecoding methods last time as a way to\nuse machine learning to look at the\npattern of response in a region of the brain, and\ntrain the decoder so it knows what the response looks like\nduring viewing of beach scenes, train it so it knows what\nthe response in that region looks like when you're\nlooking at city scenes, and then take a new\npattern, and say, is this more like\nthe beach pattern or is it more like\nthe city pattern? And that's how you could\ndecode from that region. Yes. AUDIENCE: That doesn't tell as\nmuch, in the sense that it's not telling you-- I mean, we know that there\nis residue of information nevertheless, and\nthat this community can be varied on any region\nconsidered at any time, always. NANCY KANWISHER: We have\na true nihilist here. No, it's a good question. It's not the case that you can\ndiscriminate anything based on any region of the brain. So there are some constraints. There are some\nthings you can find in some places and other things\nyou can find in other places. And they're not uniformly\ndistributed over the brain. However, the fact we\njust-- the point I just made about yes, there's\ndiscriminative information in the face area about non-faces\nbut maybe it's not used, should raise a huge caveat\nabout this whole method. How do we ever know? We see some discriminative\ninformation. How do we know\nwhether it's actually used by the brain,\npart of the brain's own code for information, or\njust epiphenomenal garbage that's a byproduct\nof something else? It's a really important question\nabout all of pattern analysis. We do it anyway\nbecause we're beggars. We can't be choosers in terms\nof methods with human cognitive neuroscience. And we want to know\ndesperately what's represented in each region. So we do this. But whenever you\nsee these lovely, \"I can decode x from y,\" things,\nyou should always be wondering. Who knows if that fact\nthat you, the scientist, can decode it from\nthat region means the brain itself is reading that\ninformation out of that region? Big, important question. All right, put another way-- so Jimmy mentioned just\ndecoding in general and that's absolutely right. But to directly harness\nthe Haxby version of this, what would we do? First, we would functionally\nlocalize the PPA by scanning them, looking\nat scenes and objects, find that region\nin each subject. Then we would collect\nthe pattern of response across voxels in the\nPPA while subjects were looking at, say, beach scenes. And so if this is the\nPPA, this is the pattern of response across voxels\nin that region when they're looking at beach scenes-- fake data, obviously,\njust to give you the idea. So we would split the data\nin half, even runs, odd runs. That would be like even runs. Then we get another\npattern for odd runs. And then we get another\npattern for when they're looking at city\nscenes with even runs, and another pattern\nwhen they're looking at city scenes in odd runs. So then, once we have\nthose four patterns, what is the key prediction\nif using Haxby's correlation method? What is the key prediction if\nthe PPA, if pattern of response in the PPA, can discriminate\nbeach scenes from city scenes? What should we see\nfrom these patterns? What's the key prediction? Claire. Key prediction-- you have\nthese four patterns in the PPA, and now you want to know is\nthere information in there that enables you to discriminate\nbeach scenes from city scenes? AUDIENCE: Is that like\nbeach even and beach odd are more similar than\nbeach even and city even? NANCY KANWISHER: Exactly. Exactly."}, {"content": "Right. It sounds all complicated and\nit's easy to get confused."}, {"content": "But the nub of the\nidea is really simple. It just says, look, the\nbeach patterns are stable. We do beach a few times, we get\nthe same pattern, more or less. We do city, we get\na different pattern. And we keep doing city, we get\nthe same pattern more or less. And the beach pattern and the\ncity pattern are different. So that's the nub of the idea. And so you can implement it with\ndecoding methods or the Haxby versions, just to ask whether\nthe correlation between two beach patterns-- beach\neven, beach odd-- is more similar than the pattern\nbetween one of the beaches and one of the cities. Just asking, are they stably\nsimilar within a category and stably different\nfrom another category? Does that make sense?"}, {"content": "This is just a variant of this\nthing I showed you guys before. We just harnessed this to\nask whether that region can discriminate. OK, and I just said all of this."}, {"content": "If you still feel\nshaky on this, there's a few things you can do. A version of my little\nlecture on this method is here at my website. You can look at that. It's just like six\nminutes and it's basically what I did before. But if you want to go over\nit again, there it is. You can reread the Haxby paper,\nwhich I know is not super easy, but it's actually\nnicely written. And if you read it carefully,\nit explains the method pretty clearly. You can talk to me or a TA. And we'll get back\nto this question of whether we should\ndo a whole MATLAB based problem set on this. OK, let's move on and\ntalk about navigation. This is a Monarch butterfly. It weighs about half a gram. And yet, each fall\nthe Monarch migrates over 2,000 miles from the USA\nand Canada down to Mexico. In fact, a single Monarch\nflies 50 miles in a single day. It's pretty amazing for\nthis tiny, little, beautiful delicate thing. Even more amazing-- it flies\nto a very specific forest in Mexico that's just\na few acres in size. And it arrives at that\nparticular forest. Now, that's already\namazing, but here's the part that is just totally\nmind blowing and that is-- and it flies back\nnorth in the spring-- and that is that this whole\ncycle takes four generations to complete. And that means that the Monarch\nthat starts up in Canada and flies down to that\nforest in Mexico-- one Monarch does that-- is the great-great-grandkid\nof his ancestor that last went on that route. Put that in your\nhead and smoke it."}, {"content": "That's pretty amazing. Consider the female\nloggerhead turtle. She hatches at a beach,\nand goes out in the sea, and swims around in\nthe sea for 20 years before she comes back 20\nyears later for the first time to the beach that\nshe hatched at. Now, it's pretty amazing, but\nsome mothers miss by 20 miles. They go to the wrong\nisland or the wrong beach on the same island. And so you might think,\nOK, it's pretty good. It's not amazing. But here's the thing-- the wrong beach\nthat those mothers go to is the exactly right beach\nhad the Earth's magnetic field not shifted slightly\nover those 20 years. They're exactly\nprecise, but they just don't compensate for the shift\nin the Earth's magnetic field. Here's a bat. This bat maintains\nits sense of direction even while it flies 30 to\n50 miles in a single night in the dark catching food. And it maintains its\nsense of direction even though it's flying around\nin all different orientations in three dimensions, and\neven as it flips over and lands to perch on\nthe surface of a cave. It doesn't get confused\nby being upside down. This is Cataglyphis,\nthe Tunisian desert ant. These guys are amazing. They crawl around on the\nsurface of the Tunisian desert where it's 140 degrees\nin the daytime, and they have to crawl around\nup there to forage for food. And then because it's so damn\nhot, as soon as they find food, they zoom back to their\nnest and go down in the nest where it's cooler. So here is a track\nof Cataglyphis starting at point\nA and foraging. He's meandering around\nlooking for food going along this whole crazy\npath to point B. And then if he finds\nfood at point B, boom-- straight line\nback exactly to the nest. Now we might ask,\nhow does Cataglyphis keep track as he's doing all\nthis stuff of where his heading is back to his nest? The first thing\nyou might think of is things like\nwhat it looks like. Maybe there are landmarks,\nmaybe there are odors. But no, he doesn't use\nany of those things. And we know that because when\nscientists who have set up this measurement device capture\nCataglyphis after he goes out on this tortuous path and\nfinds the feeding station, they capture him and move them\nacross the desert-- on which they've drawn all these grid\nlines for the convenience of their experiment-- and\nthey release them here. And what does Cataglyphis do? He goes on the exactly\ncorrect vector-- no landmarks, no relevant\nodors, and yet he's obviously encoded the exact\nvector of how to get home. Think about what that\nentails and what's involved. AUDIENCE: The same vector\nwith respect to north? NANCY KANWISHER:\nWith respect to-- yes, well, with respect to\nabsolute external direction, absolutely. So that's what I just said. So these feats of animal\nnavigation are amazing. And animals have evolved ways\nto solve all these problems unique to their environment. They've evolved these\nabilities because they really have to be able to find\nfood, and mates, and shelter. And this is not just esoterica\nin the natural world. MIT students, too,\nneed to be able to find food, and mates, and shelter. So what is navigation, anyway? And what does it entail? Well, I'll argue over\nthe next two lectures that there are two fundamental\nquestions that organisms need to solve to be\nable to navigate. First one is, where am I? And the second one is, how do I\nget from here to there, A to B, wherever there is\nthat you need to get? So we'll unpack this. There are many different\nfacets of each. But so for example,\nif you see this image, you immediately\nknow where you are, and you also know where\nto go if, for example, it starts raining. You might rush into lobby\n7, or if you're hungry, you might turn around and go\nback to the Student Center. Same deal here--\nif you see this, then you know where you\nare and where you would go to get to various things. Now, these judgments rely\non the specific knowledge you guys have of those\nparticular places. You recognize that\nexact place, and you have some kind of\nmap in your head that we'll talk more\nabout in a moment, that tells you where everything\nelse is with respect to it. But even if you're in a\nplace you don't know at all you can still extract\nsome information. So suppose you miraculously\nfound yourself-- boom-- here. I wouldn't mind,\nactually, but that's not in the cards for a while. So you're here. Even if you've just\nhiked around the corner, if you've never seen\nthis place before, you have some kind of idea of\nwhat sort of place this is. Where would you pitch your tent? Where might you try to go\nto get out of this valley? If it was me, I wouldn't. I have friends who would\ngo straight up there and try to drag me\nalong, complaining. If it was me, I'd rather\nlook for some other route."}, {"content": "But you can tell all of that\njust by looking at this image-- where you can go from there,\nnot just what kind of a place it is, but what are the\npossible routes you might take. So these fundamental\nproblems that we solve in navigation,\nof knowing where am I and how do I get\nfrom here to there, include multiple components. In terms of where am\nI, the first piece is recognizing a\nspecific place you know. So you might open your\neyes and say, OK, this is my living room. I know this particular place. But as I just pointed out, even\nif the place is unfamiliar, we can get a sense of what\nkind of place this is. Am I in an urban environment,\na natural environment, a living room, a bathroom? Where am I? A third aspect of\nwhere am I, a third way that we might answer\nthat question, is something about the geometry\nof the environment we're in. So try this right\nnow-- close your eyes. OK, now think about how far\nthe wall is in front of you. Don't open your eyes, just\nthink about how far away it is, how far away the left\nwall is and the right wall is. And how about the\nwall behind you? Don't open your eyes. How far back is\nthe wall behind you from where you are right now? OK, you can open your eyes. It's not rocket science. I just wanted you to intuit that\neven though you're presumably riveted by this lecture, and\nthinking only about navigation, you sort have a kind of\nsituational awareness of the spatial layout\nof the space you're in. So you might have a sense\nof I'm in a space like this and I'm over here in it. And we'll talk more about\nthat exact kind of awareness of your position relative\nto the spatial layout of your immediate environment. It's something that's very\nimportant in navigation. And another part of\nthat is you might think, how would I get out of here? If I'm seriously\nbored by the lecture or for any other\nreason I urgently need to get out of\nhere, you probably know exactly where the\ndoors are in this space. It's just part one of those\nthings that we keep track of. So those are aspects of\nwhere am I in this place. What are the things\nwe need to know to know how we would get\nfrom here to someplace else? Well, the simplest way to\nnavigate to another location another goal is\ncalled \"beaconing.\" And this is a case where\nyou can directly see or hear your target location. So you're sailing in the fog. You can't see a\ndamn thing, but you hear the foghorn over\nthere, and you know you're sailing to that point. So you just go toward the\nsound, nice and simple. You don't need any broader\nmap of anything else. You just hear it\nand head toward it. Or if you see\nthis, and your goal is to get to the green building,\nwell, there's a green building and you just head that way. Now, you're going to have\nto go around a little bit to get around those\nobstacles, but you know where to head because you\ncan see your target directly. These are cases\nwhere you don't need a broader, long-term knowledge\nof the whole environment. If you can see your target,\nyou just go straight for it. So that's beaconing,\nsimplest kind of A to B. And it requires no\nmental map, no kind of internal model of the whole\nworld you're navigating in. But if you can't see the\nplace you want to go, then you need some kind of\nmental map of the world. So what do we mean by a\n\"mental map of the world?\" Well, this idea was\nfirst articulated in a classic experiment\nway back in the 1940s. So this was actually one of\nthe original experiments that launched the cognitive\nrevolution, when we emerged from the scourge of behaviorism\nto realize that it was actually OK, and indeed, of the\nessence, to talk about what's going on in the mind. And a really\ninfluential study that launched the cognitive\nrevolution by Tolman was done on rats. And it went like\nthis-- he trained rats. He put them down in\nthis area, and they had to learn that there would\nbe food out there at the goal. And so they just have to make\nthe series of left and right turns to find the food. So you train them\non that for a while till they're really good at it. And then he put the rats\nin this environment. Now, the environment is\nsimilar, except there's multiple paths, one that seems\nanalogous to the old route. So what are the rats\ndo in this situation? They run down here,\nthey run into a wall, and they realize, OK,\nthat's not going to work. No surprises yet. But then, the rats\nimmediately come back out and they go straight\nout that way. What does that tell you? What did they learn? Did they learn a series of\ngo straight, and then left, and then right, and then right,\nand then go for a long ways? No. That wouldn't work over here. They learned something\nmuch more interesting. Even though they were only\nbeing trained on this task here, they learned some much\nmore interesting thing about the kind of vector\naverage of all of those turns. Everybody get this? It's really simple\nbut really deep. So from this, Tolman\nand others started talking about cognitive\nmaps, whatever it is you have to have learned\nin a situation like this so you can abstract\nthe general direction. We don't just learn\nspecific routes as a series of\nstimulus and responses. So there must be some\nkind of map in your head to be able to do this, and\nrats have that, and so do you. So let's consider this\nquestion right now. Where am I? Where are you? To answer that\nquestion to yourself, there's something like\nthis in your head. And it probably doesn't look\nexactly like that in your head, but there's some version of this\ninformation that's in your head that you're using\nwhen you answer the question of where you are. And you have some way to say\nin that map of the world, I know not just what the\nMIT campus looks like and how it's arranged, but\nI know where I am in it. Now, if you want to know\nhow to get somewhere else-- like suppose you're\nhungry and you want to go over to the\nStata Cafeteria over there. What else do you need to\nknow besides knowledge of the map of your environment\nand where you are in it? What else do you need to know? You know you have this map,\nyou know where you are, and you know where your goal is. Now you have to plan\nhow to get over there. What else do you need to know? Yeah. AUDIENCE: You have to\nknow which parts are paths and which parts are buildings. NANCY KANWISHER: Yes, exactly--\nwhere can you go in there? Actually, where can you\nphysically get through? Actually, our vector\nis right over there, but you can't go\nthat way because you can't go through\nthat glass, even though you can see through it. So knowledge of\nphysical barriers, and what's an actual path\nand what isn't is crucial. What else do you need to know? Suppose we had a\nrobot in this room, sitting right here facing the\nfront of a room like you guys, and we're programming the\nrobot on how to get over there. What are other things we'd\nhave to tell that robot to get it to plan how to get\nover to the Stata Cafeteria? Yeah. AUDIENCE: Things to watch out\nfor, like cars and traffic. NANCY KANWISHER: Absolutely. We'd have to know about\nobstacles, like moving obstacles, not just fixed ones. Absolutely."}, {"content": "What else? Yeah. AUDIENCE: Initial orientation. NANCY KANWISHER: Yes. He has to know which\nway he's headed. You're going to give\nthis robot instructions on which way to go. It matters a whole lot if the\nrobot is starting like this or starting like that. The instructions are different\nin the two cases, and likewise for you guys. To plan a route, you need to\nknow which way you're heading. If you guys have ever\nbeen in Manhattan, and you come up from the\nsubway, and you see the street's going like this, and you\nknow it's north/south, and you don't know if you're\nheading south or north-- really common thing. It's not enough to know I'm at\nthe junction of Fifth and 22nd. You need to know, am I\nfacing south or north? Otherwise you can't figure\nout which way to go. That's called\n\"heading direction.\" We just did all that. You need to know\nyour current heading. You also need to know the\ndirection of your goal in order to plan a route to it. So in this kind of\ntaxonomy of all the things you need to know\nto navigate, we've just added that if\nyou're going to navigate in your own\nenvironment, you need to know not just\nwhere you are in it, but which way you are\nfacing in that mental map. And we also talked\nabout this business of what routes are\npossible from here, how do we move around\nobstacles, where are the doors, where are the\nhazards like cars, et cetera. A final thing you\nneed to know is that even if you have\na good system for all of these other bits, it's\nstill possible to get lost in all kinds of ways. You lose track, you get\nconfused, you get lost. So we also need a way\nto reorient ourselves when we're lost. And we'll talk a lot about\nthat in the next lecture. So this is just common sense. We're doing a kind\nof low-tech version of Marr computational\ntheory for navigation. What are the things that\nwe would need to know or that a robot would need to\nknow to be able to navigate? Just thinking about the\nnature of the problem."}, {"content": "So that's what we need. What's the neural\nbasis of all of this? So I'm going to start right in\nwith the parahippocampal place area, not to imply it is\nthe total neural basis of this whole thing. It's just one little piece\nof a much bigger puzzle."}, {"content": "But we'll start in there\nbecause it's nice and concrete. All right, so this story\nstarts about 20 years ago. I think I mentioned some\nof this in the first class when I talked about\nthe story of Bob and I talked about\nRussell Epstein, who was then my post-doc. And he was doing nice\nbehavioral experiments, and thought it was trashy and\ncheap to mess around with brain imaging. And he was going\nto have none of it until I said, Russell,\njust do one experiment. Scan subjects looking at scenes. I know it's kind of\nstupid, but just do it. Then you'll have a\nslide for your job talk. And he scanned subjects\nlooking at scenes and looking at objects. And here is one of those\nearly subjects, probably me-- I don't remember-- with a\nbunch of vertical slices through the brain, near the\nback of the brain down there, moving forward as\nwe go up to here. Everybody oriented? Sorry, it's not showing up\nvery well in this lighting, but there's a little\nbilateral region right in the middle there that\nshows a stronger response when people look at pictures\nof scenes than when they look at pictures of objects. So we hadn't predicted this. Yeah. AUDIENCE: Is the\npink the eye color? NANCY KANWISHER: Yeah. Yeah, pink is-- all\nthe colors are-- there's significance\nmaps or P levels, right. So pink is higher than blue, but\nblue is borderline significant. So this is kind of dopey."}, {"content": "We didn't actually predict\nit for any deep reason. We hadn't been thinking\nabout theories of navigation or anything like that. It was just one of\nthose dumb experiments where we found something\nand we followed the data. So we found this,\nand it's, like, OK, let's try some other subjects. So here are the first\nnine subjects we scanned. Every single subject had that\nkind of signature response in exactly the same place,\nin a part of the brain called \"parahippocampal cortex.\" So this is very systematic. And there's lots of ways to\nmake progress in science. One way is to have a\nbig theory, and use it to motivate brilliant,\nelegantly designed experiments. And another is you just see\nsomething salient and robust that you didn't predict,\nand you follow your nose, and try to figure it out. So that's what we\ndid in this case."}, {"content": "It's like, OK, what\nthe hell is that? So if you think about-- we eventually called it\nthe \"parahippocampal place area\" after a little more work. If you think about\nwhat we have so far, we've scanned people looking at\npictures like this and pictures like that. And what we've shown is\nthat little patch of brain responds a bunch more\nto these than those. So my first question is,\nis that a minimal pair? Tally, is that a minimal pair? AUDIENCE: Sorry,\nI'm about my voice. NANCY KANWISHER: Sorry. Simple, simple. We're contrasting\nthis with that. AUDIENCE: Can you remind\nme what a minimal pair is? NANCY KANWISHER:\nOK, minimal pair is this thing we aspire\ntowards an experimental design, where we have two\nconditions that are identical except\nfor one little thing we're manipulating. AUDIENCE: I don't really\nthink it's a minimal pair, but I'm not really sure. NANCY KANWISHER:\nWell, I even told you what we were designing\nto manipulate, but-- AUDIENCE: There seems to\nbe too many differences between a living room and-- NANCY KANWISHER: It's ludicrous. I mean, it's a million\ndifferences here."}, {"content": "So we don't know that\nwe have anything yet. There's all kinds of\nuninteresting accounts of this systematic activation\nin that part of the brain. So just to list a few\nthat you've probably already noticed-- these things have rich,\nhigh-level meaning and complexity. So you can think\nabout living rooms, or where you might sit, or\nsomebody's aesthetic, home design, or there's\nall kinds of stuff to think about there, much more\nthan just, OK, it's a blender. So there's just complexity\nin every possible way. There are also lots of\nobjects present here, and only a single\nobject over there. So maybe that region\njust represents objects, and if you have more objects,\nyou get a higher signal. There's another\npossibility, and that is that these images\ndepict spatial layout, and that one does not. So you have some sense of\nthe walls, and the floor, and the layout of\nthe local environment here that you don't\nhave over there. And we could probably list\na million other things It's a very, very sloppy contrast. So how are we going to\nask which of these things might be driving the\nresponse of that region? Well, a natural thing to do is\njust deconstruct the stimuli."}, {"content": "So here's what we did-- this is actually way\nback 20 years ago. There were better methods at the\ntime, but I didn't know them, so I actually drove\naround Cambridge, photographed my\nfriends' apartments, left the camera on\nthe same tripod, moved all the furniture\nout of the way, and photographed\nthe space again. Ha, ha."}, {"content": "I know. And then these will\nbe probably cut out with some horrific version\nof Adobe Photoshop that existed 20 years ago. Anyway, we\ndeconstructed the scenes into their component objects\nand the bare spatial layout. Everybody get the logic here?"}, {"content": "Just to try to make a big cut\nin this hypothesis space of what might be driving that region. So what do we predict\nthat the PPA will-- how strongly will it respond? Oops, how strongly\nwill it respond if these two things are true? If it's the complexity\nor multiplicity of objects that's\ndriving it, what do you predict we will see over there? We already know you get\na high response here. What will we get over there? Yeah. AUDIENCE: Probably get more\nbiases to the furniture. NANCY KANWISHER: Yeah, we'll\nrespond more to this than that. Right."}, {"content": "It's really simple-minded. If instead, it responds\nmore to the spatial layout, what do we predict? Isabel. AUDIENCE: It's going to respond\nto the empty rooms more. NANCY KANWISHER: Yeah. And that seems like\na weird hypothesis because these are really boring,\nthis kind of nothing going on here. And there's just lots\nof stuff going on here. I mean, it's not\nriveting, but it's a whole bunch, whole lot\nmore interesting to look at these than those. Believe me, I got scanned\nfor hours and hours looking at these things. And whenever the empty\nrooms came on, I was, like, oh, my god,\nI'm just so bored. There's just nothing here,\nwhereas here at least there's stuff. But that's not what\nthe PPA thinks. What the PPA does-- oops, we just did\nthe localizer-- it responds like this. This is percent signal\nchange, a measure of magnitude of response, to\nthe full scenes, way down, less than half the response\nto all those objects, and almost the same response\nas the original scene when all you have is\na bare spatial layout. Pretty surprising, isn't it?"}, {"content": "We were blown away. We were, like, what? What? But can you see how even this\nreally simple-minded experiment enables us to just\npretty much rule out that whole space of hypotheses? It's not about the\nrichness, or interest, or multiplicity of objects. It's something much\nmore like spatial layout because that's kind of all\nthere is in those empty rooms. I mean, it could be something\nlike the texture of wood floors or something weird like that. But one's first guess is it's\nsomething about spatial layout. Does this make sense? It's just a way to take\na big, sloppy contrast, and try to formulate\ninitial hypotheses, and knock out a whole\nbig space of hypotheses. Yes."}, {"content": "Is it Alana? AUDIENCE: Yeah, I'm sorry, I\nmight have missed the design. So people who are\nlooking at the empty room would not have the furniture? NANCY KANWISHER: Good question."}, {"content": "I skipped over all of that. We did-- yes, that's true. We did mush them\nall together and one could worry about that,\nthat when you see this, you remember that that's\na version of this. Absolutely. Absolutely. And so maybe-- yes, nonetheless,\nif what you were doing-- that's absolutely true, but\nif what you were doing here is kind of mentally\nrecalling this, then why couldn't you\nalso do that here? Maybe you could. You might argue that this\nis more evocative of that than this is, but it's also got\nlots of relevant information. Yeah, Jimmy. AUDIENCE: For the\nfurniture, did you guys try placing them in the\nexact position as the scene and seeing if that-- NANCY KANWISHER: We\ndid both versions for exactly the reasons\nyou guys are pointing out. And it didn't make a difference."}, {"content": "Yeah."}, {"content": "Sorry, Cooley. AUDIENCE: It'd be--\nyou would transfer if they were just responding\nto the things, like more stuff? Like in the empty room,\nthere's more background, but there's still\nmore background. NANCY KANWISHER: Totally. You're absolutely right. This is taking us pretty far,\nbut it's still pretty sloppy. This stuff goes all the way\nup to the edge of the frame, and here there's\nlots of empty space. Is that what you're getting at?"}, {"content": "Absolutely. I took out those\nslides because I felt I didn't want to spend the\nentire lecture doing millions of controlled\nconditions on the PPA. I thought you'd get bored. But actually, another\nversion that we did was we then took all\nof these conditions, and we chopped them into little\nbits and rearranged the bits, so that you have much\nmore coverage of stuff in the chopped-up scenes\nthan the chopped-up objects. And in the chopped-up\nversions, it doesn't respond\ndifferently at all. So it's not the amount of\ntotal spatial coverage. It's the actual-- something more\nlike the depiction of space. Was there a question over there? Yeah. AUDIENCE: I was\nwondering if there would be any difference\nbetween looking at images as 2D or 3D scene, and\nactually being there to see the 3D inside of the scene. NANCY KANWISHER: Totally. Totally. It's a real challenge. With navigation,\nnavigation is very much about being there and\nmoving around in the space. And this is just a\npretty rudimentary thing where you're lying\nin the scanner, and these images are just\nflashing, flashing on, and you're doing\nsome simple task, like pressing a button\nwhen consecutive images are identical. It's not moving around\nin the real world. You don't think\nyou're actually there. But here's where video\ngames and VR come in because actually, they produce\na pretty powerful simulation of knowing your\nenvironment, feeling you're in a place in it. And so lots of studies\nhave used those methods to give something closer\nto the actual experience of navigation. So where are we so far? We've said the PPA seems to\nbe involved in recognizing a particular scene. So this just says it responds\nto scenes and something about spatial layout, maybe. Does it care about\nthat particular scene or do you have to recognize\nthat particular scene to be able to use the information? Now, our subjects mostly didn't\nknow those particular scenes. But we wanted to do\na tighter contrast asking if knowledge of the\nparticular scene matters. So what we did was we\ntook a bunch of pictures around the MIT campus, and\nwe took a bunch of pictures around the Tufts campus. And we scanned MIT students\nlooking at MIT pictures versus Tufts pictures. And then what else do we do? AUDIENCE: Get the\nTufts students. NANCY KANWISHER: Yeah, why? AUDIENCE: Oh, just to\nmake sure that it's not all about that weird\narchitecture of the set. NANCY KANWISHER: Exactly. Exactly. So this is called-- yes, whose weird architecture? I think ours is weirder. So it's not just about\nthe particular scenes or the particular subjects. So everybody get how with\nthat counterbalanced design, you can really pull out the\nessence of familiarity itself, unconfounded from the\nparticular images? So when we did that, we found a\nvery similar response magnitude in the PPA for the\nTufts students, for the familiar and\nunfamiliar scenes. Really didn't make\nmuch difference. Yeah. AUDIENCE: Taking a step\nback, so we started off with the one question\nof navigation and it involving all these\ndifferent components. I just want to place this-- NANCY KANWISHER:\nWe're getting there. We're getting there. There won't be like\na perfect answer. We're not going to end\nup with that slide, with the exact brain region\nof each of those things. We'll get some gisty, vague\nsenses of what this is. OK, so this tells\nus it's not about-- whatever the PPA is\nresponding to in a scene, it's not something that hinges\non knowing that exact scene. So it can't be something\nlike, if I was here and I wanted to get\ncoffee, what would my route from this location\nbe, given my knowledge of the environment. Because otherwise, we\nwouldn't get this result. So whatever it\nis, it's something more immediate and perceptual to\ndo with just seeing this place. So where are we? We've said that there's\nthis region that responds more to\nscenes than objects, that when all the objects\nare removed from the scenes, the response barely drops. And its response is\npretty much the same for familiar and\nunfamiliar scenes. So all of that\nsuggests that it's involved in something like\nperceiving the shape of space around you. Doesn't nail it yet, but\nit kind of pushes you towards that hypothesis. Yeah, was there a question\nhere a second ago? No?"}, {"content": "OK. AUDIENCE: I was talking\nabout experiment, but is it accurate\nwhen you look at a map? NANCY KANWISHER:\nOh, great question. Not very much. Yeah, if you take\npictures of places from above versus\nthis kind of view, you get a response in this\nkind of view, but not above. Yeah, very telling. OK, so I'm going to skip. We're not going to do\nthe 30 other experiments. We're going to skip to\nthe general picture, that here's the PPA in four\nsubjects in this very stereotyped location. And here are some of the\nmany conditions we've tested. It's not just abstract\nmaps like this. They don't produce\na strong response. Oh, this is an answer to\nCooley's question way back. Here's the scrambled-up\nscene-- much lower response. So it's not just\ncoverage of visual junk. And it responds pretty strongly\nto scenes made out of LEGOs compared to objects\nmade out of LEGOs, and various other silly things. So all of that seems to suggest\nthat it's processing something like the shape or\ngeometry of space around you-- visible space in\nyour immediate environment. Nonetheless, there's\nalways pushback. And there's pushback on multiple\nfronts, and there should be. That's proper science. So one of the lines of pushback\nwas this paper by Nasr, et al. that I didn't assign. I assigned you the\nresponse to it. Anyway, what Nasr et al. Did was scan people looking at\nrectilinear things like cubes and pyramids versus curvilinear,\nround-y things like cones, and spheres. And what they showed\nis the PPA responds more to the rectilinear\nthan the curvilinear shapes. OK, that's the first thing. And so then, they argue\nthat in general, scenes have more rectilinear structure\nthan curvilinear structure. And they did a bunch of\nmath to make that case. And so they argue that\nmaybe the apparent scene selectivity of the PPA is\ndue to a what of scenes with rectilinearity? Yeah."}, {"content": "AUDIENCE: Confound. NANCY KANWISHER: Yes,\nexactly, a confound. This is exactly what a confound\nis-- something else that covaries with the manipulation\nyou care about that gives you an alternative account, namely\nit's not scene selectivity. It's just rectilinearity. I mean, that might be\ninteresting to other people, but it would make it not\nvery relevant to navigation and much less interesting\nto me, at least. So that's an\nimportant criticism. And so then the Bryan et al. Paper that you guys read\nstarts from there and says, let's take that seriously."}, {"content": "Let's find out. And so you guys should\nhave read all of this, but just to remind you, they\nhave a nice, little 2 by 2 design-- remember we talked\nabout 2 by 2 designs-- where they manipulate\nwhether the image has a lot of rectilinear structure\nor less rectilinear structure, and whether the image\nis a place or a face. And what they find in the PPA\nis the same response to these. And it's higher to the\nscenes than the faces, and rectilinearity didn't\nmatter for the scenes. So evidently, even\nthough it does matter with these abstract shapes,\nin actual scenes and faces, it doesn't seem\nto be doing much. It's not accounting\nfor this difference. Everybody get that? OK, let's talk about this graph. Are there main effects\nor interactions here? And what are those main\neffects or interactions? Yes, Cooley. AUDIENCE: There's\nmany different scenes. NANCY KANWISHER: Yeah, of\ncategory, scene versus face. Anything else? AUDIENCE: What's the first one? What was the first thing? In PPA category,\nwhat's the subtype? NANCY KANWISHER: Oh, wait,\nthis here-- these are scenes and those are faces. I'm sorry, and this\nis the code here. These are rectilinear\nversus curvilinear. Just one main effect, or\nis there an interaction, or another main effect? Just one main effect. These guys are higher\nthan those guys. That's it. So that just tells you\nthere's nothing else going on in these data other\nthan scene selectivity. Rectilinearity doesn't\ninteract with or modify scene selectivity, and it doesn't\nhave a separate effect. Nonetheless, as\nwe've been arguing with all the whole\nHaxby rigmarole, does the fact that there's no\nmain effect of rectal linearity in here mean that the PPA\ndoesn't have information about rectilinearity? No, Josh, why?"}, {"content": "AUDIENCE: This little,\ntiny moment that could be-- you know, this is not\nthe right experiment to-- NANCY KANWISHER: That's right. This is a big-- well, it's\nthe right experiment, but not the right analysis. It's the big, average\nresponses are the same, but maybe the patterns\nare different. That wouldn't directly\nengage with this, but we wanted to know,\nwas there information in there about rectilinearity. So how would we find out? So this was your\nassignment, and I think most people got it right. But in case anybody\nmissed it, we were zooming in on\nthis Figure 4 here. So again, this is just the same\nbasic design of experiment two. And now, let's consider\nwhat's going on here. So you guys read the\npaper and you understood what was going on here. What's represented in\nthat cell right there? What is the point\nof this diagram? What are they doing here? And what does that cell\nmean in that matrix? You can't understand the\npaper without knowing that. Is it Ali? No, sorry. What's your name? AUDIENCE: Sheldon. NANCY KANWISHER: Sheldon,\nI've only asked you six times. Yeah, go ahead. AUDIENCE: So they want to\nsee whether the activation patterns can better discriminate\nbetween rectilinearity of the same category of things\nor between categories of things with the same rectilinearity. So the first thing I said is\nto the left and the second one is to the right. And they-- NANCY KANWISHER: Sorry,\nwait, here and here? No. AUDIENCE: Right side. Yeah, so that part\nis discriminating between rectilinearity,\nand that side is discriminating\nbetween categories. And they take the\ndifferences of-- well, not the differences,\nthey take how well it can distinguish between\neach of those categories and plot them down there. NANCY KANWISHER: Right, OK. That's exactly right. So this is how well it can\ndiscriminate plotted down here, but based on an analysis\nthat follows this scheme. So what does that cell\nin there represent, that dark green cell? What is the number that's going\nto be calculated from the data corresponding to that cell? AUDIENCE: Similar piece\nof same rectilinearity and same pattern. NANCY KANWISHER: Exactly. Exactly. So just as if you want\nto distinguish chairs from cars or something\nelse, if you want to know is there information about\nrectilinearity in there, you take these two\ncases which are the same in rectilinearity--\nboth high rectilinear, both low rectilinear for run\none and run two-- and that's the correlation\nbetween run one and run two for those cells. That's the within\nrectilinearity case. And if there's information\nabout rectilinearity, the prediction is those\nwithin correlations are higher than the\nbetween correlations, just as we argued a bit\nback with beaches and cities and everything else-- same argument. This is just presenting the\ndata in terms of run one and run two, and which cells do\nwe grab to do this computation. So each of the cells in\nthere-- for each of the cells, we're going to calculate\nan r value of how similar those patterns are. A pattern for rectilinear\nscenes in run two, a pattern for rectilinear\nscenes in run one-- this cell is a correlation between\nthose two patterns. How stable is that pattern\nacross repeated measures? All right, so that's\nwhat that r value is. The two darker blue squares here\nare the r values for stimuli that differ in rectilinearity. And remember that the essence\nof the Haxby-style pattern analysis is to see if\nthe within correlations are higher than the\nbetween correlations. In this case, the\nwithin correlations are within rectilinearity\nversus between rectilinearity. And so then they calculate all\nthose correlation differences and they plot them as\ndiscrimination abilities. And so what this is showing\nus here is that actually, the PPA doesn't\nhave any information in its pattern of response\nabout the rectilinearity of the scene. However, if we\ntake the same data, and now choose within category\nversus between category, ignoring rectilinearity,\nand we get the same kind of selectivity\ncorrelation difference within versus between for\ncategory, there's heaps of information\nabout category. Does that make sense?"}, {"content": "Again, if you're fuzzy about\nthis, look back on that slide."}, {"content": "I have lots of suggestions for\nhow to unfuzzy yourself on it. So interim summary-- PPA\nresponds more to scenes than objects. It seems to like spatial\nlayout in particular. It does respond more\nto boxes than circles, but that rectilinearity\nbias can't account for scene selectivity. That's all very nice, but\nwhat is a whole other kind of fundamental\nquestion we haven't yet asked about the PPA? So we've been messing\naround with functional MRI, measuring magnitudes\nof response, trying to test these kind of\nvague or general hypotheses about what it might\nbe responding to. Yes. AUDIENCE: Causation. NANCY KANWISHER: Yes,\nwhat particular causation? AUDIENCE: I guess like\nhow the scenes, like with how the PPA with what role\nit plays in the person being seen. NANCY KANWISHER: Exactly. Exactly. Again, we can test the causal\nrole of a stimulus on the PPA, all of the stuff I\ntalked about did that. Manipulate the stimulus,\nfind different PPA responses. But what we haven't\ndone yet is ask, what is the causal relationship,\nif any, between activity and the PPA and perception\nof scenes or navigation? So far, this is all\njust suggestive. We have no causal\nevidence for its role in navigation or perception. All right, so let's get some."}, {"content": "I'll show you a few examples. So one, as, you guys\nhave learned by now is these rare\ncases where there's direct electrical\nstimulation of a region, and there's one patient\nin whom this is reported. This patient again, is being\nmapped out before neurosurgery. They did functional MRI\nin the patient first. This is his functional\nMRI response to, I think, houses versus objects. Houses are not as\nstrong an activator as scenes for the PPA,\nbut they're pretty good. PPA responds much more to\nhouses than other objects. And so that's a nice\nactivation map showing the PPA. And those little circles are\nwhere the electrodes are, little, black circles. So they know they're in the PPA\nbecause they did functional MRI first to localize that region. Now those electrodes\nare sitting there. And so first thing\nwe do is record-- or first thing they did--\nis record responses. They flash up a bunch of\ndifferent kind of images, and they measure the\nresponse in those electrodes. And so what you see\nis in those electrodes right over there, 1, 2, 3,\nthat correspond to the PPA, you see a higher\nresponse to house images than to any of the other images. And you see the time course\nhere over a few seconds. Everybody clear? This is not causal evidence yet. It's just amazing, direct\nintracranial recordings from the PPA-- I think the only time\nthis was ever done, because it's pretty rare to\nhave the electrodes right there in a patient who's willing to\nlook at your silly pictures, and all of that. But now, what happens\nwhen they stimulate there? So let's look at what\nhappens when they stimulate on these sites 4 and 3 that are\noff to the side of the scene selectivity. And this is just a dialogue."}, {"content": "We don't have a\nvideo, unfortunately. The videos are more\nfun, but this is just a dialogue between the\nneurologist and the patient. And the neurologist electrically\nstimulates that region and says, did you\nsee anything there? Patient says, I don't know. I started feeling something. I don't know, it's\nprobably just me. No, it's not you. And then they stimulate again. Anything there?"}, {"content": "No. Anything here? No. So that's right next to\nthe side of the scene selective electrodes, right next\ndoor, a few millimeters away. Then, they move their\nstimulator over here. They don't move\nanything, they just control where they're\ngoing to stimulate. Patient, of course, has no idea. Neurologist says,\n\"Anything here? Do you see anything,\nfeel anything?\" Patient says, \"Yeah,\nI feel like--\" he looks perplexed,\nputs hand to forehead-- \"I feel like I saw\nsome other site. We were at the train station.\" Neurologist cleverly\nsays, \"So it feels like you're\nat a train station?\" Patient says, \"Yeah,\noutside the train station.\" Neurologist-- \"Let me know if\nyou get any sensation like that again.\" Stimulates. \"Do you feel anything here?\" \"No.\" And then he does it again. Did you see the\ntrain station or did it feel like you were\nat the train station? Patient, \"I saw it.\" These are very sparse, precious\ndata, but that's so telling. It's not that he knew he was at\nthe train station abstractly. He saw it. So then, they\nstimulate again, right on those\nscene-selective regions. Patient says again, \"I saw\nalmost like, I don't know, like I saw-- it was very brief.\" Neurologist says, \"I'm going to\nshow it to you one more time.\" Really what he\nmeans is, I'm going to stimulate you in the\nsame place one more time. \"See if you can\ndescribe it any further. And to give you one last\ntime, what do you think?\" \"I don't really know\nwhat to make of it, but I saw, like,\nanother staircase. The rest I couldn't make out,\nbut I saw a closet space, but not this one.\" He points to a closet\ndoor in the room. \"That one was stuffed\nand it was blue.\" \"Have you seen it before,\"\nneurologist, \"Have you seen it before at some point\nin your life, you think?\" \"Yeah, I mean when I\nsaw the train station.\" \"Train station you've been at?\" \"Yeah.\" Et cetera, et cetera. So it's not a lot of data. But it's very compelling. What is the patient describing? Places he's in that\nhe sees, and then he describes this closet\nspace and its colors. Interestingly,\ncolored regions are right next to scene regions,\nso that's kind of cool, too. So it's causal evidence. It's sparse. Ideally, we'd like more in\nscience, but it's pretty cool. Yeah. AUDIENCE: At this point,\nthe patient is just staring at a blank wall? NANCY KANWISHER: I actually\nforget in the paper. I've got to go look that up. I forget exactly what the\npatient was doing, whether-- I think he's just in\nthe room looking out. Usually, they don't control\nit that much because it's done for clinical\nreasons, and the patient is in their hospital bed,\nand they're just stimulating. So he's probably just looking\nout at the space he's in. In fact, he must have\nbeen because at one point, he says, \"The closet, not\nlike that one over there.\" So if he was staring\nat a blank thing, he was also looking\nout at his room. So yeah."}, {"content": "AUDIENCE: This may be\na little bit off topic. You said that the region\nfor color perception is very close to\nthis, it seems like. Is there any relationship\nbetween functional proximity and-- NANCY KANWISHER: That's\na great question. Nobody in the field\nhas an answer to this."}, {"content": "People often make hay about\nthe proximity of two regions, like there's some deep\nlink because this thing is next to that thing. The body selective region is\nright next to, and in fact slightly overlapping with, area\nMT that responds to motion. It's like, bodies move. Well, faces move\nand cars move, too. So I don't know. It's tantalizing. It feels like it ought\nto mean something. And people often\ntalk as if it does. And maybe it does,\nbut nobody's really put their finger on what\nexactly it would mean. But it's useful. So when Rosa Lafer-Sousa who\nyou met in the color demo, and I showed that in\nhumans, you get face, color, and place regions right next to\neach other in that order, that was really cool because\nRosa had previously shown that in monkeys, the\nmonkey brain it goes face, color, place in\nexactly the same order. And so we thought that's\nreally interesting. That suggests common\ninheritance because that's so weird and arbitrary. Why would it be the same? So it can be useful in\nways like that, at least."}, {"content": "So we just went\nthrough all of this. So how does this go beyond what\nwe knew from functional MRI? I'm insulting your intelligence."}, {"content": "You know the answer to this. It goes beyond it\nbecause it tells you-- it implies that\nthere's a causal role of that region in\nplace perception, some aspect of seeing a place. Now, all of this\nabout the PPA I just started in there because\nit's nice, and concrete, and easy to think about. But no complex mental\nprocess happens in just one brain region. Nothing is ever like that. And likewise, scene\nperception and navigation is part of a much\nbroader set of regions. So if you do a contrast,\nscan people looking at scenes versus objects, you\nsee not just the PPA in here. Again, this is a\nfolded-up brain, and this is the mathematically\nunfolded version so you can see the whole cortex. Dark bits are the bits that\nused to be inside a sulcus until it was\nmathematically unfolded. So there's the PPA kind of\nhiding up in that sulcus. And when you unfold it, you see\nthis nice, big, huge region. But you also see all\nthese other regions. Now there's a bunch of\nterminology and don't panic. I don't think you should\nmemorize everything about each region. You should know that there's\nmultiple scene regions. You should know some\nof the kinds of ways you tease apart the functions,\nand some of the functions that have been tested,\nand how they're tested. But you don't need to\nmemorize every last detail."}, {"content": "Because it's going to\nget a little hairy. So here's a second\nscene region right there called retrosplenial\ncortex or RSC. And actually,\nRussell Epstein and I saw that activation in\nthe very first experiments we did in the\n1990s, but we really didn't know what we\nwere doing back then. And we knew that this is right\nnear the calcarine sulcus. Remind me, what happens\nin the calcarine sulcus? What functional region lives\nin the calcarine sulcus? It's just a weird,\nlittle fact, but it's kind of an important one\nthat we mentioned weeks ago. V1, primary visual cortex-- that's where primary\nvisual cortex lives. And remember,\nprimary visual cortex has a map of retinotopic\nspace, with next door bits of primary visual\ncortex responding to next door bits of space. And in fact, that\nmap has the center of gaze out here and\nthe periphery out there. So when Russell and I\nfirst saw that activation, we had the same worry that\nCooley mentioned a while back. And that is the scenes\nare sticking out. There's stuff everywhere. The objects, there isn't\nthat much sticking out. And we thought, oh, that's just\nperipheral retinotopic cortex. But it's not. It's right next to there and\nit's a totally different thing. And it turns out to be\nextremely interesting. You don't need to know all that. It's just silly, little history. There's a third region up there\nthat's on the outer surface out there that used to be called\nTOS and is now called OPA. I'm sorry about that. You don't need to remember this. Know that there are at\nleast three regions. But TOS slash OPA is\ninteresting because there's a method we can apply to it that\nwe can't apply to the others. What would that method be?"}, {"content": "AUDIENCE: TMS. NANCY KANWISHER: Yeah, TMS-- it's right out on the surface. You just stick the coil\nthere and go \"zap.\" So of course, we've\ndone a lot of that. Can't get the coil\ninto the PPA or RSC. It's too medial. And there's another\nregion that we'll talk about more next time\ncalled the hippocampus. You saw the hippocampus when\nAnn Graybiel spent all that time digging in the\ntemporal lobe to find that bumpy, little,\ndentate gyrus, approximately right in there. And so all of these-- and probably other\nregions, but these are the core elements of\nthe scene selective regions that are implicated in\ndifferent aspects of navigation. So when you have\nmultiple regions that seem to be part of a\nsystem, that's an opportunity. Because now we have\nthe possibility that maybe we could figure\nout different functions for different regions. And then maybe that would really\ntell us more than just scenes and navigation, end of story. It's kind of rudimentary. It would be nice if different\naspects of the navigation story engage different\nparts of the system. So really what we\nwant to know is, how does each of these regions\nhelp us navigate and see scenes. And I'm not going to\nanswer that fully. The field is still trying\nto understand all of this, but I'll give you a few\ntantalizing little snippets. So let's take retrosplenial\ncortex right here. So this is first the\nresponse of the PPA right there, and retrosplenial\ncortex, which is just behind it. This is just its mean response\nto a bunch of different kinds of stimuli, showing\nyou that it likes landscapes and cityscapes,\nscenes, more than a bunch of other categories of objects. And that's true of\nboth the PPA and RSC. No surprises here-- they're\nboth somewhat scene selective. But then in a whole\nbunch of other studies summarized in this graph\nhere, Russell Epstein and his colleagues had subjects\nengage in different tasks while they were\nlooking at scenes. In some tasks, they had\nto say where they were. He's at UPenn, and he\nshowed his subjects pictures of the UPenn campus. And they had to answer\nall kinds of questions about what part of\ncampus they were, where they were on campus,\nand also about which way they were facing given the view of\nthe campus they were looking at. Then he also showed\npeople familiar scenes and unfamiliar scenes, much like\nwe did with our Tufts study. And he had object controls. And you can see the PPA\ndoesn't care about any of that, doesn't care, really, if\nthey're familiar or unfamiliar, doesn't care what task\nyou're doing on the scene. You're looking at a\nscene, it's just going. So we didn't really tease\napart functions there. But RSC responds differently\nin these conditions. It's engaged in both\nthe location task and the orientation task. It responds\nsubstantially more when you look at images of a familiar\nplace than an unfamiliar place. So this is the first time we've\nseen that in the same network. And so now, think\nabout all the things you can do when you're looking\nat a picture of a scene and you know that place. You have memories of\nhaving been there. You can think about\nwhat you might do if you were there,\nhow you would get from there to someplace else. All of those things\nare possible things that might be driving RSC. Another thing that\nmight be driving RSC is that if you're looking at\na picture of a familiar place, you orient yourself with respect\nto the broader environment that that view is part of. So what I showed you that\npicture of the front of Stata, you immediately imagine,\nI'm out on Vassar Street facing that way, roughly\nnorthwest, I think. If you look at a\npicture of a scene and you don't know\nthat scene, it doesn't tell you anything\nabout your broader heading in the broader world. So all of those are things\nthat the RSC, its function seems to depend on\nknowing that place. Perhaps the most\ntelling case comes from a patient who had damage\nin retrosplenial cortex. And the description\nin the paper of this says that this patient\ncould recognize buildings and the\nlandmarks, and therefore, understand where he was. So lots is intact-- can recognize scenes\nand know where he is. But the landmarks he\nrecognized did not provoke directional information\nabout any other places with respect to those landmarks. So this person can\nlook at a picture and say, yeah, I\nknow that place. That's the front of my house. But then if you say, in\nwhich direction is a coffee shop two blocks\naway, he doesn't know which way it is from there. So this should sound familiar. This is my guess of the bit that\nmy friend Bob got messed up. Yeah. This is exactly\nhis description-- he could recognize\nplaces, but it wouldn't tell him how to get\nfrom there to somewhere else. And so the best current guess\nabout retrosplenial cortex is that it's involved in\nanchoring where you are. You have this mental map of the\nworld, and you have a scene, and you're trying to\nput them together. Given that I see this,\nwhere am I on the map, and which way am I\nheading in that map? Again, think about the problem\nyou face when you emerge from the subway in Manhattan. You look around. Where am I, and which\nway am I heading? That's what you need\nretrosplenial cortex for. How about this TOS thing? There's lots of studies of it. I'll give you just\none little offering. So this is a causal\ninvestigation because as we discussed, the TOS\nis out on the lateral surface. So we can zap it. And so of course, we do. And so in this\nstudy, we were asking whether TOS is involved in\nperceiving the structure of space around you. So we took scenes like\nthis from CAD programs, and we just varied\nthem slightly. So for example, the position\nof this wall moves around, the aspect ratio, the height\nof the ceiling moves around, and we make this subtle morph\nspace of different versions of this image. And then for control condition,\nwe do the same with faces. We morph between this\nguy and that guy, and make a whole\nspectrum in between. And then in the task, what\nwe do is here's one trial. One of the scenes or\nfaces comes on briefly, and then shortly thereafter,\nyou get a choice of two, and you have to say which\nof these matches that one. And then what we do\nis we zap people right after we present this stimulus. And so the idea is\nthis is as close as we can get to a pretty\npure perceptual task. How well can you see the\nshape of that environment or the shape of that face? You don't have to remember it\nfor more than a few hundred milliseconds. So it's really more of a\nperception task than a memory task. And what we measure\nis, we actually muck with how different these\ntwo images are in each trial, and measure how\nfar apart they have to be in morph space for\nyou to be about 75% correct. That's the standard\npsychophysical measure. The details don't matter. But our dependent measure is,\nhow different do the stimuli have to be for you\nto discriminate them as a function of whether you're\ngetting zapped in TOS or not. And so here are the data. So let's take the\ncase where you're doing the scene task here. What this threshold\nis, is again, how different the\nstimuli need to be for you to discriminate them. So the higher the bar,\nthe worse performance. They have to be really different\nor you can't tell them apart. And so what you\nsee is when you zap OPA, that lateral\nscene selective region, discrimination\nthreshold goes up a bit. That means you get worse\nat the discrimination. The stimuli need to\nbe more different. Compared to zapping\nthe top of your head-- remember, you always\nwant a control condition, and there's no perfect\ncontrol condition because it feels differently to\nbe zapped in different places. But getting zapped up here is\na better than nothing control. And then here's the\noccipital face area. That's the lateral face region\nwe talked about before when I showed you another TMS study. Basically, whenever\nthere's anything lateral, we zap it because we can. And see, it's not affected here. Zapping the occipital face area\ndoes not mess up your ability to discriminate the scenes. However, in the face task,\nwe see the opposite pattern. For the face task, zapping\nthe occipital place area doesn't do anything compared to\nzapping the top of your head, but zapping the face area does. This is a double dissociation. If we just had the scene task,\nit would be like, yeah, maybe. Who knows."}, {"content": "Maybe, who knows why. But it's not very strong. But when you have\nthese opposite things, then we really have much\nmore strong evidence that these two regions\nhave different functions from each other. Everybody get that this\nis a double dissociation, in the same sense of when you\nhave one patient with damage in one location and\nanother patient with damage in another location\nand they have opposite patterns of deficit,\nthen we're really in business. Then we can draw\nstrong inferences. So we just said all of that."}, {"content": "So that's just a little snippet. These and other data suggest\nthat that region is strongly active when you look\nat scenes, and it seems to be involved in\nsomething like perceiving-- just directly online\nperceiving the structure of the space in front of you. So we already did\nretrosplenial cortex. And next time, we'll talk\nabout the hippocampus in there, and its role in the\nwhole navigation thing. Now, since I have ended early-- a rare event-- I actually put together a whole\nother piece of this lecture, and I thought, no, don't always\nhave a part you don't get to. But then it turns\nout we do get to it. We're going to go\nover this more later, but we're going to start with\nthis business right here. So anybody have questions\nabout this stuff so far? OK, so I've spent a\nlot of time talking about multiple voxel pattern\nanalysis, because it's the only method I've mentioned\nso far that enables us to go beyond the business of\nsaying how strongly do the neurons fire in\nthis region to the more interesting question of what\ninformation is contained in this region. But I also ended\nthe last lecture with this kind of\ndepressive note-- that you can't see much with\nMVPA applied to face patches, even when we know there's\ninformation in there with electrophysiology data. Remember, I showed\nyou that monkey study where they tried MVPA\nin the face patches in monkeys and they couldn't kind\nof read out a damn thing. And then they try MVPA on\nindividual neural responses of the same region,\nand they can read out all kinds of information. And that tells you the\ninformation is there and we just can't\nalways see it with MVPA. Now today, you've seen\ncases where can see stuff with MVPA in the scene region. So sometimes it works,\nsometimes it doesn't. And when it doesn't\nwork, we're left in this unsatisfying\nsituation that we don't know if the\ninformation isn't there or if the neurons are\njust so scrambled together that we can't see the\ndifferent patterns. So bottom line, we\nneed another method. MVPA is a whole lot\nbetter than nothing, but we want to be\nable to ask, is there information present in\nthis region even when we think the relevant neurons are\nall spatially intermingled? So let me just do a\nlittle bit of this and then we'll continue later. So goal-- this new method\nis called \"event-related functional MRI adaptation.\" And we use it when\nwe want to know if neural populations\nin a particular region can discriminate between two\nstimuli, two stimulus classes. So for example, do\nneurons in the FFA distinguish between this\nimage and that image? So if we want to\nknow that, we could measure the functional\nMRI response in the FFA and find this would be an\nevent-related response, similar responses to the two. And as I just\nmentioned, that wouldn't mean that there isn't\ninformation in the FFA that discriminates that. It just says they have\nthe same mean response. Everybody get that? Now, if we zoom in, and think\nabout what might neurons be doing, it's still\npossible-- even with the same mean\nresponse-- that neurons could be organized like this,\nwith some of them responding only to this image and some\nof them responding only to that image. But it's also possible\nthat all of the neurons respond equally to both. And we kind of\ndesperately need to know-- I mean, not in this case. This is a toy\nexample, obviously. But we often, when we're\ntrying to understand a region of the brain, we\nneed to know which situation we're in. So that neural population can\ndiscriminate these two and that one can't. How are we going to\ntell which is true? Well, we talked before\nabout multiple voxel pattern analysis, but as I\njust said, it only works when the neurons\nare spatially clustered on the scale of voxels. So imagine you have\nthese situations here. This is getting more and\nmore of a toy example, but just to give you the idea. Suppose where those neural\npopulations land with respect to voxels is like this. So if each of these is a\nvoxel in the brain, a little, say, 2 by 2 by 3\nmillimeter chunk of brain that we're getting\nan MRI signal from, if you have the different\nneural populations spatially segregated\nenough that they mostly land in different voxels,\nthen MVPA might work here. Is that intuitive? Do you guys all see that? Then we'd get a different\npattern in these voxels if we're looking at those\ntwo different images. But even if we have\nthe situation here, which is kind of\ninformationally the same, if they're spatially\nscrambled so that they're in roughly equal proportion in\neach voxel, MVPA won't work. Does that make sense? And so that's when we need this\nother method called \"functional MRI adaptation.\" Make sense? I'm going to go one\nminute over probably. So the point of\nfunctional MRI adaptation is it can work even when\nthere's no spatial clustering of the relevant\nneural populations on the scale of voxels. So let me go through\nit quickly and we'll come back to it later. So here's how it goes-- the basic idea is,\nany measure that's sensitive to the sameness versus\ndifference between two stimuli can reveal what that system\ntakes to be same or different. So for example, if a\nbrain region discriminates between two similar stimuli\nlike these, then if we measure the functional MRI\nresponse in that region to same versus\ndifferent trials-- so this would be\na different trial. You present Trump and then\nthe chimp back to back. That's one trial, compared\nto a same trial, chimp and then chimp. And of course, we\ncounterbalance everything, so we also do chimp and then\nTrump in another different case and then Trump and then\nTrump in another same case. If we find that the\nneural response is higher when the two stimuli are\ndifferent than when they're same, then we know\nthat that region has neurons that respond\ndifferentially to the two. So remember, we\nstarted with a case where the mean\nresponse is the same to this image and this image\nif you just measure them alone. But now we want to\nknow, do we really have neurons that\nrespond differentially? So we're using the\nfact that neurons are like people and muscles. If you keep doing the same\nthing to them, they get bored. Been there, done that. So you present\nthis back to back. You get a lower response than if\nyou present this and then this. That's called \"functional\nMRI adaptation.\" It's like that\nwaterfall MT adaptation we talked about before, but just\ncrammed into a fine time scale. And so then if you do that, you\ncan ask what a region thinks is the same. So then, we could ask, what\nabout these two images? Does it think\nthose are the same? And if we find a response like\nthat, what have we learned? So if these two\nrespond like that, what have we learned\nabout a region that shows? This is all fake\ndata, obviously, but if we saw that,\nwhat have we learned? And then I'll let\nyou go, as soon as I get a nice answer to this."}, {"content": "Yeah. AUDIENCE: So if it's the\nsame between two pictures of the same stimuli, that\nmeans that it's activated. It can discriminate. But if the yellow is at\nthe same degree as the red, it would just be the brain\nreacting to different pictures. NANCY KANWISHER: You\ntotally get that. It's probably right,\nand you totally get it. Key point-- just because I\ndon't want to torture you guys and go way over-- but key point\nis, it's the same response is the lower response. We tell that with this case, and\nwe actually give it a same one. So same is lower than different. That's just how\nthis method works. Then we're basically\nasking, does that count as the same\nto this brain region? And we're finding, yes, it does. That tells us that\nthose neurons are invariant to all\nkinds of things-- viewpoint, facial\nexpression, when he last dyed his hair, who the hell\nknows, all these other things. So we'll talk more about this. But the idea is, now we have\nanother method in addition to MVPA that can start to tell\nus what neurons are actually discriminating. OK, sorry to go over."}], "16. Music": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] NANCY KANWISHER: All\nright, OK, so let's start. We're talking about music\ntoday, which is fun and awesome. But first, let me give you\na brief whirlwind reminder of what we did last time. We talked about hearing\nin general and speech in particular. And we started, as usual,\nwith computational theory, thinking about what is\nthe problem of audition and what is sound. It's the first step of that. And sound is pressure waves\ntraveling through the air. And the cool thing\nabout hearing is that we extract\nlots of information from this very, very\nsimple signal of pressure waves arriving at the ear. We use it to recognize\nsounds, to localize sounds, to figure out what\nthings are made of, and to understand events around\nus, and all kinds of things. And these problems are a\nmajor computational challenge. And in particular,\nthey are ill-posed. That means that the available\ninformation doesn't give you a unique solution\nif you consider the computational\nproblem narrowly. And that's true for\nseparating sound sources. So if you have two\nsound sources at once, say, two people speaking or\na person speaking and a lot of background noise, that's\nknown as the cocktail party problem. Those sounds add on\ntop of each other. And there's no way to pull\nthem apart without bringing in other information,\nknowledge about the world or knowledge about the\nnature of voices or speaking or who's speaking. Or you need something else,\nor else it's ill-posed. That is not solvable just\nfrom the basic input. Another case of an ill-posed\nproblem in audition is the case of reverb. So the sound that I'm making\nright now that's coming out my mouth is bouncing\noff the walls and is arriving at your ears\nover each little piece of sound that I make is arriving\nat different latencies after I say it as it travels\ndifferent paths bouncing around the room. There's not too\nmuch reverb in here, so it's not that noticeable. But if we did this\nin a cathedral, you'd hear all these echoes. OK, and so that makes\nanother ill-posed problem, because all of those\ndifferent sounds are added on top of themselves\ndiminished in volume over time. And you get the sum\nof all of those, and you have to pull\nit apart and figure out what that sound is. So both problems\nare solved by using knowledge of the real world. In the case of reverb, it's\nactual implicit knowledge that you all have\nthat you didn't know you have about\nthe physics of reverb. Because if we play you\nsounds with the wrong physics of reverb, you won't be\nable to deal with reverb. And that says it's implicit\nknowledge in your head, which is pretty cool, that\nyou use to constrain the ill-posed problem. We talked about speech. Phonemes are sounds\nthat distinguish two different words in a\nlanguage, like make and bake. Those are two\ndifferent sounds that make the difference\nbetween two words. Each possible speech\nsound is not a phoneme in every language of the world. Languages have some subset of\nthe space of possible phonemes that distinguish words\nin their language. Phonemes include vowels that\nhave these stacked harmonics in the spectrogram,\nand consonants which are the quick transitions\nin the vertical stripes in the spectrogram, leading into\nthe harmonic stacks of vowels. We talked about the problem\nof talker variability, that a given phoneme or\nword sounds very different, looks very different\nin the spectrogram if spoken by two\ndifferent people. And conversely, the same person\nspeaking two different words looks very different\nin the spectrogram. And so that means\nthat the identity of the speaker and the\nidentity of the word being said are all mushed up together. And that means that if\nyou want to recognize the voice independent\nof what's being said, or recognize the word\nindependent of who's saying it, you have a big computational\nchallenge, a classic invariance problem. Yeah, Ben. AUDIENCE: I don't\nmean to hold us up."}, {"content": "I just wanted to make sure\nthat I'm understanding. So the difference between\nconsonants and vowels, are vowels just harmonic,\nlike connective elements between consonants? And are consonants\nthe percussive? Or are they actual-- like, I just didn't\nunderstand that. NANCY KANWISHER: Yeah, so\nin the spectrogram, those-- I didn't put that\non the slide here-- but those horizontal red\nstripes in the slides that I showed you last time,\nthose in the spectrogram, those are bands of energy at\ndifferent frequencies that are sustained\nover a chunk of time. And those are typical of\nvowels, or singing or musical. And those harmonic\nsounds that have pitch. And so vowels have\nthose sustained chunks that look like this\nin the spectrogram. And then there are these\nweird vertical stripes and transitions in\nand out of the vowels that are the consonants. AUDIENCE: Vowels\nare when you don't have [INAUDIBLE] spectrographs\nbecause air is just flowing through and you're\nfiltering it somehow, like positioning your vocal\ntract in a certain way. And consonants are when\nyou close off that air or restrict it in some way. So like S's and F's, you're\nnot closing all the way off, but you're really\nconstricting the vocal tract. And in a lot of\nother consonants, you're actually\nfully closing it. NANCY KANWISHER: OK,\nand then we talked a bit about the brain basis. And I pointed out that\nthe neural anatomy of sound processing-- the\nsubcortical neuroanatomy is much more complicated than\nthe subcortical neuroanatomy of vision. In vision, you have\none stop in the LGN, and then you go up to the cortex\ncoming up from the retina. In audition, you have many\nstops between the cochlea, where you pick up sounds in the\ninner ear, and auditory cortex. Some of those stops\nare shown up here. And we didn't discuss them. So then we talked about\nprimary auditory cortex. That's on the top of\nthe temporal lobes, like right in there medially. You went in. And it has this\ntonotopic property, and that is a map of frequency\nspace with this systematic high-low-high mapping of\nfrequency space that you can see here-- high, low, high, like that. This is the top of the\ntemporal lobe right there. And I pointed out that in\nanimals and in one recent MRI study, the response properties\nof primary auditory cortex are well modeled by these fairly\nsimple linear filters, known as spectrotemporal receptive\nfields or STRFs, shown here. So they're simple\nacoustic properties of a given band of\nfrequencies rising or falling at different rates. So today, we're going\nto talk about music. And this is also an important\nmoment in the course. Because up to now, we've been\ntalking about functions that are mostly shared with animals. Speech is kind of on the cusp. I was going to make this\npoint before speech. And that's actually muddy,\nbecause lots of animals are really good at\nspeech perception. Chinchillas can\ndistinguish ba from pa. Go figure, anyway. So they can perceive\nspeech, but obviously they don't use it in the same way. But music is most\ndefinitely uniquely human. And so most of the things we'll\nbe talking about from here on out are things about the\nhuman brain, in particular. And I think these are\nthe coolest things in human cognitive neuroscience,\nbecause they tell us something about who we are\nas human beings. But they are also the\nhardest ones to study. Why is that? AUDIENCE: [INAUDIBLE] NANCY KANWISHER:\nNo animal models. And I'm always lamenting\nhow-- about the shortcomings of each of the methods in\nhuman cognitive neuroscience. And we have lots of them, and\nthey complement each other, but there's a whole\nhost of things that none of those\nmethods are good for. And so now we're\nreally out on thin ice trying to understand\nthese things with a weaker set of methods where we can't\ngo back and validate them with animal models. And that's just life."}, {"content": "That's what we do. So now let's back\nup for a second and consider, why am I\nallocating a whole lecture for such a fluffy,\nfrivolous topic as music. And I would say, that's\nbecause it's not fluffy. It's actually fundamental. And it's fundamental\nin the sense that music is both\nuniquely human-- no other animal has anything\nremotely like human music-- and it's also universally human. That is, every human\nculture that's been studied has some kind of music. So music is really\nan essential part of what it means to\nbe a human being. It's really at the\ncore of humanity. And that alone makes\nit interesting."}, {"content": "But further-- question? AUDIENCE: So, like, birdsong-- NANCY KANWISHER:\nBirdsong doesn't count. No, birdsong doesn't count\nin all kinds of ways. One, it doesn't have\nanywhere near the flexibility and variability. There are like narrow domains\nin which each male zebra finch makes a slightly\ndifferent version of the call, but within an\nextremely narrow range. There's actually a\nbrain imaging study that looks in brain imaging\nin songbirds and asks, do they have reward brain\nregion responses to music. And the answer is,\nyes, in some cases. Like, do they enjoy it,\nright, is that part of-- and the answer is\nyes, but only when the significance of the\nbirdsong is something that's relevant to them, like, there's\na potential mate right here, then they like it. But they don't like\nit just for the sound. And that makes it very\ndifferent from humans. And there are other\ndifferences as well. So it's further\nreally important to us humans in a whole bunch of ways. One, we have been doing\nit for a very long time. And so, for example, the\narchaeological record shows these 40,000-year-old bone\nflutes that you can see from the structure of flute make\nparticular sets of possible pitches. And further, most people\nwho've thought about this have argued that singing\nprobably goes back much farther than the bone flutes. After all, you don't have\nto make anything to do it. You can just sing. Some have even\nspeculated that singing evolved before language. It's just speculation,\nbut that's possible. In any case, it goes\nway back evolutionarily. It also arises early\nin development. So very young infants are\nextremely interested in music. They're sensitive to beat and\nmelody, independent of pitch. We'll talk more about\nthat a little bit. And finally, if\nyou're not impressed with any of those\narguments, people spend a lot of money on music. And if that's your\nindex of importance, it's really important. Last year, $43 billion in sales. So I'd say it's not\na frivolous topic. It's a fundamental topic. It's near the core of what\nit means to be a human being. And all of this raises a\nreally obvious question. Why do we create and like\nmusic in the first place? What is it for? And this is a puzzle that people\nhave thought about for at least centuries, probably millennia. And this includes all\nkinds of major thinkers, like Darwin, who said,\n\"As neither the enjoyment nor the capacity of\nproducing musical notes are faculties of\nthe least direct use to man in reference to his\nordinary habits of life, they must be ranked amongst\nthe most mysterious with which he is endowed.\" So Darwin is implicitly\nassuming here that music is an\nevolved capacity. It's not something that we just\nlearn and that cultures invent, if they feel like it\nor don't feel like it. But it's actually evolved and\nshaped by natural selection. And that means there\nmust be some function that natural selection\nwas acting on that was relevant to survival. So people have speculated about\nwhat that function might be. Those who think that music\nis an evolved function, including Darwin, he speculated\nthat it's for sexual selection. And his writing is so beautiful,\nI won't paraphrase it. He says, \"It appears probable\nthat the progenitors of man, either the males or\nfemales or both sexes, before acquiring the power of\nexpressing their mutual love in articulate\nlanguage, endeavored to charm each other with\nmusical notes and rhythm.\" So that's Darwin's speculation. It's just a speculation,\nbut a lovely one. Also, note that he threw away\nthis radical idea in here: \"before acquiring the power\nto express their mutual love in articulate language.\" So he's speculating that\nmusic came before language. Again, all speculation, but\ninteresting speculation. More recently, up\nthe street, there's a bunch of people who've been\nthinking about this a lot. And Sam Mehr at Harvard\nhas been arguing that the function\nof music and song, in particular, which\nhe thinks is really the fundamental basic kind\nof native form of music, has an evolutionary\nrole in managing parent-offspring conflict. And that's something that\nmany evolutionary theorists have written about. The genetic interests of\na parent and an offspring are highly overlapping, but\nnot completely overlapping. The parent has other\noffspring to take care of besides this one right here. That one right there wants\n100% of the parent's effort. Therein lies the conflict. And so Mehr has proposed\nthat infant directed song arose in this\nkind of arms race between the somewhat competing\ninterests of the parent and the offspring. And it manages this\nneed the infant has to know the parent is\nthere with the fact that the parent has other\nneeds, so i guess idea they can sing while attending to\nother offspring, and on and on. So there's other kinds of\nspeculations like this. But importantly, this is\nnot the only kind of view. It's not necessarily\nthe case that music is an evolved capacity. So others have\nargued that it's not. So Steve Pinker,\nalso up the street, has argued that\nmusic is \"auditory cheesecake, an exquisite\nconfection crafted to tickle the sensitive\nspots of at least six of our mental faculties. If it vanished from our species,\nthe rest of our lifestyle would be virtually unchanged.\" I think that might say a\nlittle more about Steve Pinker than it does about music. Nonetheless, it's\na possible view. What he's saying is\nthat music is not an evolutionary\nadaptation at all, but an alternate use\nof neural machinery that evolved for\nsome other function. And then once you have\nthis neural machinery, what the hell, you can\ninvent cultural forms and use it to do other\nthings like music. And the most obvious\nkind of neural machinery that you might co-opt\nfor that function would be neural machinery for\nspeech or neural machinery for language, which, as I\nargued briefly last time, are not the same thing. One is the auditory\nperception of speech sounds and the other is\nthe understanding of linguistic meaning. So the nice thing\nabout this is, finally after all this entertaining\nbut speculative stuff, we have an empirical question. This is something we\ncan ask empirically. Does music actually\nuse the same machinery as speech or language,\nor does it not? Some of the rest of\nthese speculations are very hard to test."}, {"content": "So stay tuned."}, {"content": "We'll get back to that shortly. But first, let's step\nback and think, OK, if music is an evolved\ncapacity, it should be innate in some sense,\nat least genetically specified, right, because\nthat's what evolution does is that natural selection acts\non the genome to produce things that are genetically specified. And it should be present\nin all human societies, since the branching\nout of human societies is very recent in\nhuman evolution. So is it? Well, is music an innate? So, suppose we found specialized\nmachinery in the brain and adults for music. And we showed\nreally definitively, it's really, really, really\nspecialized for music. Would that prove innateness? No, why not?"}, {"content": "AUDIENCE: Might\nhave [INAUDIBLE].. NANCY KANWISHER: Bingo,\nthank you, very good. Yup, exactly. So this is something that many,\nmany people are confused about, including colleagues\nof mine, most of the popular scientific press. Just because there's a\nspecialized bit of brain that does x doesn't\nmean x is innate. It could be learned. And the clearest example of that\nis the visual word form area. Everybody get that?"}, {"content": "OK, so we've got to\ntry something else. What if we find sensitivity\nto music, in some very music particular way, in newborns? Now that will get closer,\nbut here's the problem. Fetuses can hear pretty\nwell in the womb. And if the mom is singing\nor even if there's music in the ambient\nroom, some of that sound gets into the womb. So that means that even if you\nshow sensitivity to music, even in some very particular\nway, in a newborn, it's not a really tight argument\nthat it wasn't, in part, learned. So this is a real challenge."}, {"content": "It may just be\nimpossible to answer. I'm not sure. I don't know how-- I don't know what method\ncould actually answer this."}, {"content": "But at the very least,\nit's really difficult and nobody's nailed it. So we can backtrack and\nask the related, not quite as definitive question: \"But\nOK, how early developing is it?\" So often, developmental\npsychologists take this hedge. It's like, we can't\nexactly establish definitive innateness. But if things are\nreally there very early and develop very fast,\nthat's a suggestion that at least the system is\ndesigned to pick it up quickly. So even if there's a\nrole for experience, there's some things that are\npicked up really fast and some things that aren't. And so how quickly\nis it picked up? So it turns out there's\na bunch of studies that have looked at this. And young infants are in\nfact highly attuned to music. They're sensitive to\npitch and to rhythm. And in one charming\nstudy, they took two to three-day-old infants\nwho were sleeping, put EEG electrodes on\nthem, and played them. They wanted to test\nbeat induction, which is when you hear a rhythmic beat. You get trained to the beat. And you know when\nthe next beat is. And that's true even if it's\nnot just a single pulse. So they played these\ninfants sounds like this. Oh, but the audio is not on. Now it's going to\nblast everyone. All right, hang on. AUDIENCE: It's playing. NANCY KANWISHER:\nOh, it is playing? Turn up more? OK. Didn't want to deafen people. OK, here. AUDIENCE: It's going\na little [INAUDIBLE].. Just turn it up so\nyou can hear it. AUDIENCE: Go to\nHDMI, [INAUDIBLE] plugged in [INAUDIBLE]. NANCY KANWISHER: It's not, but\nthat's supposed to work, right? It has worked before AUDIENCE: In there. AUDIENCE: Let's just check your\nsystem settings really quickly. So I can hear you\nfrom my system. NANCY KANWISHER:\nYeah, it's weird. AUDIENCE: Wait, if I can hear\nyou from my system, you're-- NANCY KANWISHER: Then,\nit is going out, yeah. AUDIENCE: Oh, somebody\nunplugged both. OK, let's try [INAUDIBLE]. NANCY KANWISHER: Aah. AUDIENCE: OK, try\nit one more time. NANCY KANWISHER: OK, here we go. [MUSIC PLAYING] Did you hear that glitch? Let me do it again. Take it back here. [MUSIC PLAYING] Everybody here the\nhiccup in the beat? So that's what\nthese guys tested. They played rhythms like that\nto two to three-day-old infants. And-- [MUSIC PLAYING] Oh, now it's working."}, {"content": "OK, great. OK, anyway, so here's what\nthey find with their ERPs. This is the onset of that\nlittle hiccup, the time when that beat was supposed to\nhappen and didn't, the missing beat right there. And this is an ERP\nresponse happening about 200 milliseconds later for\nthat missing but expected beat. And let's see,\nthis is a standard where the beat keeps going. Now you might say, well, of\ncourse they're different. One has a beat there\nand one doesn't. They're acoustically different. So they have a control\ncondition which has a beat, but a different\npreceding context. So where that beat is not-- I'm sorry, where it\nhas a missing beat, but that's expected by\nthe previous context. So that's just evidence\nthat even young infants have some sense of beat. So moving a little later,\nby five to six months, infants can recognize\na familiar melody, even if it's shifted in\npitch from the version that they learned. And that's really\ncool, because that means they use relative\npitch, not absolute pitch. And that's something\nthat adults do in music. We're very good at that. But no animal can do that. You can train animals to do\nvarious things like recognize a particular pair\nof sounds or even a few sounds, a few pitches. But if you transpose it,\nthey don't recognize that. Yeah, Ben. AUDIENCE: Isn't it\npossible that we're just sensitive to\nrhythm and pitch rather than being\nsensitive to music itself? NANCY KANWISHER: Yes,\nhang on to that thought. It takes more work to show\nthat it's music per se rather than just\nrhythm and pitch. We'd have to say what\nwe meant by rhythm. If we load enough into\nthe idea of rhythm, then it's like most of\nmusic right there. But we might say just even beat. How about that, right? And actually, already\nthis study already is not just an even\nbeat, because it has more context than that. That is, for example, the\nbeats in this ERP infant study were not emphasized louder. The infants have to be able\nto pick out what the beat is from that complex sound. It's not automatically\nthere in the acoustic signal as the louder onset sound. Five-month-old\ninfants, if you play them a melody for one\nor two weeks, so they get really familiar\nwith it and learn it, and then you don't play it again\nand you come back eight months later, they remember it. So music is really\nsalient to infants. On the other hand, newborn\ninfants' appreciation of music is not-- what is that not doing there? Oh, yeah, that's right. So they don't prefer consonance\nover dissonance, right. And they're insensitive to key. And they detect timing\nchanges in rhythms, whether they are\ntiming changes that are typical in the\nkind of music they've heard or typical in a more\nforeign kind of music. And so a really nice\nstudy that shows this is that in Western music,\nit's really common to have-- most Western music\nhas isochronous beat. So you can see that over here. Here's an isochronous beat. Those are even,\ntemporal intervals. And there's a whole note\nhere and then half notes. And they're all multiples\nof each other, just wholes and halves, with the beat\nhappening every four notes. Non-isochronous beat has\nthis funny business where there's a whole note and a half\nnote, making up just three-- what do you call those things-- they're not beats. What are they called? AUDIENCE: Three-beat notes. NANCY KANWISHER: Sorry,\nthree notes, I guess. But it's not even notes,\nbecause it's whatever. I don't know what\nthe terminology is. But anyway, this sound\nhere followed by 4. This is non-isochronous rhythm. Those are really\ncommon in Balkan music where they do all kinds\nof crazy things, like 8/22 or something like that. I mean, like really, really\ncrazy musical meters. They're awesome, I love them. But they are very other. Like, if you grew up\nin Western society when you first hear\nBalkan rhythms, it's very hard to copy them. But six-month-old\ninfants get rhythms equally well if they're\nisochronous or non-isochronous. By 12 months, they can\nonly get automatically, like immediately,\nperceive and appreciate rhythms that are familiar\nfrom their cultural exposure. That is isochronous if\nthey're from a Western society or non-isochronous if they're\nfrom a Balkan country. Yeah? AUDIENCE: just what is\ngetting a meter again? NANCY KANWISHER:\nWell, so there's a whole bunch of studies."}, {"content": "I'm just summarizing here. That is, they're sensitive\nto violations by all kinds of measures of little whatever\nbehavioral thing you can get out of a five-month-old, whether\nit's how much they're kicking their legs or how much-- often, it's how\nhard they're sucking on a pacifier is\nanother measure. So you just see, can\nthey detect changes in a stimulus or violations\nby any of those measures. Or you could do\nit with the ERPs. So brief exposure to a\npreviously unfamiliar rhythm is enough for a\n12-month-old to appreciate the relevant distinctions\nin that rhythm, but not for adults. So if you haven't heard\nnon-isochronous Balkan rhythms until now and you try dancing\nto them, good luck to you. You can probably\nget it eventually, but it will take\nyou a long time."}, {"content": "So does this sound familiar? Perceptual narrowing, right? So we keep encountering this. We encountered this\nwith face recognition, with same versus other races,\nsame versus other species. You see it in face recognition. We encountered it with\nphoneme perception. The phonemes-- remember,\nnewborn infants can distinguish all the phonemes of\nthe world's languages, even those exotic clicks\nthat I played last time from Southern African languages. And you guys can't distinguish\nall those clicks now. So that's perceptual narrowing. It makes sense, of course,\nbecause the reason we have perceptual narrowing is\nyou want to have invariants. You want to appreciate\nthe sameness of things across transformations. And if your speech culture\nor your music culture is telling you these two things,\nthis variation, doesn't count, you want to throw\naway that difference and treat them as the same. And then once you do that, you\ncan't make that discrimination anymore. So on this question\nwe started with, is music an evolved capacity. If so, it should be innate. And we haven't really\nanswered that question, maybe. But as I said, it's really\nhard, and maybe ultimately unanswerable. But certainly it's\nearly developing. What about this other question? Is it present in\nall human societies? Well, I said before\nbriefly that it is. Oh yeah, sorry, we have\nto back up and say, OK, to answer this question, we\nhave to say what is music. To answer whether it's\npresent in all societies. And this has been a real\nproblem, because music is notoriously hard to define. And many people\nhave made a point of stretching the definition\nof music, including the ridiculous and\nhilarious John Cage. So this is his\n1960 TV appearance. [VIDEO PLAYBACK] - Over here, Mr. Cage has\na tape recording machine, which will provide much of\nthe-- will you touch the machine so we can know where it\nis-- which will provide much of the background. Also, he works with a stopwatch. The reason he does this\nis because these sounds are in no sense accidental\nin their sequence. They each must\nfall mathematically at a precise point. So he wants to\nwatch as he works. He takes it seriously. I think it's interesting. If you are amused,\nyou may laugh. If you like it, you\nmay buy the recording. John Cage and \"Water Walk.\" [EXPERIMENTAL MUSICAL SOUNDS] [END PLAYBACK] NANCY KANWISHER: Anyway, it\ngoes on and on like that. I guess it was a little\nedgier in 1959 than it is now. But he's making a point. He's making a point is,\nwhat the hell is music. And he's saying, I can\ncall this music if I want. And everybody's enjoying it. Anyway. So you can watch the\nYouTube video, if you want. It's quite entertaining. Despite this kind\nof nihilistic view that anything could\ncount is music, there are some\nthings we can say. First thing I'd say is, if\nyou want to study music, one of your first\nthings you run into is, oh, what's going to count. You run into this problem here. But actually, I\nthink that doesn't need to be so paralyzing\nas it feels at first. You can just take the most\ncanonical forms where all of your subjects will agree that\nthis is music and this isn't. And then someday you can\nstudy the edge cases later, but you don't need to agonize\nabout them in order to get off the ground and study it. Further, we can ask what\nis music cross-culturally. Oh, right, I keep\nforgetting my next point. And let me make another point\nis that music is not just about a set of\nacoustic properties. You may think of music as\njust an auditory thing, a solitary experience, because a\nlot of the time it's like that. But remember that that's a\nvery recent cultural invention. And throughout most\nof human evolution, music has been a fundamentally\nsocial phenomenon, more like this, experienced\nin groups of people as a kind of deeply social,\ncommunicative, interactive kind of enterprise. Or even if not in a\nlarge group, music is very social in\nthis sense here. There's a whole bunch of cool\nstudies about the role of song in infants and how infants\nuse song to glean information about their social environment. And the point is just\nmusic is extremely social. It's not just defined by\nits acoustic properties. But in addition, we\ncan ask, OK, let's look across the cultures\nof the world and ask, are there universals of music? Is there anything in common\nacross all the different kinds of music that people experience\nin different cultures? For example, are there always\ndiscrete pitches or always isochronous beats. I already showed you\nthere aren't always isochronous beats. And this is nice because\nit's an empirical question. There's a really cool\npaper from a few years ago where they took\nrecordings of music from all over the world,\nall those colored dots, and they asked, what\nare the properties that are present in most\nof those musics and how prevalent are they. And what they found is there's\nno single property of music that's present in all\nof those cultures, but there's many that\nare present in most, and there are a lot\nof regularities. So this is a huge\ntable from their paper where they list many\ndifferent possible universals. And what you see is the relevant\ncolumn is this one here. And the white is the percent\nof those 304 cultures that they looked at that have\nthat property in their music. So these top ones\nare very prevalent, just not quite universal,\nbecause there's a couple of cases\nthat don't have it. So one of the most\ncommon ones is the idea that melodies are made\nfrom a limited set of discrete pitches,\nseven or fewer, and that those pitches are\narranged in some kind of scale with unequal intervals\nbetween the notes. So that's as close to\na universal of music as you can get,\nalthough you can see from that little\nteeny black snip that it's not quite\nperfectly universal. And the second thing\nis that most music has some kind of regular pulse,\neither an isochronous beat or even the\nnon-isochronous ones have different subdivisions\nwith different numbers of beats so that there's a\nsystematic rhythmic pattern. So there's something kind\nof like melody and something kind of like rhythm in almost\nall the world's musics. They did find some\npretty weird ones, one I can't resist playing for you. This is from Papua New Guinea. So as they say, the closest\nthing to an absolute universal was song containing\ndiscrete pitches, or regular rhythmic patterns,\nor both, which implied to almost the entire sample. However, music examples\nfrom Papua New Guinea contain combinations of friction\nblocks, swung slats, ribbon reeds, and moaning voices-- I don't know what those\nthings are either, but I'll play them\nfor you in a second-- that contained neither discrete\npitches nor an isochronous beat. OK, here we go. [VIDEO PLAYBACK] [PAPUA NEW GUINEAN MUSIC] [END PLAYBACK] OK, pretty wild, huh? So maybe wilder,\narguably, than John Cage. But anyway, so there are\nsome like pretty remote edges to the concept of music. I mentioned before the case\nof consonance and dissonance and that infants don't\nprefer one over the other. In fact, this links to a\nreally cool recent study from Josh McDermott's lab. And so the question he asked is,\nwhy do we like consonant sounds like this-- oops, [INAUDIBLE] play. Here we go. [RHYTHMIC SOUND] Kind of nice, right? But we're not so hot about this. [OFF TUNE SOUND] Right, everybody\nget that intuition? OK so what's up with that? So many people have\nhypothesized for a long time that that difference\nis based in biology, or even it's like a\nphysical analog of it, beats and stuff like that. But actually, it's an\nempirical question. And so one way to\nask that question is to go to a culture\nthat's had minimal exposure to Western music, all of which\nreally prefers consonance over dissonance. Yes, [?"}, {"content": "Carly? ?] AUDIENCE: Is\nconsonants [INAUDIBLE] differentiated [INAUDIBLE]? NANCY KANWISHER: Oh, yeah, yeah. I'm sorry, totally\ndifferent word-- consonance, C-E,\nhas no relationship to consonants as\ndistinguished from vowels. A consonant and a vowel,\nthose are two different kinds of phonemes. Here, consonance is that\ndifference between those two sounds I just played. And it has to do with\nthe precise intervals of those harmonics in\nthe harmonic stack. All right, so what McDermott\nand his co-workers did is to go to a Bolivian culture in the\nrainforest in a very remote location to test these\npeople here, the Tsimane'. And the Tsimane'\nlack televisions and have very little access\nto recorded music and radio. Their village doesn't have\nelectricity or tap water. You can't get there by road and\nyou have to get there by canoe. So that's what McDermott\nand his team did. They went down there\nto visit the Tsimane'. And what they found,\nthey played them consonant sounds and dissonant\nsounds, and with a translator, and spent a lot of\ntime making sure that they really understood\nthe difference between liking and not liking. And they tested\ntheir understanding of what it means to like\nsomething or not like it, and all kinds of other ways. And the upshot is,\nthe Tsimane' do not have a preference for\nconsonance over dissonance. So it's not a\ncultural universal. And that's consistent\nwith the idea that it's not a preference\nin infants either. So this is something\nspecific to Western music. So that's kind of introduction\nto some stuff about what music is and what its\nvariability is and the fact that its presence is universal. And there are many very common\nproperties across the world's musics, and it developed early. So let's ask, is music\na separate capacity in the mind and brain. All right, so let's start\nwith the classic way this has been asked\nfor many decades, and that's to study\npatients with brain damage. And it turns out\nthere is such a thing as amusia, the loss of music\nability after brain damage. And so there are\nboth sides of this. There are people who\nhave impaired ability to recognize melodies without\nimpaired speech perception. And there's the\nopposite-- people who have impaired speech\nrecognition without impaired melody recognition. So that is, of course, a\ndouble dissociation, sort of, it's a little mucky in there. If you state the word\nsimply like that, if you look in detail, there's\nsome muck, as there often is. So let's look in a little more\ndetail at these two cases, the most interesting ones\nwho seem to have problems with auditory tunes but not with\nwords or other familiar sounds. So here is a horizontal slice. This is an old study. So it's a CAT scan\nshowing you something's up with the anterior temporal\nlobes in this patient. And this was true of these two\nclassic patients, CN and GL. Both of them were very bad\nat recognizing melodies, even highly familiar melodies, happy\nbirthday and stuff like that, they don't recognize. They mostly have intact\nrhythm perception. And this is a core question\nwe'll come back to. It's a complicated\nnon-resolved situation. But these guys had\nintact rhythm perception and relatively intact language\nand speech perception. However, upon\nfurther testing, it becomes clear that these guys\nhave a more general problem with pitch perception,\neven if it's not in the context of music. So this is a question that\nI asked all of you guys to think about for in\nthe opposite direction in your assignment\nfor Sunday night. When I asked you\nwhether those electrodes in the brains of\nepilepsy patients that are sensitive\nto speech prosody, to the intonation\ncontour in speech, I asked you whether you\nthought they would also be sensitive to the intonation\ncontour in melodies. And most of you said, yes, it's\npitch, pitch contour, must be. Well, it's a perfectly\nreasonable speculation, but not necessarily. Maybe we have special\npitch contour processing for speech and different pitch\ncontour processing for music. It's possible."}, {"content": "It's an empirical question."}, {"content": "Was there a question\nback there a second? OK, so maybe this is about pitch\nfor both speech and music, not music per se. And so there are\nmore detailed studies of patients with\ncongenital amusia. And just like the case\nwith acquired prosopagnosia versus congenital prosopagnosia,\nwhether you get it from brain damage as an adult\nor whether you just always had it your whole life, and\nnobody knows exactly why and there's no evidence\nof any brain damage, the same thing happens\nwith a congenital amusia. So something like 4%\nof the population, they might say\nthey're tone deaf. But just to tell\nyou what that means, it can be really quite extreme. They can just completely fail\nto recognize familiar melodies that anyone else\ncould recognize. They may be unable to detect\nreally obvious wrong notes in a canonical melody. They're just really\nbad at all of this. And further, they don't have\nwhopping obvious problems with speech perception. So at first, it was thought\nthat speech perception was fine. But if you look closer, it\nlooks like actually there is, even outside of music,\nthere is a finer grained deficit in pitch contour perception\nthat shows up even in speech. So what I mentioned before, so\nwe can ask this in the case. This is sort of the reverse\ncase of the ones you considered. Now we have people who have\nthis problem with pitch contour perception in music. Are they going to have a\nproblem also with pitch contour perception in speech? So that's what this\nstudy looked at. So they played sounds like this. And you have to\nlisten carefully. There will be sentences spoken. And you have to see if they're\nidentical or different. So listen carefully. [VIDEO PLAYBACK] - She looks like Ann. She looks like Ann? [END PLAYBACK] NANCY KANWISHER: How many people\nthought that was different? Good, you got it. So one is the\nstatement and one is-- it's sort of a question. It's in a sort of\nBritish accent. It's a little harder to detect,\nbut different intonation contour. So that's what the Tang, et al. Paper was talking about\nis that distinction. So we can then ask,\nthat subtle distinction, are people with congenital\namusia impaired at that. So if it's specific to\nmusic, they shouldn't be. But if it's any intonation\ncontour, they should be. Yeah, I'll play the other ones. So they are in fact impaired. This is accuracy here, the\ncontrols are way up there, the amusics are down there. So they are impaired at this\npitch contour perception thing, even in the context of music. I'm sorry, I said that wrong--\neven in the context of speech. So it's not just about music. And in the controls, they\nhave sounds like this, which are just tones. Got that? It's the same kind of\nthing, but not speech. And you see a similar\ndeficit in the amusics compared to the controls. And then they have a\nnonsense speech version. [VIDEO PLAYBACK] - [INAUDIBLE] [END PLAYBACK] NANCY KANWISHER: Same deal-- the amusics are impaired\ncompared to the controls. So that shows that the\ndeficit for these guys is not specific to\nmusic per se but it seems to be a pitch contour\nproblem in general that extends to speech. Yeah?"}, {"content": "AUDIENCE: Which of those-- NANCY KANWISHER: We'll\nget there, sort of. It would have been nice if the\nTang et."}, {"content": "al. paper had included some musical contour stuff. They didn't, but I'll\nshow you some of our data shortly that gets close to this. OK, so all of that suggests\nthat this amusia is really more about pitch than speech. I'm sorry, what's\nthe matter with me. It's really more about\npitch than music. But the reading that\nI assigned for today is a very new twist in\nthis evolving story. So this used to be a\nnice, clean lecture with a simple conclusion. And now all of a sudden,\nI ran across that paper. It's like, wow, OK, that\nmight not be quite the case. So what did you guys\nget from the reading? In what way does that slightly\ncomplicate the story here? Yeah, [INAUDIBLE]? AUDIENCE: [INAUDIBLE] NANCY KANWISHER:\nYeah, what they found is that amusics,\nnot all of them, also have problems with rhythm. And that is inconsistent\nwith the idea that amusia is just about pitch,\nwhether in speech or music. And that says, OK, many amusics\nalso have problems with rhythm. Yeah? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: So\nthere's a standard battery that people use that asks-- Dana, help me. What does the standard\nbattery ask people? AUDIENCE: There's\na lot stuff, tests, things like listening to\nlike a clip of a symphony and having to decide whether\n[INAUDIBLE] or they're too slow. NANCY KANWISHER: Kinds\nof things that people without musical\ntraining answer fine, although there's quite a range. I'm at the way bottom\nend of Dana's scale when she gives these. AUDIENCE: That\nrhythm falls apart, might not be able to\ntell the difference. NANCY KANWISHER: Just that this\nprior evidence on the stuff I showed and a whole\nbunch of other studies seem to suggest that amusia,\nboth in acquired brain damage and congenital\namusia, seem to be really when you drill down more of\na problem with pitch per se, even pitch in speech. And so then if it's about pitch,\nwhy would it also go along with rhythm? And so when it goes\nalong with rhythm, that starts to sound more like\nthis is something about music. It gums up the story. Talia? AUDIENCE: So I don't really know\nif this could be a compound, but when it comes\nto natural speech when you have some\nkind of intonation, like pitch differences\nwhen you emphasize, like especially in\nterms of a question, aren't there also some kind of\nrhythmic differences as well? NANCY KANWISHER: Yeah. AUDIENCE: So how do you\nseparate the two out? NANCY KANWISHER: You just\nhave to do a lot of work to try to separate those out. And so the paper I signed to\nyou guys did some of that work. There's still room to\nquibble, but they did. There was experiment\ntwo, and they tried to deal with exactly\nthat kind of thing of saying, OK, let's try to\nmake sure that-- well, actually the controls\nthat they were doing is slightly different. They were to make sure that the\nbeat task didn't require pitch. So it's very, very tricky\nto pull these things apart, which is-- AUDIENCE: Yes, so like the\nbeat task doesn't make sense, but I was just, like,\nin the verb first one, even from the paper that\nwas assignment Sunday. I don't know, so you're saying\nthat it's totally possible to separate out rhythmic\ndifferences from when you're just changing pitch. NANCY KANWISHER: It's\nreally, really difficult."}, {"content": "It's really difficult. Dana's trying to do experiments to\ndo this right now. And she's invented some\ndelightful and crazy stimuli that try to have one\nand not the other. It's very tricky. You can have rhythm\nwithout pitch change. That you can totally do. It's really hard or impossible\nto have a melodic contour without some beat or other. We have some crazy stimuli\nthat sort of do that, but they're pretty crazy. So anyway, these are very\ntricky things to pull apart. And this is all right\nat the cutting edge. These things have not\nbeen cleanly separated. I'm running out of time. So do you have a quick question?"}, {"content": "OK, sorry about that. So conclusions from\nthe patient literature, they're suggestive evidence\nfor specialization for music, but no really clear\ndisassociations. Music deficits are\nfrequently but not always associated with just\nmore general pitch deficits. And all of this is\ncomplicated because there's lots of possible\ncomponents of music, right. When there's pitch\ndeficits, is it pitch or relative pitch,\ninterval, key, melody, beat, meter? All of these things are\ndifferent facets of music. And so it's really not resolved\nexactly what's going on here. It's kind of encouraging that\nthere's a space in there, but not resolved. So let's go on to\nfunctional MRI. And we're going to\nrun out of time. So let me just take a\nmoment to figure out how I'm going to do this. What the hell am I\ngoing to do here? Well, I hate to-- OK, you guys are going\nto tell me at 12:05. Yeah, OK."}, {"content": "Maybe we can get\nall through this. So here's a really charming\nstudy from a few years ago that tried to ask whether\nthere are systematic brain regions that are engaged\nin processing music. And they used a really\nfun perceptual illusion that you're going to hear."}, {"content": "I'm going to play a speech clip. And it's part of it is going\nto be repeated many times. And just listen to it and think\nabout what it sounds like. [VIDEO PLAYBACK] - For it had never been his\ngood luck to own and eat one. There was a cold\ndrizzle of rain. The atmosphere was murky. There was a cold drizzle. There was a cold drizzle. There was a cold drizzle. There was a cold drizzle. There was a cold drizzle. There was a cold drizzle. [END PLAYBACK] NANCY KANWISHER: What happened? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: Yeah? What happened? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: You\nstart to hear a melody. And you didn't hear the melody\nthe first time he said it. It was just normal\nspeech, right. Speech has this kind\nof intonation contour. And he's speaking with\nan intonation contour. But then somehow when\nyou keep hearing it, it turns into a melody. So it turns out that doesn't\nwork for all speech clips. In fact, it's really hard to\nfind speech clips for which it works. But there are some. But everyone has that\nexperience, or most people do. And that gives us a\nreally nice lever, because we can take that same\nacoustic sound when you hear it as speech and when you hear\nit as melody and we can ask, are there brain regions\nthat respond differentially. It's sort of analogous to\nupright versus inverted faces. Well, it's even better. It's the exact same\nsound clip that's construed one way at first\nand another way afterwards. Everybody get that?"}, {"content": "So that's what these guys did. They used a standard\nblock design. They just listened\nto those sounds and they just\nlooked in the brain to see what bits respond more\nafter the sound starts getting perceived as music\nthan before when it was being heard as speech. And they got a bunch\nof blobs in the brain."}, {"content": "It's a bit of a mess,\nbut they got some stuff. And so that's fun."}, {"content": "But it's also ambiguous. We still don't know if\nthis is about some kind of pitch processing, which\nbecomes more salient-- you hear it as abstract\npitch-- or whether it's really about melodic contour or what. So that's a cool study, but\nI think it doesn't really nail what's going on. So another angle at this is\nto ask whether music recruits neural machinery for language. So let me say why this has\nbeen such a pervasive question in the field. So there's a lot of people who\nhave pointed out for 30 years, or probably more, there\nare many deep commonalities between language and music. So they're both distinctively\nor uniquely human. They're natively auditory. That is, we can read language,\nbut that's very recent. Really, language is all about\nhearing, evolutionarily. They unfold over time. And they have complex\nhierarchical structure. So you can parse a\nsentence in various ways and there are all\nkinds of people who've come up with ways to have\nhierarchical parsings of pieces of music as well. So there's a lot\nof deep connections between language and music. And so many people have\nhypothesized that they use common brain machinery. And there, in fact, many\nreports from neuroimaging that argue that in fact they\ndo use common machinery. Like, we found overlapping\nactivation in Broca's area for people listening\nto music and speech. However, both studies\nare all group analyses. I forget if I've gone\non my tirade in here about group analyses. Have I done the group\nanalysis tirade in here? You'll get more of it later. I'll do a brief version now,\nand you'll get more later. Here's the problem--\ngroup analysis is you scan 12 subjects. You align their brains\nas best you can."}, {"content": "And you do an analysis\nthat goes across them. And you find some\nblob, say, here, yeah, be there, for listening to\nsentences versus listening to non-word strings. OK, that's a standard finding. Then you do it\nagain for listening to melodies versus listening\nto scrambled melodies. And you find the blob overlaps. And then you say, hey,\ncommon neural machinery for sentence understanding\nand for music perception. Now that's an interesting\nquestion to ask."}, {"content": "It's close to the\nright way to do it."}, {"content": "but there's a\nfundamental problem. And that is, you can find an\noverlap in a group analysis, even if no single subject\nshows that overlap at all. Why? Because those regions vary\nin their exact location. And if you mush across a\nwhole bunch of individuals, you're essentially blurring\nyour activation pattern. And so all of the prior\nstudies, until a few years ago, had been group analyses\nand they found overlap. And who the hell knows\nif there was actually overlapping activation within\nindividual subjects, which there would have to be\nif it's common machinery. Or if they're just nearby\nand you muck them up with a group analysis and\nthey look like they're on top of each other. If you didn't quite\nget that, we'll be coming back to that point. For now, all you need\nto know is many people ask this question\nand the methods were close but problematic."}, {"content": "But luckily,\nhowever, Ev Fedorenko did this experiment\nright a few years ago. So here's Ev and\nhere's what she did, she functionally\nidentified language regions in each subject individually. And we'll talk more about\nexactly how you do that. You listen to sentences\nversus non-word strings. You find a systematic\nset of brain regions that you can identify in each\nindividual that look like this. Here is in three subjects. Those red bits are\nthe bits that respond more when you\nlisten to a sentence versus listen to\nnon-word strings or read sentences\nversus non-word strings. Then what she could do is\nshe said, now that I found those exact regions\nin each subject, I can ask of those\nexact regions, how do they respond to music\nversus scrambled music. So she played stuff like this. [MUSIC PLAYING] OK, so nice canonical\nand nothing crazy, weird. We're not going with\nthe New Guinean music and asking edgy questions. We're just saying\nsomething everybody agrees that's music, versus\nyou scramble it and it sounds like this. [MUSIC PLAYING] OK, it's actually\nthe same notes. I know, I know. A lot of people that go, that's\ncool, that's really edgy. Yeah, it is. But to most people, it's\nnot canonical music. And so what Ev found is that\nnone of those language regions responded more to the\nintact than scrambled music. So language regions are\nnot interested in music. We'll talk more about that\nnext week or the week after. Then she did the opposite. She identified brain regions\nhere in a group analysis just to show you where\nthey are, anterior in the temporal lobes,\nthat respond more to intact than scrambled music. She identified those\nin each subject and measured the\nresponse of those regions to language, sentences\nand non-word strings. And each of those regions\nrespond exactly the same to sentences and\nnon-word strings. So basically, the\nlanguage regions are not interested in\nmusic, and the music regions are not interested in language. And therein, we have a-- AUDIENCE: [INAUDIBLE] NANCY KANWISHER:\nThank you, exactly. So music is not using\nmachinery for language. That was one of the\nhypotheses we started with. And it was not. So that's true, at least for\nhigh-level language processing, that computes the\nmeaning of a sentence. But what about\nspeech perception? Remember, last time I made the\ndistinction between the sounds, like ba and pa, which\nhave a whole set of computational challenges,\njust perceiving those sounds, which is quite\ndifferent than knowing the meaning of a sentence. So what about speech\nperception or, in fact, any other aspect of hearing? So what I'm going to try to do\nis briefly tell you about one of our experiments. I'm sorry, I try not to turn\nthis whole course into stuff we've done in my lab, but\nit's one of my favorite ever. And it's a cool, different\nway to go at this question from the other MRI experiments\nwe've talked about before. So the background is,\nOK, let's step back. What's the overall organization\nof auditory cortex? And when we did this experiment\nfive or six years ago, not a whole lot was known."}, {"content": "Basically, everybody agrees."}, {"content": "Whoops, I put the\nwrong slide in here. Everybody agrees that primary\nauditory cortex is right there with that high-low-high\nfrequency thing we talked about from there. But from there on out, in\nthe last couple of years, there's an agreement about\nspeech selective cortex that I showed you\nbriefly last time and other people have seen that. But there's lots of hypotheses\nand no agreement with anything else and no real evidence for\nreally music-selective cortex. But there's a problem\nwith all the prior work where you sit around\nand make a hypothesis and say, oh, let's see, are\nwe going to get a higher response to, say, intact versus\nscrambled music, or faces versus objects, or whatever. All of those are scientists\nmaking up hypotheses, and then testing them. And there's nothing\nwrong with that. That's what scientists\nare supposed to do-- invent hypotheses,\nand then make good designs and go test them. But the problem with that is,\nwe can only discover things that we can think to test. What if deep facts\nabout mind and brain are things that nobody would\nthink up in the first place? And so that's where we can\nget real power from what are known as data-driven\nstudies, where you collect a boatload of data and\nthen use some fancy math and say, tell me what the\nstructure is in this data. Not, is this hypothesis that\nI love true in these data. And I'll do anything to\npull it out if I can."}, {"content": "See it in there, find\nevidence for it in there. But yeah, exactly. But if we collect a whole\nbunch of data and do some math and see what the structure\nis, what do we see? So that's what we\ndid in this study. I'm going to speed up to try\nto give you the gist here."}, {"content": "So \"we\" is Sam Norman-Haignere\nhere and Josh McDermott. [SOUND RECORDING EXPERIMENT\n PLAYING] And so we scanned\npeople while they were hearing stuff like this. We first collected the\n165 categories of sounds that people hear most commonly. This is classic cocktail party\neffect you guys are doing. You have to separate me speaking\nfrom all this crazy, weird, changing background. And so anyway, we\nscan people listening to these sounds, which broadly\nsample auditory experience. And so we collected sounds\npeople hear most often and that they can recognize\nfrom a two-second clip. OK, enough already. [CELLPHONE RINGING] Oh, yeah, just to\nwake everyone up. So we scan them listening to\nthose 165 sounds, broad sample of auditory experience. Then, from each\nvoxel in the brain, we measure the exact magnitude\nof response of that voxel to each of the 165 sounds and\nwe get a vector like this. Everybody with me? That's one voxel right there,\nanother voxel, another voxel. We do this in all\nof kind of greater, suburban, auditory cortex. That is not just primary cortex,\nbut all this stuff around it that might even remotely, that\nresponds in any systematic way to auditory stimuli. They grabbed the\nwhole damn thing. So you do that in 10 subjects. You have a big\nmatrix like this-- 1,000 voxels in each\nsubject, 11,000 voxels across the top, 165 sounds. That's our data. So each column is the\nresponse of one voxel in one person's brain to\neach of the 165 sounds. Everybody got it? Now, we have this\nlovely matrix, which is basically all the\ndata we care about from this whole experiment. Then, we throw away\nall the labels. Poof. It's just a matrix. And then we do some math,\nwhich essentially says, let's boil down the\nstructure in this matrix and discover its\nfundamental components. That math happens\nto be a variant of independent\ncomponent analysis, if that means anything to you. If it doesn't, don't\nworry about it. The gist is, we're\ndoing math to say what's the structure in here. And we're doing it\nwithout any labels. So this analysis doesn't even\nknow where the voxels are or which of your 10 subjects\nthat voxel came from. It doesn't know\nwhich sound is which. And so it's very\nhypothesis neutral. It's a way to say, show me\nstructure with almost no kind of prior biases. Just show me the structure. So everybody get how that's kind\nof a totally different thing to do from everything\nwe've talked about so far? So that's what we did. I'm going to skip the math\nand the modeling assumption."}, {"content": "It's not really\nthat complicated, but I think I'm going\nto run out of time, so very hypothesis neutral. And what we find\nis six components account for most of\nthe replicable variance in that whole matrix. I'll tell you what a\ncomponent is in a second. Did you have a question? AUDIENCE: Is it just like\nwith ICA, but [INAUDIBLE] PCA [INAUDIBLE]? NANCY KANWISHER: With PCA,\nyou assume orthogonal axes. With ICA, you don't\nassume orthogonal axes. And so it's very,\nvery similar to PCA. And it starts out\nas PCA and then it does some more rigmarole. Yeah, it's the same idea. Like basically, tell me the\nmain dimensions of variation. Yeah? AUDIENCE: And are these\nmatrices sparse and [INAUDIBLE]?? NANCY KANWISHER:\nYes, they are sparse. And that is one of the\nassumptions you use. There isn't only one way\nto factorize a matrix. It's an ill-posed problem."}, {"content": "So you need to make\nsome assumptions."}, {"content": "And that's one of the ones we\nmade, but you can test them. So what we find\nis six components account for most of the data. And four of those reflected\nacoustic properties of the stimuli. One was high for all the sounds\nwith lots of low frequencies. Another was high for all the\nsounds with high frequencies. What is that? Sorry, speak up? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: They're\nsensitive to frequency, but where is that in the\nbrain that you've already heard about? AUDIENCE: Primary-- NANCY KANWISHER:\nPrimary auditory cortex as a tonotopic map. So this is awesome."}, {"content": "Because if you go\ninvent some crazy math and you apply it to your data\nand you discover something you know to be true,\nthat's very reassuring. The math isn't just\ninventing crazy stuff. It's discovering stuff we\nalready know to be true. That's known in more\nbiological parts of the field as a positive control. Invent a new method,\nmake sure it can discover the stuff you know to be true. So check, check, OK. But then it discovered\nsome other stuff. And I'm just going to tell\nyou about two of them."}, {"content": "So here's one. So I was just loose about\nwhat a component is. A component is a magnitude of\nresponse for each of the 165 sounds and a\nseparate distribution in the brain, which I'll\nshow you in a moment. So here's one of\nthose components. And we've taken the 165 sounds\nand added basic category labels on them. We put them on Mechanical\nTurk and people told us which category they belong to. So that enables us to look\nat this mysterious thing and average within a category. So this is its component. And if you look at\nit, you see that it's really high for English\nspeech and foreign speech that our subjects\ndon't understand. And then, oh, what's,\nthat intermediate Thing Oh, that's music with vocals. It has a kind of speech. And way down here-- that's non speech vocalizations,\nstuff like laughing and crying and sighing. So there's a voice\nbut no speech content. So that's a speech component. And as I mentioned,\nthis had been seen before in the last few years. So it wasn't completely new. But what's cool about this\nis just emerged spontaneously from this very broad screen. We didn't go and\nsay, hey, can we find a speech selective\nregion of cortex, if we try really hard. Oh, yeah, we validate\nour hypothesis. This is like, let's sample\nauditory experience-- and wow, there it is. Yeah? AUDIENCE: I mean, you\nassigned [INAUDIBLE].. NANCY KANWISHER:\nWe put them on Turk and had people say what\ncategory they fit into. Yeah? AUDIENCE: [INAUDIBLE]. Categorizing by speech is\na very good way [INAUDIBLE] better way than [INAUDIBLE]. NANCY KANWISHER:\nAbsolutely, absolutely. This is a first pass."}, {"content": "And one hopes to go\ndeeper and deeper. If we could separate different\naspects of speech, consonants and vowels,\nfricatives, whatever, there could be much\nmore to be done. Yeah, I got to-- oh, boy, OK. And when do I have to\ngive them the quiz? It's shortish. They don't need a\nfull 10 minutes. What is it? Seven questions? AUDIENCE: Eight. NANCY KANWISHER:\nEight-- eight minutes? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: OK, make me\nstop definitively at 12:18. OK, so that's cool."}, {"content": "It's not exactly new, but\nit's a really nice way to rediscover things that\nwe thought to be true. All right, then there's\ncomponent 6 that popped out. What is component 6? Well, if we average\nwithin a category instrumental music\nand music with vocals, and everything\nelse is really low. We didn't go looking for this. Boom-- music selectivity. That's pretty amazing."}, {"content": "Never really been seen before. People have looked\nand they've made some kind of sort of smoke\nand mirrors, like, not really. This is the first\ntime it was seen and it just popped\nout of the data. And that says that\nit's not just something you can find if you try really\nhard and go fishing for it. It's actually a significant\npart of the variance in this whole response."}, {"content": "I'm going to skip everything\nexcept clarification questions now, because I'm-- go ahead. AUDIENCE: Did these\nvoxels correspond to the music [INAUDIBLE]? NANCY KANWISHER: Sort\nof, it's complicated. Sorry, it's a long answer. So this really looks\nlike it's music. And so now, I was vague\nabout what a component is, but it's both that\nresponse profile and it's a set of\nweights in the brain. So if you project this\none back in the brain, you get this band of\nspeech selective cortex right below primary\nauditory cortex, like that. And if you project the music\nstuff back in the brain, you get a patch. This is sort of an\nanswer to your question. You get a patch up in\nfront of primary auditory cortex and a patch behind. So here we have a\ndouble dissociation of speech selectivity and music\nselectivity in the brain, OK? So music doesn't just\nuse mechanisms for speech as many people have proposed. It's not true, right. So when you see\ndramatic data like this, a natural reaction is to say,\nlike, really, get out, come on. Like, music\nspecificity, like what? So very briefly, Dana\nhas just replicated this in a new sample of subjects. It does not matter if those\nsubjects have musical training, like students from\nBerklee School who spend like six hours\na day practicing, versus people who\nhave essentially zero music lessons\never in their life, you get those components in both\ngroups, maybe slightly stronger in the trained musicians. We're not quite sure yet. But in any case, it is\ntotally present in people with zero musical training. That doesn't mean it's\ninnate, because people without musical training\nhave musical experience but no explicit training. Skip all of this."}, {"content": "Here is her replication. Boom, boom. It's there with and\nwithout training. I'm going to skip all this."}, {"content": "You can read it on the\nslides, if I lost you in here, because I want to\nshow you something else. That music selectivity\nwas not evident if you just do a direct\ncontrast in the same data. Take all the music conditions,\nall the non-music conditions, you get a blurry mess. It's not strong."}, {"content": "You have to do the\nmath to siphon it off. And that's OK."}, {"content": "But I like to see\nthings in the raw data. And so probably\nwhat that means is that the music is overlapping\nwith other things in the brain. And so the direct contrast\ndoesn't work well, the math can pull them apart. But wouldn't it be nice\nto see them separately? And so we've been doing\nintracranial recordings from patients with\nelectrodes in their brain. And I'll just show you a\nfew very cool responses. So this is a single electrode\nin a single patient. These are the 165\nsounds, same ones. This is the time course. And this is a speech\nselective electrode. It responds to native\nand foreign music. Those are the two green ones-- I'm sorry, native\nand foreign speech. And it responds to music\nwith vocals in pink. Everybody see how that's a\nspeech selective electrode? So there's loads of those. But we also found these. Here is a single electrode. Look, each row is\na single stimulus. Here's a histogram of responses\nto all the music with vocals, music without vocals, much\nstronger than to anything else. You might be saying, well,\nwhat about those things."}, {"content": "Let's look at what\nthose things are. Oh, even the violations\naren't really violations. Whistling, humming,\ncomputer jingle, ringtone-- those are sort of musicy. So that is an extremely\nmusic-selective individual electrode in\na single subject's brain. No fancy math that might\nhave invented it somehow. It's just there right\nin the raw data. Further, and here's\nthe time course, you can see the time course of\nmusic with instruments, music with vocals, everything else. Really selective. So this is the\nstrongest evidence yet for music specificity\nin the human brain. But there's one more cool thing\nthat came out of this analysis. And that is we found\nsome electrodes that are not just\nselected for music, but selected for vocal\nmusic, selected for song. And that's really amazing. Because as I started\noff at the beginning, many people have\nsaid that song is a kind of native form of music. The first one to evolve\nand all that kind of stuff. And so we did all the controls. It's not the low-level stuff. And there's lots\nof open questions. We started with this\npuzzle of how did music evolve, if it did evolve. And we made a little\nbit of progress. It doesn't share music machinery\nwith speech and language. If it's auditory\ncheesecake, as Pinker said, it's auditory cheesecake that\nnot only uses machinery that evolved for something\nelse, but changes it throughout development and\nmakes it very selective. These guys speculated\nthat song is special. Maybe it is. And sexual selection, who knows? We have no data."}], "10. Development, Nature & Nurture I": [{"content": "[DIGITAL EFFECTS] NANCY KANWISHER: So\nlet's start with one of the deepest questions humans\nhave ever asked themselves. We're not messing around in\nthis class; we're going for it. And one of the\ndeepest questions is, where does knowledge come from? And as you'll know, if\nyou've taken even a teeny bit of philosophy or read\neven a teeny bit, you know that some of the\nclassic views in Western philosophy-- especially the\nempiricists, Locke and Hume-- argue that all knowledge\ncomes from experience, right? On the other hand,\nthere are a number of other schools of thought in\nWestern philosophy, of which a dominant figure is\nImmanuel Kant, who argued that experience\nalone is not enough. You can't just have experience\nand figure out all the stuff we have figured out. And so he argued that there\nhas to be what he called \"a priori conditions\"\nof cognition, which can't be derived from\nexperience themselves, but have to be given\nprior to it, OK? So you have to have to build\nsome structure into a mind or brain to get\nit off the ground. You can't just start\nwith absolutely nothing and get anywhere. OK, and he also argued that\none of the key elements of this a priori structure that\nyou have to build in was space and time-- organizing principles of\ncognition and thinking. And so in his\nversion of it, space is nothing but the form of all\nappearances of outer sense, and it can be given prior to\nall actual perceptions and so exist in the mind a\npriori, and can contain, prior to all experience,\nprinciples which determine the relations of these objects. OK, well, is that just\nempty philosophical hot air? It's kind of hard to understand\nexactly what he means. You're actually have to go\nspend a good deal of time with reading him to\nmake any sense of it-- or cheat and get your\nfriends to tell you, as I do. But no, I'll argue it's not just\nempty philosophical hot air-- that these are, in\nsome important sense, empirical questions. And there are\nempirical questions that our field\naddresses very directly. And so on Wednesday,\nwe'll talk about whether your representations of\nspace in your head are innate or not. It's pretty much directly\nwhat Kant is talking about-- or the modern version of\nwhat he was talking about. And today, we'll talk about\nwhich aspects of the brain are innate and which\nour learned, OK? That's the agenda. OK, so this little kind of\nEaster egg brain here very schematically shows\nyou some of the regions that we've been talking\nabout in this class so far, with regions that\nare, to varying degrees, specialized for processing\nthings like shape, and color, and motion, and faces,\nand places, and bodies-- visually processing all of\nthese things in approximately those locations. And as I've mentioned,\nthese regions are present in approximately\nthe same location-- with some individual\nvariability-- in pretty much every normal person. One of my lab members\nsays, you keep saying that, and it's just not true. There's some percent\nof subjects who just don't show these things. He's kind of right, OK. So maybe, I don't know,\n5%, 10% of subjects, you wouldn't see\nsome of these things. And we've never actually\ndone the serious work of bringing those subjects back,\nscanning the hell out of them, and finding out whether they\nwere just asleep in the scanner or it was a bad scanner\nday, or whatever it was. I bet they all have them,\nand it's just sometimes you don't see it, but I'm trying\nto be a little more honest."}, {"content": "OK, but you just look at this. Given this very\nschematic version of it, you say, how would\nyou build this system? How would you start with an\nembryo and build into a genome, or build into\nwhatever experience is going to happen to\nthis developing organism? How would it end up with this\nvery particular structure, with those things in\napproximately the same place-- or at least the same relative\npositions-- in all subjects? The face bits are always\nlateral to the color bits. The place bits are\nmedial to the color bits. The shape bits are out\non the lateral surface. It's like always like that."}, {"content": "How do you build a\nsystem like that? I find it hard not to\nimmediately think, well, some aspect of this\nmust be innate, or how would it be so damn\nsimilar in each individual, right? But it's not the\nonly hypothesis. Some big part of it-- even if\nsome aspect of this is innate, some big part of it may\nalso be learned or derived from experience, OK? So what do you guys think? Do you think the fact\nthat these structures are in systematically the\nsame place across subjects mean you have to build\nin all that stuff, somehow figure out how\nto get a bunch of As and Ts and Gs and Cs in your DNA\nto give you a blueprint for how to build that structure? What do you think? Yeah? AUDIENCE: I mean,\nit's a combination, but it's hard to, then,\nthink about how that's involved in\n[INAUDIBLE] generation and then kind of\nbecome more innate? NANCY KANWISHER: Yeah, so\nto some extent, experience-- what I mean here is\nlearn from experience within each individual. You could argue\nthat \"innate\" really means \"learned through the\nexperience of our ancestors, and hence wired\ninto the DNA,\" yeah. Anyway, I find this not\nan obvious question, and so we'll talk about\nwhat the data say here. So first of all, we're going\nto do some very basic facts about brain development, just\nto get the picture of what we're talking about physically\nwith the development of brains. So we can ask, what\nis present at birth? And so it turns out that most of\nthe neurons in the adult brain are generated before birth, OK? So most of the actual\nneurons are generated early. You're not making a whole\nlot more after birth-- a few, but not a lot. Further, the current view is\nthat most of the long-range connections-- that means like\na connection between this part and that part of the brain-- are also present at birth, OK? Nonetheless, even though a lot\nof stuff is present at birth, a lot of stuff changes in the\nfirst couple of years of life. Most obviously, the\nbrain doubles in volume in the first year,\nfrom a two-week-old, to a one-year-old,\nto a two-year-old. The cortical thickness-- you\ncan see here the dark stuff, which is the gray\nmatter out there-- increases sharply between\nyears one and two. But also, the complexity\nof each individual neuron increases dramatically in\nthe first few years of life. So here's a schematic picture\nof a piece of gray matter here. We have some number\nof neurons here with a few little processes\nand a few connections. And over the first\ncouple of years of life, those connections\nget much more dense, and the neurons get\nmuch more complex. OK, and the final\nthing that really matters early on in development\nis that myelination happens rapidly in the first few years. And remember, myelin--\nthis is a little reminder-- neuron with that yellow stuff,\nwhich is a bunch of cells that wrap around the axons,\nthe long processes of a neuron. And that myelin\nsheath builds up a lot over the first couple of years. And that's important, because\nthe myelin sheath enables those neurons to send\ntheir signals faster down their axons, OK? OK, and this is just a\npicture of different-- of a vertical slice like\nthis through the anatomy of infants of different ages,\nfrom 107 days up to about a year. And the colored\nstuff in the middle is degree of\nmyelination, which you can see with various\nkinds of anatomical scans. You can see it starts at 107\ndays with a tiny little bit in the middle, and it gets\nmore and more myelinated and moves from\ncenter to periphery over the first year of life. So all those fiber\npathways are getting accelerated as they get wrapped\nwith myelin and hence sped up. OK, all right, so bottom\nline is most neurons and long-range connections\nare in place at birth, but development continues\nrapidly in the first two years, especially increasing complexity\nof neurons and synapses and myelination of long-range\nconnections and white matter, OK? So it's just basic anatomy,\nnothing functional yet. OK, now we're going to\nconsider in some detail the case of face perception,\nnot really because that's what I work on-- or used to work on, mostly-- but just because\nthere's a very rich set of data where people have\ngrappled with this question in the case of face perception. Next time, we'll talk about\nthe navigation network and reorientation-- what parts\nof that system might be innate and learned. So I'll just say right\nout of the beginning that this is an extremely\nactive area, where every time I turn around, another paper\ncomes out that contradicts a previously-published finding."}, {"content": "And so that makes\nit fun, but it means there isn't going to be some\nreally tight, perfect story here."}, {"content": "And I'd rather take you guys\nstraight to the cutting edge, even though it's kind of a mess,\nthan give you a nicely packaged but surely wrong picture, OK?"}, {"content": "Because again, I think what\nmatters most in this area is how do you go about\nanswering these questions, rather than what is the\ncurrent state of the thoughts about the answers. OK, so how are we going\nto think about, how does face perception develop? Well just to get\nstarted, I'm going to show you a very brief\nmovie of a 72-hour-old monkey, and see what you think. He's sleepy. He's pretty interested\nin that face. And watch now. Hmm. [LAUGHS] Pretty cute, huh? So what do you think? What does this tell us\nabout face perception? Yeah? AUDIENCE: Did they try\njust moving anything in front of him? NANCY KANWISHER: Good question. Good for you. Quily, is that right? AUDIENCE: \"Quile-y\" NANCY KANWISHER:\n\"Quile-y\", all right. Yes, so Quiley asked, did\nthey try moving just anything in front of him? Absolutely the right question. So that monkey seems pretty\ninterested in that face, but a face is a moving thing. Motion is very salient to young\nprimates-- humans, and monkeys, and many others, absolutely. What else did you see in here? Yeah. AUDIENCE: It started\nimitating [INAUDIBLE].. NANCY KANWISHER: Yeah, kind of. I mean, the person-- the adult human there--\nwas moving their mouth open like this, and the monkey\nwas doing something with their mouth. So what would that require?"}, {"content": "Sorry? AUDIENCE: I like,\nI have another. Also, was the monkey allowed\nto touch its face before this? NANCY KANWISHER:\nYeah, good question."}, {"content": "Good question. 72 hours is damned early,\nbut it's not zero experience, right? So who knows what they've\nmanaged to pick up that early. There are actually\nstudies in humans, which I'm hoping Heather\nknows better than me. Those Andy Melzoff things. How young are those humans? Those are like first hour. AUDIENCE: Yeah, [INAUDIBLE]. NANCY KANWISHER:\nI think it's a-- AUDIENCE: [INAUDIBLE] NANCY KANWISHER: So\nthere are studies in humans where you can\nshow versions of that, with newborn infants copying-- the experimenter comes up\nand sticks their tongue out at the infant, and the infant\ndoes that back, kinda sorta. Certainly within the first two\ndays, maybe even earlier, OK?"}, {"content": "OK, so it's very suggestive. It's tantalizing, but we\nneed controlled conditions. It doesn't tell us\neverything we need to know. OK, so if we think\nabout it, there are ends of the hypothesis space\nabout how all of this could go. As Alana mentioned, everything\nis both genes and experience. That's true, but there\nare very, very importantly different ways in which\ngenes and experience can act together-- some in which\na big part of the heft of what the adult form has\nmight be built in, and other stories where\nmost of the structure comes from experience. So just because everything\nis both doesn't mean we shouldn't flesh out\nexactly what comes from what. So on one end of\nthe spectrum, you might imagine that there's\nsome very, very rudimentary precursor that has to be built\nin, plus a learning mechanism, OK? Or a bunch of\nrudimentary precursors, which are just there\nto get the system to learn in the right way, OK? And so we'll talk\nshortly about the idea that there might be some kind\nof innate template for faces that gets monkeys and\nhumans to look at faces. And then, the idea is once you\nget them to look at a face, then experience can take over\nfrom there and do the rest. But you've got to get them\nto collect the right input. And there's lots of interesting\ncomputational work going on now where people are using various\ncomputational models to say, what do we have to\nbuild into, say, a convolutional neural\nnetwork or some other kind of computational model to get\nit to do some complicated thing? I just came from a job talk\nthe last hour-- really amazing talk-- where the guy is\nshowing that if you build in, basically, curiosity\nearly on in a network, you get much more general\nlearners than if you build in a bunch of goals for\na developing network to seek. anyway it's a very active\narea, and the paper that I just decided\nto assign to you guys, just kind of skim\nit and get the gist."}, {"content": "The basic idea-- this\nis from Shimon Ullman, who is a very deep\nthinker in this field. And he argues that hands are\nvery important in infants. Faces are important, but so are\nhands, because hands do stuff. And we're social\nprimates, and we want to learn from other social\nprimates like our parents. And watching their hands\nis extremely informative. Whatever they're\ndoing with their hands is probably stuff we\nneed to learn about. And further, we need to know\nwhere they're looking, right? So gaze perception. I think I did this demo before. If I'm talking to you guys,\nand I start doing that, it's really hard, even though\nyou know I'm just faking you out, not to have your\nattention pulled over there, and infants need to\nlearn that as well. So Shimon Ullman's\nbasic idea is that you can start with an extremely\nrudimentary system, and all you have to build\nin is this idea that he calls \"mover,\" right? So the idea is that if you look\nin a whole set of, say, YouTube videos, and you just look\nfor patches of the image that are moving, that's no good. It won't be a hand. It might be a whole animal,\nor a face, or something else. But if you look\nin YouTube videos, a proxy for natural experience--\nit's OK; it's not perfect, but it's something- you look\nfor a patch of the image that moves over and then causes\nanother previously-stationary image patch to move. That's what happens when\nwe pick stuff up, OK? And so his idea is you can\nbuild in this extremely simple thing-- Mover, which is a very\nsimple visual algorithm, can find image patches and move\nover and cause another image patch-- or then the two image\npatches move together. And Mover will enable you\nto identify hands in images pretty well. He looks in YouTube\nvideos and shows that it's really good\nat picking out hands. And then, further, once\nyou've picked out hands, that's a really\nimportant teaching signal in teaching you to read gaze. Because often, people\nlook at their hands before they do things\nwith them, yeah? So the idea is there's a\nvery active ferment now in computational\nmodeling saying, how can we start with just the\nmost rudimentary, minimalist stuff that has to be built in,\nand then build on experience to get the rest from there? Is that idea clear? It's worth reading\nthat paper, though. It's beautifully written. He's brilliant. OK, so that's one\nend of the spectrum. Nobody thinks that you\nlearn absolutely everything from experience. You've got to\nbuild in something. Plus, we know all those\nneurons are there at birth. And so the idea\nis some version-- the minimalist\nnativist view says you build in a few very\nrudimentary things, and they're enough to\nbootstrap learning. OK, on the other end of the\nspectrum, you might think-- and many have\nproposed-- that we're born with a nearly\nadult-like system that only needs fine-tuning\nfrom experience, right? Nobody thinks that zero\nexperience is necessary. That would be kind of\ncrazy, or implausible. But on the other extreme, this\nview is that most of the stuff is built-in. OK, everybody get the\ntheoretical space here that we're considering? OK, so what kind of data can\nconstrain these questions? Well, one obvious question\nis, what is present at birth? What is the initial state-- or as close as we can get to it? Then we can ask, how does\nthe system change over time from birth onward? And then we can ask, what are\nthe causal roles of experience and biological maturation\nin that change after birth? So that's the whole\nset of questions we'd need to answer to\nunderstand how development works. And a very central-- if\nnot the central-- challenge of development is that\nexperience and maturation are deeply confounded as you look\nfrom birth onward, right? So five-year-olds are\nboth more mature-- they've had more time for\ntheir biological systems to wire themselves up, including\ntheir bodies, and their brains, and the whole bit-- and maybe some of that\nis just on a maturation kind of autopilot. But they've also had\na lot more experience. So one of the central\nchallenges of development is trying to figure out\nhow those later stages-- like two months old, one\nyear old, 10 years old-- how those changes that happen\nbetween birth and those stages can-- how can we tease apart which of\nthat came from just maturation and which came from experience? All right, OK. Importantly, things that\nhappen well after birth need not be learned, right? So think about puberty. Puberty is going to\nhappen around 10, 11, 12. And OK, you've got\nto eat and have some basic inputs\nto your system, but it's pretty much\ngoing to happen. It's not a product of\nwhat you were taught or the particular\ninformation that landed on your sensory receptors. I'm sure there's some\nobscure influences that I don't know about,\nbut mostly, it's on a developmental autopilot. It's just going to happen. OK, so keep in mind--\nthis is really important-- that things that\nhappen well after birth aren't necessarily learned. It might be just maturation\nthat's continuing, right? OK, just as being 5 feet tall\nversus a foot and 1/2 tall isn't really learned. It's just a maturation\nprogram that unfolds. OK, so we can ask these three\nquestions both behaviorally and naturally. And ultimately, we want\nthem to tell the same story. When I said there's some\nchaos in this field right now, I mean that basically, they're\nnot converging very well yet, but that's fun-- sort of."}, {"content": "[LAUGHS] Sometimes\nit's aggravating, but mostly, it's fun. OK, so let's start with\nsome behavioral data. So let's consider\nthe initial state of face perception in newborns. OK, so we can ask, what kind\nof perceptual, face perceptual abilities are\npresent in newborns? And we can ask whether they\ncan detect a face-- that is, discriminate a\nface from a non-face, whether it's a body, or an\nobject, or something else. We can ask about preferred\nattention to faces. Do they, do newborns\nwant to look at faces more than non-faces? We can ask about the\nability to recognize faces, to discriminate one\nface from another, OK? And we can ask about the\nability to recognize faces across image changes. So we spent a lot of time\nin the first few lectures talking about the central\nproblem of invariance in vision-- about, how do you know\nthat this image that you're looking at here is the\nsame person as that image, even though those are\nvery different images? And actually, this image\non your retina right now is more different than\nthis image on your retina than if we got one of you and\ncame up-- had you come up here and had you look forward. So the image changes that result\nfrom a change in orientation are greater than the\nimage changes that result from a change in identity. So it's a big\ncomputational challenge. When is that solved? And then, there are these\nso-called signatures of face perception\nthat we've talked about a little bit-- for\nexample, the inversion effect. Recall the inversion effect\nis larger in magnitude for faces than non-faces. So we can ask when\nthose things develop. OK, so let's start\nwith face detection and preferred\nattention to faces. Well, so classic\nstudies from the early '90s, and actually, some of\nthem going back to the '70s, did the following\nvery low-tech thing-- a low-tech drawing of\na low-tech experiment. You take a newborn infant. In this case, they're less\nthan an hour old, right? You've got to set up\nin maternity wards. You want the data,\nthat's what you do. Of course, you have to ask\nthe parents and all of that. But then, you take this\ninfant and you sit them on a person's lap with\na video camera overhead, and you move different objects\nover the infant's head, OK? And the different objects\nthat were moved, in this case, were patterns that were\ndrawn on this paddle that's moved over the infant's head. And the pattern could be a\nschematic face like that, a scrambled schematic\nface like that, and a blank with nothing in it. And what you measure is,\nhow far does the infant turn their head or their eyes\nfollowing that paddle as you move it over them. OK, nice low-tech measure. And what you find is they turn\ntheir heads and their eyes farther when it's an actual\nschematic face than when it's a scrambled schematic face or a\nblank, within an hour of birth. Then you can still say,\nwell, their parents probably smiled at them quickly before\nthey were snatched away to do the experiment, so they\nhad some face experience, but boy, not a whole lot. And this is a very\nabstract face here. So this has long been taken as\none of the key bits of evidence that something seems likely\nto be innate about faces, OK? But now, what needs\nto be innate for that? And it's a bizarre thing, where\nthis happens in the first two months of life and goes away. And there's a lot\nof consideration of what that means. Maybe the first two months\nis enough to bootstrap learning in the way\nI was just talking about-- bootstrapping, getting\nattention to the right places. But there's also a huge\nliterature on this phenomenon where there's a big\ndebate about exactly how simple those cues need to be. So people have done\nmany variations of this and one dominant story\nis that all you need is a pattern that has more stuff\non the top than on the bottom, OK? And that's enough\nthat infants will follow this more than that. And the idea is that in\nthe visual environment of an infant, that's\nsufficient to pick out faces. So there's been pushback\nagainst this view as well."}, {"content": "It's probably a little\nmore complicated than that."}, {"content": "We won't go down the rabbit\nhole of all those details, but whatever it is,\nit's pretty simple. So this is another example of\nwhat I was mentioning before with the Ullman case. This is a case where it\nmay be possible to build in something pretty basic-- a pretty basic\ntemplate-- and then let learning take it from there. Make sense? If the infants are\nlooking at faces, then they can use some kind of\nsynaptic plasticity, whatever, and learn from their\nexperience to discriminate one face from another. OK, so these things are\npresent within a day or two. What about discrimination\nof individual identity? First problem, how\nare we going to be able to tell what\na newborn can see? And so I didn't\nwant you guys to be to thrown by this method\nin the last assignment, so I told you where there's a\nversion of the explanation I'm just going to give. So if you already watched\nthat, my apologies."}, {"content": "You can read your\nemail for a minute. So the classic experiment-- a classic experiment--\nthat enabled us to really ask how a newborn,\nnon-verbal infant, what they see in the world, is\ndone by Kellman and Spelke. Liz Spelke up at Harvard\nwas at the forefront of getting this method\nto really tell us a huge great deal about what\ninfants see and understand about the world. And this method that\nI'm about to show to you has been the basis of what's\nsometimes called \"The Infancy Revolution,\" which is basically\nthe insight that, actually, infants know a lot. Their perceptual systems\nare really sophisticated. They know about physics. They know all kinds\nof social stuff. Within a few months of\nlife, they know a lot. And that's been a radical\nchange in our understanding of development based on\njust behavioral work. So here's the method. OK, so what Spelke did-- I always forget\nto bring the demo. Hang on one moment."}, {"content": "We don't need much. OK, so she showed infants\nstuff like this, OK? The two hands are not there. You just arranged\nto see this, OK? So even if you hadn't\nseen me, imagine if you hadn't seen me pick\nup the phone and the pen, and you didn't already\nknow what they were, and you're seeing this, OK? That's what they see, OK? So now, the question is,\nwhen infants see that, do they think that that's this-- thing behind a rectangle-- or do they think it's\ntwo separate bits moving behind the rectangle? It could be two separate\nbits moving together, right? Everybody get the question? OK, so how would we know\nwhat the infants thought was back there? OK, well, we use what's known\nas habituation of looking time. Again, you sit the\ninfant on a parent's lap, and you show them\nstuff, and you just measure how long they look. It's magnificently low-tech\nbut really profound. OK, so what we're\ngoing to show here is how long the infant looks\non each trial as a function of how many times you do it. So you show the infant\nthis the first time, and they look for 40 seconds. That's a long time. You show them again, they look\nfor 35 seconds, and so forth. And by the fifth or sixth\ntime, the infant is bored. Like been there, done\nthat, bored, right?"}, {"content": "OK, now they're bored. Now we have a moment to say,\nOK, what did you think it was? And so now, what you can\nask is, what do they think-- you then show them\neither this or this, and you ask them which of\nthose they're bored to, right? So the idea is if,\nwhen looking at this, they thought there\nwas a continuous line behind the occluder, then they\nshould be more bored by this. But if they thought that was\ntwo separate pieces, then they should be\nmore bored by that. Does that makes sense? Because it's the same thing\nthey're already bored with. I mean, it's not\nexactly the same. The occluder isn't there, right? But it's more similar. OK, so here's the data. Here's what they find. So what does that mean? What do the infants see\nwhen you show them this? It's right there in the data."}, {"content": "Look at the first\ntest trial here. This is the first\ntest trial, when you show the complete\nline or the broken line. What do they see here? Yeah, they saw the complete one. That's why, when you present\nthe complete one again, they're still bored-- already saw that. Make sense?"}, {"content": "So isn't that awesome? It's so low-tech and\nso simple, but this is how you can ask an\ninfant, what do you see? Yeah? AUDIENCE: Why does it switch\npositions in the second trial? NANCY KANWISHER: You know,\nfrankly, I never understand why infant and\ndevelopment people do a second and third trial. Seems to me by this\npoint, the jig is up. I think it's just because it's\nhard to get enough infants, and you need more\ndata, and so they do a second and third trial. But to me, that's\nthe diagnostic one. And that's probably not\na significant switch, but whatever's going on\nout there is obviously much less important than this. Heather, do you have a\nbetter answer than that? Why do they do\nthose other trials? They always do, and it\njust seems like, what? [LAUGHS] AUDIENCE: I don't know. NANCY KANWISHER:\nYeah, I don't either. AUDIENCE: [INAUDIBLE]? NANCY KANWISHER: Oh, you\ndo it every which way, but you do it pretty fast. They get bored, and you don't\nwant to wait half an hour and come back, right? I mean, you could do that. Then that would be a\nmemory question, right? Yeah, Jimmy. AUDIENCE: Just curious,\nis this conserved between [INAUDIBLE] do they\nall see complete lines, where [INAUDIBLE]? NANCY KANWISHER:\nIt's pretty robust. Well, OK, so first\nof all, these methods are awesome, that you can\nlearn these deep things about perception in infants. But these data\nare noisy as hell. There's no error\nbars on this plot, but I bet if there were, you'd\nhave to run a lot of infants to get to the point where\nyou reach significance. Because a lot of times, the\ninfants will just throw up, or they'll just do what-- they\ndo all kinds of random things. So the data are extremely\nnoisy, and it's very hard to get enough data\nwith an infant to say anything about the\ndifference between one infant and another. By the way, there's a very\nexciting development going on in this department\nright now, where Kim Scott, who's a former grad\nstudent of this department, has figured out how to do\nlooking time experiments like this online, OK? And that's hugely important,\nbecause the number one bottleneck in this kind\nof developmental research has been finding enough\ninfants, or getting enough data per infant. And so I think that she's going\nto just crack it wide open. Talia? AUDIENCE: I guess I'm\na little bit confused how we know what the infant\nreally saw based on how long it looked at something. Could it be that maybe\nthey look at like-- maybe they look at the\nbroken sticks longer, because it's like what\nthey thought was behind it, so they're now excited that\nthey get to see what's-- NANCY KANWISHER: Maybe, but\nthen, why would you get this? So we know from this that\nthe more familiar it looks, the less time they look. So you would have to\ncome up with-- yeah, there's wiggle\nroom in these data, but you'd have to come--\nyour account would have to say, why would they\nlook less, and less, and less long when we repeat\nthe exact same thing, right? And you could tell a\nstory like, OK, it's a little bit different, because\nthe occluder isn't there. But it's a little bit\nthe same, and that's kind of edgy and fun. Or you could tell\nanother story, but I think the bulk of the\ndevelopmental literature shows that when you\ndo this kind of stuff, it's a change that\nmakes infants look more. I'm going to go on unless there\nare questions of clarification, just because there's so\nmuch other cool stuff. OK, so how can we use this\nto study face recognition? That was just a\nsidebar on the method. OK, so there's a\nlab in Italy where they have an infant psychology\nlab next to a maternity ward, and they've been doing\nall these awesome studies. OK, and they test\n1-3-day-old infants. And so one of the\nthings they did is show infants, just like the\nparadigm I just showed you. They show the infant the\nsame face again, and again, and again. That's the habituation phase. And then, this is a\nslightly different one. You give them a choice\nof whether they-- actually, you don't\ngive them a choice. I take it back. Yeah, you show this\ncondition or that condition, and you see how long\nthey look at each across different infants. And so this is the same person\nfrom a different viewpoint. Actually, pretty subtle, as\nwe discussed with the Jenkins study way back. And that's a different\nperson from that viewpoint. And what they found is\nthat-- it's hard to see, but a very low P level\nmeans that there's a significant\ndifference in how much the infants looked at those two. So that's pretty amazing. 1-3-day-old infants can\napparently recognize the identity of a face, a novel\nindividual they don't already know, with similar-looking\nfaces, without hair, and across view changes. Wow, right?"}, {"content": "So that's pretty impressive. OK, and so then, they've done\nall kinds of other variants. If you have them rotate all\nthe way from front profile, there's no longer a\nsignificant difference. Infants can't do that. And then they do all\nkinds of other variants. If you show them the\nsame individual and then habituate to that, they\ncan tell the difference between viewpoint. That's the same, and\nthat's different, even though it's\nthe same identity. So you can use this\nto test what they think is same or different,\nwhich is a deep question to ask. If you're interested in\nrepresentations and cognition, the question of what an\ninfant, or an animal, or a bunch of neurons thinks\nis the same or different is the essence of characterizing\nwhat it represents. Yeah, Quiley? AUDIENCE: [INAUDIBLE] the\nrotated face [INAUDIBLE]?? NANCY KANWISHER: Down here? Yeah."}, {"content": "Yeah, they do. So here, basically,\nit's either identical, or it's different\nin some respect. So given a choice, when\nit's rotated anyway, the familiar one\nis more similar. But down here, this one is\nmore similar in viewpoint. Yeah? AUDIENCE: And these are\nnot like the [INAUDIBLE] in such [INAUDIBLE] the\nstudent, the [INAUDIBLE] NANCY KANWISHER:\nSorry, say it again? They're not like-- AUDIENCE: The children have\nseen faces before this. NANCY KANWISHER: Well,\nas little as possible. As I say, I mean, they've\nseen some, but not very many, and they haven't\nseen these faces. So when you're trying to get\nthose innateness questions, you go as close to\nbirth as you can, but you can't usually\ngo into the very moment of birth itself, right? And so there's usually\nsome experience, and it's a challenge,\nbut this is pretty early. Yeah? AUDIENCE: So couldn't that just\nmeant that the face perception network is just like-- it develops really quickly,\nright after [INAUDIBLE].. NANCY KANWISHER:\nIt could, it could."}, {"content": "Based on these data\nalone, it could. That's considered\nkind of unlikely, but I agree that that's\nconsistent with these data. In the first two days\nof life, the whole thing wires itself up. That's be pretty unusual. It's not really consistent\nwith those samples of neurons that people have looked\nat elsewhere in the brain, but maybe there's a special\nlittle circuit that just wires itself up really fast. So not likely, but possible, OK? All right, now, you might\nsay, well, maybe there's some kind of simple\nvisual features that are short of an actual\nface representation here. This doesn't show us that\nthis is something about faces per se, even though it can\ngeneralize across viewpoints. So it's not just pixel\nintensity, right? So what is the\nclassic way we asked this question in face\nperception, where we ask, is this really something\nabout faces, or is it something about the low-level\nperceptual properties of the face? AUDIENCE: Turn it upside down? NANCY KANWISHER: Yeah,\nturn it upside down. God's gift to the face\nresearcher, right? So-- oh, I guess that\nwas not on this slide. OK, right? OK, so now, in the\nnext experiment, they present whole faces, or\njust the internal features without hair, or just the\nexternal features without hair. So the infants can\ndo that at the top. They know those\ntwo are different. They can do this here, and\nthey can do that there. OK, not too shocking yet. Just tells you any of those\ncues can support performance. But now, we can ask, is\nthat just pattern-matching? No, it's not. Because when you turn\nthem upside down, you find that only-- let's see, it's only\nperformance in this case that suffers when you turn\nthem upside-down, not this case or that case. OK, so that shows that there\nare a variety of cues here that infants could be using, but when\nyou show them just the internal features-- the\nactual face proper-- that part, the ability to\ndo this discrimination, goes away when you\nturn it upside down. So that part, at least,\nseems to be at least somewhat face-specific, or\nhas the signature of face-specific processing. Make sense? OK, I mean, as a\npattern, it'd be just as easy to recognize\nthis upside-down and distinguish it\nfrom that upside-down, if it was just the pixels\nyou were registering. But if you were doing\nface processing that's something like adult\nface processing, you'd expect that\ninversion effect. OK, all right, so where are we? And I should just say, even\nthis is actively debated. In fact, the author\nof this study considers this\nnot to be evidence that that processing\nis face-specific. I think she's got some of\nthe strongest evidence ever, but she's got some\ncounterargument about how in the inverted\nfaces, they don't look as long in the situation phase. And so it's like I'm telling\nyou these cool methods, but boy, every one of\nthem can be fought over. OK, so where are? We've just shown\nthat discrimination of individual identity is\npresent in very young newborns, recognition across viewpoints,\nand inversion effects are all present within the\nfirst few days of life. OK, so newborns have very\nimpressive face perception abilities, and that's\nparticularly surprising given that their acuity\nis terrible, right? the vision is really\nblurry for young infants, so it's amazing that\nthey can do these things. But now, there's room for\nquibbling about whether this is really a face-specific system. So the inversion\neffect is suggestive, but they haven't totally\nnailed the case about what's being tapped into here. Is it really face\nperception per se-- something specific\nto face perception-- or is it some more generic\nkind of object perception? OK, and further, we want to\nknow what happens after that."}, {"content": "OK, so you don't need\nto memorize this table."}, {"content": "I'm just going to make a\nfew simple points with it. There are lots and\nlots of studies where people have tested\nbehaviorally all kinds of different aspects\nof face perception, and the basic story\nis that by age four, you see the little\nsmiley face means that this adult-like property\nof the face perception system is present by age four. So all of those signatures\nof face perception that are present in adults\nare present by age four, OK? And in fact, much of the\naction is much before that. You can see that\nall of these things are present at the earliest\nage they've ever been tested. The little square means\nnobody's tested it at that age. So all this stuff is\ndeveloping very fast, right? OK, one particularly\nimportant thing here that you read\nabout a little bit, but that I want to take a moment\nto make sure you understand because it's so\ninteresting and cool, is the phenomenon of\nperceptual narrowing, OK? And this happens\nin face perception, and it happens in phoneme\nperception in speech. And I'm going to do a demo here. So I'm going to show you\na monkey face briefly. OK, it's going to\ncome on in a second, and you just look at It. Here we go."}, {"content": "Boom, there it is, OK? OK, in a moment, I'm going to\nshow you another monkey face, and you're going\nto shout out same if you think it's the\nsame, and different if you think it's different,\nand, huh, if you don't know. How many people don't know? Yeah, it's different, right? OK, well, OK, maybe\nthat was too hard. Let's try it with a human, OK? Remember how hard that was? Now let's try it\nwith a human face. I'm going to show\nyou a human face. Everybody ready? Here we go."}, {"content": "OK? OK, and I'm going to\nshow you another human, and you're going to say,\nis it same or different? Here we go."}, {"content": "Duh! Easy, right? OK, so here's the amazing thing. You were better at\nthat monkey face task when you were six months old. You could do that\nmonkey face task when you were six months old. One of the things that you\nhave learned from experience is that you don't\nneed that information, and you threw away your\nability to do that, but you had it when you\nwere six months old. Isn't that awesome\nand interesting? That's called\nperceptual narrowing. So the experiments, in\nparticular, do the following. You use that preferential\nlooking paradigm-- the preferential looking to\nthe novel face in infants-- as your measure of\ndiscrimination ability. What can they discriminate? And so you show\ntwo human faces-- two different\nindividuals, like this. And so now, what you see is\nthat at six months, nine months, and adulthood,\npeople preferentially look to the novel face more\nthan the familiar face, OK? That's just what\nwe've just done. People like to look at the new\nthing, not the old thing, OK? However, if we do six months,\nnine months-- oh, yeah, that's what we just said. OK, they can do that. So now, if you try\nthis on monkey faces, you find that\nadults are like us. We're barely able to tell\nthe familiar from the novel. We're not so good at\nmonkey face discrimination. Nine-months-old are the same. But at six months,\ninfants can discriminate the monkey faces, and you could,\ntoo, if somebody had asked you. So there's a very similar\nphenomena with phonemes. Those of you who are not\nnative speakers of English maybe aware of some\nphonemes in English, if you learned it relatively\nlate, that are hard for you to discriminate. There are sounds in Hindi-- I forget, it's like\na \"da\" and a \"ta,\" that sound identical to me, but\nthat are just like completely obviously different to\nnative Hindi speakers. And all languages have this. So of the kinds of phonemes\nthat are discriminated in any language\nin the world, you could discriminate all of those\nwhen you were six months old. And one of the\nthings you do when you learn a language\nis just throw together in the same bag things\nthat are actually different that other\npeople can discriminate if your language doesn't\ndiscriminate it, OK? And so you get\nthat with phonemes, and you get it with faces. OK, everybody get what\nperceptual narrowing is? OK. OK, you also get this-- I mentioned this way back-- with perceiving faces\nof other races, right? Not just faces of other\nspecies, but if you grow up in an environment\nwhere you're only exposed to races A, B,\nand C, and you later have to discriminate\nfaces of races D, E, and F, you're not\nso good at it, right? All the same deal."}, {"content": "OK, all right. So how would we know whether\nthis change between six months and older is just\nmaturation-- it's just some kind of\ndevelopmental program that's going on autopilot\nindependent of what you see, or whether it's learned\nfrom experience? Josh? AUDIENCE: You control\nfor experience. NANCY KANWISHER: You control\nfor experience, absolutely, like the Sugita paper. OK, so we'll get to\nthat in a second. So we started with these\nkey questions-- what is the initial state\nat birth, and we showed impressive perceptual\nabilities within a few days, although people dispute\nwhether those abilities are a face-specific system. And we don't know much about\nwhat that system is, other than it works surprisingly\nwell given the low acuity. And we showed that how\nit changes after that, there's perceptual narrowing\nbetween six and 12 months, but a great deal is not known\nabout what happens then. And so now, we're\nonto this question of how are we going\nto un-confound what changes after\nbirth, whether it's maturation or experience. And I'm not going\nto have time to get to these other awesome methods. We're going to focus on\ncontrolled rearing, of what you read the Sugita paper. OK, so just to remind you\nof the basics, most of you seemed to get the\npaper just fine. The big idea was again, using\nthis preferential looking method, what Sugita et al. Showed is that when they\nreared monkeys for six, 12, or 24 months without ever\nletting them see a face, and then tested them on\nthe very first session that they ever saw faces\nwith preferential looking, they found that on the very\nfirst exposure to faces, the monkeys looked more at\nfaces compared to novel objects, right? They showed that face\npreference, sort of akin to infants looking\nat the paddle, and they discriminated\nbetween faces-- very similar faces--\nwith adult-like accuracy. And this part, I don't know\nif you found it surprising, but when this paper came\nout I, was like, whoa, that is crazy, right? Because as I said, the whole\nspace of sensible hypotheses is, OK, maybe a lot\nof stuff is innate, but you're still going to\nneed experience to tone it up, for God's sake, right? Who would think the entire\nadult ability could exist without any experience at all? So I don't know if\nyou had that reaction, but I think that's\na sensible reaction. It's a pretty astonishing\nfinding in that paper. Unfortunately, there's\none author on that paper. It was done once, and it's\nsuch a labor-intensive study that probably nobody will\never try to replicate it. So in the back of many\npeople's minds is like, really? Can that really be true, or\nis there something funny here?"}, {"content": "So I hope somebody\nreplicates it someday, but it hasn't been done yet. OK, the other thing that\nyou guys presumably noticed is there was perceptual\nnarrowing in that study. There were many interesting\nthings in there. It's actually\nquite a rich paper. But after the initial\ntesting session, no matter how long\nthe deprivation, the monkeys were then housed in\neither an environment with just humans or just monkeys. And so whether that\nwas 6, 12, or 24 months after birth of face\ndeprivation, they then lost their ability,\nat that point, to discriminate the\nunexperienced faces, OK? So they went through\nperceptual narrowing. Does that all make\nsense to you guys? You got that? Good."}, {"content": "OK, all right. So anyway, that suggests\nthat an awful lot of the face perception system is present\nwithout any exposure to faces, and that's pretty astonishing. What experience\nseems to do there is not create abilities,\nbut eliminate them right for the species\nthat you don't see. OK, so first\nreaction is, really? Second reaction,\nis there any way to account for this in terms of\nsome non-face-specific system? I think you can, but\nit takes some work, and the counter-explanations are\nreally difficult. You can say, well, maybe this is all\nbeing carried by some more generic object system. They didn't test inverted\nfaces, unfortunately, but if it was carried by\na generic object system, why would you find the\nperceptual narrowing? Why would they have\nlost their ability for the unexperienced species? So I think that story\nis hard to tell. And, of course,\nthe other question I'm sure you guys\nare wondering is, what is going on in\nthose monkeys' brains? Yeah, OK, so let's get to that. Let's talk about what we\nknow about development of this system by\nlooking at brains. And first of all,\nthere's been lots of work on this in older kids, age 5 and\nup, going back over a decade. And it's now clear that\nall of that basic machinery I showed you is present by age\nfive, in most kids age five. It's continuing to\nchange after that, but you can detect most of\nthat stuff by age five, or six, or seven-- something like that. OK, trouble is, that's\ncool, but age five is late with respect to\nexperience and with respect to all those behavioral\nabilities that I showed you. So we need to go earlier. And so a couple of years\nago, Rebecca Sachs-- who's straight up\nthere, two floors up-- started scanning infants, OK? And this is-- as Heather can\ntell you-- almost impossible. It is right on the edge. It took Rebecca and her lab\nmany, many years of work over five years just to\nget the system going. There were all kinds\nof technical advances, like making scanning coils\nthat were optimized for infants and comfortable for infants. Rebecca herself went\nto great lengths, including producing some\nof her own subjects. That's her son Arthur\nthere and her two-- her grad student and postdoc\nwho were working with her. But all of this massive\neffort was worth it, because what they found\nwas, first, for comparison, this is adults with a contrast\nof faces versus scenes, OK? So this is basically the PPA in\nblue responding more to scenes, and the FFA in here and some\nother face-selective bits responding more to\nfaces in adults. What do you see in\nsix-month-old infants? It's astonishingly\nsimilar, right? You can really see a\nvery similar layout of the functional\norganization of the brain already by six months. So that's a huge advance. That pushes way back\nthe timeline by which these things had developed. Previously, everybody\nis talking about, oh, what changes after age five? Age five, come on? OK, it's mostly\nthere by age six. OK, now, importantly, these\nsystems are not adult-like. Their selectivities\nare very different. Those regions are less\nselective in infants than they are in adults. But the spatial layout is\nthere already by six months, and that, importantly,\nconstrains-- whatever our model\nis of development that pushes it way back. OK, so now, the\nnext questions are, what is it about that region-- or those particular\nregions-- that makes them become face-specific\nalready by six months? How does the face\nsystem know to take up residence in that systematic\nlocation in the brain, and what is the\nrole of experience in their construction? And how could we\never answer this?"}, {"content": "One way to answer that is\nto use an animal model, OK? So there's been-- yes. AUDIENCE: OK, yeah,\nsimilar question about-- NANCY KANWISHER: I'm\nsorry, I didn't hear."}, {"content": "About what? AUDIENCE: General\nphysical layout-- like why does your stomach\nalways come in the same place, and would it maybe be\nthe same mechanism that guides development of any organs\nand the layout of the body, [INAUDIBLE]? NANCY KANWISHER: Yes. Now, I don't know much about how\nhearts, and kidneys, and livers develop, but my understanding\nis that's pretty much wired in. There's some chunks of DNA that\ntell you how to build a kidney and where to put it\nin your body, right? And so that is one of\nthe hypotheses here. It's a tempting\nhypothesis, right? There's all that structure. It's a very tempting\nhypothesis, but that doesn't mean it's necessarily right. Yeah, it absolutely is. It's a hypothesis we should\nconsider and take seriously, yeah. OK, so but we want data. We want to find out. OK, so animal models. So starting a few years\nago, Marge Livingstone over at Harvard Med\nSchool over there-- a couple of miles over there-- started doing these\nalso really amazingly heroic studies where she\nwas scanning infant monkeys. OK, now, this is\nreally hard to read, so let me tell you\nwhat we got here. We have the cortex. This is all the same animal\nat different time points, and each of these\nthings is the cortex unfolded mathematically\nand flattened so you can see the whole thing. I don't expect you\nto know what's where. I can barely tell myself. But if you look at it, what\nyou see is at 81 days of age, there's just blue stuff. There's no orange stuff. The orange stuff is the\nface-selective response. In fact, if you\nlook down, you start to see, oh, that looks--\nyeah, yeah, OK, that looks pretty systematic. It starts replicating\nafter that. And so the claim is you\ndon't see face selectivity until about 170 days\nafter birth in monkeys. OK, that's about here. Here's another monkey\nfor comparison. If you stare at\nit, you'll see, OK, there's these systematic\nbits-- boom, boom, boom, boom-- and maybe a little hint\nat 170, but-- there's some garbage up there, but\nnothing systematic before that. Yeah? AUDIENCE: So there's no\ncontrol of the environment? This is like monkeys-- NANCY KANWISHER:\nNormal monkeys who have exposure to human faces\nand monkey faces hanging out in the lab, yeah. We haven't gotten to\ncontrol rearing yet. It's coming. OK, first thing is just, when\ndoes it develop in monkeys? OK, all right. So are you surprised by this? It's not there here,\nand it is there there. You should be surprised."}, {"content": "Why are you surprised? This is what you guys predicted. Quiley? AUDIENCE: I guess I'm\nsurprised because they were able to discriminate. NANCY KANWISHER: Yeah,\nwhat is up with that? Absolutely! The Sugida paper really made\nit look like that system was innate, right? No experience-- boom! They're fine. It was just behavior, but it\nwas a good behavioral study. So why the hell isn't it here? Everybody with the program\non how surprising that is?"}, {"content": "OK, so a bunch of things. First of all-- and it\ngets stable after that, and replicable. Well, the first thing is\none's a behavioral measure, and one's a neural measure. Maybe those fabulous\nbehavioral measures weren't actually being driven\nby some face-specific system. Wouldn't that be sad, right? I mean, they did\nlots of controls. It was a nice idea. I thought they did as well\nas they could, but who knows? Maybe those monkeys\ncould do that task with some other system and they\ndidn't need their face system for it. That's one possibility, right? Then, you could have the face\nsystem not develop till later, but the monkeys\ncould do it before. But the other thing\nis, notice that Sugita didn't test their monkeys\nuntil, with the youngest ones, six months of age. So maybe it just got\nwired up just before-- right there-- they\nwere tested, OK? So it seemed\ncontradictory at first, but it's not completely,\nliterally contradictory, yeah? OK, all right, so now, the fact\nthat this stuff doesn't show up until here, does that mean\nthat this face system requires experience to develop? You know the answer, because\nwhenever I ask that question, the answer is always no. Why does that not imply\nthat you need experience with faces to wire up? It's tempting. You look at it,\nand it's like, OK, you had to look at\nfaces all this time before you wired it up. Boom, there it is-- very tempting. But-- is it Jessica, no? Sorry, what's your name? Yeah. AUDIENCE: Bele. NANCY KANWISHER: Bele. Oh, sorry, you told me\nthat like six times. AUDIENCE: I could be merely\ndue to mature, physical. NANCY KANWISHER: Yeah, it\ncould be just maturation. I keep making the same point,\nbecause it's important, right? Just because it shows\nup later doesn't mean it's learned, right? Maybe it's like puberty,\nor height, or something like that that's on some\ndevelopmental program that's just going to unfold\nindependent of what you see, OK? So how would we find out? We would do controlled rearing. And that's exactly what\nthese guys did, OK? So in another paper that just\ncame out a couple of years ago, they raised baby monkeys without\never letting them see a face. Much like Sugita did,\nthey use welder's masks every time they were in the\nlab, so the monkeys never got to see faces. And like Sugita,\nthey went to lengths to treat the monkeys nicely. They heard the calls\nof their com-specifics, they got lots of attention,\nthey had rich visual experience. They just didn't see faces. So it sounds kind of tragic\nand horrible at first, but it's actually not that bad. They had social contact\nand visual experience. They just never saw faces-- both this study and\nthe Sugita study. All right, OK, so they could\nhear and smell other monkeys. So the face-deprived\nmonkeys saw no faces at all until 90 days old. And at that point, they went\nstraight into the scanner, OK? And the first time they\nsaw faces was inside an MRI machine getting scanned, OK? So what do you think? Are the face-deprived monkeys\ngoing to show face patches? So there's no way\nto tell, because we have all these contradictory\nbits of evidence here, right? From Sugita, you\nmight think yes. Hard to tell."}, {"content": "So let's just look at the data. OK So here first is a normally\nnormally reared monkey 260 days old just\nfor comparison. And those face patches in yellow\nin two different monkeys here, B4 and B5, left and\nright hemisphere. OK, so those yellow bits\nare the face patches. OK, normal 260-day-old monkey. Now we're going to see\na face-deprived monkey, 260 days old. This monkey was face-deprived\nthat entire time up until scanning. No face patches. The plot thickens-- no\nface patches at all. So these guys published this\npaper in a very high-profile journal and said-- this is the title of paper-- \"Seeing faces is necessary for\nface-domain formation,\" OK? Face domain just means\nface-selective patch. OK, everybody see? You deprive them of face\nexperience, you don't see it. OK, that's pretty\ninteresting, and it strongly suggests that the face system\nis not innate but depends on face experience, doesn't it? Rare case where the\nanswer is, yes, it does. And it feels like it contradicts\nthe Sugita finding, right? But not exactly. You could still wiggle\nout of it, right? You could say, OK,\nthe thing that Sugita was studying doesn't\nuse those patches, so it's not flat\nout contradictory. Sugita was measuring\nbehavior; these guys are looking at brains. So it's kind of unsatisfying,\nbut it's, in principle, possible. Me and everyone else has\nbeen nudging these guys to run the Sugita behavioral\nexperiment on your monkeys, please! And I gather that's\ngetting going, but I haven't seen\nany of the data yet."}, {"content": "So we don't know how\nthat's going to resolve."}, {"content": "OK, so let's take stock."}, {"content": "What is the initial state? We show with behavior\nthat there is both attention to faces and-- present in newborn humans, and\nface specificity seems like it, but it's not totally nailed,\nwhereas functional MRI says there's no evidence for\nface specificity at birth-- at least in monkeys, right? That's other. Yeah, OK, so how are we\ngoing to reconcile this with all the behavioral\nresults I showed you, that there seems to be\na lot of face abilities present in newborns? Well, one possibility is\nthat face specificity exists behaviorally, but MRI fails--\noh, sorry, face specificity exists in the brain, but\nMRI fails to detect it. There's a whole rigmarole about\nwhether functional MRI works well in infants. It's barely possible,\nas I mentioned. It's also hard with\ninfant monkeys. Their blood flow\nregulation is different. They're squirming and wiggling. There are a million issues\nwith scanning babies, whether human or monkey. And so you could always\nsay, well, it was there, and just the MRI data\nare just kind of crappy, or blood flow\nregulation to the brain develops later-- an argument\nmany people have made. However, a paper was\npublished last week that argues against\nthat hypothesis. The same group just showed\nthat the somatosensory touch system is totally in place\nby 11 days in baby monkeys. So that suggests that you can\nget really nice functional MRI data at 11 days of\nage in baby monkeys, and it makes it less\nlikely that this is some kind of spurious\nfailure to detect something that was actually there. I'm not going to test you\non every little detail here."}, {"content": "I want you to think\nabout the logic of how you can ask these questions. OK, the other possibility\nis that the face abilities that we showed behaviorally are\nusing some more generic object recognition system, not using\nthis face-selective system in the brain. OK, so how does it\nchange over time? Well, we showed\nthat behaviorally-- in humans, at least--\nall the hallmarks of face-specific processing\nor present by age four, and we get this perceptual\nnarrowing between six and 12 months. But then we showed that\nwith functional MRI-- at least in monkeys-- there's no evidence for face\nspecificity before 200 days, right? AUDIENCE: [INAUDIBLE]? NANCY KANWISHER: I gather\nthey're working on it, but I haven't seen any\nof the data yet, yeah. OK, so that lack\nof face specificity is consistent with\nthe idea that all that human early face\nrecognition behavior is driven by a\ndifferent system-- because they don't have their\nface system yet, presumably. But it's also consistent\nwith this idea that it's just failing\nto be detected. Even though I said\nthat's probably not true, given you can detect other\nstuff, it might be true here. The ability to see\nthings with MRI depends where you're\nlooking at the brain. OK, so what about\nthese causal roles of structured experience\nand biological maturation? OK, so we argued that\nearly face experience isn't crucial for the\nface recognition system. That was the Sugita\npaper you read. But now, functional MRI is\nshowing that face experience is necessary for the development\nof face patches, at least in monkeys. And so a very sensible\nreaction, is what, what, what? How are we going to\nmake sense of this? This is a big conundrum."}, {"content": "It's going to get worse on\nMonday, where there's yet more contradictory data. And further, if that\nface system isn't innate, then what, if anything, is\ninnate about face perception, right? So maybe what all these data are\ntelling us is, not that much. Maybe just a biased\nlook at faces, or some very simple\nimage template that's sufficient in the\nenvironment of infants to get them to look at faces. So there's a lot of\nstudies I didn't have time to work into this lecture,\nwhere people stick cameras on the foreheads of\nnewborns, and they collect, what is the typical\nvisual experience of a newborn? And then, you can take that-- you can take that experience\nand ask, what kind of-- you can write\nmachine learning code to say, what would you have to\nbuild in to reliably pick out the faces in typical\ninfant input? And it's probably\nnot that complicated, because infants don't see that\nmany different kinds of things, right? OK. We showed early visual\ndiscrimination abilities of faces in newborn infants. But again, it's not\nclear that's part of the face-specific system. And we showed that\nthe face patches-- at least in monkeys-- seem to require experience, OK? I'm just recapping here. But now, there's\nthis big question of, how do those face patches know\nwhere to develop in the brain? Like here they are in humans,\nthese little purple blobs. The occipital face area I've\ngot two different fusiform face areas, because various\npeople think there's two. I'm not sure."}, {"content": "I don't really care;\ndoesn't matter. Anyway, how do they know\nto land right there? OK, we keep bringing up this\nquestion and dancing around it, but so far, I've given no\nbasis for thinking about this. One possibility\nis that infants-- monkey and humans-- are\nborn with some earlier kind of selectivity of\nthat patch of brain. It's not a whole face template. It's not a whole face system. Maybe it's a bias for\ncurvy things, right? And then, somehow, that\nmakes the faces land there, and the system wires itself up. It's not exactly clear\nhow that would go."}, {"content": "But that's one kind of story. Another story is\nbased on this fact I told you at the beginning\nof the lecture, which is most of the long-range\nconnectivity of the brain is present at birth. And so maybe the\nparticular connections of that patch of brain are\nalready there at birth, and maybe that\npatch of connections are sufficient to somehow\ngate the input to that system and arrange for it to end\nup being face-specific, OK? So this is a very active\narea of investigation, and there's other very active,\nongoing kinds of investigation where people are trying\nto understand how this development might work. One way people are\nlooking at this-- I mentioned this\nbriefly, but I think it's super exciting--\nis people are asking with deep nets and other\nkinds of modeling, what do you have to build into a\nsystem to get it to produce face recognition abilities? If you're trying\nto make a deep net, you're trying to make it really\ngood at face recognition, do you need to give it\na template of faces? Do you need to give it\nonly experience with faces? What do you need to\nbuild into it to get it to be really good, right? And so that's a very active\narea of investigation. And you can actually-- with some\nongoing work with Jim DiCarlo's lab, we're asking, OK, deep\nnets don't have topography. Next door units in a deep net\ndoesn't mean anything, what's next door versus far apart. Location doesn't mean\nanything in a deep net, but you can make\nit mean something. And then you can ask when,\nand whether, and how, and why you get face patches\nin a deep net and what computational role they serve. Well, totally weirdly,\nI'm finishing early, but I'm not going to finish. I'll take questions,\nand then I'll maybe add a little bit more. I think that was all\nI had here, right. Any questions about all this? If it feels a\nlittle bit chaotic-- I've sort of said\nx and not x, and x, although they're not\nexactly x and not x. They're just-- yeah, Sirdul. AUDIENCE: So the fMRI tends\nto [INAUDIBLE] activity in boxes, right? [INAUDIBLE] you said\ncontain millions of neurons. So is it possible\nthat the neurons that are specific to\nfaces are distributed at an early age throughout\nthe brain, and somehow the function for them-- NANCY KANWISHER: They\nget spatially clustered. AUDIENCE: Yeah, but\nthe neurons themselves already exist at birth? NANCY KANWISHER: Absolutely. That's a great hypothesis. It's absolutely possible."}, {"content": "Everybody get the idea? You have all those\nface neurons at birth, and maybe they're\nface-specific at birth, but they're\nspatially spread out. And then they have\nto find each other and hang out together\nnext to each other before you ever\nget an MRI signal. It's totally possible logically. It seems to be quite\nunlikely actually, because it would be very\nhard for all those neurons, with their necessary\nconnections-- which is, after all, how they\nbecome face-specific, is what their inputs are and\nwhat they're connected to-- it'd be very hard for\nthem to migrate spatially across the brain maintaining\ntheir connections. Yes, you're going to push back?"}, {"content": "Go for it. AUDIENCE: Well, I\nthink [INAUDIBLE] But since you said\n[INAUDIBLE],, they care about what their\nneighbors are doing. So maybe it's just like\na neighboring neuron's properties, but the\n[INAUDIBLE] in this chain moves it back until\nthat brief [INAUDIBLE].. But that progression is the\nmost efficient way to pop up. NANCY KANWISHER: It's totally\npossible, totally possible, absolutely. Yep, other questions? And this is wide open. Nobody knows, right? Let me just see what else\nI have time for briefly. So funny, I took\nout all these slides because I just thought I'm\nnot going to run out of time, and go over, and\ndrive everyone crazy. I moved all this stuff\nto the other lecture. Maybe I will just-- All right, hang on,\nlet me just glance at the lineup for Wednesday. Yeah? AUDIENCE: Is there--\nthe perceptual narrowing is really surprising\nand fascinating. Does anybody have a model for\nhow that processing might work or what it might be for? I mean, it feels\nlike a lot of it-- assumptions, or the\ncommon sense assumptions when we look at fMRI, and\nwhen we look at neural signals is that they all\nmean positive things. But maybe a lot of that\nsignals, a lot of activity might be inhibitory-- might be the opposite. NANCY KANWISHER: Totally, yeah. But how would that explain\nperceptual narrowing? AUDIENCE: Well, if what you're\nlearning is what to ignore, then maybe it takes a lot\nof effort to ignore things. And not really sure."}, {"content": "I'm not sure exactly, yeah."}, {"content": "NANCY KANWISHER: No,\nit's a good point. Like I mentioned\nat the beginning, one of the limitations\nof functional MRI is we don't know what the\nactual neurophysiological basis of the bold signal is. It could be anything that\nincreases your metabolic costs, and hence changes blood flow. But one of the things that\nincreases metabolic costs is inhibiting other neurons. And so way back in the\nearly days of, actually, PET imaging, before\nfunctional MRI came along, there was an early proto version\nof a face-specific paper. It didn't nail everything,\nbut it was not bad for 1981, when I think it was published. And the person who\ndid that paper, Justine Sergent argued that\nit's very, very ambiguous what it means to find\na hotspot in the brain where the activity--\nthe metabolic activity-- is higher, say, when you\nlook at faces than objects. And her point was, that could\nbe the part of the brain that really sucks at\nface recognition. That's the part\nthat's going, ah, I can't deal with this thing! What is this thing, right! That's really bad at it, and\nthe neurons are firing a lot. It's sort of facetious,\nbut sort of not. And it's probably not\nthe right account, but it is an important\nreminder that we actually don't know what actual\nkind of neural activity is driving those\nthings and whether it's excitatory or\ninhibitory, absolutely. Hang on one second. I feel like there was\nanother part of what you said that I was going to engage on. AUDIENCE: No, It feels\nlike somehow, possibly, connected to the\nperception [INAUDIBLE].. NANCY KANWISHER: Yeah. Yeah, possibly. We'd have to work it out. AUDIENCE: In one of the\nlectures [INAUDIBLE],, NANCY KANWISHER: Yeah. AUDIENCE: And then, [INAUDIBLE] NANCY KANWISHER: Yes. AUDIENCE: [INAUDIBLE] NANCY KANWISHER: Yes. AUDIENCE: Then,\nI'm a bit confused, because, like, you said before,\nalmost like all the wiring is [INAUDIBLE]. NANCY KANWISHER: OK,\nlong-range wiring. AUDIENCE: Oh. NANCY KANWISHER: OK? Which is very different\nthan all the circuits that live in each\nlittle patch of cortex. Remember, I showed\nyou this big change in the complexity of neurons\nand the number of connections. Oops, looks like\nwe've lost it now. So they're changing a lot within\neach patch of cortex, right? So those local circuits\nthat are doing computations are surely changing a lot over\nthe first couple of years. It's just the long-range\nconnections between that patch and some remote region-- where it gets its inputs and\nwhere it sends its outputs to. But hang on a second. You asked something-- there's\nalso very interesting stuff about the other race effect. I did mention that a\nmonth ago or so, didn't I? Which is another version of\nthis perceptual narrowing. And in fact, a friend of mine\nwho's a great face researcher has not yet\npublished this paper, but she found the following. Totally, that's right-- you\nmentioned the adoption studies. So what she has done is ask-- did I tell you guys\nabout this already? I feel like I did,\nbut maybe not. Anyway, so what you find\nis that people are-- they all look alike. Whoever they are, if\nyou've seen fewer of them than whoever we\nare, you are less good at discriminating them. That's just what it is. But so Elinor McKone\nasked if there's a developmental timeline\nfor getting your way out of the other race effect. And so what she did\nwas-- she's in Australia, and she got various\ncommunities of people who move from dominant\nracial composition x to dominant\nracial composition y and who made that move\nat different ages. And so what she finds\nis that, actually, much like learning the\nphonemes of a language-- which, even if you-- hey, let me back up a second. I said that with phonemes,\nyou can discriminate all those phonemes of all the\nworld's languages at birth, and by six months,\nyou've thrown away the abilities for\nall the phonemes you can't discriminate. However, if you then go learn\na foreign language sometime between six months\nand, say, 12, you can become a native speaker. So you can learn\nthem back, right? So there's another\nwindow-- it gets narrowed-- but you still have a\nwindow to learn them back, OK? After you're like 12,\n15, whatever, forget it. You won't be a native\nspeaker, right? Same deal with the\nother race effect. This is exactly what McKone\nfound with the other race effect. People who moved to a different\ndominant racial community learned the ability to\nnatively discriminate people in that other race if\nthey moved before age 12. So it really seems like\nthere's some general ability. Oh, I remember David's\nother question."}, {"content": "Why does this make sense? I don't know exactly\nwhy it makes sense, but certainly, neural activity\nis expensive metabolically, and we don't want to\nmake discriminations we don't have to. And so it can be just that\nthe nervous system is learning what kinds of\ndiscriminations it needs to make in its environment and\nwhat kind it doesn't, right? And with the case of\nphonemes, it's actually part of what you're doing\nin speech perception, is you want to know,\nevery time I say \"ba,\" it sounds different in\nall different contexts. And so part of the essence\nof the difficulty in speech recognition is understanding\nthat all those different \"ba\"s are the same sound, right? And so part of what perceptual\nnarrowing might be doing is saying all those things-- \"da,\" \"ta,\" whatever\nit is in Hindi-- those are all going to\ncount as the same thing. And that's going to\nhelp you process speech in your native language\nbut hinder when you try to learn a foreign language. Yeah? AUDIENCE: So something\nI'm wondering with perceptual narrowing is how\ngeneral like the starting point is. So I'm basically wondering--\nbecause in the studies, they compared human\nand monkey faces. NANCY KANWISHER: Yeah. AUDIENCE: And I'm\nwondering if there's any correlation with\nhow similar the DNA, like how they're able to\ndiscriminate between the faces. So whether that's\ndifferent types of monkeys, or different animals-- NANCY KANWISHER: I'm\nnot getting it, right? Early on, you can\ndiscriminate both, right? So what's the question? AUDIENCE: So I'm wondering\nwhat other animals can they discriminate, and what-- NANCY KANWISHER: I see, I see. How far does it go? Yeah, good question. I don't know that anybody\nhas asked little kids if they can discriminate other kinds of\nfaces other than monkey faces. I'm sure there's some limit\nto it-- like fish faces? Probably, I don't know, yeah. But there's also, actually,\nin terms of that extended-- I don't know the\nanswer to that, yeah. There's going to be some limit. But in terms of the\nquestion of how long can you relearn those\nabilities or maintain them, it's not like\nperceptual narrowing is going to happen at\nsix months automatically. So if you manipulate it--\nso the studies on humans, if you send-- I feel like I said\nthis in here before, but it must have\nbeen somewhere else-- if you send parents\nhome with books with monkey pictures in them,\nparents of six-month-olds, and you say, look,\nevery night, go through the book with your kids\nand say, there's Monkey Joe, and there's Monkey\nBob, and there's Monkey Whoever with\nyour kids, and you have them do that from age\nsix months to 12 months, they don't perceptually\nnarrow, because they continue to get that experience, right? Interestingly, if the\nparents go home and just say, look, look, that doesn't do it. You have to give them some\nsocial cue that is essentially saying, this thing is\ndifferent from that thing. And if you do that\nwith an infant, even when they don't really\nunderstand language much, they get that cue, and they\nlearn to discriminate-- or they maintain their ability\nto discriminate monkey faces. Yeah? AUDIENCE: Does that\nhold up even when they're past the 12 months old? NANCY KANWISHER:\nWell, I'm guessing it will be just like the\ncase that McKone showed with other race effects, right? I'm guessing the other\nspecies effect will be like the other\nrace effect in that if you, say, start\nworking in a monkey lab when you're eight years old-- that would be weird,\nbut you could-- or you-- I don't know, whatever. Anyway, that you would be able\nto relearn it on the same time scale that you would relearn-- relearn, or learn for the\nfirst time, previously unfamiliar races of faces. But maybe those are slightly\ndifferent timelines. Yeah? AUDIENCE: Could you\ndo something similar with the monkey faces,\nbut with phonemes in different languages? NANCY KANWISHER:\nI'm sure you can, and I'm sure that\nhas been done, but I don't know that literature."}, {"content": "Yeah. Yeah, you mean like keep-- well, OK. I mean, it essentially\ndoes get done, right? So kids who stay\nin environments-- let me think about this. Well, certainly, an\ninfant who's being raised in a\nbilingual environment will maintain their ability\nto discriminate those phonemes from any of the languages\nthey hear, right? AUDIENCE: So you're saying, with\nthe monkeys thing, some kind of social cue to know that-- NANCY KANWISHER: I\nsuspect that's true. I don't know this\nliterature well enough. I do know-- yeah, actually,\nit's coming back dimly. Heather, do you know this? Janet Werker AUDIENCE: [INAUDIBLE]. NANCY KANWISHER:\nOK, so Janet Werker is this amazing infant\nphoneme perception researcher. And I'm pretty sure that\nif you present infants with just like a TV\nin the background with a foreign language, even\nif the infant doesn't have much else to do, that's not enough. And you need to look at\nthem, and engage with them, and speak mother-ese-- like,\nhey, infant, blah, blah, right? I think you need to do all of\nthat for them to maintain it, but I'm-- AUDIENCE: Yeah, that's correct. I think there also\nhas to be interaction. They can't also just be\nwatching the [INAUDIBLE].. It has to be\nslightly [INAUDIBLE] reciprocal [INAUDIBLE]. AUDIENCE: And the\nfact that [INAUDIBLE].. NANCY KANWISHER: Correct, yeah. AUDIENCE: So even if it's\nnot just [INAUDIBLE],, it has to be [INAUDIBLE]. NANCY KANWISHER:\nIt has to be what? AUDIENCE: It has to\nbe like [INAUDIBLE].. It can't be [INAUDIBLE]. AUDIENCE: Yeah, which makes me\nof [INAUDIBLE] or something-- like if you interact in\ndifferent ways, [INAUDIBLE].. NANCY KANWISHER: Cool, yeah? AUDIENCE: Yeah, I have a\nquestion about how long that [INAUDIBLE] lasts. If someone spoke\na foreign language when they were younger,\nthen moved somewhere else or were adopted and then\nstopped speaking the language, [INAUDIBLE],, could they\nsort of be [INAUDIBLE]?? NANCY KANWISHER: I don't know."}, {"content": "I'm sure there's a\nliterature on that."}, {"content": "You don't know\nthat, Dana, do you? Sorry, like so you're\nraised bilingual, and then you stop having\nthe experience early on from your second\nlanguage, and then you're re-exposed\nlater at age eight? AUDIENCE: [INAUDIBLE]. AUDIENCE: Yeah, you\nstill have the-- yeah, you maintain\nthe [INAUDIBLE].. AUDIENCE: Yeah, like after-- NANCY KANWISHER:\nWell, but wait-- AUDIENCE: But you're not able\nto speak the language, right? AUDIENCE: Yeah. AUDIENCE: But you\nstill [INAUDIBLE].. AUDIENCE: But I guess you-- NANCY KANWISHER:\nBut then, that's not consistent with\nperceptual narrowing. AUDIENCE: If you're exposed\nto it before two years? AUDIENCE: Yeah. NANCY KANWISHER: Yeah. AUDIENCE: And then\nyou move away? NANCY KANWISHER:\nWell, if it goes beyond that six-month\nthing, yeah, OK. AUDIENCE: I think\nthat's the case, yeah. You might not have\nthe higher structure, but if you like you the\nsyntax and some vocabulary, you'll have a better accent\nthan someone who did not have that early\nexperience, might not be able to differentiate\n[INAUDIBLE].. But-- AUDIENCE: You just [INAUDIBLE]. AUDIENCE: [INAUDIBLE],,\nI think that's correct. NANCY KANWISHER: OK, good. One more question. Josh? AUDIENCE: So do we\nknow of cases where there's [INAUDIBLE] a mismatch\nbetween [INAUDIBLE] sort of information? Like-- NANCY KANWISHER: Like this? AUDIENCE: Yeah, like--\nwith this property in some of the domain of\nsome of the [INAUDIBLE].. Basically be [INAUDIBLE]. NANCY KANWISHER:\nOh, god, I don't have my dictionary of\nknowledge filed that way so I can pull up an\ninstance of that, but I'm sure there\nare loads of those. AUDIENCE: [INAUDIBLE]. NANCY KANWISHER: Yeah,\nwell, because when we-- because we're making all\nthese assumptions about which behavioral ability is subserved\nby some particular activation in the brain. And mostly, we\ndon't know, right? We know when we have\nthe rare opportunities to do causal tests. We have a better\nidea that that system is at least causally involved\nin that behavioral ability. But yeah, often, those links\nare much looser than we'd like. All right, see you\nguys Wednesday."}], "18. Language I": [{"content": "so this is the lineup for today we're going to be talking about language today and on wednesday but i want to start with something that i gave very short shrift at the end of lecture last time and i'm going to give it short shrift again but in a slightly different way you'll need this for the reading which hopefully you've already tried started as a representational similarity analysis is subtle and rich and interesting and it's taken me years of revisiting it to get its full force so just keep going at it and hopefully every time you'll get it a little better so let me try another brief version of this so representational similarity analysis is sort of like a generalized case of multiple voxel pattern analysis that applies to other kinds of methods and it characterizes a bigger conceptual space so to remind you multiple voxel pattern analysis with functional mri is this business where you split your data in half so you have one set of scans where people are looking at say dogs in another set where they're looking at cats and a whole other separate replication where they're looking at dogs and cats you look at the pattern of response across voxels in each of those four conditions dog one dog two cat one cat two and you ask if the pattern is more similar for the two different splits of the data in the same condition dog one dog two and cat one cat two the diagonal here then in the two cases where they're different dogs to cats everybody remember that this should be like if you're having trouble with this come see me or the tas that's not good okay okay so now that's mvpa and you can use that to ask of a given region of interest in the brain or the whole brain if that the pattern of response in that region can distinguish between class a and class b that's what it's good for so that's worth knowing but it's kind of impoverished it's binary i mean cats versus dogs okay it's a dopey example i choose but whatever you choose is just going to be two things it only takes you so far in characterizing what's represented in that region you can make it richer if you force it to generalize so if these two are a smaller size and a different viewpoint from those and it still works then we show that there's generality train on one kind of condition test on a slightly different version of them that tests the invariance that's richer and more interesting but even so it's it's limited so representational similarity analysis is a bigger richer way of characterizing representations by looking at the pattern of response across multiple conditions not just two in their variations so instead of something like this we'd have something like this with a whole bunch of different stimuli or conditions that we scan people on and then we look at all the pairwise combinations how similar is dog to cat how similar is it to pig or horse or you know table or chair or whatever right so then we have all of these pairwise similarities which gives gives us a bigger you know a richer idea of what's going on there okay and so now we don't have to choose a binary classification in there we can look at that entire space we can think of this whole space as what is represe as our proxy for what is represented in that region of the brain okay so now that's cool so everybody sort of get the gist of how this set of pairwise similarities in a region of the brain is a kind of richer idea of what's going on in that region and what it cares about right everybody kind of got that sort of okay now chunk that matrix as one thing okay that's a representation of what's represented in this part of the brain but now we can take that unit and we can say we can do the same thing on a totally different kind of data okay so here's what we just did here's like some region of the brain voxels we can do the same thing in behavior now we can say okay you rate for me how similar is a dog to a cat on a scale from one to ten i don't know six or something okay how similar is a cat to a pig four i don't know right you can see you imagine you get some similarity space you could just get people to rate them and you could make a whole new matrix here okay now you're characterizing your conceptual space over those same items behaviorally by asking people how similar similar each thing are here we're comparing similarity of patterns of responses across voxels here we're doing it by asking how similar it seems to people behaviorally everybody get how that's a similar kind of enterprise or we could record from neurons in monkey brains and show them the same pictures and just look at the response across say 100 neurons in the monkey brain to a dog and a cat and a pig and so forth and then we could ask how similar is a response across neurons in the monkey to each pair of stimuli just as we did that across each pa each each pair of stimuli across voxels everybody got that so in each case we're getting a matrix like this now we can do the totally cool oh sorry we're not quite yet we can also do that not just on functional mri voxels in the whole brain or in one region but we can make separate matrices these are obviously all fake data i didn't take the trouble to make different matrices for each right but we could make different matrices for different regions of interest in the brain okay one for each voxels here what's their pairwise set of similarities across those stimuli voxels over here what's their pairwise set of similarities okay now we can correlate these matrices to each other okay so we can say for example we had a bunch of people do ratings and give us their behavioral similarities based over these stimuli and then we looked in some region of the brain and got the brain's similarity space and they're represent and their responses across voxels how similar are those to each other okay so it's like we've moved up a level each matrix is a set of correlations between each pair of stimuli but then once we have that set of correlations we can take the whole matrix and correlate it to another matrix this would be a way of asking in some region of the brain how well does the representation in this chunk of brain match people's subjective impression of that similarity space when you ask them about it everybody see how that's a way to ask that question okay we can also relate functional mri voxels to neurophysiology responses across neurons we can ask how similar is your ffa's let's not take the ffa your lo that likes object shape how similar is its shape space in your brain measured with functional mri to shape space in this part of the monkey's brain registered with neurophysiology that's pretty cosmic right we're asking if the monkey sees the world the same way you do in a sense for this method by using these matrices and asking how similar they are across species and methods yeah you can do whatever you like okay so you can take you know you can do garden variety functional mri like we've been talking about in here just like the haxby thing from 2001 that's when it all started right just get a vector across voxels for one condition a vector across voxels for the two condition and correlate them you can do that in responses across neurons okay but you can also do more exotic things you can train a linear classifier on a bunch of voxels and say how well can it decode the response to pig to the response to dog and you can put that number in the in that cell okay so you can do it different ways any measure of similarity or very confusingly there's an increasing trend to talk about dissimilarity not similarity by subtracting the r values from one i find that annoying but it's all over the literature and who cares whether it's similarity or dissimilarity it doesn't really matter they're both ways of uh collecting a representational space yeah are there any any debates in the demand that we should be available since this is like a correlation of coordination oh a million you're supposed to fisher transform it and do all that garbage and we're not discussing that in here i'm just trying to give you the idea i don't need to be dismissive i'm skipping over all of that stuff to just give you the gist of the idea you know for present for purposes in this class you could just eyeball that in that you'd say oh they're really uh no they're not identical i guess i did switch it i did switch a few of them oh okay anyway whatever for purposes in this class you could just eyeball them mathematically and r value we're leaving out all the details yeah okay and of course we can compare behavior in a person to physiology in a monkey or behavior in a monkey to physiology in a monkey and here's one thing you need for the reading i hope it didn't already stump you it's in a tiny part of one of the figures we can make up a hypothesis of what what's represented here we might say hey consider this patch of a brain maybe it represents the animate inanimate distinction in the ideal case that would mean all it knows is animals versus non-animals okay and so that would mean this should be the representational symbolism similarity space if these are all the animals they're all exactly the same as each other all the non-animals are the same as each other but animal any animal and any non-animal are different so this is a hypothesized similarity space of our guess of what's represented in a region a model of what we think is represented in a region and we can we can correlate that to any of these matrices to ask whether our hypothesis of what's in there is right does that make sense okay okay so why is that so all this whole thing so totally cool it enables us to compare representational spaces across regions of interest in the brain okay the ffa to the ppa do they have similar representational spaces across subject groups this batch of subjects and that batch of subjects without having to align voxels we're not aligning voxels we've left loxels behind we're only using these matrices okay we can do it across species across methods and across hypothesized models of what we think is going on like that okay so more generally this probes representations in a richer way we don't need to have just 10 or whatever i put there we could have if we keep subjects in the scanner long enough for monkeys in the lab long enough we can get hundreds of stimuli and really characterize a rich space and we're looking at not just two discriminations but lots um the key requirement for representational similarity analysis to be able to do all this cool stuff is the axes need to be the same so the stimuli that you're getting the similarity of need to be the same in the person doing behavior the person doing mri the monkey doing physiology the model if the axes are not the same then there's no way to correlate the matrices make sense okay we'll keep coming at this again and again you'll see it in the paper for tomorrow night and we'll come at it again uh in class on wednesday okay so that was all ketchup so today we are going to talk about language and let's start by reflecting on what an amazing thing language is so right now there's a miraculous thing going on i'm taking some weird abstract hard to grasp even for me kind of ideas someplace in my head god knows where somewhere in there and i'm trying to take those ideas and translate them into this bunch of noises coming out my mouth that's already pretty astonishing like what what does that idea look like who the hell knows how do you take an abstract idea and turn it into a string of sounds that's wild nobody really knows pretty much a damn thing about how that works fascinating mystery right but then that bunch of noises is going through the air and producing let's hope pretty similar ideas in your head wow okay we do this all day every day big deal but it is it's astonishing it's just astonishing that that works at all okay so that's the essence of language that's why it's so cool um and let's think about um how we're going to think about this so the first thing to note is language is universally human all neurologically intact humans have language there are about 7 000 languages in the world sadly this number's shrinking all the time they are all richly expressive including sign languages there are no kind of impoverished languages that don't capture the full richness of expressible human experience they're all equally rich language is uniquely human yes chimps and parrots can accomplish all kinds of cool things especially if you train them extensively but what they have is not anything really like language and to give you a vivid sense of this let's look at chaser the border collie and what i want you to think about as you look at this little video of chaser the border collie is what is the difference between your language abilities and chasers chaser's pretty damned impressive but you are more impressive so watch it and enjoy and think about how it's different from what you do of us burst with pride if our dogs can respond to two or three commands but what if we haven't begun to understand the possibilities of what the animal mind can really do our friend astrophysicist neil degrasse tyson is host of nova science now and he brings us big news from the frontier welcome chaser beloved six-year-old border collie of psychology professor john pilly good girl she was born to live in the scottish mountains chase and heard she go go john has taught chaser to tend an extremely large if unconventional herd of a thousand toys and she knows the name of every single one of these i hope i find this hard to believe so i test chaser's memory with a random sampling chaser find inky well she got one right find seal whoa and that one too in fact she got all nine right but what about a new toy she's never seen or heard the name of chaser's never seen darwin hasn't even ever heard the name darman so we're going to see if she picks out darwin by inference find darwin i have to ask her again okay chaser chaser chaser find darwin [Music] she did it chaser's never seen that doll before yet she settled on the one toy she didn't know by deduction it's similar to the way children learn language but how does chaser's ability compare with other species besides us chimps and bonobos are the animal kingdom's top linguists capable of learning sign language but very slowly they can solve some sophisticated problems but they don't always pay close attention to humans is he come here i see my dog my dog wants me to be around whereas a bunch of people they don't need me they're basically like hey you got any food can i get any food off of you they're not interested in making me happy since dogs do like to please that humans need to find a way to tap the potential in all of our houses okay put in the tub and dogs like chaser are just waiting for us to discover all that they can do smart dog [Music] and neil degrasse tyson is here with the astonishing chaser here tell me what you learned about animal behavior and child behavior who would have thought that the animals are capable of this much display of intellect i think we like thinking of humans as some top of some ladder and don't even imagine that other animals could even approximate what we do all right i think we all want to see what the demo can we do a demo of this sure goose okay can i do this one you can do this one chaser chaser find abc abc you did it we thank you and we want everyone to know that it's a truly remarkable nova tonight four meals reporting tonight on nova science now on pbs and to you and your broken dogs at home good night okay she's a very good girl and she knows a lot of nouns right a thousand nouns apparently um but what can't you do that you guys can do is this language yeah it's word identification it's not language you can actions how vibrating to be able to use verbs together okay okay that's good verbs and nouns together what else yeah there's some fortification of things if there were like a bigger abc and a smaller bbc type of thing that distinction would have been possible alex the parent can do that one i don't have a video of alex and i don't want to get too hung up on this but some animals can do that kind of stuff what else yeah yeah it's probably closer to like sound identification like how i can identify like the sound of a train or the sound of a car so just some rudimentary thing like visual form and sound how about when she found darwin sorry it wasn't that case just like like he said deduction it was just like it wasn't any other ones that's right that's right but that's pretty impressive isn't it turns out kids use that rule too in learning language it's a whole set of studies of how kids use rules to try to figure out what people are referring to when they learn novel words and that's one of the things that kids use is if there's a thing here that i don't know when somebody's saying a sound here i don't know that thing is probably goes with the sound yeah yeah i would say like i took 1985 last semester we talked about like an exact experiment where kids were able to like learn the words of toys that were like not like english words that were like dax and stuff but then when they were given like a new object they would be able to identify it as a different exactly mutual it's called mutual exclusivity and that's exactly what what chaser's showing here okay so pretty impressive but not fully language right more like memorizing a bunch of nouns plus mutual exclusivity plus some other stuff maybe um she certainly can't understand who did what to who and why right that's just this is not even in the ballpark this is kind of the essence of what we talk to each other about is this kind of stuff all kinds of complicated relationships between different concepts that we communicate in language so animals in not just taught english but animals in their natural environments communicate in rich and detailed ways with each other but usually in each case about a very restricted domain you know what what kind of danger is around what kind of food sources around those basic kinds of narrow things that are of survival value those are the things that animal communication systems usually deal with and in contrast human languages are open-ended and compositional right compositional means that we combine words to say new things things no human being has ever said before okay so that you don't see in animals okay okay so what is language cognitively that is what do you have to know to know a language okay a bunch of basic things one is phonology the sounds of language we've talked about this a bit in the case of speech perception just hearing the difference between a ba and a pa or seeing the equivalent gesture american sign language is a fully expressive natural language and there the phonemes are different pieces of hand movements rather than sounds but function as phonemes all the same okay we talked about specif a region of the brain that responds very specifically to speech sounds in humans okay moving up into the language system that's just the input system we have and by the way we also talked about the visual word form area a very recent addition to the input system in language but that's only a few thousand years old it's really phenology that's the native form of language that's been around for uh tens if not hundreds of thousands of years in human evolution so semantics we need to know what words mean that's lexical semantics but we also need to know how meaning arises when words go together okay and related to how words go together we need to know about the syntax of a language that is the structure or grammar of a language all right and so each language has a set of rules about how you string words together in that language and usually central to that not the only thing but a central part of that is word order and that whole set of rules for how you string together words following word order rules determines the meaning of the string of words for example shark bites man is different than men by shark okay and that just comes out of the syntax that we know that in english in this kind of construction the first word is going to be the agent the one who's doing the thing and the third word is going to be the patient the one who's receiving the doing okay and that's just built into your language system that you know that implicitly okay there's also the pragmatics of language that is how we understand what somebody actually means when they say something to us which isn't always just a function of the actual string of words coming out their mouth okay so if somebody says it will be awesome if you pass the salt it's not all that awesome to have the salt it really means please pass the salt right the pragmatics of the situation tells you the actual intent yeah okay and so to do pragmatics involves thinking about the other person's intent what are they thinking what do they want what's going on in their head and using all that background knowledge to constrain what do they mean by this particular utterance okay so that's just a survey of the main pieces of what we mean by language but for the next two lectures we're going to focus on the core which is syntax and semantics uh this stuff in here and i will sloppily use the word language to refer to this stuff not all the other stuff and and we'll focus really on the sentence understanding okay so what do we want to know about sentence understanding well the first thing we want to know is is it even a thing right is is language a thing separate from the rest of thought okay second thing we want to know is if it is at least something of a kind of a thing does language itself have component structure within it are there different parts of the language system that maybe do different things and if so what is represented and computed in each of those parts and third how do we represent meaning in the brain okay so these are the things we'll address over the next two lectures and let's start with this question that will probably take up the bulk of this lecture is language distinct from the rest of thought okay another way of putting this a more familiar way is to ask what is the relationship between language and thought or even more pointedly could you think without language you probably every one of you has wondered about that at some point so take like two or three minutes talk to your neighbors about this see if you can figure out whether you can think without language and then let's pull your insights talk okay if you guys all nailed it i'm sure you solved the whole thing right people have been talking about this for you know probably millennia so um what do you guys think what were some of your reflections on this question come on you guys yes quietly uh we okay i said that like i think that they could think of that language because of like we talked previously about how uh registration like babies are capable like very complex topic um he was like arguing that the oil research like there's also this thing that maybe it's like kind of like their own language that we don't understand but i don't think not really if you take three-month-old babies not really so perfect absolutely you already know you can hear this okay babies can think right you take 985 you'll learn more they can really think about all kinds of stuff it's really amazing how much they understand um and at you know three to six months there's like little or no language so there's a beautiful case of thinking without language yeah david on the other side right like if you don't give a name to something if you don't give a word to something then it's hard to really know it like maybe there are uh 20 different types of in the color green and if you don't decide to call one of an olive or another one khaki screening or something like that then you can't see the difference yeah well i don't know if you'd ever think of the difference you okay let's think about this do you think you could see the difference suppose i held up you know all of an olive patch and a khaki patch to you and for whatever reason you had been raised with deprivation of the words olive and khaki but somehow it's not about just the perception question it's about remembering yeah bingo bingo so that's roughly what the literature shows anya helped me out here i forgot to look this up the literature still show that perceptually you can discriminate them just fine it doesn't make a damn bit of difference if you have words for it but if you have to remember it sorry faster faster okay but accuracy of d prime i don't think is different maybe a little bit okay oops caught i meant to look this up i knew this was going to come up okay write me an email to look this up and help me find the relevant stuff anyway it doesn't make a huge difference perceptually but it does if you have to remember it for later yeah i was actually going to say because i'm actually reproducing the experiment that found that the difference there was a difference in cognitive in wait in perception or memory um so they found that i believe it was um because they've been a long history with this they find one thing and that's partly why it was like a difference in reaction time interesting enough they found that if they introduced interference in their like linguistic system then that difference went away so that's evidence that the language is causing the difference and that's in a perceptual discrimination okay first scholars yeah yeah well behavioral well yeah effects often are yeah as well i remember one of the first neuroscience talks that went to my college was a woman who had been obviously happy with that was terribly stroke and she was separated from people asia year after week and speaking and put all the language and would like to appear like here i remember the question that i asked is you know you have this really terrible thing right you know did you like what did your inner voice sound like and she said well i didn't know you have one and we've walked into a thing and then she said well i must have thought into images and feelings and the interesting thing that you know i experienced when i was reading my talk was that you know the more english i learned the more my thoughts comes with grammar so i still you know could have these thoughts but they were formulated in this way than they were when i had the structured language okay that's great so we're going to learn more about all of that absolutely okay very good um so cool question not obvious let's see what the data say so first of all you guys uh talked about uh babies and how they can think but animals can think too maybe not fully as richly as we can but they can think in all kinds of subtle rich ways and animals don't have language and so that's another case animals and infants and i'm mentioning numerosity because these are things we happen to have mentioned in here remember the approximate number system animals are great at that very young infants are great at that when they don't have language at all also by the way people whose language do not have any number words whatsoever can do approximate numerosity so here's a cool study from ted gibson's lab a few years ago they went down into remote parts of the amazon to study this group of people the para ha here they are in their canoe they are a hunter-gatherer tribe of just a few hundred their language is as far as linguists can tell unrelated to anyone else and it has no number words so there's a whole there's a whole dispute about that but the current view is there really no number words at all not even for zero or one okay so how do they do at approximate magnitude well let's see so here is the testing session down in the amazon and this is the experimenter lining up a bunch of i think they're batteries and this guy's asked to match the number of balloons to the number of batteries and he has to do it aligned this way so he can't just put them one next to the other if you let him he'll put them one next to the other but this is designed to test it better and he puts down four balloons bingo very good okay what no number of words in his language okay what about um this case i hate people oh the plot is thickening with a lot of thread he laughs he thinks that's pretty funny but watch this valiant goes ahead really well okay so he i think he gave nine for ten or something like that anyway um if uh if if i had any of you guys do this task and i prevented you from counting by having you do verbal shadowing or something else to tie up your language system you would do exactly the same as this guy does okay so the approximate number system doesn't require language doesn't require number words in your language to get the concept and it doesn't require use of language to do the task sorry he actually saw a man put all of him he saw yeah yeah just like you should yeah just just that i mean that's the actual experiment being conducted right there okay okay okay so we've just argued that at least the approximate number system is present in animals who don't have a number of words infants who don't and people who don't have adults who don't have number words what about other aspects of thought and what can we learn from studying brain disorders as isabelle mentioned a moment ago very rich source okay so here's the question we're considering we're taking language and thought or cognition and we're asking whether they're totally separate in the mind and brain or whether they're totally the same thing or whether there's some relationship but they're somewhat different okay so that's a question what do we learn from brain disorders well let's start for with developmental disorders and there are unfortunately a large number of these for example there are language savants people with down syndrome williams syndrome turner syndrome these are all developmental disorders in which people have very low iqs but notably in each of these cases very good language perhaps the most striking is williams syndrome these kids are remarkable they have very low iqs they can't do the most basic spatial reasoning tasks they can't cross the street safely they can't you know they they can't live independently at all and yet they're highly social and their language is almost indistinguishable from any of yours okay not quite if you test them subtly you can find some differences but it is rich and complex and it's it's bizarre because you'd think if your thoughts are so impoverished because your iq is low how could you have rich language but that's the weird thing about william syndrome their language is extremely rich and in fact poetic and quite beautiful and expressive so that's really surprising and suggests that you can have quite severely impaired cognition and very good language so that's the first crack that these things are more separate than you'd guess actually i find this one more surprising than all the others but in cases of brain damage which was the first mental function localized in the brain so this is historically important way back in 1861 paul broca stood up in front of the anthropology society of paris and he announced that the left frontal lobe was the seat of speech okay and this is on the basis of his patient tan who had a big nasty lesion right there in what became known as broca's area um tan was his name because after that lesion that was all he could say okay so broca this is back when the mainstream view was very much against localization of function in the brain there were people like franz josef gaul who were going around saying that different parts of the brain did very different things but goal was kind of a nut and he was not taken seriously by the academic elite whereas broca was a fancy member of the french you know academic societies and a muckety muck and when he announced that the left frontal lobe is the seat of speech everybody had to pay attention so it was big stuff importantly broken noted that tan wasn't globally impaired at thinking that tan could do all kinds of things even though he could not speak so he was already onto this critical idea way back in 1861 and he's just the most famous uh in that in that group there were a bunch of people before him in the decades before who were reporting similar kinds of dissociations okay so what would it be like to have intact thought despite impaired language okay so isabelle mentioned asking somebody who had a stroke here's a okay right so here's another case this is a case of this guy here tom lubbock who died a few years ago from a brain tumor in his temporal lobe that destroyed most of his language but it destroyed it gradually and this guy was a writer he was an art critic a critic for a major english paper and as he started to lose language he wrote about it and he wrote about it very beautifully and he said my language to describe things in the world is very small limited my thoughts when i look at the world are vast limitless and normal same as they ever were my experience of the world is not made less by lack of language but is essentially unchanged so that's a very powerful and surprising piece of writing it's a little bit mysterious because here's this guy writing beautifully and telling us his language is impaired so his idea of language impairment may not be mine i wish i could write that well nonetheless he's clearly reflecting on you know what is a very big loss of his previous language ability and i'm sure it was very painstaking to write these sentences and he's still telling us that even though he's lost a lot of language it has not changed his experience okay so that's just one subjective impression so that argues against this extreme view that they're the same thing right um but it leaves a lot of slop yes because he had a key point of speaking and learning about the award before yes a very important point absolutely so this is a case of somebody who had a lesion in midlife 40 50 something like that he had a whole lifetime of using language to learn and bootstrap all of cognition so absolutely we have to separate two different questions do you need language to become a normal intelligent functional human being throughout you know do you need it throughout development or once you've developed do you still need it to think and those are two very different questions and in fact absolutely you need language to develop if you reflect for a moment on all the things you know okay take a quick mental inventory survey all the things you know it's a lot of things right almost all of those you learn because somebody told you okay most of what we know we learn from language maybe you read about it right but that's somebody telling you in a different way right okay so language is crucial for development of cognition and for learning absolutely but now we're asking a different question of whether you need it whether it's the same thing in adulthood okay so the this guy is a little bit complicated because he obviously still has a lot of language left let's consider cases of people who have essentially no language due to brain damage so this is known as global aphasia and rosemary varley in england has been studying a group of three people i think she's got a few more but here are her three three main ones who have global ephesians she's been studying them for a few years and um sorry it doesn't show here at all sorry about this lousy projector shows on my screen they're big nasty lesions taking up a lot of the left hemisphere and basically knocking out you know essentially all the language regions in these three individuals and here's their performance on a bunch of different language tasks they have to look at a picture and name it they have to understand reversible sentences that's like uh boy kiss girl versus girl kiss boy they need to know who did the kissing and who got kissed right um and a whole bunch of questions like that and they are at chance at every one of these okay so these are people not just people who can't speak they're people who can't speak or understand language pretty much at all okay so it's as close as we can get to a case of a person who has no language ability okay so can these people think so rosemary varley has done paper after paper in which she finds clever ways to communicate tasks to these people to find out what kind of thinking they're capable of here's one you have to order this series of pictures okay so look at it for a second and you can figure out that it goes uh you know basically from right to left okay um so can people with global aphasia do this task yes they're perfect at it no problem whatsoever okay now you might dispute is that cause and effect is it knowledge of sequences are they different i don't know but anyway it's pretty rich task here okay here's another task look at these pictures and tell which of them are things you know and which of them are things you have never seen before that i drew okay takes a moment but you can figure it out okay top three things are real things and those three things are things i drew okay so we could ask does a person with global aphasia know the difference basically do you have to be able to name things to know the difference of what's a real thing and what's not here's another task which of these is the plausible event that's more complicated because here we need to know here we just need to know is that a real thing that i know here we need to know who's doing what to who and does it make sense so it taps world knowledge figuring out who's doing what to whom which many people think is at the core of language so how do people global global aphasia do perfectly at both of these things well not perfectly but the same as control subjects yeah um i'm just confused like how do you get the question like across what they need to do i don't know exactly but you do something like for example you ever play charades like that so like it's not exactly like could someone argue that like there's like actions that you're doing or some kind of form of like language their communication they're not language okay so when we say language we really mean language not necessarily noises coming out the mouth because american sign language counts um and we didn't have time to put that in this lecture which is a damn shame because it really does count in every way and is very interesting and uses similar neural structures and all that stuff um but language is different than communication there's all kinds of ways of communicating right yeah how old are these patients again uh i don't know exactly but they're probably it's almost always strokes they're probably 40 to 60. it's developed i mean it's it's not really it's not a sort of infant no no no these are all people who had brain damage in midlife or later in life yeah okay so that's pretty impressive okay um so basically these people with global aphasia are able to do every single task that rosemary varley has tested them on so i just showed you causality nonverbal meaning here's a cool one remember reorientation you should may well be on the final exam to remind you i did a whole like most of a lecture on this thing about reorientation remember rats and infants if you put them hide food there and put them in this box they later go 50 50 to the two corners even though that wall should disambiguate which is the exactly correct corner they should always go here they have the knowledge that it's there but they go 50 50."}, {"content": "okay and remember i said that liz spelke has this interesting argument that the key thing you need to be able to solve that task is language right because in fact if you test adults and you tie up their language system they behave like infants and rats but if you don't tie up their language system they can do the task which is pretty suggestive that language is the crux of the matter however the global aphasics do this test just fine okay so now we have to go to min young's hypothesis which is that maybe the role of language in reorientation is learning about that whole spatial system during childhood which the global aphasics could do not maintaining the ability once you've gained it okay all right they can do i won't give you all the data on this but they can do arithmetic tasks logic tasks algebra tasks they appreciate music they can think about what other people are thinking okay so everything that all the kind of high level abstract quintessentially human abilities that we are impressed with ourselves for being able to do these people can do without language so language and thought are not the same thing okay you can still think in lots of different ways even after you use language on the other hand as what has already been brought up global of physics had language during development okay so saying that you don't need it as an adult is not the same as saying you don't need it during development you absolutely do need it during development okay because it's the key way we learn about the world and for example there are studies from rebecca sax's lab showing that deaf kids who learn language later for example if they're born not to deaf parents but to hearing parents who don't cotton on to the fact that it's important for them to learn asl early and hence they don't get language until later those kids are not as good at understanding what other people are thinking something that we usually learn about through language okay okay further even though i'm making a big deal about how you can think without language i'm not saying that languages are relevant to thinking okay every time i write a grant proposal i think oh god i have all these ideas in my head and i have to waste weeks and weeks and weeks putting them all down on paper to try to get money to fund my habit and then i get into like sentence three and i suddenly realize oh oh no i haven't been thinking about this clearly at all right so this is my very informal introspection on the role of language in my own thinking like even when i think there's a clear thought the same thing happens when i go to prepare a lecture it's like oh yeah i know the stuff that i've put together some slides i'm like slide two no i don't really know this stuff right um so there is some role uh for language and thinking and i'll give you one uh one example here um one one of the many things that language can do is to uh make information more salient okay so right now close your eyes everyone close your eyes i mean it i can see if they're open okay while keeping your eyes closed point south okay you may not exactly know where south is but make a good guess okay point use your whole arm so everyone can see when they open their eyes okay okay keep pointing but now you can open your eyes and you can look around and see where everyone else is pointing you guys are not bad not bad not bad but we got some over here a little turned around here it's roughly over there okay um so yeah hang on wait a second a little bit yes right um well hang on no i don't know yeah right it's over there okay um okay so you know your vector average was closer to the true thing than a random vector but not so hot if your language forced you to keep track of this you'd be better at it and we know that from the case of the palm para these guys here who live in australia aboriginal people and they spend a lot of time going around in the remote outback of australia where they need to know where they are and where who is going where and when is really of the essence in their lives and in their social interactions so when they run into each other they don't say hi how are you instead they say which way are you going and a typical answer might be north northwest in the middle distance how about you okay um they don't talk about things being left or right or behind them reference frames that have to do with the person's own body which are frankly really stupid reference frames because i can say this thing is to the left and then i turn and now it's not to the left anymore like how stupid is that right these guys have a much better system they would rather say oh you have a bug on your southeast leg right okay so these guys people who speak this language they have to be aware of absolute compass directions all the time just to speak okay and so they're oriented all the time unlike us and in that sense their language makes salient certain kinds of information it's not that you know we can't think about direction it's just that most of the time we're not aware because our language doesn't force us to think about it yeah okay so interim summary um we've been asking this question of whether thought is separate from and possible without language okay before you guys take off you wrote it on the board this board right here awesome okay uh you guys need to tell me when there's time to take the quiz so you're gonna have seven minutes because there's seven questions and so at um uh 12 18. um let me know and i will turn the board around okay 12 17 because it'll take me a minute to turn around all right thank you take notes tell me about that talk okay so here's a question we've been engaging in is thoughts separate from and possible without language and the the literature from a neuropsych patient says yes absolutely they're totally separate global of physics have many forms of thought without language so given that what would you predict from functional mri so if i told you which is true that these are the brain regions that are active during language tasks for example when you understand the meaning of a sentence what would you predict should they be activated only by language not by non-linguistic tasks what do you think take a moment to think about it these are the regions that are engaged when you understand the meaning of a sentence would you expect them to be engaged based on what i've just told you when you do mental arithmetic when you think about spatial orientations when you appreciate music no right if they're separate they're separate they should go on in different brain regions everybody have that intuition no you don't have that intuition i mean i mean you you think about things in terms of words even as a mental crutch even if you didn't have to okay fair enough fair enough so it doesn't nail this case it could well be that you have separate systems for all those other things but you still lean on the system not necessarily but you use it sometimes in fact there's evidence for that that we won't get to today but um okay but the initial thought is you don't need to activate it right okay well here's the surprise up until recently pretty much the whole brain imaging literature says that language overlaps with all of these things in the brain that the activations overlap in the brain they're all the same thing okay that's been the received story for 20 years or so of brain imaging and that just does not fit with the patient literature so we have a conundrum here just a few examples um stand ahead says arithmetic recruits networks involved in word association processes people who study music say regions such as broca's area and wernicke's area which have been considered specific to language are also activated by certain aspects of music thus the idea of language specificity has been called into question and on and on there's a million of these i just put a few of them up there okay so what's going on how are we going to resolve this contradiction on the one hand the patient literature suggests that language is separate from the rest of thought and on the other hand most of the neuroimaging literature says that if you look at those language regions you find them activated in all these other kinds of things one hypothesis is david's that they're activated but not essentially so but there's another hypothesis and that is that there's a methodological flaw with most of the prior research okay what is that methodological flaw it's an inappropriate use of something called a group analysis i've alluded to this a few times briefly but let me do it for real now okay let me first say it's not that a group analysis with functional mri is an evil thing that should never be done they have uses but particularly for the question of asking whether common regions of the brain are engaged in two different tasks it is not a good method for the following reason so first let's say what is a group analysis with functional mri it just means and again i'm going to be very sketchy with this because this is not a actual hands-on methods class i'm just trying to get you to understand the gist of the methods you take a bunch of scanned brains and you align them in a common space as best you can okay you can't do it perfectly because brains are anatomically different from one person to the next okay but you do your best to align them as best you can then you do an analysis across those aligned brains and you ask what is consistent across this group of subjects that's a very useful question to ask if we want to know overall what are the brain regions that are consistently activated when you understand language across this whole group of subjects that's a good use of a group analysis you'll find that picture i just showed you before with stuff going down the left temporal lobe a bunch of left frontal lobe stuff and that will be a very blurry picture of the regions that are most consistent across subjects yes charter you line them anatomically as a new map like sell side to each other or if you like blinded functions okay so therein lies a universe of options what i'm talking about now as a group analysis is aligning them anatomically and that's where the problem comes in and where we're going to go from that is you need to align them functionally okay if you just align them anatomically then the following can happen so you do a standard group analysis and you say for example let's do a language task an arithmetic task and a music task and let's suppose you find this basically broca's area vicinity is activated in an overlapping fashion in all three okay each of those is based on an analysis of 12 or 20 subjects aligned as best we can okay so that's basically what the literature shows is lots of stuff like that but here's the problem you can get that result in a group analysis even if the actual data looks like this in each individual subject no overlap at all in any subject but those regions are in slightly different locations and so if you average across this you get that everybody see the problem so it's not that it's a bad idea to do a group analysis it's a nice initial blurry picture of the approximate consistent locations in the brain for a given task the problem is when you say oh there's overlap therefore the same thing because you can get this result even if there's no overlap in any subject at all okay so the whole literature did this for 20 years and made all this talk about how language is on top of everything else in the brain and for a long time i was sitting by the sidelines going oh my god and then eventually um and federico came along and she knew about language and i said let's figure out maybe they're right maybe that's true or maybe it's like this let's find out okay so how do we do that um what you do is exactly what char dual mentioned a moment ago you align them not anatomically but functionally that's a whole reason to use functional reasons of interest we've encountered this before when i was carrying on about why we do functional localizers with the fusiform face area this is the same deal it's just that that insight started in the back of the head and hasn't reached the front of the head yet or it's about here so some people get it here and the farther forward you go the less people realize this is an issue which is really ridiculous because it gets more and more important as you go this way some stuff is actually aligned in the back and nothing is aligned in the front anyway so what do you do you do just what we did with the ffa in all the other regions one in each subject individually you identify those language regions okay you run some localizer it's like okay i got this and that and that and then once you identify them you can ask okay does that region and that subject show activation for arithmetic no that's next door right etcetera everybody got this this is really important i guess just because i'm obsessed with it maybe maybe it's not i honestly don't know if it's globally important or if it's just my personal obsession but you need to know it for this course we'll leave it at that okay um so this is standard and people who study vision and it's less standard in people who work in other domains but they're they're slowly cottoning on okay so how do we identify language regions in each subject individually there are lots of possible ways to do this but here's the here's the way i'm going to show you that's been used a bunch by federenko and others so we start by saying okay let's find candidate brain regions that respond to language okay which i told you by language i mean sentence understanding for present purposes so if we want to look at sentence understanding we've got to start with sentence understanding so if you look at the screen you'll see some of the stimuli we use okay so subject is lying in the scanner and they see that okay and then we can either give them a task or not and we'll talk about that in a second what are we going to compare it to well there are lots and lots of different things we could compare it to the control for different things but we started off with this if you read this here okay so the idea is it's visually similar you can hear the sounds in your head you can pronounce those things to yourself but there's really no syntax and no meaning okay not perfect but the first pass okay okay so when you do that you get activations that look like this here are four different subjects and you can see they're very systematic things see these three blobs in each subject and a bunch of stuff in the temporal lobe like that in each subject they're quite systematic but absolutely not identical okay all right so yes it's just what i did okay so now what do you do next well we just made this up sentences versus non-word strings who says that's a good thing to do okay so the next thing you do is you gotta validate your localizer task to make sure it isn't just like trivial in some sense so the first question is is it reliable okay so here's session one three different subjects activations we'll just scan them again there's a lot of talk about fancy statistics blah blah blah just scan them again okay wow look how similar these two little hot spots this elongated one i mean it's remarkable extremely reliable within a subject and yet somewhat different across subjects okay so check one reliable more interestingly does it generalize across task and presentation modality okay so before we just had people reading sentences and i keep saying reading is not the native form of language so let's replicate that reading and and now we're adding a memory task so at the end of each string a little probe comes up and you have to say was this word or non-word in the previous thing sequence and let's compare that to just listening to the sentences wow look how similar so that tells us that we're not studying reading or speech we're studying language after those things converge those regions don't care if you saw a word or heard the word they just care if you're representing the meaning of a sentence everybody with me why that's important okay all right check check okay does it generalize across languages suppose you're bilingual and speak two different languages okay here's two subjects who speak both english and spanish wow look how similar okay so it's really language in general not english or spanish or a particular language okay does it generalize across materials okay so we could have reading sentences versus non-words that we've been talking about here with two different runs in one subject or we're gonna have subjects listen listening to speech versus degraded speech like this here's the speech case during my days of house arrest it felt as though i were no longer part of the real world okay versus this [Music] okay so very degraded you can't understand what's being said but it has similar prosity and some similar structure and the point is you get very similar activations with those very different kinds of contrasts okay so now we have really validated this thing it checks out in all the ways it should it doesn't care about modality it does care about meaning and it does and it's highly reliable so now we can put it to use now we can ask what does each of those regions do all right so to do that in each participant then we find those regions with this localizer okay now let me just step back a second there's nothing magic about this localizer per se when you want to study something you use common sense you try something you validate it it may turn out later that oh the thing that we thought we were identifying language with this localizer it's got this other stuff and then maybe you refine your localizer and do something different so it's not that this is the only possible way it was just a sensible approach yeah okay so you use this to find those regions here they are in these four subjects and now um you can say let's find you know so that you have to figure out some way to say that thing corresponds to that to that to that and there's a whole bunch of math that was invented to do that but you know you can basically see it with your eyeballs that those guys roughly correspond and those guys roughly correspond the math is just a way to do that and then once you've found that region you can measure its response in a whole bunch of new conditions and ask what it does okay and in particular oh so yeah so this is different from a group analysis where you don't identify those regions you just choose regions anatomically okay so if we just align them and said okay that's a region well we don't have much of the language stuff there not much there a lot there not much there okay that's not great then we take another one and we define this okay this is a problem no language stuff here lots of language stuff there none lots not good okay everybody see how that's a problem okay i guess i'm flogging this we can move on now but the main problems with the group analyses are you might fail to detect neural activity that's actually there because it doesn't align well enough across subjects and so it doesn't reach threshold it's not consistent but for present purposes the more relevant problem is you might fail to distinguish between two different functions because they variably coexist within that region or not okay so we're not doing that for present purposes instead we're going to now go back to the conundrum of why do the patient studies suggest that language is distinct from the rest of thought but the past functional mri studies suggest that language overlaps with other functions in the brain and we're going to consider the hypothesis that if you study individual brains and localize those regions individually in each subject then the story might be different okay and it is so here's the task that federenko and i did a few years ago we came up with seven different tasks i won't bore you with all the details it doesn't really matter we just had lots of stuff arithmetic spatial working memory various cognitive control tasks working memory tests all kinds of stuff focusing on things that music focusing on stuff that other people had said overlaps with language in the brain okay and so first thing is you got to make sure those other tasks actually produce activations because it's easy to make up a task and have it not do much and then that's not very interesting so yes each one of those tasks produce lots of activation look at all that red stuff looks like a bunch of pizzas right okay so they produce good activations now the question is do those activations overlap with the language regions okay so let's consider two of them this is basically wernicke's area and broca's area two well-known language regions identified individually in each subject and now averaging the response over all the conditions here's a response when subjects read sentences and non-word strings sentences and non-word strings okay that's how we define those regions but this is in data that wasn't actually used to define those regions we held out some data just to cross-validate it okay now the question is how do those regions respond to all of these other things they don't pretty much at all okay so notice what's happened here the prior literature shows massive overlap between language and all these other things in our data when you identify those language regions in each subject individually and measure the magnitude of response in those other things they don't respond so this shows stunning specificity of the language regions consistent with the picture that comes from the patient literature from studies of brain damage language really is separate in the brain from all of these things okay everybody get that picture and the reason the literature had it wrong is they were mushing brains together and blurring the hell out of their data and drawing wrong conclusions okay i'm speeding up because i don't want to run out of time okay so we started with these questions here is language distinct for the rest of thought i'm saying yes language may be necessary to learn to think and it is indeed but the evidence from the neurological patients is pretty powerful global physics with pretty much no language can think in myriad sophisticated ways and when you do your functional mri studies right you find that the language regions in the brain in fact do not are not active during non-linguistic thinking make sense questions wow i finished on time you"}], "20. Theory of Mind & Mentalizing": [{"content": "okay so we are now going to do the third part in our sort of trilogy of uniquely human functions so starting a few weeks ago we moved from things that are shared with animals like navigation and basic visual perception very similar between humans and monkeys and uh other uh number all of these things that are shared uh with animals to talk about functions that are uniquely human and that includes music and language and today we're going to talk about the coolest and most quintessentially human mental function is and that is thinking about each other's thoughts so to get started thinking about this um let me remind you guys of what should be pretty obvious that we human beings are profoundly social in many many different respects so if you think about you know if you recount what happened in your day to someone else pretty much all of the elements of what you're encoun recounting our interactions with other people these are the things we care about these are the basic structure of our lives um other people are the source of our greatest happiness for most of us if you ask people at the end of life what matters most they'll say i shouldn't have wasted all that time working so hard and my job didn't matter and i didn't realize actually it's just other people are the only thing that matter interactions with other people or lack thereof are also the source of one of the deepest kinds of human suffering for many of us whether it's an everyday thing like a breakup with a or with a with a lover or a loss of a loved one or a family member um and also depriving people of social interactions this is like society's um kind of strongest form of punishment right is solitary confinement um interactions with other people um our failure to understand them is devastating in the case of autism where people struggle to understand what other people are all about and in terms of our amazing abilities as human beings most of what we know we learn from other people sometimes we figure stuff out on our own but if you take an inventory of all the stuff you know you read about it or somebody told it to you you learned it from other people and consequently some of the greatest feats of humanity from arts to science to everything else are products of people working together okay further many people have hypothesized that social cognition our ability to understand and deal with interact with other people is one of the strongest drivers of the evolution of the human brain so many have argued that the hardest problem we solve on a daily basis is understanding other people and it's also a very important problem and so that's a powerful natural selection force understanding other people and that has shaped the structure of the human brain not everybody agrees with that kind of extreme view that it's the primary driver but it's an interesting hypothesis and it surely played some role social cognition also is just a very large percent of human cognition and it's a large percent in terms of minutes of every day if you tally up different forms of social cognition this is one we're doing right now and we're about to engage in an hour and 20 minutes of it right here and probably when you leave this room you'll engage in other kinds of social cognition so it's just a large percent of what we do all day every day and it's also a large percent of what the cortex does so roughly that stuff and other bits are engaged in different aspects of social cognition so what exactly is social cognition to get a sense of what is entailed in social cognition which is a very complex multi-part multi-faceted enterprise i'm going to show you a um a short video of an interaction between an 8 a bunch of 18 month old infants and an experimenter and what i want you to do is just watch it it's very charming but also think about what these kids must know to be able to do what you're about to see can you see the screen there okay okay that little kid in the corner doesn't know this guy he's just been brought in for the experiment and he's just watching this weirdo doing this thing put the eye contact never met that guy before here's another case he's dropped a clothespin what is the matter with this guy [Laughter] looking more and more suspicious okay so what did you notice what are those little kids 18 months oh there's another one this is cute but we don't need it let's go on um what did you notice about um what those little kids were able to do what what is entailed in being able to do that what have they figured out lots of things yeah they understand intention yeah yeah all they're doing is watching this guy do these clumsy actions and he's not saying anything he's just grunting and they're figuring out what he intends absolutely what else yeah sort of being able to interpret the sounds of the grunts that footage was making so especially like the one completion like sound huh uh-huh yeah one could ask which of those things are more important actions or the sounds i don't think they took it apart here but it's an interesting question yep so they they understand some kind of vocal communication not language but some kind of intent definitely they'd be part of it yeah do you understand how to be helpful without coming in i didn't hear without sorry without like interviewing people coming in their way yeah yeah they know how to be helpful but not just they know how they have a will to be helpful remember these kids never met that stranger before this video started or maybe a minute or two before so it's fascinating not just what they're able to figure out but what they're motivated to do right that's a quintessentially human thing is to spontaneously help a stranger who you've never met before and are not related to right okay all right so but focusing more on the cognitive abilities um what what you need to do to figure out another agent's actions is to figure out what that agent is doing and that's externally observable you can watch you can use your perceptual system construed broadly to figure out what is this person doing in some general sense and that's important and and subtle and multifaceted but it's nowhere near enough really what you want to know is why are they doing that thing okay and that's not directly observable you can't see the why of a person's actions you have to infer it in fact to infer you have to infer a bunch of hidden mental states and those things are much more abstract than just you know i'm picking up the phone right you know that's just an action you can see it but if you try to think about why am i picking up the phone now we're in a whole different ballpark and so what you need to figure out to hit to figure out the agent's hidden mental states you need to figure out what can that agent see or hear okay and here it's really important to not lose a level here we're not talking about what we can see in understanding another agent we need to understand what what that agent can see about someone else okay so we're getting kind of meta here with multiple levels okay um we also need to understand the other agents desires and goals of what they want or what they're intending okay so how might we figure these things out um sometimes there are simple cues that might suffice so you might make an inference like if a person is reaching for an object they want that object okay so there the externally observable thing might give you a pretty direct inference about that it hurt the internal hidden state of what the what the agent wants okay but a lot of times that's not going to work right that's going to work in some cases but only a few and further the percepts and the goals that we've mentioned here aren't enough okay they'll work in some cases but humans do much more than that so let's consider this case here's and here's a um an agent who's doing some action and we can observe their body motions and what we want to understand is how this other agent watching them is going to infer things about this guy okay so we're interested in what's going on in the mind of this guy as they watch that guy okay now let's consider the case that this guy's trying to understand this is romeo here why did romeo reach for the bottle okay well to understand why romeo reached for the bottle you need to perceive and infer a whole bunch of things you need to see the hand reaching for the bottle to know what happened okay but then to really understand the case of romeo you need to understand that his intention is to drink the liquid in the bottle that's why he reached for it okay can't see the intention to drink the liquid you can only see the reaching then you further need to understand why is he intending to drink the liquid well because he believes the liquid is poison um i don't know why my pop-ups are all messing up here whatever he believes that julia is dead and he wants to die okay so all of that is part of what is entailed in understanding why romeo reached for the bottle okay and crucially the stuff in red these things are the beliefs and desires are not directly observable they're highly abstract okay and they're crucial they are the best way to explain and predict behavior so when we need to understand other people and what they're doing and why we're in this abstract space of beliefs and desires we can't see them directly we have to observe we have to infer them indirectly and they're essential because that's what we need to do to understand other people okay all right so we talked before about perceiving uh an agent um i'm sorry about inferring what an agent can can perceive and inferring the agent's desires and goals but as i just pointed out we also need to know the agent's beliefs what they think okay so all of this stuff in here inferring the hidden mental states of agents is what we mean by mentalizing inferring other people's mental states okay and the cases we're talking about here are inferring the percepts of another agent inferring the desires of another agent and inferring the beliefs of another agent okay all this abstract stuff okay no computer system can do this not even close see we can still say that we can't say that about object recognition anymore but we have this little precious reserve where we can still say that no animal can do these things except in very restricted cases so there's an active ongoing research program in a bunch of labs testing chimps and subtle tasks to try to figure out when they can infer things about the mind of another chimp or person and there are a few restricted cases where they can make some inferences about the mental contents of other agents but the current dominant view is that those inferences are very restricted to very particular situations usually involving competition over food and they don't generalize um in in any way okay so in this whole enterprise specific cues like making an inference that reaching for x means wanting x will help in some cases but will only get us so far okay we do much more than that and the question is how all right all right so inferring mental states to understand other people involves person inferring their percepts their beliefs and their desires okay um so how do we do this well a first question that we ask in this class and that's kind of a sensible thing to do is when we're trying to understand this whole space of how people think about another agent's percepts beliefs and desires we might just think okay maybe that's just part of generic cognition who says that's a separate domain of cognition that we should study separately maybe we should just study thinking in general thinking about objects thinking about physics thinking about people maybe it's all the same thing okay so let's stop let's start by considering is it really a separate thing from the rest of cognition okay well there's a classic behavioral paradigm in this field that's provided some evidence in this you may have heard about this in other classes but we'll talk about it because it's so kind of fundamental to all of the work on thinking about other people's thoughts and that is called the false belief paradigm it's really a way of testing beliefs and the reason you test false beliefs rather than true beliefs is if you ask about another agent's false belief true beliefs um then your prediction about what they're going to do next is confounded with what is true in the world and if you want to really tap into what's going on in their mind as opposed to what you know what would be true in the world you have to use a false belief to pull those apart okay so the classic way this is done the sally and task goes like this this is the sound there are many variants of it but this is the classic original version uh that appears in hundreds of papers um so here's sally and and ann and sally puts her ball in the basket okay you show this to little kids or or animals too versions of it we're doing a little kid version you say okay here's sally she puts her ball in the basket uh i don't know why my pop-ups are screwing up anyway then ann comes along sally leaves the room and comes in and moves sally's ball from the basket to the box and ann closes the top of the box then the question is when sally comes back where will she look for her ball okay where will she look for a ball in the basket right okay if you do this very simple question for three-year-olds they'll say in the box if you do it on five-year-olds they'll stay in the basket okay adults say in the basket as you guys say you have to think for a second right if you just kind of blurt out the first thing that comes to mind you'll behave like a three-year-old and say in the box but if you think for half a second you realize duh she doesn't know it got moved to the box she'll look where she thinks it is in the basket okay everybody with the program here okay so that's very very simple task it's the basic false belief paradigm and to make it more vivid i have to show you a video of rebecca sacks giving this task to a bunch of kids and talking about it it's a it's a delightful video and it'll give you a really vivid sense of you know how smart a three-year-old is and how much they understand and yet how fundamentally and totally they fail this task versions of this task come on here we go the first thing i'm going to show you is a change between age 3 and 5 as kids learn to understand that somebody else can have beliefs that are different from their own so i'm going to show you a five-year-old who's getting a standard kind of puzzle that we call the false belief test this is the first pirate his name is ivan you know what pirates really like what pirates really like cheese sandwiches cheese i love cheese yeah so my friend has his cheese sandwich and he says i really love cheese sandwiches when ivan puts his sandwich over here on top of the pirate chest and ivan says you know what i need a drink with my lunch and so ivan goes to get a drink and while ivan is away the wind comes and it blows the sandwich down onto the grass and now here comes the other pirate this parrot is called joshua and joshua also really loves cheese sandwich so joshua has a cheese sandwich and he says yum yum yum i love cheese sandwiches and he puts his cheese sandwich over here on top of the pirate chest so that one is his that one's joshua's that's right and then his went down the ground yeah that's exactly right now so he won't know which one is his spontaneous don't even have to ask evan comes back and he says i want my cheese sandwich so which one do you think ivan's gonna take i think he's gonna take that one yeah you think he's gonna take that one all right let's see oh yeah you were right you took that one so that's a five-year-old who clearly understands that other people can have false beliefs and what the consequences are for their actions now i'm going to show you a three-year-old who got the same puzzle and ivan says i want my cheese sandwich which sandwich is he gonna take he's gonna take that one let's see what happens let's see what he does here comes ivan and he says i want my cheese sandwich and he takes this one uh oh why'd he take that one [Music] so the three-year-old does two things differently first he predicts ivan will take the sandwich that's really his and second when he sees ivan taking the sandwich where he left his where we would say he's taking that one because he thinks it's his the three-year-old comes up with another explanation he's not taking his own sandwich because he doesn't want it because now it's dirty on the ground so that's why he's taking the other sandwich now of course development doesn't end at five and we can see the continuation of this process of learning to think about other people's thoughts by upping the ante and asking children now not for an action prediction but for a moral judgment so first i'm going to show you the three-year-old again i have been being mean and naughty for taking joshua's sandwich yeah yeah should i even get in trouble for taking joshua sandwich yeah so it's maybe not surprising he thinks it was meena viven to take the joshua sandwich since he thinks ivan only took joshua sandwich to avoid having to eat his own dirty sandwich but now i'm gonna show you the five-year-old remember the five-year-old completely understood why i even took joshua's sandwich was ivan being mean and naughty for taking joshua's sandwich [Music] yeah and so it's not until age seven that we get what looks more like an adult response should i even get in trouble for taking joshua's sandwich no because the wind chicken for switching sandwiches okay so everybody got the idea of the false belief tasks past passed in the four and five-year-olds not in the three-year-old and the three-year-old not only fails to get the answer right but when asked why it happened he comes up with a totally different account okay and you can see that three-year-old is not a dummy three-year-olds are smart and can do all kinds of things but they don't get this particular thing okay all right what about kids with autism well kids with autism either fail this task altogether or they pass it much later than neurotypical kids okay but now we've got to figure out why why would a relatively high functioning kid with autism say a seven-year-old who's got language and who seems to understand the question why would they fail this task why would anybody fail this task there's a couple of things going on here the essential element of the false belief tasks that we're interested in is that it requires you to attribute thoughts to another agent right that's what this task was made to tap but you might fail it not just for failing to attribute thoughts correctly you might fail it for other reasons you might fail it because this task involves this weird situation whereas there's the other agent's belief and there's a reality and they're different and that's kind of confusing it's like representing x and not x at the same time maybe that's just a particularly generically hard cognitive thing to do okay and the third possibility is that the true state of the world is so salient and dominant it may be hard to just inhibit that true reality in order to infer uh the the um the belief a belief is a kind of less visible salient thing than the true state of the world and so maybe just having an inability to inhibit dominant salient representations would infer interfere with your ability to do this task so people with autism or in fact three-year-olds might fail for any of these reasons so how are we going to figure out whether people with autism are actually failing this task because of their difficulty and in attributing thoughts well the way to figure that out is to come up with a really really clever control task okay this task was invented by debbie zaichik when i was in graduate school she was my office mate in graduate school and she came up with this task and i said that is really brilliant so we want to figure out whether it's a belief per se uh that's the the difficulty in attributing the thought or the belief to another agent that's the crux of the problem so in zach's false photo task the idea is it's a logically isomorphic task but it's about a physical representation not a mental one so what you do is you show sally putting her her ball in the basket uh and then you have a what was then like widely known to to kids a polaroid photograph a camera come along we didn't have cell phones back then so it's a polaroid camera takes a picture of sally putting her ball in the basket and then ann moves the ball from the basket to the box and then you ask the kid why where will um where will sally look for her ball i'm sorry where will where is sorry then you ask the kid where is the ball in the photograph okay sorry i screwed it up here's a belief version the kid watches sally and anne in this case you do a photograph version of it so you there's no um you're not asking about another person's beliefs you're using a photograph and you're showing sally put the ball in the basket basket you take a photograph of it and moves the ball to the box and then you ask in the photograph where's the ball okay you're not asking amount about a mental belief you're asking about a physical representation in the photograph okay so do you see how even though i bungled it on the first time it's really a logically isomorphic task you're in both cases you're asking about a representation that differs from reality but one's a mental representation that's where the kids with autism fail the task this is the physical representation kids with asd fail the false belief task not the false photo task and that rules out these other accounts because in both cases there's a representation that differs from reality you have the x and not x challenge right that's true of both of these um and in both cases the true state is kind of more dominant than the representational state in the in the belief or the photo and yet they have a problem with the um with the belief version not with a photograph version suggesting that this is the correct account of why they fail that makes sense was there a question yeah okay so all of that is consistent with the idea that attributing uh thoughts to another agent is a special distinctive thing that can be that's what i just said um so we have evidence that that that attributing thoughts is a distinct domain of cognition it's just not part of your generic ability to think about anything and we see that from the fact that typical children have this very systematic uh developmental time course where they get this at age five they don't get it at age three and we see it from the selective loss of this ability in kids with autism that they get the false belief task way later than they get the false photograph task was there a question here so the kids are never asked what does amber see that question then comes up in the fb task in the fourth photograph task um i'm sure people have done versions of that task but tell me what you're getting at here i spoke to do like an apocalyptic person i would assume that the final question remains the same so i would ask the kids what do you think and perceives uh given the change in the stimulus and then the gate response given the new media as to what the actor you're trying to get a tighter control to the false photo task is that yeah instead of where will she look for the ball yeah um but it's not really about what she perceives it's about where she thinks the ball is right and so the the false belief tasks have been done every which way from where does sally think the ball is to where will she look for the ball and you get the same answer in all of those so i think that's that's closer to where is it in the where is it in the photograph is really where does she think it is that's that's the that's the parallel yeah because she's not still perceiving it at that point yeah okay so that's behavioral evidence to suggest that there's really something different about inferring another person's thoughts and beliefs than there is from the rest of cognition the distinctive developmental time course and this kind of selective deficit and autism so what can we learn from functional mri is there a special part of the brain for making these inferences about other agents thoughts and beliefs okay so rebecca and i did this experiment 100 years ago where we scanned people while they were doing simple simple verbal tasks so we wrote false belief stories and sort of false photo stories generalized and we scanned people while they lay in the scanner and just read these simple descriptions and answered basic questions so you can try this right now here's a false belief story um your you read susie parked your sports car in the driveway in the middle of the night nathan moved her car into the garage to make room for his minivan susie woke up early in the morning susie expects to see in the driveway a sports car or a minivan yes sports car right exactly what she thinks is there not what is there the control um experiment that we wrote many many of these a volcano erupted on this caribbean island three months ago baron lava rock is all that remains satellite photos show the island as it was before the eruption in the photos the island is covered in rock or vegetation right okay so here um again it's just like debbie zach's asd control here it's you're asking about a representation in the satellite photo that's no longer true of reality and you have to distinguish the two so we scan people just doing these tasks okay and if you look in a whole brain group analysis that i was much dissing before but that's a good first step you see here's a slice through the brain like this you see a bunch of hot spots that respond more when you do these tasks than those tasks okay and there's a bunch of these regions deep down in the middle of the prefrontal cortex here that you can see in a slice like that here is a region called mpfc for medial prefrontal cortex it does all kinds of interesting things and it'll get mostly short shrift in this lecture it activates in this tab and for reasons you'll see in a minute activates in this task um oh god i'm pop-ups or have a mind of their own uh but here's another region the right tpj tpj stands for temporoparietal junction so in me if my temporal lobe is going down here my parietal lobe is here frontal lobe is there temporopridal junction is somewhere right around there okay everybody oriented and if we look at that region shown symbolically here what you see in the time course of response in that region doing this task is here's what happens in that region this is time here many seconds as they read and answer that task and here's what happens when they read and answer uh the false photo task so false belief tasks false photo task that just shows you the same thing as activation yeah you can see it evolve over time okay so um what happens in the npfc region oh god why is this not happening is that showing up oh there it is okay um right in the mpfc region you see a similar thing you get a response below baseline here we'll talk about that what it means to have a response below baseline in some conditions in the next lecture it's actually not all that mysterious it just means that baseline remember is usually lying in the scanner staring at a dot going dumb dw dumb or whatever you do when you're staring at a dot in the scanner and uh the key point for now is just that you also see a higher response to the belief than photo case okay okay so what's going on in these regions this activation this higher response to the belief than photo case even though i was touting what a brilliant control condition the false photo task is it is but it's still open to a bunch of different possibilities okay so that act those activations could be just thinking about a person after all our false belief stories all involve people and our false photo stories did not so maybe this isn't about beliefs per se it's just about thinking about people in general any any aspect of people okay or it could be any mental inference we make about the internal invisible states of a person okay any anything that might be going on in their head or it might be particularly attributing thoughts and desires to the person okay so how are we going to unconfound these with a new experiment and some new conditions so here's a new condition that refers just to a person not about their internal invisible states or their thoughts or desires subjects just read simple stories like i see what's happening it's not showing it's showing something different on the screen from what's on my slide here i have no idea why but anyway that's why i keep wondering what's there and what's not okay um okay so in the external case in this condition you lie in the scanner you read stuff like andrew just had a growth spurt so he was gangly and rather awkward like most teenagers he had bad skin and bad taste in clothes he wore mostly baggy jeans and flannel shirts okay so it's you know it's not riveting but it's not boring either you read a bunch of these they're interesting enough okay but no mental states there just outward appearance okay the next condition refers directly to the person's thoughts nikki nikki knew that his sister's flight from san francisco was delayed 10 hours only one flight was delayed so much that night so when he got to the airport he knew what flight was hers okay not even that interesting but it's talking about what he inferred what he knew beliefs okay but there's a third condition that refers to an internal state but not a thought or a belief refers to a visceral state sheila skipped breakfast because she was late for the train to her mother's by the time she got off the train she was starving her stomach was rumbling and she could smell food everywhere okay so this case is interesting it's vivid it refers to a mental state but not a thought it's a physical state hunger okay i mean it's a it's a mental representation of a bodily sensation okay everybody get the distinction between internal thoughts and and and feelings sensations okay so ah this contrast is consistent with any of these hypotheses and we're going to test those hypotheses with these three conditions okay so here are the three hypotheses we just described here and here are the three conditions i just gave and i want you guys to tell me what we're going to predict that we will see in the right tpj according to each hypothesis which namely which of these conditions will produce a high response and which will produce a low response okay so let's start with this case on the hypothesis that the right tpj responds whenever you're reading about a person what are we going to find which of these conditions is going to produce a height response all of them yeah absolutely so that's a prediction here all of them okay what about if it's interested in internal internal bodily sensations or or actually in in any internal mental states the last two absolutely both the visceral case and the thoughts case sorry that cell in that cell okay and what about if it's specifically about attributing thoughts to another agent just the last one right okay very good so what do we see so first of all here's just the localizer task always nice to look at your localizer and make sure it worked out so this is a response of the right tpj to the belief and photo condition just like i showed you before higher when you do the belief tasks and the photo task okay just a reality check key question what is the response of the right tpj in that main experiment with the three conditions we just described and here's what it does it's high only in the thought condition only when you're when you're reading about thinking about another person's thoughts and that's significantly higher than either the external properties or the um this uh or the visceral states and those two even though it looks like there's a little bit of a trend that visceral is higher than external that's not significant yeah um on the previous slide is it like thoughts and desires so like why can't like i was just confused about like the example for the bristol case for smelling food everywhere like couldn't that fall under it that's a good point yes it could yes you could infer a desire in that case absolutely yeah that's right um so yeah that's a good point it's intended to just identify the vivid visceral state uh and it's probably hard to do that with it without invoking some kind of desires here um yeah i would i would consider it a con a confound for that particular example um i'm guessing it was not so for the others in fact um it sort of couldn't have been given the way this came out right but good point okay so um okay so and if you do a whole group analysis of the whole brain and you say what bits do you get in a contrast of reasoning about another person's thoughts versus their external appearance or their visceral states uh their bodily sensations you get the right tbj again okay so everybody got this to suggest that the right tpj is extremely specific uh specifically interested in inferring another person's thoughts not even just their bodily sensation so it's not all mental states of another person that engage this region i mean i find this quite remarkable because that's so specific you know but before you hear about this you think okay thinking about another person's thirst or hunger or pain is that really different than thinking about their beliefs but oh yes it's different right the tpj does beliefs not thirst and hunger and pain yes yeah so there's a whole literature on this and um uh i think if you okay so first of all we need to like get the level straight when you're just thinking you're not thinking about thinking you're just thinking right so you're not engaging this region right so when we're talking about thoughts and we're talking about you thinking about another person's thoughts so the parallel would be you thinking about your own thoughts right so i think you know i i can't tell you exactly what the literature is on this i'm sure there's a few experiments but i think what you'd have to do is adopt that kind of meta perspective on yourself right a lot of a lot of our thinking is sort of thinking about thinking but not in a very explicit separable way i'm not being very clear on this but um you know i think if you asked if you ask people for example um you know when you saw this surprising event whatever it is you make something up what were you thinking uh you might engage that region i realize i'm not totally sure if there's literature on this heather is there there must be literature on this so they've done some inspiration you get mpfc for that yeah well go ahead well we just thought i'd talk about this and um it's kind of like insert but it's either so they're they're both two networks that are particularly clear but not just rtpga right rtbj and other regions yeah so you could get some rtbj when answering those kinds of questions okay so you get something in the vicinity i'm just trying to get okay so uh-huh right but the other part of this is i bet you have to do something quite explicit to do that because in some sense we're thinking about our own thoughts kind of implicitly a lot of the time right so i'm guessing that it's when you ask about it explicitly yeah i i forget details of the past but it was very great about this right next to you right okay anyway good question i'm sorry i don't have a totally adequate answer yet i'm guessing the literature doesn't have a totally adequate answer yet um okay all right um so recall that i uh mentioned that the uh the contrast between doing the false belief task versus the false photo task gets not just the rtbj it also gets this medial frontal region okay and that needle frontal region responds more to the belief than photograph task like this what does it do in this split between uh thoughts visceral thinking about other people's thoughts their visceral states and their external appearance it doesn't care okay so there's a real division between these different brain regions that are engaged when you do the false belief task the rtbj is very specifically interested in very specifically engaged when you think about another person's thoughts not when you think about their bodily sensations the medial prefrontal region is engaged in all three of these conditions okay so what it looks like is that of these three hypotheses anytime you think about another person that's true of the mpfc whereas the right tpj responds specifically when you attribute thoughts and when you and desires to another person okay okay now you may have been wondering about the fact that all of these experiments are using words it's kind of not like normal social cognition you're reading about all this stuff um and if these regions were really doing what we're claiming they're doing we should be able to find them in other situations where you make inferences about other agents beliefs so in more recent experiments they've been showing pixar movies to subjects in the scanner so you can just watch yourself make a few inferences about the agent's beliefs imagine you're watching this in the scanner and just let's just do a little bit of it to get the gist [Music] no words it's the key okay so there's a whole little microcosm of uh mental states here uh in other parts of this same six-minute pixar movie there's very vivid bodily sensations there's a porcupine who inflicts real pain with porcupine quills so there's bodily states and inferences about bodily states and inferences about mental states that go on and by um showing this movie to subjects in the scanner and then labeling which parts of the movie require the viewer to make inferences about the thoughts and beliefs of the protagonists and which require them to make inferences about bodily sensations like usually pain if you do that contrast you find the same set of regions the rtbj and its left hemisphere bit and you find some medial prefrontal stuff and you find some other stuff okay so what does that mean that means that you don't need words to identify this region you if you induce the same cognitive processes just from watching a a wordless movie um you show the same selective activations um and that's cool because it tells us that uh this is not about some kind of verbal reasoning it's really about the kind of deeper cognitive process whether you do it based on a movie or based on a bunch of sentences um and that's a powerful generalization we we like uh imaging results where the result generalizes across very different kinds of tasks and this this really strengthens the evidence that this is really what's going on in this region and it also means you can look for this region in kids okay and i didn't manage to fit that into this lecture but there's a whole other research enterprise where in rebecca's lab they've been scanning kids watching this pixar movie and asking how that region develops and they find that actually the region continues to develop even after age four it continues to develop and what happens is it doesn't uh it doesn't so much get bigger as it gets more selective in the younger kids you get activation both for um well it's just less selective anyway so uh this shows generalization so now we've shown um that we see the rtbj is selective for thinking about other people's thoughts we see that with false photo false belief versus false photo contrast we see that it's highly specific it's not just any thoughts you have about another person and we see it generalizes depicts our movies okay okay so let's consider now moral reasoning as a test case for theory of mind why moral reasoning well if you think about it reasoning about what's a morally acceptable or unacceptable action on the part of another person is all about what the person intended and what they knew okay so intent is very fundamental it's built into the legal system think about the difference between murder and manslaughter right they both involve killing another person but one is with intent and the other is accidental and our you know common moral reasoning and our legal system cares deeply about that difference okay um okay so for example i'm going to give you a moral reasoning task uh and just think about this and your your task is going to be to decide how morally permissible is the action described here um grace's action in particular okay so grace and her friend are taking a tour of a chemical plant and when grace goes over the coffee machine to pour some coffee grace's friend asks for some sugar in hers and there's white powder in a container by the coffee the plot thickens the white powder is a very toxic substance left behind by a scientist and therefore it's deadly when ingested in any form versus a butt the white the container is labeled sugar so grace believes that the white powder by the coffee is sugar left by the kitchen staff so grace puts the substance in her friend's coffee and her friend drinks a coffee and dies now your question is how morally permissible was grace's action on a scale from one to totally not okay morally forbidden to seven morally permissible okay so think about that on a scale and write down your number on a piece of paper you don't have to divulge it okay everybody got the question everybody decided more or less okay write down your number now consider a slightly different case slightly but crucially different case this case is known as the accidental harm case now consider the case where instead okay instead of being labeled sugar you get the same story but now the container is labeled toxic so grace believes that the white powder is a toxic substance left behind by a scientist nonetheless she puts the substance in her friend's coffee and their friend drinks a coffee and dies now consider how morally permissible is grace's action from one to totally not okay to seven morally permissible and write down your number okay okay how many people gave a lower number that is more morally forbidden for the second one than the first one okay if you didn't you probably weren't paying attention okay so you can see that it's the crux of the matter what grace believed when she did the action okay that's why we're talking about moral reasoning here as a test case of theory of mind because what the agent knew at the time of the action is of the essence and thinking about the moral status of their action okay everybody got that okay so this is a powerful test case and notice that also in the clip that i showed you from rebecca's ted talk she showed that um kids ability to use an agent's knowledge in doing what you guys just did that kicks in a little bit later than the standard false belief task so sometime after they get the basic idea of false belief they start to apply it takes a while to to kick in in this other case okay so this is known as intentional intentional harm as opposed to accidental harm okay it's just the terminology in the field um okay so what do you think will happen in autism if we ask people with autism these two questions and what do you think will happen if we apply tms to the right tpj it's right out there on the lateral surface just asking for it so it's a totally doable experiment it's been done what do you think happens okay let's take the case with autism how do you think people with autism will respond to these two questions the same as you guys did yeah yes char duel probably like the average distance between the average distance between how bad they think the second one just be less than yes exactly why um because they might not be able to make the distinction between grace knowing that the container was toxic versus the container being labeled toxic it's like both of them would be confounded which is like truth of how the women's absolutely absolutely everybody get that and share that intuition to the extent that autism is a particular deficit in understanding what another person knows or believes that's the only difference between these two cases to the extent that you have difficulty representing that you will have less of a difference in your moral judgment about these two things because you have a hard time representing that person's knowledge it's not that autism is a deficit in moral reasoning it's that moral reasoning entails thinking about other people at least these cases not all of it but these cases involve thinking about other people's thoughts and taking them into account and to the extent that that's difficult for you you will make less of a distinction exactly right yeah was there a question begging yeah okay okay what do you think will happen if you zap the rtbj with tms while subjects are doing these tasks yeah yeah yeah yeah that's the prediction if the rtbj is the main bit that's doing the inference about that's representing the beliefs of others then if you zap it you might change people's moral inferences more moral judgments that's pretty wild that's what happens except the rtpj and they make a smaller distinction between accidental harm and incident and intentional harm okay so both of those things are true i won't drag you through all the details of the experiments but the the basic findings from this whole line of work show that first of all neurotypical people agree as you guys did that accidental harm is more morally permissible than intentional harm okay and people with autism give less forgiveness for accidental harm compared to intentional harm than neurotypicals okay just because they that ability to represent the key knowledge that that tells you it's accidental is something they're not good at okay what is the role of the rtpj the data show that forgiveness for accidental harms first of all i left this out before it's correlated in neurotypicals with activation of the right tbj during moral judgment so if you just measure across a whole bunch of those moral judgment problems how strongly activated was your rtpg as you read that problem that's correlated with your ability to forgive somebody for accidentally harming someone again showing that there's a relationship between you're representing the thoughts and beliefs of another person and you're using that information to exonerate them from a harm they didn't intend yeah is it different for for thoughts versus external actions yeah um so um so first of all i'm i'm treating autism very superficially here it's an extremely hetero heterogeneous thing that varies not just you know along a spectrum you know which it clearly does but probably along many spectra and it's highly heterogeneous so these experiments are just done in high functioning adults who are you know totally past false belief tasks um they pass them later in life but they get to you know otherwise you can't test them on these kinds of experiments and the effects are quite subtle they're just a slightly lesser difference between accidental and intentional harm okay so just to clarify that which i probably should have said but your question is are the uh deficits in autism specific to thinking about thoughts rather than thinking about actions this is ongoing work but a lot of research has shown that that it it is more specific to thoughts and that a lot of the stuff you read about just basic perceptual um difficulties i mean most studies find that people with autism are a little bit worse at face recognition but not much worse in tasks asking about goals of actions like reaching for objects what is that person's intention mostly they don't find a deficit in autism so the perceptual basics seeing people and seeing what they're doing is much less impaired that's what the current literature suggests there's always the worry that you know we're not asking in the right way or testing in the right way um and the literature is highly inconsistent from one study to the next i used to work on autism and i just you know couldn't stand it anymore because every time a study is done it gets the opposite of the previous study i think because the population's so heterogeneous but from a gloss it looks like there's more of a deficit in the inferences about thoughts than inferences about actions yeah i just want to clarify so the autistic subjects are also explicitly told that grace believes lovable yes it's explicitly uh no it's exactly what i uh gave here uh yeah no grace believes yeah you're right grace believes yes explicitly and in spite of that it's known yep yeah yeah and so i think you can think of this as a subtle case these are people who pass the explicit false belief task but like the seven-year-old kids there's one thing if you're asked what does this person believe and another if you're asked a moral reasoning task for which you have to realize to bring the belief into account you know it takes more of your own kind of active was there another question what if you ask like instead of grace what did you say to me what if what you ask them like about themselves so you are you and your friends are thinking it's more of a chemical times and giving them the exact same scenario would that be any different um yeah that's interesting it's like the question about uh you know to what sorry question is suppose you ask people with autism this same question but it's not about grace it's about you you do all of this um i'm not sure good question probably somebody's looked at that yeah i'm not sure if they answered this already but uh do people with autism have something different in their art we're getting there you should absolutely be wondering that and i haven't yet and we're getting there good that you ask in fact that's probably my very next slide um okay um okay so causal role we showed the causal role of the rtpg in neurotypical subjects you zap the rtbj and you slightly reduce the difference in moral permissibility of the accidental harms and the intentional harms okay so all of these findings suggest that the rtbj is causally engaged in understanding the difference between intentional and accidental actions and that that ability is specifically disrupted in autism all of which leads to the natural prediction that genealogists made about the rtbj in autism so what do you think is rtbj affected in autism how many raise your hand if you think there's going to be something different in the rtbj and autism versus typical subjects okay raise your hand if you think there isn't not sure okay well you sort of both write in different ways okay so the answer is this so so um uh in rebecca sax's lab they did a study with a a really large number of typical subjects it's you know because of this heterogeneity in the autism population it's really hard to get a stable result you can believe so and it helps to have a really large it's hard to get enough autism subjects so we try and get as many as we can and the most you ever get in a study around here is you know 20 30 and that's a big struggle but it helps to have a really large neurotypical control population to reduce your error bars on what the neurotypical population shows so this study is probably the biggest that's been done they had 31 high functioning people with autism and 462 neurotypical individuals they didn't just go run 400 new subjects for this when you when you run that localizer task you've got it in every study you run and so then you can take all those localizer tasks across hundreds of subjects so um and so what they find is um both if you look at regions of interest analysis like find the rtbj and if you do a whole brain group analysis you find no differences between people with autism high functioning people with autism and typical subjects in the size location or response magnitude of the rtbj um okay when people do theory of mind tasks so you should be surprised everyone is surprised you all made the prediction everyone else made the prediction too um and that's pretty bizarre um but does that mean that the rtbj is not affected in asd chardool the information from the rpmpj is not used by other parts of the brain it's a great hypothesis maybe the information is in there and it's some kind of a disconnection thing and so it can't you know could be accessed by other processes right absolutely what's another hypothesis yeah is bill sorry in a different order what do you mean yeah but then we'd have to think about how the different temporal order would lead to the different behavioral outcomes right am i yeah david maybe he's given a different priority so like what you're processing there might not be as important to the person itself yep okay so it might be there but less salient or less important but how is that going to account for the lack of a difference between the asds and typicals remember you run your basic false belief versus false photo contrast and you find the rtpj and surprisingly even in this fairly large sample it looks the same in size location and response magnitude in the asds and in the typicals now i left something out this is this is high functioning adult asds who can now pass the false belief task right that's crucial because that's the task you're doing in the scanner they don't understand the task there's no point scanning them kind of going huh what right so these are people who are you know very high functioning and they can totally do the task right otherwise you can't run the experiment um so yes what are the behavioral differences well that's a very good question that's another reason that i stopped working on autism there's a whole there's a whole battery that you run to try to establish that you know these people officially really for the purposes of scientific study count as having autism and these people really officially don't at mit you need to run those studies on everyone because some of your control subjects end up in the other group um and um and and so those are a whole kind of battery of things from you know involving an hour-long interview with a trained person who tallies things like how much eye contact is made and what kind of give and take happens in conversation and all that kind of stuff i just don't i guess for the experiment because i mean yeah their behavioral response might not necessarily be hard to be changed yeah absolutely so yes it's possible that the rtpj is absolutely fine in people with autism and there's no difference as those initial results seem to suggest and that whatever differences you see with autism reside elsewhere but that's surprising given all the stuff i've said over the last hour about how uh at least you know um in the case of moral reasoning these same high functioning the same people who show the same activation of the rtbj have slightly different moral reasoning right so there's yeah like or so for moral reasoning for example could be what they base their morals off but might not be intended to survive like at that point in their life different idea of what more other people mentioned yep that's true yep never in this test um they function the same way the people who are being examined are yes in the same way yes the difference so why don't they test them without performing those good good exactly so we're in this funny position of we've sort of identified you know theory of mind um inferences as a as a critical difficulty in autism but these are people the only ones we can scan on that kind of task are people who can already pass it so we're already in a weird situation now you might have predicted that they could pass it based on other cognitive abilities right that they they um come up with another strategy and in that case they wouldn't be using their rtbj but another hypothesis is it just develops later they've got it there it is they use it it activates the same that's yeah and so your point is why don't they test some of the moral reasoning tasks right and see if it comes online right well the one that they can't function on because exactly maybe they don't know when to use them that's right that's right that's right it's a it's a very good suggestion that's probably been done and i don't know this heather do you know if people scanned asds doing the moral reasoning task probably leanne has done that right it's a really good suggestion and and i actually now can't think why they wouldn't have done that do you mind just going on pubmed and look it would be leanne young and it would be um yeah moral reasoning from fmri i bet she's done that maybe heather will get you this because it's a very good suggestion yeah why not test them on the thing that's different okay anyway um what i'm what i'm getting at here is you know all these hypotheses you guys are raising are very good ones but there's another one which is maybe the rtbj isn't functioning right even though we see it activated more when they do the false belief task than the false photo task maybe we'd see a difference if we looked at the pattern of responses in there right okay all right so um in this study um uh koster hale and sax did something that should be very familiar to you guys they took these two cases sort of a version of what you're suggesting yeah maybe it does entail it i think of it as an mvpa experiment but actually heather that's the thing to look at is does koster hale see a difference in overall magnitude and that i don't know anyway they did the mvpa version so you have subjects do those same tasks the accidental harm the intentional harm you split your data in half and you ask whether the rtpj represents the difference between accidental harm and intentional harm okay everybody get why this is a sensible thing to do okay so first you do that in um neurotypical subjects okay um and you find here is the court remember this is the original hacks b version the correlation within versus correlation between so this is a correlation within and that's correlation between so this is accidental the pattern in the rtpj for accidental harm to accidental harm across stories and intentional to intentional is higher than from accidental to intentional here i'm sort of skipping over the details hoping you guys remember this is this making sense okay so typical um classification with with correlations and you see that that was significant in this group of subjects uh of typical subjects okay so that's cool so there's information in the rtvj about whether um an action was intentional or accidental that's cool now we've learned something more than just it activates when you do these tasks we know something about what it represents but you might say that's so teeny ick yeah it was significant but really so what do you do in that case do it again absolutely you don't go find some fancier stat that gets your p level so you have to start no no no no you do it again rebecca and her lab members being good scientists did it again and they got the same thing excellent new bunch of subjects new bunch of stories replicate and generalize do it again and so yes indeed we can the spatial pattern contains information further you can then again in this bunch of neurotypical subjects look at the degree to which subjects rated the moral permissibility to be different in the intentional and accidental look at their behavioral ratings during the task that's here and you can see that's correlated with the degree of pattern information in the rtbj okay everybody get that so the more you pay attention to that distinction behaviorally when you're doing the task the more you think accidental harm is really much more okay than intentional harm the greater that difference in your behavioral ratings the greater the discrimination ability in your rtbj while you're doing it okay so that's a further length that that's where the action is just a correlation not causation but it's a nice one yeah okay so all of this is yeah yes it's in the rtc party technically as means there's no certain people between us always going to presentational horses and there is a communications so nurse of course ohio have a difference in the congregation just univariate overall magnitude accidental versus intentional in neurotypicals but not in asds aha so it's not just a pattern result yeah it's in the text it's not okay okay okay um okay but that's the interaction uh-huh okay but then the version of nava's question which i resonate to very much is if you just did the original kind of dufour thing of is the rtbj just as big and selective and is it in the same place just because it was a huge that's true okay so they don't have the data okay okay fair enough okay good point okay so that's why you know you ask that question it's a very good question i'm thinking yes they should have done that reason they didn't do it is they could have the big sample because they were using localizer data which they had from study after study after study every time you run a theory of mind test you run that localizer and then you just go back a few years and you've got 300 subjects right but they didn't run the moral reasoning task on hundreds of subjects and so they don't have the power to be able to see it yeah okay fair enough okay so back to this this is just showing that in the neurotypical subjects um there's pattern information in the rtpj about intentional versus accidental harm everybody got that and it's correlated with your behavioral reading of the moral permissibility okay so that's cool um so does rtpj distinguish between accidental and intentional harm in asds okay so these are the data i just showed you actually they did three experiments showing this here into endurotypicals and here's the asd data no difference at all okay so so what that means is even though asds have the same size and location and magnitude of response of the rtbj in the standard localizer task as typical subjects the key difference that's been found so far is that in neurotypical subjects our tpj holds information about the distinction between intentional and accidental harm in in asds it doesn't okay that's probably just one of a bunch of things that are going to be different this is as far as i know the only one that's been published that sees i see some squints are you not getting this or do you have a question about it yeah what happens in the evidence uh the fault there isn't an obvious discrimination that you can do see the the nice thing about the moral reasoning task is it's got these two outcomes these two um conditions accidental harm and intentional harm so that gives us a way to go in and do the pattern analysis question there so with false beliefs you'd have to think of some other dimension to look at and it and the experiments are not set up that way with with stimuli that are on either side of a of a dichotomy so that you can do the discrimination you could do representational similarity analysis actually come to think of it then you wouldn't have to have the whole dichotomy that's interesting okay heather has rebecca done that you're my informant here you could take okay so um shash is suggesting um what you know why not do this kind of ask this kind of question of this standard localizer experiment and i said well it wasn't set up with an obvious dichotomy um and and then i was thinking actually you could take all of the belief conditions and you could do rsa on those in the asds and on the typicals and ask if their patterns are different right i bet they've done that see what i mean anyway all right well i'll stop speculating and just ask she's right there two floors up can just ask all right uh anyway does everybody get this basic idea here so the thing the rtbg is there in the high functioning people with autism but it doesn't hold the same information okay all right um all right so where do we get with all of this we used all of this stuff on moral reasoning as a way to look at the rtbj in theory of mind we found that that people with asd put less weight on a person's beliefs when judging the moral permissibility of an action tms to the rtbj disrupts moral judgment pattern analysis shows that the tpj distinguishes between intentional and accidental harm in neurotypicals but not in people with asd okay so there's a nice little story developing here i'm sure it's not the whole deal"}], "24. Attention and Awareness": [{"content": "NANCY KANWISHER: So we won't\nget through the whole attention lecture. I saw this coming."}, {"content": "I just felt like that last\nbit was important enough. We'll cut as needed. But I do want to\ntalk about attention. And let me start by\nsharing with you some of the key ideas about\nwhat attention is. OK, so to get into the mode\nof thinking about this, let's consider the\nfollowing question. How do you feel about\npeople driving while talking on their cell phones? Smart, not smart? And while you're thinking about\nthat, also consider the case-- like let's suppose\nthat you have had a hands-free setup,\nso you don't have to be looking down\non your cell phone or typing away or\nholding your cell phone. Maybe that's OK. What do you think? Is there no problem with driving\nwhile talking on your cell phone, provided you're\nnot looking down and pecking away at it? Yes?"}, {"content": "What do you think? I want to know what\nyou really think. I know what all the PR says. Is it fine? Yes? AUDIENCE: I would say it depends\non whether you're driving-- Like if the road is clear and\nit's like your usual path, like driving is pretty\nautomatic at that point. But it it's like high\ntraffic or a new area, then I think it would have\na significant affects, so you shouldn't. NANCY KANWISHER: Totally. My rule is, if I am\ntalking on my cell phone, certainly, if I'm turning\nleft, I put the damn cell phone on my lap. And I tell whoever it\nis, I can't talk to you and turn left at the same time. All right, turning left is\nthe hardest thing we do. Self-driving cars\ncan't turn left. Have I mentioned this? How does a self-driving\ncar turn left? It turns right three times. Why is that? Because turning left\nis social cognition. It's like, do they see me? Do they know I'm here? Are they looking\nat my indicator? Do they realize I'm\ngoing to turn left? This is hard. This is social cognition. Nobody's mastered that yet. Anyway, it's hard for us too. Anyway, the real\nquestion here is not for me to lecture you about\ndriving but to think about, why is that a problem? Why can't you talk to a person\nand pay attention to driving? What is the big deal, right? And so the intuition is we have\nsome kind of limited processing ability. OK, we're not like super\nsupercomputers who can just do millions of things at once. We have some kind of limit in\nhow much stuff we can handle, OK? And I think everybody\nwill have this intuition. You can't think about lots\nof different things at once. I like to think of this as the\ntoaster model of cognition. That is, you plug in the\ntoaster, and the lights dim, right? So if everything's\non the same circuit, there's some kind of unitary\nthing, resource that's limited. And if some more of it goes\nhere, less if it goes here. OK, so obviously we don't\nhave simple circuits like that in our brain. And the relevant\nscarce commodity isn't just electricity. It's not electrons. It's some other kind of thing\nwe don't totally understand. But there's still some sense in\nwhich of our mental processes are on the same circuit. OK? I'm assuming everybody is\nsharing this intuition here. So think about this. How many people feel like\nyou can listen to music and read difficult\nstuff at the same time? Raise your-- I'm curious. How many people feel\nlike they can do that? Only a few. That's so interesting."}, {"content": "Sort of. Yeah, I can't do it\nat all, like at all, like even background\nmusic that I don't even care that much about. Someday-- I mean, I\nthink these are really stunning individual differences."}, {"content": "I don't know if there's\nany good work on it. I haven't seen it. But I think it's\nreally interesting. Some people can. Some people can't. I don't know what's\nup with that. How about recognizing faces\nand scenes at the same time? Can you do that? Yeah? How many people feel like\nyou can recognize a face and a scene at the same time? All right. In fact, Michael Cohen,\nwho gave that lecture on brain-computer interfaces\na month ago or so, showed some beautiful\nwork that, actually, you are better at recognizing a\nface and a scene presented simultaneously than two\nfaces or two scenes. Can you think why that might be?"}, {"content": "Yeah, Isabelle? AUDIENCE: Context. NANCY KANWISHER: Say more. AUDIENCE: If you see somebody,\neven a familiar face, you can either-- it helps identify them as,\noh, I know that person. Then, obviously, they're there."}, {"content": "NANCY KANWISHER: Right. So they can go together\ninto a thing, maybe chunk it as a thing or something. That's a good answer."}, {"content": "It wasn't the one\nI was fishing for. Yeah, Jimmy? AUDIENCE: If people and\nplaces are separate things that your brain calculates,\nif it's two faces, you have to calculate this\nthing with a face number one before going to face number two. Whereas if it's [INAUDIBLE] NANCY KANWISHER: Exactly. Exactly."}, {"content": "And you do, right? You have an FFA and a PPA."}, {"content": "And they're friends, right? So what Michael showed\nis not just that you can recognize a face and\nhold it in working memory, a face and a scene better\nthan two faces or two scenes, but the degree to which\nyou have that cost of doing two things\nin one category rather than spreading\nover two categories is linearly proportional to\nhow different the activation patterns are for\nthose categories in the ventral visual pathway. So faces and scenes are totally\ndifferent from each other. And so you get a big benefit\nfor separating your two items across faces and scenes. Other things that are more\nsimilar in their pattern of response in the ventral\npathway, like faces and bodies, you get a smaller benefit. OK? So it's consistent\nwith this idea that, to the degree that we\nhave separate processors, you can do, to some extent,\nprocessing in parallel, OK? It doesn't explain why not\neverybody can read and listen to music at the same time. Because, as I argued\na few weeks ago, these things don't\noverlap at all. So there are many mysteries. But there's some\nintuition there. OK, to get a little\nmore intuition about limited processing\ncapacity, can you guys see? When I was sitting\nover there last time, I couldn't see\nthe screen at all. Can you guys see it? It's OK? All right. Yeah? AUDIENCE: Do you think\nthe problem is [INAUDIBLE] NANCY KANWISHER: Not for me. Instrumental music, no\nlyrics still a problem. So I don't know."}, {"content": "I mean, I'm sure there's\na literature on this. I just don't happen to know it. I'm just trying to\nshare the intuition. So I don't-- it's not\nthe only thing for me. OK, so what I'm going to do--\nthis is a super low-tech demo. I'm going to show you an\narray of colored letters. Grab a piece of\npaper or something where you can write\ndown a few letters. And I'm just going to flash\nup one array very quickly. And I want you to write down\nas many of the blue letters as you can. OK, ready? There's only a few of them. So you can. OK, ready?"}, {"content": "Here we go. OK, write them down. Last year, everyone\ngot all of them. So I tried to go a\nlittle faster this time."}, {"content": "OK. OK, we're going to do it again. Ready? There's going to\nbe another display, and you're going to write\ndown all the blue letters. Everyone ready?"}, {"content": "Here we go."}, {"content": "OK, just wanted to\nshare the intuition. The probability-- did\nanyone miss the N here? OK, how many people got the N? Nobody's going to admit it. I wanted a few people\nto miss the N, right? I really did zip through. I probably cheated and\nmade this one go faster. You missed it? OK, thank you."}, {"content": "I'm sure a few others did. OK, anyway, the point\nis that, if you do this properly in a lab,\nthe probability of detecting it here is\nmuch less than there, right? So what does this show? It shows that we have\nlimited capacity. We can't process all\nof those blue letters in parallel, right? When there's a single\none, you get it just fine. But when there's a bunch,\nyou don't necessarily get it, right? OK. It also shows that we\nhave ability to select the information, right? So you weren't bothered\nby the red letters. If I'd asked you right\nafter about the red letters, you probably couldn't report\nany of them at all, right? It's a whole field\nthat studies that. We won't get into that."}, {"content": "OK. So in fact, the\nprobability of reporting the N in these two displays\nis independent of the number of red letters. They just don't matter. They are not entering into that\nlimitation, whatever it is. The limitation is\nonly for the ones you're paying attention\nto, the blue ones, OK? OK, so why is our\nmental capacity limited? OK?"}, {"content": "Nobody really knows an answer. And I actually think this is\na really unsatisfying part of attention research because\nit sort of seems obvious. But I think it's not. So sometime in the\nnext 10 or 20 years, some smart computational person\nwill analyze this well and get a more satisfying answer. But right now,\nhere's where we are. The standard story is, well,\nwe have only so many neurons and so much capacity. And you can't do\neverything at once, right? So we can't process everything\nin the whole visual field at once. That's the standard story. But the reason I find\nthis unsatisfying is like, why the hell not, right? We have all this parallel stuff\nor the whole visual field, at least in the first\nfew stages of processing. And we have quite a degree\nof parallelism after that. So I think that's\nthe standard story. But I'm just marking that I\ndon't find it very satisfying. Yeah? A second answer, which\nI think is also not totally satisfying but also\na little bit right at least, is that, typically, you're\nonly going to do one action. Right?"}, {"content": "You're going around\nin the world. Let's forget colored letters\non a display in a lab. Let's think about a person\nwalking around in a busy city street doing something, right? There's typically only\none or a very small number of things you're going to\ndo next, like walk down the sidewalk and\nnot bump into people or pick up this object, right? You don't need to act towards\nall the things in your world. And in fact, if you\nhad to, so given that you're only going\nto do one thing, why distract the whole rest of\nyour motor-planning system by feeding it all this\ninformation that's is just going to clutter\nit with garbage? Why not give it just the\ninformation it needs? OK, so that's the\nstandard story. It's very squishy and vague\nbut hopefully intuitive. And there's some nice,\ncompelling examples that illustrate this. So there's a fish\ncalled the pike fish that preys on smaller\nfish called sticklebacks. OK? And if you stick a pike fish\nin a tank with sticklebacks, it will catch the\nfirst stickleback faster if there's only\none in the tank with it than if there are 10\nin the tank with it. OK? You might think, you've\ngot 10 to choose from. You'll get a fish faster. But 10 is more\ndistracting, right? And so maybe our\naction-planning systems also prefer the single stickleback. Again, there's no\ncomputational precision."}, {"content": "I'm just sharing\nintuitions with you. OK, so let me give you some\nmore evidence that there really are significant capacity\nlimits in perception and that, in fact, there's a lot\nof stuff right in front of us that comes right onto our\nretina that we don't see. OK? So I'm going to\nshow you an example. I'm going to show you a\npicture for just a few seconds. And I want you to\njust look at it. And then I'm going to ask\nyou some questions about it. OK?"}, {"content": "Here we go. OK, so how rich a\npercept did you get? Did you see lots of stuff\nand get lots of detail? Or do you just\nfeel like you just have the vaguest sense of a few\nbuildings, a street, that's it? How many feel like they got\na lot of pretty good detail? No one does. Or everyone's bored. I don't know which. AUDIENCE: What do\nyou mean good detail? NANCY KANWISHER: The colors\nof buildings, the presence of objects, details on\nthe architectural styles, where an awning was,\nthat kind of thing. AUDIENCE: I feel like\nI got [INAUDIBLE] NANCY KANWISHER: Well, most\npeople looking at this feel like-- I mean, who knows what it means? I mean, we're just\nsharing intuitions here. But most feel like,\nthat was pretty rich. I have a sense of it. I have a sense of maybe\nwhat country that's in and what kind\nof stuff is there and what kind the style is. You get a feel for the place,\nall that kind of thing. Maybe not every damn\ndetail, but lots, right? So the general intuition\nmost people have is a fair amount of detail. OK?"}, {"content": "Well, let's look\nat that some more."}, {"content": "This is actually a very,\nvery heated topic right now. Me and Michael Cohen published\na paper a couple of years ago called The Bandwidth of\nPerception, which is an effort to grapple with this question\nof how much information is there in your current\npercept right now. And there are many different\nperspectives on this."}, {"content": "Let's find out a little\nmore with a further demo. So what I'm going\nto do is I'm going to show you that picture again. And it's going to flash\non a number of times. And each time it\nflashes on, there might be something\nthat's different. So take notes on any\ndifferences you might detect. OK? OK. OK, what things changed? Yeah? AUDIENCE: There was a woman\nwalking down the sidewalk. NANCY KANWISHER: And? AUDIENCE: That's all I got. NANCY KANWISHER:\nOK, but she changed. What changed about her? AUDIENCE: Other\nthan her clothes? NANCY KANWISHER: Yeah. Over the successive\npresentations, was she there sometimes\nand not others? Did she change? Yeah, she appeared\nor disappeared. OK, good. What else, Isabel? AUDIENCE: The awnings changed. The buildings changed colors. NANCY KANWISHER: Very good. Very good. How many people saw\nan awning change? Maybe half of you. OK. What else changed? AUDIENCE: The car. AUDIENCE: The model of the car. NANCY KANWISHER: The\nmodel of the car. Very good."}, {"content": "Yeah? AUDIENCE: I feel like\nthe shops changed. But I don't know when or how. NANCY KANWISHER: OK. OK. You want to see\nhow they changed? OK, here's how it ended. Here's how it started. Are you surprised how much? Raise your hand if you're\nsurprised how much changed. Yeah, a lot, right? OK, so what does that tell us? It tells us that\neither the sense we have that we really saw a\nlot of what's going on there was wrong. We didn't see as\nmuch as we thought. Because if we saw as\nmuch as we thought, we should notice massive\nchanges like that. If you didn't see the\nawning, look over there. I mean, how could-- look\nat the color changes. Pretty major, right? Or we perceive all that\nstuff in the instant, and it just goes poof by the\ntime the next one comes along. That's one of the things\nthe field is finding about those things are\nvery hard to tell apart, not impossible, but hard. Yeah. OK, so most people feel\nlike, wow, much more changed than I thought. I can't resist one\nmore hilarious demo. So have you already\nseen this like in 9.00? How many people have\nseen this before? Oh, I don't want to bore you. Do you mind seeing it again? We could skip it. It's kind of fun. Sorry? Do it? OK. OK."}, {"content": "OK. So you're just going to\nwatch this video and just track things\nbecause there may be changes happening\nhere and there, and you want to notice them, OK? Here we go. [MUSIC PLAYING] [VIDEO PLAYBACK] - Clearly, somebody in this\nroom murdered Lord Smythe, who, at precisely\n3:34 this afternoon, was brutally bludgeoned to\ndeath with a blunt instrument. I want each of you to\ntell me your whereabouts at precisely the time that\nthis dastardly deed took place. - I was polishing the brass\nin the master bedroom. - I was buttering his lordship's\nscones below stairs, sir. - I was planting my petunias\nin the potting shed. - Constable, arrest Lady Smythe. - How did you know? - Madam, as any\nhorticulturist will tell you, one does not plant\npetunias until May is out. Take her away."}, {"content": "It's just a matter\nof observation."}, {"content": "The real question is,\nhow observant were you? Clearly, somebody in this\nroom murdered Lord Smythe, who at precisely\n3:34 this afternoon, was brutally bludgeoned to\ndeath with a blunt instrument. I want each of you to\ntell me your whereabouts at precisely the time that\nthis dastardly deed took place. [END PLAYBACK] NANCY KANWISHER:\nTotally different guy. [VIDEO PLAYBACK] - I was polishing the brass\nin the master bedroom. - I was buttering his lordship's\nscones below stairs, sir. - I was planting my petunias\nin the potting shed. - Constable, arrest Lady Smythe. [END PLAYBACK] NANCY KANWISHER:\nIt's actually an ad. But it doesn't hurt\nto get its message. All right, it's a British ad\nwith an important message. But it's a pretty impressive\ndemo too, isn't it? How many people feel\nlike lots of stuff changed that they didn't notice? Yeah, that's intuition. So the idea here is that all\nthat stuff hits your retina. All of it kind of gets\nprocessed to some degree. But it's amazing how much\nof it goes unnoticed. OK?"}, {"content": "All right, oops. Sorry. OK, you might think, OK, is\nthis something that only happens when it doesn't really matter? OK, you were\nlooking for changes. But your life\ndidn't depend on it. What about commercial pilots? So here's a classic\nstudy where they brought in actual\nreal commercial pilots with thousands of hours\nof flying experience. And they had them fly\nin a flight simulator. They had them land a plane on a\nrunway in the flight simulator under foggy conditions. And I forget what percent. I have to cheat and\nlook at my notes. It doesn't say. It does."}, {"content": "I'm just not seeing it. Some large percent\nof the pilots never saw this plane sitting\nright there on the runway. They landed the planes\nin the simulator right through that plane. And when they were\nshown it subsequently, they were shocked\nand couldn't believe they didn't see it, right? They were using a\nheads-up display that tells them\ntheir orientation to where the runway is. And they're paying\nattention to this stuff, landing on the runway. And they just do not even see\nthat very relevant thing, OK? So it's not just something that\nhappens in like weird psych demos and funny movies. Even for very important things,\npeople miss absolutely major, important information. OK, so what all this\ntells us is attention is a filter that lets some\ninformation into our awareness but completely filters\nout of awareness a lot of other\ninformation that lands on your retina or your cochlea. OK? And there's two key\nproperties of attention that go hand-in-hand. One, those capacity limits\nwe've been talking about. You can't do everything at once. And two, selectivity,\nthat is there's some way some subset\nof that information comes in some way\nto select it, OK? All right, so let's say a\nlittle bit more about attention. There's lots of different\nways and forms of attention. So let me give you a few key\ndistinctions about attention. So far, it's just kind\nof a vague word that gets used lots of different ways. So long ago, the great Helmholtz\nthought about attention and realized that there were two\ndifferent kinds of attention. So he noted way back\nin 1860, our attention is quite independent of the\nposition and accommodation of the eyes and of any known\nalteration in these organs and free to direct itself by a\nconscious and voluntary effort upon any selected portion of a\ndark and undifferentiated field of view. This is one of the most\nimportant observations for a future theory\nof attention. Indeed, it is, right? So his point-- I think we did\nthis at some earlier lecture. His point is you can fixate\non my nose right now. OK, everybody fixate on my nose. Not that it's that\nfabulous a nose. It'll just serve for\nthe demo right now. And if I hold up different\nnumbers of fingers out here-- keep fixating on my nose. No cheating. OK? How many fingers are off\nto the left side of my nose from your perspective? OK. How many fingers are\noff to the right side? OK."}, {"content": "You can do that. You can pull up this information\nor pull up that information without moving your eyes. OK? That's called covert attention\nbecause the input is identical. And you are just\nsomehow adjusting the dials on your\nperceptual system to pull up this or pull up that. OK? So that's called\ncovert attention. To be unconfounded\nfrom overt attention, which is actually the most\npowerful kind of attention. Overt attention, you\nmove your eyes from point to point to select\ndifferent information. OK, so overt attention is a\nmuch more powerful filter. And we make about two to\nfour eye movements a second. And it's very powerful\nbecause the center of gaze has very high\nresolution information. Remember high density\nof photoreceptors at the fovea in\nthe center of gaze, and the density tails\noff in the periphery. So we have much better\ninformation in the fovea than in the periphery. OK, so it's both\nphotoreceptor density, and it's also cortical area. So in retinotopic\ncortex, back here, primary visual cortex,\nV1, V2, those regions, you have about 20 square\ncentimeters of cortex, like that area of cortex-- pretty big-- something like\nthat processing the central two degrees of vision. OK? Huge cortical area devoted\nto a tiny little part of the visual world. And much less per degree\nfor the periphery. OK, so both at the\nphotoreceptor stage and at higher-level\nprocessing stages, we vastly over represent\nthe center of gaze. OK? That's why if you have loss\nof foveal vision and macular degeneration, it's really awful. You can't read or\nrecognize faces. That's where you need\nthis fine-grained foveal information. OK, so that means\nthat moving your fovea and parking it on different\nparts of the array is an extremely\npowerful way to select different kinds of information. So to give you a feel for\nhow much people do this and how they select\ninformation, here's a video. This is taken from a\nhead-mounted camera of a person who is\nwatching these two people. And the yellow dot is\nwhere their fovea is. So they're talking to\nmy former postdoc Matt. And they're fixating on\nhis face as he talks. And sometimes they take a\npeek at the other person. And you can see there's very\nfine-grained adjustments of where they look\nas this goes on. And now they're walking down\nthe hall in this building, and they're following her. Watch what happens when\nthey turn the corner. Check out the signs. Read the little notices. Look down the hall. And then watch what happens\nwhen they go around the corner. Oh, new person. Look at the new person. Right? Sorry, it's too dark to\nsee what's going on here. Oh, this is a little\nfixation patch where they're recalibrating\nthe eye tracker to figure out to make sure it's working. Here comes a new person. They look at his face. Saccade back and forth\nbetween the two faces, right? Whoever's talking,\nyou look at them. And you collect\nhigh-resolution information from that person's face. With both head turns, you\ncan see their both head turns and eye movements. OK, you get the idea. I didn't totally explain. So this is a head-mounted\ncamera and eye tracker, OK, of a person who was\nwalking around the building encountering people. And it was showing you both\nwhat was in their field of view and where they were fixating\ntheir eyes in that view. So you can see there's really\nfine-grained, moment-to-moment sampling of visual\ninformation all the time with overt attention\nwith eye movements, OK? Make sense? OK. OK, first, so that's the first\ndistinction about attention, covert versus overt. OK? Now, you might say,\nwhy would we bother with this subtle, sophisticated\ncovert attention when we can just move our eyes\nand do overt attention? And I think there's a\nbunch of reasons for that. One is other people can\nsee where you're looking. And there's sometimes you want\nto attend to stuff over there and not let people know, right? So there are many examples of\nthis from elevator eyes, people who look you up and down. It's not politically correct. It's not nice. It's not considerate. People notice if you do that. So don't do it. You can covertly attend\nbelow the face, if you like. But don't overtly move\nyour eyes down there because they will know. OK? We primates are\nvery, very attuned to where each other are looking. We are the only primate who\nhas whites around the eyes. I just heard a talk last\nweek by Michael Tomasello, who's one of the\nmajor primatologists. And he says that\nthe fact that humans have whites of their eyes that\nmake it so easy to tell where they're looking must\nmean that we mostly want to share information\nwith each other about where we're looking. We're a very cooperative,\ncommunicative species. But not always. Sometimes we want to\nsneak a peek at something where people don't know. The case that I\nnotice all the time is I'm at a conference and\nsome very familiar face comes along and\nsays, hey, Nancy. How are you? And I'm thinking,\nwho the hell is this? And the whole time, I'm thinking\nI can see the name right there. I can't quite resolve it. I know that if saccade\ndown for a half a second, they will see it. And I will be busted. And so I'm sitting there with\na name right there racking my brain trying to think\nwho the hell it is. Anyway, so there are many\ncases like this where we don't want to be caught looking. So those are all\ncases where you might want to use covert attention. Also, sometimes\nyou want to track lots of things in parallel, and\nyou can't foveate all of them. You can only foveate one thing. So I don't know\nanything about sports. But think of your favorite\ncomplicated sports example where there are multiple\nplayers moving at once and you need to keep\ntrack of all of them. That would be a classic\ncase of covert attention because you could covertly\nattend to several of them at once. And you have only one fovea. Well, you have two, but\nthey go to the same place. OK, so that's the\nsecond distinction overt versus covert-- or the first one. Right? So the next basic distinction\nof different kinds of attention are the kind where\nwe decide where we want to look versus the\nkind where the stimulus draws our attention, OK? So there are lots of examples. Like web pop ups\nare all designed to pull your attention,\novert and covert. Even you don't want to\nlook at that damn thing. But the weird, little\ndancing figure, they're all optimized to pull\nyour attention over and make you read the ad, right? And they're pretty effective. OK, so that's called\nstimulus-driven attention or exogenous attention. It comes from the outside. And it pulls you in. OK? Another classic\nexample is pop-out. If you look at this\ndisplay, it's very hard not to notice and have\nyour attention drawn to that red thing. Certain properties\nof stimuli that just automatically capture\nyour attention. OK, that is to be\ncontrasted with voluntary controlled attention. That's like the case\nwe did before where you were fixating on my nose. It was totally up to\nyou whether attend-- I mean, I told you to. But you could have\nmade up your own mind and attended to neither. And I wouldn't\nhave known, right? So you can decide what you\nwant to pay attention to. And as I think I\nmentioned in I don't know what context\na few weeks ago, thank God we can decide\nwhat to pay attention to. Because there's lots of stuff\nthat goes on in the world that we don't want to have\ndominate our mental life. And controlled or\nvoluntary attention is one way that we can have\nour mental life dominated more by things we want it\nto be dominated by and less by things we don't, right? So that's that notion here."}, {"content": "Like for example,\nyou're sitting here. And it's like noon. And you're just thinking,\nOK, I'm really hungry. I'm really hungry. If you were my dog Charlie,\nyour entire mental life for the whole next half an\nhour would be, I'm so hungry. I'm so hungry. I'm so hungry. But you're a person. And so that thought may\nimpinge now and then, but you can drive it away and\nthink about something else. Because it's not going\nto get you anywhere to focus on how hungry you are. I know I just made it worse."}, {"content": "I'm sorry about that."}, {"content": "OK. OK, the way that\nscientists have typically studied voluntary attention is\nthey ask subjects to do this. And much like the\ncase we just did, here's kind of very\nbasic paradigm. You have subjects\nfixating on a cross. And typically, in covert\nattention experiments, you want to make sure there\naren't overt eye movements. And so you'll have an\neye tracker to make sure the subject is keeping\ntheir eye on that cross. OK? And then you give\nthem a little cue that says pay attention\noff to the right, but don't move your eyes, OK? And then shortly thereafter,\na little cue comes up. And you have to hit\na button quickly that you detected the target. OK? It comes out at variable delays. So you can't just\nhit the button. OK, if you do that, you\nfind that the reaction time to detect that target, if\nit's where you're attending, is really fast, not much\nmore than 200 milliseconds, which is damned fast, right? Now consider a case where you're\ninstructed to attend over here. And the way you get\nthese experiments to work is that these cues are\nvalid 80% of the time. So there's a reason for\nsubject to-- there's a motivation for them to\nfollow your instruction. So they're trying\nto answer quickly. And there's like,\nOK, they're ready. It's almost certainly\ngoing to be over here. But oops. It's not."}, {"content": "OK? Then reaction time is almost\n100 milliseconds slower, which is a huge effect in\npsychology, 100 milliseconds. OK? OK, so you're much slower\nto detect something if it's at an\nunattended location. OK? And if you have a neutral trial,\nyou're somewhere in the middle. OK, so that is exogenous\nor voluntary attention. OK, and again, this\nis covert attention. No eye movements. All right, so third\ndistinction, the example I just gave you was\nspatial attention. You're attending to this\nlocation or that location in space. OK? That's probably the most\npowerful and common kind of attention is\nusually the things you're interested in are\nin a particular place. And you attend to that place. And there you go."}, {"content": "But it's not the only kind. You can have\nfeature-based attention. So if your utensil drawer is\na hell of a mess like mine is, like this, if your task\nis to find the black vegetable peeler, best of luck to you. It'll take quite a while."}, {"content": "It's in there. It's right there. But it takes a while, right? In contrast, if the task is find\nthe purple rubber spatula, duh, right? OK, so that's\nfeature-based attention. You don't know the\nlocation in advance. You know something about the\nfeature you're looking for, that it's black or that it's\npurple or round or square or whatever the feature is. OK, so different\nkinds of filters you can set on your\nattention system. OK, so that's just\nto give you some of the phenomenology of the\ndifferent kinds of attention. How does all this\nwork in the brain? I'm not going to tell\nyou how it works. We'll just focus mostly on\nwhat the brain regions are. OK, so let's go back to this\ncase here, voluntary attention. So now the question is, what\nhappens when you get this cue? You're not going\nto move your eyes. But you're kind of cranking\nup that part of space. OK, what's going on in\nthe brain right there before the stimulus comes on? Everybody get the question? OK, you can sort of\nfeel it happening. But what does that mean? Well, this is very amenable\nto a simple functional MRI experiment. And in the early days\nof functional MRI, a whole bunch of people at\nonce realize, oh, right, we can answer this\nlongstanding question of whether early retinotopic\nparts of the visual system are affected just\nby a cue like that, even before the stimulus\ncomes on, right? And I think it was 1998. A whole bunch of people\nstarted doing this in 1997. I was one of them. But a whole bunch\ndid it once in 1998. I think like six\npapers were published all doing versions of\nthis next thing, which is one of those obvious ideas. We got scooped. But anyway, everybody\ngot the same result. So basically, if you just\ndo a simple comparison-- this is the version they have. Subjects are fixating here. There's two stimuli. They're looking in V1 and V2. And if you just do a contrast\nof the case where you're looking here and you're\nattending, waiting for a target here versus waiting for a target\nthere without moving your eyes, you get a big contralateral\nmodulation in V1 and V2. This is a slice near the\nback of the head here. So this is a piece\nof calcarine sulcus or primary visual cortex, right? And so you can see, even before\nthe target stimulus comes on, just attending over there gives\nyou a big baseline increase in neural activity. Everybody clear\nwhat's going on here? And of course, you can\ndo the opposite one and see that it shifts to\nthe opposite side of space. OK?"}, {"content": "OK, so that's all before\nthe stimulus comes on. You can think of it as priming\nthe brain, kind of juicing up those neurons getting\nthem ready to go, so that, when that stimulus\ncomes through, boom. Your reaction time is faster. OK? OK, so that's modulating\nparts of visual cortex before a stimulus comes\non to get it ready. But we can also look\nat, what is the effect on a stimulus once\nit comes through, an attended stimulus or\nan unattended stimulus? To show you that,\nI'm going to show you a kind of feature-based\nattention and an ancient-- this is a paper we published\nin 1998, I think. This is a nonspatial version. So we gave subjects--\nguess what-- faces and houses and a\nlittle crosshair. And we had subjects\nin different blocks say whether the two\narms of the cross were the same or\ndifferent length, OK? So vertical one is\ndifferent length. So that's a different case. Whether the two houses\nare same or different or whether the two faces\nare same or different. OK, so actually, it's\nspatial and feature, when you think of it, because\nthey're in different places. OK? So we then looked in\na bunch of regions. I'll show you the data from\nthe fusiform face area. And the key thing about\nthis is, in all three tasks, we had the identical stimuli. So there's always\nfaces and houses and crosses in the same\nplace in your visual field, in all of those blocks. It's just a matter of\nwhich of those things you're paying attention to. OK? So what do you think we'll\nsee in the fusiform face area in this experiment? Is it going to care whether\nyou're attending to faces or attending to houses or\nattending to the crosshair? Same stimulus all the time. Yeah, Jimmy? AUDIENCE: [INAUDIBLE]\nwhen you're not attending. But when you're\nattending, [INAUDIBLE] NANCY KANWISHER:\nExactly what happens. OK, everybody hear\nthe prediction? You'll still get something. But you'll get more when\nyou're paying attention to it. OK, so here's the FFA\nresponse over time. Here's the time course. And these gray blocks\nare the blocks. These are the different\nattending to houses, faces, color, houses, faces, crosshair,\nhouses, faces, crosshair. The gray bars are\nwhen the subjects are attending to faces. Now, here, I actually\ncan't quite tell. Yeah, I can sort of tell. You can't see it on the screen. But there are little rest\nperiods between those blocks. So I'm trying to\nfigure out if you're right that there's some\nresponse greater than baseline. I think there's actually very\nlittle selective response greater than baseline. By design, we made this\na whopping attentional manipulation, so that all of\nthe tasks are really difficult. And when you're\ndoing one of them, you just barely feel\naware of anything else. In fact, I vividly\nremember the first time we ran this experiment, I\nwas a subject in the scanner. And I did the first block. And I was doing just crosshairs. And I went through the\nwhole crosshair thing. And it wasn't till the end\nof the experiment I realized, oh, right, there\nwere faces there. I was just completely\nunaware of them. So we designed it to really\nso tie up your mental capacity that you just didn't have\nprocessing resources left for anything else. And so if there is a response\nto everything else here, it's really low. But you can see, certainly, the\nattended thing is much more. It's much stronger\nin the attended case than the unattended case. OK? So this is a general property. Like basically, all of\nthe perceptual regions we've talked about are strongly\nmodulable by attention, OK, from retinotopic\nregions on up. OK, including V1 and, in fact,\neven including the lateral geniculate nucleus. So one synapse up\nfrom the retina, you're already modulating\nactivity there by attention. OK?"}, {"content": "I know I said this, but\nit maybe went by briefly. You have 10 times as\nmany connections down from cortex down to the LGN\nas you have going forward. OK? One of the things they're\ndoing is setting up selective filters, so that only\nthe stuff you want to process makes it to higher stages. OK, Yes? AUDIENCE: So does this\nsort of phenomenon generalize across\nthe brain areas? I mean, it's like-- NANCY KANWISHER: It's\ngenerally true of pretty much everywhere, yeah. AUDIENCE: It might be\nthe intuitive physics thing is justified. So it's better to see\nthe same stimulus. NANCY KANWISHER: Exactly. It's an instance of\nthis, exactly right. Exactly right. It gives us one\nof our paradigms. In functional MRI studies,\nhave the same stimulus, vary the task. OK? Some things don't work\nas well, things that are just very dominant stimuli. In this experiment, if we hadn't\nput the faces in the periphery and given subjects a\ndamn difficult task, the modulation\nwouldn't have worked. Because faces are\njust so dominant, they're going to punch through\neven if you don't want to, OK? Like web pop ups."}, {"content": "You also-- I'm going to skip this\nbecause we won't have time. You could get very\nsimilar things in primary auditory cortex\nlistening to high frequencies or low frequencies. These are all the same stimuli. This is voxel selected\nfor low frequencies, voxel selected for high frequencies. You have a high frequency\ninput in one ear, low frequency in the other. As you switch between,\nthose responses toggle. OK, so all of that tells you\nthe effects of attention, how it modulates activity\nall over the brain. But what is the source of\nattention signals in the brain? And that source is\na set of regions we have encountered\nbefore, sometimes called the frontal-parietal\nattention network, these blue and green\nbits up in here, back here in the parietal lobe,\nup here in the frontal lobe. And they are active\nwhen you shift attention from one location to another,\nfrom one feature to another, or when you do any difficult\nattention-demanding task. We've also talked about\nthem in the other context of the multiple demand system. It's pretty much the same\nset of cortical regions. That pretty much any time\nyou do a difficult task, almost no matter what the task\nis, these regions turn on. So they're not just\nabout visual attention. They're kind of about basically\ncontrolling your mind, right, selecting information, making\nyourself do difficult things. Who knows what that\nis computationally. But these regions are very\nsystematically engaged. And they're particularly\nsystematically engaged when you're shifting attention\nover different locations. OK, so just to remind you\nin contrast, everything else we've talked about, face areas,\nmusic areas, language areas, they're very specific\nfor one mental process, domain specific. These are the opposite. They're ludicrously\ndomain general. OK?"}, {"content": "All right, I'm going\nto skip the video. When the system is\ndamaged bilaterally, all kinds of weird\nstuff happens. OK?"}, {"content": "I'll post this. If you guys send me\nan email to remind me, I'll post this clip in. Balint's syndrome, where\nyou have bilateral damage back there in these\nparietal regions, people can only see\none object at a time. OK? They're looking at a\ncomplicated thing like this. And they would see, I see Shosh. See anything else? No just Shosh. Nothing else there? No. Just Shosh, right? Totally weird. Anyway, so they get\nlocked on one thing. They can't shift attention. OK. OK, I want to talk at least\nbriefly about awareness. So let's talk a little bit about\nneural correlates of awareness. And so first question\nis, if we want to study perceptual awareness\nand not just perception, how are we going to\nuncouple those things? We've sort of talked about a\nfew examples with attention. With attention, the\nthing you're attending to is at least much more\ndominant in your awareness than the stuff you're\nnot attending to, even if the other stuff\nseeps in a little bit. So that's one way, where you\nhave the identical stimulus. But you were varying\nthe degree of awareness. But another way-- oh, I need you\nguys to pass out the glasses. You want to both do\nthat at different sides? OK, so I'm going to\nshow you a stimulus. These guys are going\nto pass around glasses. And let me say in\nadvance, I want them back. I use these every year. So drop them off\nhere when you leave. OK, so what you're going to\ndo, you put them on either way. Doesn't matter. OK, so first, we're\ngoing to do optics. Nothing interesting. So look at this stimulus\nand close one eye. OK, now look at it\nthrough the glasses. Look at it through the\nglasses, and close one eye. And you should see just\na face or just a house. And if you close the other eye,\nyou should see the opposite. Does everybody get that? OK, that's not psychology. That's optics. The glasses are just\nfiltering one image into one eye and another\nimage into the other eye, OK? This is all this is is a way\nto get different information to your two eyes. OK, now just look\nwith both eyes. And don't do anything. Just kind of look. And if anything cool happens,\nyou can kind of go, ooh, aah. Or you can tell me\nwhat's happening. Just watch. Doesn't always\nhappen immediately. Yeah, Kwylie, what's happening? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: Sorry. What's that? AUDIENCE: Every time I blink,\nit changes from the house to the face. NANCY KANWISHER: Aha. OK, it changes from the house\nto the face only when you blink. Yeah, Kwylie? AUDIENCE: So at first\nwhen I first put it on, I was like I saw the house\nand the face superimposed. And then you told\nus put one eye. And then I opened both eyes,\nand it went from the house to the face. NANCY KANWISHER: Uh huh. Uh huh. And then did it stay there? Or does it keep flipping? OK, if this is not working\nfor you, don't panic. There's nothing wrong with you. It's hard to get everybody's\nred-green balance the same. Yeah."}, {"content": "Sorry. Question? Shardul, yeah? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: So I\nshare your intuition. I think I can choose too. But there's actually a\nwhole literature on that. And the guy I was collaborating\nwith on this project, 20 years ago, insists\nthat, actually, that's a wrong intuition. You can't choose. And I said, oh, the hell. The hell I can't. I'm in the scanner\nbeing your best subject ever because I'm\nswitching exactly when you want me to switch. Don't tell me I can't switch. He said, no, the\nliterature says you don't. Anyway, I don't know\nthe latest on that."}, {"content": "Yeah? AUDIENCE: Kind of related,\nit feels a lot harder to see the house than the face. NANCY KANWISHER: Yeah. AUDIENCE: I can see the face\na lot easier than switching. NANCY KANWISHER: Yes. It's not optimally set up, so\nthat it's perfect for each. Really the reason I do this\nis to amuse myself looking at all of you with your-- thank you. OK, so you can keep\nlooking or not, but I'm going to tell\nyou what's going on here. The cool thing\nabout this is when-- if it didn't switch\nfor you, the person-- is there anybody for\nwhom it didn't switch? One. OK, so maybe your color\nvision or who knows what. But anyway. OK, if it doesn't switch,\nthere's nothing wrong with you. The percept everyone else has is\nit just flips every few seconds from one to the other. OK. So what's cool about this\nis, when it switches, nothing changes on your retina. Only your state of\nawareness changes. And that gives us\na wonderful lever to study what goes on in the\nbrain when awareness switches, unconfounded from the stimulus. OK? It's like varying attention,\nbut it's more powerful. So of course, we put\npeople in the scanner. We put mostly me\nand a few others. But anyway. We popped ourselves\nin the scanner. We just taped these\nthings on our forehead, nice low-tech experiment. And we looked at\nthat exact stimulus. OK? And we scanned the\nbrain while people sat there watching the\nstimulus flip back and forth. OK? So this is a stimulus\nfor the whole experiment. This is the percept. It switches back and forth. The subject has a little\nbutton box, so they can say, now I see the face. Now I see the house. Now, of course, the choice\nof a face and a house was not random. Why did we choose\na face and a house? So that we could\nlook at the response in the FFA and the PPA. FFA loves faces, hates houses. PPA loves houses, hates faces. Perfect."}, {"content": "Right? So the question\nis, are they going to switch when your percept\nswitches, even though nothing's changing on your retina? What do you guys think? Switch? Switch? How many people think\nit's going to switch? How many people think\nit's not going to switch? A few."}, {"content": "OK, all right, so\nthat's what we did. Here is now the raw MRI time\ncourse averaged over the FFA and averaged over the PPA for\none five-minute experiment or three-minute\nexperiment in one subject. Probably me."}, {"content": "I forget. Again, stimulus is the\nsame the whole time. The letters are the times when\nthe subject pressed the button. And you can sort of get\na sense that there's a little bit of maybe like\nhere's a phase the FFA response goes up. Here again the house goes up. But it's kind of hard to tell. So really, the way\nto analyze these data is to take all the face\nto house flips, right, and align them and signal\naverage to get rid of noise. OK? So we can look at, what happens\nbefore and after a switch from face to house? And what happens in the\nopposite direction switch? Everybody get the idea? It's just a way to\nclean up the noise here. And here's what happens. This is time zero. The subject presses\na button saying that their percept has flipped\nbetween a house to a face. The response in\nthe FFA shoots up. And the response in\nthe PPA shoots down. Isn't that cool? OK, now why are these peaks and\nvalleys after the button press? Yeah. Evan, right. There's a delayed signal, right? OK?"}, {"content": "This is harder. Why do they come back\ntogether out there? Yeah, because it flips back. It flips back. And all we've done is signal\naverage to one button press. But there are different\ndurations of percepts. Sometimes it lasts\nthree seconds. Sometimes it lasts 10 seconds,\neverything in between. By the time you're\n12 seconds out, most people have flipped again. That's why it goes back. OK, make sense?"}, {"content": "Yeah? AUDIENCE: [INAUDIBLE] NANCY KANWISHER: I don't know. And I'm not sure that\nthat was generally true. I hadn't noticed that before. But we should\nscrutinize the images. I can't actually remember if\nthis was averaged over subjects or if this is one subject. I suspect that's a fluke. But we could look at it and see. OK, so the point of all of this\nis that these regions, the face area and the place area,\ncare about what you are experiencing,\nunconfounded from what's hitting your retina, right? They are reflecting the\ncontents of your awareness, not just what's coming into\nyour eyes, which is cool. OK, so that shows that\nthese regions kind of track awareness. OK? But can we find any\nevidence for perception without awareness\nusing neuroimaging? OK?"}, {"content": "So to make this point, I'm\ngoing to accelerate slightly, but I think there's\njust barely time. There are lots and lots\nof studies of this genre. And I'll tell you about one."}, {"content": "So I'm going to show you. I'm going to flash up a\nvery rapid series of digits. You have to get ready\nto write stuff down. Your task is to see if there\nare any letters in the digit. There might be zero. There might be one. There might be a few. Write down any letters you see. It's going to go by really fast. OK, everyone ready? OK."}, {"content": "Here we go. OK, write down any\nletters you may have seen. OK? All right, let's do another one. Everyone ready? OK, write down any\nletters you may have seen. OK? OK, raise your hand if you\nsaw both the A and the P in the first sequence. A few of you. Less than half. Raise your hand if you saw both\nthe X and the H in the second. Almost everyone. All right, well, I\ncheated slightly. But never mind how I cheated. The way you cheat in demos-- you guys will be\nteaching someday. You have the one you want\npeople to get wrong first. It's a total cheat. So it's slightly cheated. But if you do it right-- it didn't work last year. That's why I cheated. Anyway, even if you do\nit right in the lab, you get a really strong effect. There was only one\ndigit between the A and the P in the first sequence. And it's like your brain\nis still dealing with the A when the P comes along. You just don't even see the\nP. You're looking for letters. You don't see it. Whereas there were three\ndigits between the X and the H in the\nsecond sequence. And just to show\nyou some real data. So this has been done\nlots of different ways. Here's an example\nof this experiment. And this is the time that people\nget the second letter when they don't have to report the first. Well, the first\none's colored, right? So you either have to\nreport the colored letter and detect the letter\nafter it or just detect the letter after\nthe colored thing. So if you don't have to\nreport the first one, there's no dip in accuracy. Oh, sorry. This is a function of the\ndistance between the two items in the sequence. But if you do,\nthere's a big dip. That's maximal with\none intervening item. Yeah? OK, well, here it\nsays two or three. But anyway. OK, so that's called\nthe attentional blink. And the idea is there isn't\na physical blink of the eyes. But your attention\nsystem is tied up processing the first target. And it doesn't get\nthe second one, OK? So there are dozens,\nprobably hundreds of papers on this phenomenon. It's pretty cool. But for present purposes,\nwe're going to use it to say, does that unseen second\ntarget get into the brain? Presumably, it\nlands on the retina because you didn't blink. So it could probably get there. Probably got to V1. How far up the\nsystem did it get? Can you think of how we might\ntest this using functional MRI. How would we see how\nfar those stimuli go in an experiment like this? What would we use? What would we measure\nthe MRI response to? How could we design\na version of this that you could do\nwith functional MRI? We need some MRI response,\nwhere, if we get that response, we know that it's a response\nto a given stimulus. What would we measure? And what stimuli would we use? AUDIENCE: Well, we could\nuse faces or something. NANCY KANWISHER: Yeah. It's always the same. Yeah. Faces and houses. Lots of ways to do this. But it's not even my experiment,\nand they used faces and houses. OK, so they did a version\nof that very same thing. This is a bunch of\ngarbage flashing on. Early on, there's a face. The subjects have to\nsay which of those three faces they've studied it is. And then after that,\na scene comes on, or it doesn't come on. OK, they have to just\nsay, was there a scene? First of all, which face was it? And was there a\nscene afterwards? OK, so it's a variant of\nthe thing you just did. So here's the behavioral data. If you don't have\nto report the face, then you are very accurate\nreporting the scene. If you do have to\nreport the face, then you're very bad at it if\nthe scene comes right after. But if there's a big\ninterval in between, you do OK with the scene. Same thing we saw before but\nnow with faces and scenes. OK, that's the behavioral data. What do you see\nin the PPA, right? The second target\nis always a scene. So what you see\nin the PPA, here's a response in the PPA to that\nsecond scene if it's a hit. That is if you detect it, right? You correctly say, yes, there\nwas a scene in that trial. Here's a response\nwith a correct reject. There was no scene\nin that trial. And you correctly\nsaid there was not. OK, so that difference\nshows you the response in the PPA to a scene\nthat you've seen, that you detected consciously. But here's a critical case. I don't know why there's\na little pop up there. Anyway, this is a case\nwhere there was a scene, but you've said there wasn't. OK? That's called a miss. You missed it. It was there, and\nyou didn't see it. And what it shows you\nis two cool things. Well, first of all, it tells\nyou that the more aware you are of the stimulus,\nthe stronger response. But the crucial\nthing it shows you is this difference right\nhere, which is significant. This is a kind of perception\nwithout awareness. You did not detect the scene. You said there was no scene. But your PPA detected\nthe difference. Everybody get that? So we have evidence\nfor perception by the PPA at least of a\nscene without awareness. That make sense? So there are many, many\nstudies like this that kind of take it every which way. This is just one\nlittle example of how you can use neuroimaging to\nask, how far up the system does an unseen stimulus get? Make sense? OK, so we are about out of time. And I just gave\nyou a little taste of some of the work on neural\ncorrelates of awareness, showed you, with binocular\nrivalry, a neural response that's correlated with awareness\nunconfounded from the stimulus, uncoupling, again, perceptual\nawareness from what's hitting your retina, and, in the\ncase of the attentional blink, some evidence for\nperceptual representation without awareness. OK?"}], "21. Brain Networks": [{"content": "[SQUEAKING] [RUSTLING] [CLICKING] NANCY KANWISHER: Before we\nget on to the topic for today, I felt like last Monday's\nlecture was not my best. I don't know why. It's not that I\ndidn't put time on it. I looked and I had the wrong\nlecture numbers on slides. There was all kind of chaos. I'm sorry about that. Sometimes you put\nin a lot of effort, and you still give a lecture\nthat isn't all that clear. So let me try to tell you what\nI thought were the main points. I started off by saying why it's\nreally fundamentally important to be able to understand\nnot just what people look like from the outside, but what\nwe really care about people is what's going on the inside\nabout their thoughts and their beliefs. And we are constantly\nmaking inferences about what people know, and\nbelieve, and want, and think. And we do that all\nthe time to understand why they're doing\nsomething and to predict what they'll do next. And so it's\nfundamentally important. It's the essence of being\na human being in many ways. It's the essence of literature. And we do it all the time. And a classic way that people\nhave studied false beliefs is-- or thinking about other\npeople's thoughts is with the false-belief task-- the Sally-Anne task\nthat I described. And the reason people\nuse the false-belief task rather than just a belief task\nis if the beliefs are true, you can answer what somebody\nwill do based on the world, not based on their mind. And so to unconfound the\ntwo, we use a false belief that's different than\nthe state of the world. So we can be sure\nwe're asking people what will happen next based\non what that person believes. And through decades of use of\nthe Sally-Anne false-belief task and variations\nof it, it's clear that there's a very\ndistinctive developmental time course and ability to\nsolve this problem. Five-year-olds\nsolve it no problem. Three-year-olds\nsystematically fail. And people with\nautism typically get-- pass this task\nlate or not at all. High-functioning\npeople with autism pass the task, just\nlater, like 7, 8, 9 years, not five years old. OK? So that's the kind of\nbehavioral background evidence that there's something\ndistinctive about thinking about other people's minds. Then we considered\nwhether there's special brain mechanisms. And I argued that,\nyes, there are. There's a bunch of them."}, {"content": "But the most impressively\nselective one is the TBJ shown up there. And the evidence that\nit's specifically involved in thinking about\nother people's thoughts comes from the fact\nthat that activation is a greater activation\nwhen you think about-- when you solve the\nfalse-belief type problems, when you think about\nanother person's thoughts compared to when you think\nabout a representation, a physical representation,\nlike a photograph or a map, OK? So those are logically\nisomorphic problems. We have to always\nanswer a question about a representation. It's just the representation\nis in somebody's head or it's a physical\nrepresentation in the world. And in that difference, you get\nthat region of the brain, OK? So that's cool because it's\na very nicely designed-- it's not quite a--\nnothing's a minimal pair, but it's a minimal pair\nin some respects, right? It carves out whether\nthe representation is mental or physical, but\nit doesn't solve everything. And a suite of other\ntasks have shown that that region is actually\nspecific in a whole bunch of other respects. It doesn't respond just whenever\nyou think about a person. There are external properties. And most impressively,\nit does not even respond when you think\nabout their visceral body sensations, like thirst,\nand hunger, and pain. So the TBJ doesn't\nrespond to just thinking about any mental states\nof another person. It's specifically thinking about\ntheir thoughts and beliefs. And that's pretty damn\nremarkable, right? It's, how abstract can you get? And yet, here's a\nspecific brain region for that very abstract,\nvery specific thing. And the final little\nbit of evidence I showed you is that\nit also generalizes. It's not just about\nlanguage because you can show people movies\nthat have no words in them but that clearly show\ncharacters who must be thinking about each other's thoughts. And in those moments when\nthe characters are thinking about each other's\nthoughts, that region turns on, more, for example,\nthan when they're thinking about each other's pain, OK? Yeah. AUDIENCE: Did somebody\nlook at what happens if other people think about me? Or if I think they\nthinking about me? NANCY KANWISHER:\nYou mean if you're thinking about other\npeople thinking about you? AUDIENCE: Yeah, exactly. NANCY KANWISHER: Yeah, I would\nassume that that region would be engaged. I'm sure there are\nstudies on that. Because you're thinking\nabout their thoughts, right? AUDIENCE: But more? Is it more interesting? NANCY KANWISHER: Probably\njust because it's more salient, right? I actually, oddly,\nin this class, I talk about\nattention at the end, which is weird because attention\nis an issue with every study. But most of the brain\nregions we've talked about, surely, including this one,\nare modulable by how strongly you're attending to something. So if something's really\nsalient, or important, or you're really paying\na lot of attention to it, you're going to get\nmore activation. And if it's more\ninteresting to think about what other\npeople think about me than to think about what other\npeople think about each other, you'll find some modulation\nin here, I'm sure. OK, and then finally, I\ntalked about moral reasoning as a test case. It's not that the\nTPJ is selectively involved in moral reasoning. It's that many of the critical\naspects of moral reasoning depend on what a person\nknew at the time. And so to use that information\nin moral reasoning, you need to pull that region in. So I realized I wrote\nthat question ambiguously on the quiz. I meant to ask, is the TPJ\nengaged specifically or only in moral reasoning,\nto which they answer-- the correct answer would be no. But I didn't put\nthe \"only\" in there. And I decided it was ambiguous,\nso if you said \"yes,\" you got the points. Anyway, I gave several\nbits of evidence that, using the moral-reasoning\ncase, that the TPJ is-- it's stronger\nevidence it's involved in thinking about other\npeople's thoughts, first, that we showed\nthat people with autism will have this\ndifficulty in thinking about each other's thoughts. Even once they can pass\nthe false-belief task, they put less emphasis, less\nweight on what the person knew at the time when evaluating the\nmoral status of their actions, OK? It's not that they\nmake a mistake or that they're unable\nto morally reason. It's a pretty subtle thing. It's just a small\ndifference in how much they weigh what another\nperson knew at the time, OK? That's also known as less\nforgiveness or less exoneration for accidental harm, right? You kick somebody by\naccident, and they go ouch, well, maybe you get\na little bit of blame because you were a\nklutz and you should have thought or something. But it was an accident, so\nyou should be exonerated. People with autism exonerate\nslightly less, right? OK. So we then talked about\nthe fact that if you zap the TBJ with TMS,\nstick a coil there, you do the same thing. You slightly reduce\nthe weight people put on what the person\nknew at the time in their moral evaluation\nof the person's actions. And then I showed\nthis bizarre fact that, as I think\nGisella asked, well, shouldn't the TBJ be different\nin people with autism? Yes, absolutely, according\nto all of this, it should be. But the basic univariate\nmeasures-- how big it is, how selective it\nis, where it is-- do not find a difference\nin that region with that contrast in\nhigh-functioning people with autism. That's surprising. But one possible answer to\nthat is even though it's there and it's just as big and\nstrong and all of that, it's-- that doesn't mean\nit doesn't represent different information. And I showed you an example\nthat in typical people, you can decode from the TPJ\nwhether the person is reading about another person's\nintentional harm or accidental harm. And you can't in\npeople with ASD. OK? So that's my summary\nof last time. And then all of that was\nfocusing very particularly on the most fancy,\nquintessentially human aspect of social cognition, which is\nthis business of representing each other's\nthoughts and beliefs. But I pointed out at the\nend that there are also lots and lots of other\nfacets of social perception and social cognition,\nmany of which have somewhat selective\nbrain regions, lots of them other parts of the brain,\nand we just didn't have time to filtrate in to that, OK? Hopefully that was a little bit\nclearer than I was last time. OK, so, so far, in\nthis course, we've been focusing on all\nthese bits of brain that seem to do very\ndistinctive, often very selective things, OK? So the one we've just\nbeen talking about is that little guy right there. But we've talked about a\nlot of these things in here. And the field of\nhuman-cognitive neuroscience has invested lots of\neffort to find these things and try to characterize\nwhat each of them does. And that's pretty cool, right? This is all stuff we didn't know\n20 years ago, and it's nice, and it counts as real\nprogress, I think. But it leaves lots of\nthings woefully unanswered. None of these regions\ncan act alone, even though I've depicted them\nin a somewhat silly fashion, as nice little\nM&Ms on the brain. None of them act alone. None of them could act alone. They need information\nto process, so there has to be\ninput to each region. They need to be able to tell\nother regions what they figured out or there's no point. And probably, as\nthey solve a problem, as they conduct\ntheir computations, they're probably\ninteracting all the time with lots of other regions. So we desperately need\nto understand not just that this patch does faces. There's lots more\nwe need to know. And one of the things\nwe really need to know is, what is it connected to,\nand who is it interacting with? OK?"}, {"content": "OK. So that's what I just said. And so that means\nlooking at not just the cortex that\nwe've been focusing on through this whole course,\nthis dark matter that's on the surface of\nthe brain up there. But today, we're going to\ndo a figure-ground flip on the brain, and we're going\nto start paying attention to all that stuff that used\nto be background down there, all that white matter\nunderneath, which is like a big heap\nof myelinated fibers that connect long-range regions\nof the brain to each other, OK? So you might say,\nOK, just wires-- who cares about the wires? That was my attitude\nfor a long time. I've gotten over it. We desperately need to\nknow about the wires for all kinds of reasons. So I'm going to go through\na whole bunch of reasons. And there's a lot\nof little details, and I don't want you to panic."}, {"content": "I just want to give you the\ngist of why this is worth paying attention to. OK, so first of\nall, white matter makes up 45% of the human brain. So that alone tells you it's\nnot like some trivial thing. It's a big part of your brain. This is all the more\ninteresting because that's not true in other animals. So I think white matter\nmakes up a higher percent of the human brain\nthan any other animal, or at least we're way up there. In mice, it's only 10%. And maybe that's a relatively\nuninteresting thing about scaling with brain\nsize, but maybe it's something deeper about\nhuman brain-- what's special about the human\nbrain and nobody knows. And here's a fun fact. If you took all the myelinated\nfibers in the human brain and you laid them\nout end to end, you could go around\nthe world three times. So we've got lots of\ncableage sitting in here. OK. So I briefly argued before that\nyou simply cannot understand the cortex without understanding\nits connections of one region to another. It's just crazy to study one\nlittle patch of the brain and not know who it's\ntalking to and where it gets its inputs from. And as I just said, the\npressing need for that knowledge is heightened by the\npresence of this map, which we didn't use to have. Now that we have this\nmap, it's all the more important and pressing to\nknow what the connections of those regions are. OK."}, {"content": "So here's a nice quote\nmaking this point."}, {"content": "This is Heidi Johansen-Berg\nand Matt Rushworth. They say, \"Connectivity patterns\ndefine functional networks. The inputs to a brain region\ndetermine the information available to it, whereas its\noutputs dictate the influence that brain region can\ncan have on other areas. Therefore, simply by knowing the\npattern of inputs and outputs of a brain region, we can\nbegin to make inferences about its likely\nfunctional specialization.\" So I think that's a nice quote. It makes the point that\nit's not just that we need to know the connections,\nbut the connections and the function are bound\nto be deeply enmeshed. One constrains the other. Yeah?"}, {"content": "OK. Further, recall way\nback, which will quite possibly return on\nthe final exam-- how do we define\na cortical area? I gave you criteria\nfor a cortical area. And one of the criteria\nwas a distinctive pattern of connectivity, right? So it's part of the identifying\nproperties of a cortical area is what it's connected to. And so that's another\nreason we should care. A third reason is if we knew\nof a given cortical area what its long-range connections\nwere to lots of other regions, that connectivity\nfingerprint-- remember we talked briefly about\nconnectivity fingerprints a month or so ago? That fingerprint,\nthe distinctive set of connections of that region-- you can think of\nit as a signature of not just how\nthat region differs from other regions in\nthat same individual brain but how we might find a\nhomolog of that region in another species. And that would be a very\ninteresting thing to do. Wouldn't it be cool to know,\nis there a TPJ in macaques? Well, macaques can't\nsolve an analog of the theory-of-mind task. Chimps-- we could\ndebate a little bit. And narrow domains-- kind\nof sort of, a little bit, not really. Macaques-- no, OK? So is there a homolog? Is there a corresponding\nregion that-- maybe we took that region, and\nwe adapted it and made it work better so we could\ndo better things with it? And if so, what is it\ndoing in macaques, right? I mean, I think that's just\na totally cool question. And in principle,\none way to say what counts as \"the same region\"\nacross species, which is kind of a weird question. They're different\nspecies, so what would \"the same region\" mean? One way to say what\nthe same region means is to have a similar\nconnectivity fingerprint, OK? So there are several\nstudies that try to do that. I couldn't cram them\ninto this lecture, but if you're interested\nin reading on it-- reading about it, shoot me an email. I'll send you some papers. OK. I also mentioned that the\nspecific set of connections of a cortical region,\nparticularly its inputs, play an important\nrole in development. Remember the rewired ferrets? If you redirect\nthe input to what would have been primary\nauditory cortex in a ferret and you have that input\ncome in from the eyes, you can get what would have\nbeen primary auditory cortex to become a lot like\nprimary visual cortex. So connectivity is\nimportant, not just in how a region\nfunctions and how we say what counts is\nthe same across species but is probably also\ncrucially important in the development\nof regions, OK? I also showed you evidence that\nthe visual word-form area-- we can pick out\nexactly where it's going to land in\nan individual brain by the connectivity\nfingerprint of that region before kids learn to read,\nfurther evidence that connectivity determines\nlater function. OK. As if this is not\nenough, other reasons to care about white\nmatter is that disruptions of white matter are at the root\nof many clinical disorders-- dyslexia, autism, developmental\nprosopagnosia, amusia, all of these things and\nothers, for all of them, disruptions in long-range\nwhite-matter connections have been implicated as possibly\nplaying an important role in the etiology of that disease. Aging-- most definitely\ndecline in white matter is prominent in aging. Sorry to say, there's a 10%\ndecrease in white-matter fibers per decade starting at age 20. Use yours now while\nyou have them."}, {"content": "Let's change the topic."}, {"content": "OK. There's a lot of talk about how\nwhite-matter connections may change with experience, and\nlearning, and plasticity. And that's a pretty\npatchy literature. And it's not a very\nimpressive literature. The classic thing you\nprobably learned in 9.00, that when you juggle, you\nget changes in white-matter connections from\njuggling expertise. Maybe. Maybe not. There's some problems with\na lot of that literature. So it's an interesting\nquestion, but it's not clear what the strong answers are. And finally, I don't know\nabout circuit design. Probably some of you do. But I gather that\npeople who think a lot about circuit design-- one of the key features you\nneed to take into account is wiring length. You want to keep wiring\nlength short, right? You have conduction delays. You have heating. You have space taken\nup in circuits. All of those things are\nbad in circuit design, and they're bad in\nbrain design too. So a lot of reason to think that\na major factor in the design of brains, especially\nhuman brains, is minimizing wiring length\nbecause wiring length is very expensive metabolically. You've got to\nmaintain ion gradients across cell membranes. It's expensive developmentally. These damn things need to\nfigure out where to go, and if they don't go\nto the right place, you have a\ndevelopmental disorder. And so it's probably\na real constraint on designs of brains. OK, so that was a\nwhirlwind-- lots of reasons to care about\nwhite matter and connectivity. Oh, plus, at least\nin animal research, there's a whole suite\nof amazing new methods for looking at connectivity\nin animal brains. And [INAUDIBLE] can\ntell us more about that than I could\nbecause she's working in a lab that's right at\nthe forefront of developing those methods. Someday, we're going\nto apply those methods to a human brain-- I can't wait-- and get\nthe whole wiring diagram. OK. Anyway, so what do we know\nabout the connectivity of these regions? Well, you may be thinking, don't\nwe already know all this stuff? After all, I showed you\nthis diagram way back. And you've probably seen\nit every damn course you take in this department. It's in most textbooks\nin the field-- the whole wiring diagram\nof the visual system. So don't we already\nknow all this stuff? So what's the big deal? Well, here's the big deal. That's a macaque brain. And in macaque brain, you\ncan get the actual answer to what is the actual\nstructural connectivity of this patch of cortex\nto that patch of cortex. There's a whole\nbunch of methods, but traditionally, you\ninject some dye here that's uptaken by\nneurons that travels along axons that goes here. You kill the animal,\nslice up the brain, and find that tracer over here. And then those two things\nare absolutely connected. That's the gold standard. And that's the basis of most\nof those studies, that method and variations thereof. But we can't do that\nin human brains. And so we do not have\nanything like this information in human brains. Yes, David. AUDIENCE: When was this done? NANCY KANWISHER: Oh,\nthat is a compilation. This was published,\nin, I think, 1991. But that was a compilation\nof heaps of studies that have been done before that. It was a big review\narticle looking at all of this literature, where\nlots of classic neuroanatomy people would do these\nthings where they would inject tracers,\nand slice up brains, and look in other places. And it was just a vast\namount of literature that did that for many decades. It's sort of fallen\nout of favor, even though these\nthings are, at least-- I don't know-- these are\nreally crucial questions. Now people use other\nmethods to do that. You can use all kinds of\noptogenetic and other methods to map connectivity in animals. Yeah."}, {"content": "AUDIENCE: I have a question. [INAUDIBLE] NANCY KANWISHER: In here? Oh, that's a good question. Oh, it's probably dorsal\nand ventral pathways. Let me see here."}, {"content": "Yeah. Yeah, the red ones-- this is another thing I didn't\neven really mention, probably let alone give a\nshort [INAUDIBLE].. That was lame. But anyway, the visual-- high\nlevels of the visual system-- we focused on the\nventral visual pathway coming down the bottom\nof the temporal lobe. But there's a whole\nother visual pathway that goes up into the parietal lobe. Did I talk about that a little\nbit-- reaching and grasping? No, I didn't. Lame, lame, lame, lame. Anyway, a major part of\nthe field I didn't get to. Anyway, it's a whole other\npart of the visual system that seems to be more involved\nin visually guided action. And they're actually\nvery interconnected, but they're trying to emphasize\nthat the dorsal pathway is at least somewhat\nseparable in monkeys. But my point is this\nis monkeys where they have the\ngold-standard methods, and they can actually discover\nthe real connectivity. Sadly, we can't do\nthose things in humans. And in humans, we have only\nthree methods, and none of them are very good. So we'll talk about them\ntoday anyway because this is such an important\nquestion, but the bottom line is-- this drives\nme out of my mind-- we basically don't know\nthe connectivity of any of those regions for\nsure in human brains. And somebody's\ngot to solve that. Maybe one of you will\ngo invent a method that works in humans that helps us\nsolve that problem because it's actually, I think, really\nparalyzing to our field. So I'll tell you what we\ndo know, which isn't much. But, you know, beggars\ncan't be choosers. OK, the first method has\nbeen around for a few years, and that's gross dissection. And I mean gross, like\nthat kind of gross-- so only good for\npost-mortem brains, but it's really quite amazing. This is a bottom view of\nthe brain back and front. This is actually a\nphysically dissected brain. Like, it takes a real\nserious neuroanatomist and lots of fancy methods-- I mean, not fancy\nmethods but lots of careful, precise teasing\napart of bits of brain. And you can actually see these\nbig fibers coming up here. So if this is the\nback of the brain and we're looking\nup like this, what do you think those fibers\nare connecting right there? Big fiber bundle coming\nfrom deep down in the brain up to right in there. AUDIENCE: Is that\nthalamus to [INAUDIBLE]?? NANCY KANWISHER: Bingo. Exactly. OK, so that's the\nLGN right there. And this is called\nthe optic radiation. It's this huge cable\nof fibers that come up. OK, first, here's\nthe optic tract. Actually, I forget. That's not-- I think this\nis the optic tract that's been snipped there. Then it comes up in here,\nmakes a stop in the LGN, and then this big\nbatch of fibers comes up right there to\nprimary visual cortex, OK? Everybody got that? OK, so you can actually see\nit in dissecting a dead brain. OK, that's pretty cool. But what if we don't want\nto wait for people to die? Often, we want to ask\nquestions about a person right now in their brain. Do they have this disorder? Are they at risk\nof that disorder? What is their connectivity? So for that, we\nhave two methods, and I'll talk about\nthese two methods in the rest of the lecture. The first one is\ndiffusion imaging. OK, so I talked about\nthis briefly before."}, {"content": "But let me remind you of what\nthe basic principles are. So here is a picture of the\noptic nerve with a bunch of axons oriented like that. It's a big cable\nwith a whole bunch of little fibers in there. And the basic kind\nof biophysics is that water wants to diffuse more\nalong this length, following the orientation of\nthe fibers, than it wants to diffuse this way, OK? And diffusion imaging-- I'm not\nexplaining any of the physics, but just take it for my word\nthat what diffusion imaging does is give you a picture\nof the direction of water diffusion, OK? So you get a picture\nof a piece of brain, and it'll show you, for\nexample, that right in there, all the fibers-- well, the water is\ndiffusing this way. And over here, the water's\ndiffusing that way, OK? And that's just what you see\nin a diffusion image, OK? And so the inference\npeople make is if you have all those\nparallel lines telling you there's lots of\ndiffusion like this, there's probably a big fiber\nbundle going like that-- and there is. That would be the\ncorpus callosum. OK?"}, {"content": "All right. So this method works great for\nfinding the big fiber bundles. OK? I'm going to dis diffusion\nimaging in a bunch of ways, but it is great for\nfinding the big fiber bundles because in\nthose big fiber bundles, axons are very parallel. There's a whole bunch of them,\nand you can really see it. OK. And so people have\nbeen using this for over a decade to find\nsome of the major fiber bundles in the brain. So you may have heard of\nthe arcuate fasciculus that basically connects language\nregions in the temporal lobe up to Broca's area in\nthe frontal lobe, OK? It's a big bunch\nof fibers that go-- I guess in me, they go\nlike this, boom, right? [INAUDIBLE] And you can\nsee those guys with-- this is a distant reconstruction,\nbut you can see those with diffusion imaging. Another one, the goes from the\nfront of the temporal lobe up to the frontal lobe. You don't need to\nmemorize these. I don't care about that. I just want you to get the\nidea of what you can see. Yeah, question? AUDIENCE: So these are\ndiscoverable without the person having to do\nanything [INAUDIBLE]?? NANCY KANWISHER: Yes. Yes. These are anatomical images. So in diffusion imaging,\nyou don't do anything. You can sleep, actually. That's ideal because\nit's long and boring. Actually, it's not\nboring, but the scanner shakes like hell in a\ndiffusion-imaging scan. It's pretty wild. We could charge\nadmission for it. I don't know."}, {"content": "I find it quite wild. Anyway, this is the inferior\nlongitudinal fasciculus. As it goes down\nthe temporal lobe. So when we talk about the\nventral-visual pathway-- face areas, place\nareas, all that stuff-- this is the big fiber\nhighway that sits right on top of that whole\nchunk of gray matter that does all the processing. And it's a big pile of\nfibers that go straight down the temporal lobe, OK? OK."}, {"content": "And so here's more recent data."}, {"content": "This is from Anastasia Yendiki\nover at MHG Charlestown over there. And she's developed this\nlovely piece of software that enables you to take\ndiffusion images and identify, based on an atlas\nshe's put together, 18 of the major fiber\ntracts in the human brain-- so nine per hemisphere. And this is just showing\nyou some of the big ones. This is the inferior\nlongitudinal fasciculus I just showed you and so forth. Yeah. AUDIENCE: So how does\nthis compare to just a postmortem dissection? Could you see the-- NANCY KANWISHER:\nIt's a good question. It's a good question."}, {"content": "I don't exactly know. It wouldn't be easy. That thing I showed\nyou works because you take the stuff off\nthe top, and it's just kind of sitting there. But then you would have taken\na lot of other stuff out, and you wouldn't be able\nto see that other stuff you had to take out. You know what I mean? So here, you can surf through\nand pick out any of these. So it's definitely\ngoing to be better. But which of these you can\nsee with postmortem dissection I'm not sure-- some of them,\nsome of the bigger ones but probably not all of them. OK, so here are some\nof the major tracts. OK. But you can do a little bit\nmore than just find them with diffusion imaging. You can also characterize\nthem a little bit."}, {"content": "And this is a whole universe."}, {"content": "There's people who\nspend their lives with all kinds of\nfancy measures, and I'm just going to tell\nyou about the most common one. So recall that the whole\ndeal with diffusion imaging is it's looking for orientations\nof maximum water diffusion. So some parts of the brain\nhave a systematic set of directions of\nwater diffusion, and other ones don't, right? Inside a ventricle, the\nwater can go any which way. There's nothing determining\nwhich way it goes. So this is called\nisotropic because you have diffusion going equally-- in equal amounts in all\ndirections and anisotropic, right? So it goes systematically\nmore in one direction, one axis than others, OK? Diffusion can't see the axial\ndirection, like left or right versus to left. It can just see\nthat this axis is more prominent than this one,\nor this one, or this one, OK? So you're not actually seeing it\nmove in a systematic direction. OK, so that's the basic signal. So what you can do is in\na little patch of brain, you can ask not\njust, what direction has maximum diffusion,\nwhich is what I've been talking about so far. You can say, how much more does\nit go in that maximum direction than any of the others? Is it more like this\nor more like that? And you can imagine a\nwhole spectrum in-between. OK, so you're just asking,\nhow oriented is it? Is it totally oriented\nor just partially? And that measure is called\nFractional Anisotropy, or FA. It's prominent enough in\nthe field you should just learn this phrase. And you read any\narticles, especially any clinical articles,\nthis is the first thing you'll see in any\nclinical papers that use diffusion imaging. OK, and so fractional\nanisotropy-- there's a bunch of fancy definitions. And we don't care. We just want the idea. It's just, to what degree is\nthat little patch of brain in this little part\nof a tract that you've identified more like this\nor more like that, OK? Is it anisotropic or isotropic? OK? And so this has been\nused a lot to try to ask about the nature of fiber\ntracts in different groups-- young versus old,\ndifferent clinical groups, autism versus typical,\nschizophrenia, you name it. Experience-- you train\npeople up on a task-- do you change the FA, the\nFractional Anisotropy, of some particular tract. OK? So it's just a\ncharacteristic of tract is, how oriented is\nit along the way? Is it super clean,\ntotally oriented? Or does it have some\nisotropy mixed in? OK? All right, so this is\nall over the literature."}, {"content": "Let me give you one cool\nexample from Gabrielli lab that came out recently. So they identified the arcuate\nfasciculus that I showed you before, going from the--\nbasically, Wernicke's area curving around\nup to Broca's area up there so that you can\nidentify it anatomically in each subject\nindividually, OK? Now you've got it. You've identified\nwhich voxels are part of the arcuate fasciculus. And then what they want to ask-- what they wanted to ask\nis, is the integrity, or the characteristics of\nthe arcuate fasciculus-- is that important for\nlanguage-- for dyslexia? So they measured the\nFA along this tract. How oriented is it all\nthe way along here? And then you get\nsome kind of average. And they measured that\nin a bunch of kids with dyslexia and in a bunch of\nkids with no reading disability who are matched in\nother dimensions of non-verbal\ncognitive ability, OK? And what they found is\nthe fractional anisotropy was higher in the typical\nkids than the kids with reading disability,\nwith dyslexia, OK? And from that, they implicated\nthat this connection may play some role in dyslexia. OK? It's not totally\nobvious because one would think this region is\nconnected to that region-- those are languagey\nregions, right? It's not visual regions. You think of dyslexia as a\nproblem seeing the letters and which ones are\noriented which way. And this suggests\nthat, at least, higher-level connectivity\nbetween language regions may be implicated, OK? Yeah. AUDIENCE: So this just\ntalks about the architecture and not the per unit\ninformation being [INAUDIBLE]?? NANCY KANWISHER: That's right. AUDIENCE: There's no\ninformation [INAUDIBLE].. NANCY KANWISHER: That's right. It's just saying,\nwhere are the wires, and how organized are the wires? Period."}, {"content": "Yeah. AUDIENCE: So they won't\nflow through some technique as-- if I can mess\nwith it, like I'm measuring it, if\nthere's some means to miss the\n[INAUDIBLE] diffusion, will that have any effect? NANCY KANWISHER: I\ndidn't quite get that. Say it again. AUDIENCE: So there's\nthis water diffusion that's happening that\nI'm going to measure. But what if I have some\nway to intervene and change the rate of diffusion some such? NANCY KANWISHER: I don't\nknow how you'd do that. I mean, it's a pretty\nbasic physical property-- diffusion of water and how it's\nconstrained by lipids, right? AUDIENCE: But that\nshouldn't affect, like the function of\ninformation flow [INAUDIBLE]?? NANCY KANWISHER: Ooh."}, {"content": "I have no idea. I mean, that's a biophysical\nquestion I don't know about. But notice, this is a\npretty distant proxy. You're mostly looking at\nwater between axons, not even within them. And so it's just a proxy\nfor, how well can we see those fibers and how\nthey're oriented, OK? Yeah, it's pretty removed\nfrom actual signals going along the wires. Anyway, so everybody get\nthe sense that-- you know, it's one little finding. But it implicates something\nabout that tract in dyslexia. OK, so that's interesting. But first, it's\njust correlational. Lots of things are\njust correlational. Most of the stuff in this\nclass is just correlational. Same is true here. But a little more\nseriously, it's not totally clear what\nfractional anisotropy means, OK? So there's a real\ntradition of treating high-fractional anisotropy\nas if that's good. After all, we're\nin a fiber bundle. Shouldn't all the axons\nbe oriented nicely in there and not all scrambled? Surely, oriented is good,\nand scrambled is bad. Well, maybe, but sometimes,\nfibers cross a fiber bundle. So you can have a fiber bundle\nlike this with other fibers crossing it. And so when that happens,\nmaybe that's good. And so people use FA as\na proxy for good fiber. People say \"fiber\nintegrity\" even. But there's a whole question\nabout what exactly it means. People will spend\ntheir lives looking at the biophysics of fibers\nand all the different things that fractional anisotropy and\nthe other measures might mean. And it's actually pretty\ncomplicated and unresolved. Another challenge with\nfractional anisotropy is it's extremely\nvulnerable to artifacts. All of diffusion\nimaging is extremely vulnerable to artifacts, OK? And I'm going to give you\nan example of a study we did a few years ago. So I was, for a while,\ntrying to work on autism. I've, more or less,\ngiven up because it's, as far as I can tell, impossible. But back while I\nwas still trying, we scanned a whole bunch of\nkids with and without autism with diffusion imaging, OK? And at the time, there were\nabout 50 published papers, almost all of which said one of\nthe things you find with autism is that there's an\nunderdevelopment of long-range connectivity\nand an overdevelopment of short-range connectivity. And so then people\nwould free associate with all kinds of\nspeculations about, OK, this explains aspects\nof the autism phenotype. They can't put\ndifferent ideas together because their connections\nacross the brain aren't as good. And they're obsessed\nwith little details because they have too many local\nconnections and all kinds of-- suggestive, but very, very\nfuzzy ideas like that. So 50 papers pretty much all\nfound underdeveloped lower fractional anisotropy and\nlong-range connections, long-range tracts in autism,\na very established finding So we went in not to\nraise hell but just to kind of replicate\nsome of those basic findings while\nstudying some other things. And, in fact, when we did\nwhat everyone else does-- that is standard analysis-- you collect your\ndiffusion-imaging data, and you eyeball it\nloosely, and if it really looks terribly\ntainted with artifact, you throw that subject out. And, otherwise, you keep it,\nand you analyze your data. And you look at, here\nare the 18 fiber tracts that I showed you before. And you ask, which of\nthose have higher or lower fractional anisotropy\nin kids with autism compared to typical kids? And the basic finding-- we replicated the usual finding. And that is, overall-- this is column A--\nmost of those tracts showed lower\nfractional anisotropy in the kids with autism\nthan the typical kids, OK? Many of those differences\nwere individually significant in\nindividual tracts. Those are the ones\nwith the asterisks. OK. So that's the standard\nfinding in the literature, and we replicated it. However, we noticed\nthat a lot of the data really seemed suspect. And we started\nmeasuring the amount of head motion between the\nkids with autism and the kids without. And guess what. Kids with autism move in the\nscanner more than kids without. And guess what. Diffusion imaging and fractional\nanisotropy in particular are highly influenced\nby head motion. So then we said, OK, let's\nget a little more careful. And so we did a more\nstringent analysis. And we looked at the kids. We had quite a few of\nthem in each group. And we took the subset\nof kids who we could match for head motion, OK? So now we've got the kids with\nautism and the typical kids, but we've now got the\nsubset we have to choose to match for head motion, OK? It usually means the typical\nkids who move a little more and the autistic kids who had\nslightly less head motion. That's what you need\nto do to match them. And when we do that, the\nusual pattern disappears. Now there's only a\nsingle tract that shows lower\nfractional anisotropy in the kids with autism\nthan the typical kids, OK? The inferior\nlongitudinal fasciculus. So that's worrying. But then further, we thought,\nOK since many of those kids we had, especially the\ntypical kids-- many of them we had scanned twice. So we thought, OK, let's\nreally make this case. This is clearly a\nproblem in the field."}, {"content": "In fact, it's a broader problem. Pretty much any comparison\nacross age groups or clinical groups-- one group moves more\nthan the other group. Uh-oh. What about the\nentire literature? Hundreds, probably thousands\nof published papers, essentially, none of which\npay attention to this-- this is 2014. People have cleaned up their\nact since, but up until 2014, almost none of them\npaid any attention to this whopping problem. So we figured we better\nmake this point salient because there's a\nlot of money and time being wasted publishing garbage. And we want to make\nthe point saliently. So we took the typical kids\nwho we had scanned twice, OK? And sometimes a kid\nwill-- the same kid will move more in one\nsession than another session. So we said, OK, let's\ncompare the very same kids on the session where they\nmove more than the session where they moved less. And you know what? We replicated the\nautism phenotype. Those were typical\nkids, not autistic kids. The point is head\nmotion alone will reduce fractional anisotropy\nand will look a whole lot like a clinical disorder. And so every time you see that\na clinical disorder is marked by some anatomical difference,\nyour first thought should be, how carefully did\nthey deal with head motion and other\nartifacts that are going to differ between groups? OK? So I say that not to dis\nthe entire literature but just to alert you that\nthese things can really matter. The paper from Gabrielli\nLab that I just described-- I looked, of course, before\nI presented it in here, and they cited us, and\nthey used our methods for matching head motion-- good for them. So these things\nare changing, and I think the field will\nstart cleaning up its act. But it's amazing\nit took this long."}, {"content": "OK. All right, so\nfinding fiber tracts and characterizing them\nwith fractional anisotropy are nice, but, really,\nwhat we want to know is what's connected to what, OK? Which of these things are\nconnected to each other? Which other brain regions\nare they connected to? And so to find that out,\nwe need to not just study white matter itself\nand the tracts, but we have to get\nout of the tracts and into the gray matter. So we need to start in\na patch of gray matter and figure out where we can go\nby following those axons, OK? And so the method for doing\nthat is called tractography. So there are many\nversions of this."}, {"content": "I showed briefly\nthese pictures before."}, {"content": "I'm sure you've seen these. The simplest idea\nof what you do, leaving out all\nthe details, is you start in some\ngray-matter region, some voxel in the gray matter. You want to know what\nit's connected to. You just follow those little\norientations, and you can-- you see where you can go. OK? And so that's basically\nhow you make this diagram. OK? You're just following those. You start over here you follow\nthe orientation-- go do, do, do, do, do, do, do, right? OK? I mean, you do that\nin a computer, right? An algorithm does that,\nfollows along-- ch, ch, OK? OK, so that's\ncalled tractography. And the idea's\nawesome-- how great to be able to see what's\nconnected to what. And there are many,\nmany thousands of papers that do\nthis for good reason. We need to know what's\nconnected to what. This is our\ncurrently best method for looking at the\nstructural connectivity of different gray-matter\nregions to each other. And so you can ask,\nfor example, OK, let's put a seed in\nthe fusiform face area and see where it goes. Wouldn't that be cool? Right. Wouldn't it be cool? Unfortunately, it doesn't work. So I have to tell\nyou that I don't know if I'm the best person\nto report to this because I'm not-- I've only been trying to\ndo this for a few years. But, I've been collaborating\nwith the best people in the world over there\nat MGH Charlestown who are working closely with us. And we can't get this\nthing to work worth a damn. And so now I'm actually confused\nwhether the entire literature is garbage. I don't think it's\nentirely garbage. But I think it's full of\noveroptimistic evaluations of what you can tell\nfrom tractography because in our hands, we\nstarted with reality checks, put a seed in the lateral\ngeniculate nucleus. Let's make damn sure\nwe can get up to V1."}, {"content": "Well, you can get\nup to V1, but you can get up to V2,\nand V3, and V4, as well, which are\nall wrong, right? LGN only goes to V1. Worse, you stick a seed next\ndoor in the medial geniculate nucleus, which is the part\nof the thalamus that goes up to auditory cortex,\nyou also end up in V1. Wrong."}, {"content": "Wrong. Wrong."}, {"content": "Wrong. There's not very many anatomical\nconnections in the human brain where we actually know\nthe right answer where we can do these reality\nchecks, but of the ones we know that we've\ntried, it doesn't work. And we're using the best\ndiffusion-imaging scanner in the world. It's right over there. So maybe I'm doing\neverything wrong. But at the very\nleast, I think there are a lot of problems\nwith this method. This is not just me\nworrying about this. And many people\nhave been worrying about this for the whole 15,\n20-year life of diffusion tractography. And some of the challenges\nare, like, famous. So to follow those\nlittle orientations, you need to-- you can see,\nlike there'd be lots of places where, OK, there's a bunch of\ndifferent ways you could go. It's ill posed, right? So people use heuristics to\nconstrain those solutions. And those heuristics\nare based on assumptions about how fibers bend\nin the brain, namely that they don't make\nreally sharp angles, right? That's reasonable. Most of the time they don't,\nbut sometimes they do. And in particular, when\nyou're going from white matter to cortex, often, you\nmake a very sharp turn. And so it's very, very\ndifficult to figure out how to get from a\ngiven gray-matter patch into the underlying\nwhite matter exactly what the connectivity is. So that's one problem. Another famous problem\nwith tractography is called the\ncrossing-fiber problem. So imagine a bunch of axons\nsomewhere in the brain that cross like this versus\nimagine a bunch of fibers in the brain that come up to\neach other and then go apart, OK? Everybody get this? The connectivity's\ntotally different here-- no way you're ever going\nto distinguish those with diffusion tractography. So people try to get higher\nand higher resolution to see down those individual\nthings, but they're not there. Yeah. AUDIENCE: Why would\nsomething like that happen? NANCY KANWISHER: Yeah,\nwhy would they do that? Weird stuff happens\nin the brain. So it's not incredibly common,\nbut it's not unheard of. Yeah, remember, the\nbrain wasn't dissolved-- designed now optimally\nto solve all the problems it needs to solve with the\noptimal solution from scratch. It evolved gradually over time. And so there are all\nkinds of weird things that are workarounds for\npre-existing decisions that evolution made earlier. And so both brain and body\nhave lots of bizarre attributes that aren't how you would\ndesign it from scratch. They're just the fix that\nevolution made at that point given what had\nalready been fixed. And so there's weird\nstuff like that. Anyway, I mention\nthis to say I'm more negative about diffusion\ntractography than probably anyone else because I've spent\na lot of the last two years trying to do it, and it's\nbig bust, and I'm cranky. So it's probably not as\nbad as I'm laying out. Plenty of people do it. They get some kind\nof answers out of it, but it's problematic at least. My best guess is that it\nis OK for fingerprints. If you're asking, OK,\nhere's some patch of brain. How much does it connect to,\nsay, these 85 other regions? And is that different than the\nfingerprint for this region? That's probably OK because a lot\nof those individual solutions might be wrong, and there's\nstill enough left over to see a kind of difference. So I feel like you can--\nconductivity fingerprints are probably worth doing. But, actually, just\nanswering the question of, is there a structural\nconnection from A to B-- I don't know. I can't get it to work. OK? OK, so I think I did all\nthis before just to-- conductivity fingerprints--\ndo you remember this? You start with\none place, and you measure how well you can\nget from each location to each of these other ones. And I showed you\nbefore that the work of Zeynep Saygin and a\nbunch of other people has shown that you can--\nactually, in an adult, you can predict where\nthat adult's fusiform face area is just from their\ndiffusion tractography data alone because it has a\ndistinctive connectivity fingerprint, OK? I don't want to go\nthrough all that again. Do you guys remember that,\nmore or less, the gist? OK, so that just\ntells you that there is this systematic mapping\nbetween the connectivity of a region and its function. And connectivity fingerprints,\ndespite all these problems I've been carrying on\nabout, have enough signal left in there to predict\nthe function of a region and maybe to say something\nabout homologies across species. OK, blah, blah, blah."}, {"content": "Right. OK."}, {"content": "So where do we get? You can find the major fiber\nbundles with diffusion imaging. That's worthwhile. You can characterize\nfractional anisotropy. I don't really know what it\nmeans, but it means something. And you can find very\napproximate connectivity fingerprints good enough\nthe predict function. OK, so that's worthwhile. But actual structural\nconnections of one particular cortical area-- not very good. At best, it's a weak signal. So that's a drag. So let's consider\nthe other method people have used to try\nto work these things out. And that's resting\nfunctional correlations. So let me describe\nwhere this story starts."}, {"content": "This story starts with a\npaper in 1995 by Biswal, and this is the\nfigure from his paper. So, first he had people move-- they had-- he had people in the\nscanner doing finger-tapping. So they're lying in the scanner. He's scanning their brains while\nthey tap both fingers or not, or tap both fingers or not. And you get these-- it's\nhard to see-- these two little bits of motor\ncortex corresponding to the finger-motor region. OK, no surprise there. We're just mapping a\nlittle bit of motor cortex. But then he does something cool. He looks at the time\ncourse over that experiment in one of those motor regions-- in one hemisphere, and he\nlooks at the time course in the other hemisphere when\nthe subject is at rest, not doing anything, OK? Sorry, I left this out. You scan them doing\nthis, and then you scan them just lying there\ngoing, dum-de dum-de dum, or whatever you do when\nyou don't have a task, OK? And he finds that these very\nfar-apart regions at rest, when the subject is not\ntapping their fingers, are extremely correlated. So that's very not obvious. These things are\ncentimeters apart. The subject isn't doing\nanything in particular. You're not telling\nthem what to do. And they certainly aren't\ntapping their fingers. So why are these two bits of\nfinger-motor cortex going up and down in lockstep like that? Well, nobody knows, actually. I mean, this was however-- 20-some years ago, right? Still, nobody really knows why\nthose damn things are going up in lockstep like that. But it's systematic,\nit's tantalizing, it makes you want to play\nmore, and many people have. OK, so I would\nsay we still don't know exactly why those things\nare going up and down together. But the pattern of brain regions\nthat go up and down together has proven to be a\nwhole fascinating window into the brain. OK, so that's our\nnext topic here. OK, so here's another depiction\nof more exactly what you do. OK, so step 1-- you find a seed region in here,\nin left somatosensory motor cortex, OK? So that's that region there. You get its time course, OK? Sorry, at rest. You find that region, and\nthen you scan the person while they're just told to\ndo nothing in particular. You get the time course averaged\nover all those voxels at rest. There it is, OK? Now you take that time course. And you correlate it\nwith the time course of every other\nvoxel in the brain. And you say, show\nme all the voxels that are correlated with\nthis region at rest. And you get this-- lots of systematic\nbrain regions that are highly correlated\nat rest with that region you started with. Everybody get what we just did? OK, totally non obvious. Well, you might say, OK, fine. This is finger-motor cortex. This is the other one. That's what I showed\nyou from Biswal before. But why this thing? Why this thing way\ndown deep in the brain? Why that thing down in\nthe cerebellum miles away in the brain? Why are they all in\ncahoots with each other. I like using \"in cahoots\" when\ntalking about correlations because nobody knows what\nthe correlations mean. So \"in cahoots\" is as technical\nas I think we should get. Yeah? AUDIENCE: --correlations\nwithout a time shift. Just [INAUDIBLE]. NANCY KANWISHER: Good question. Good question. Wouldn't we love to know\nabout the time shift? But here's the problem. There should be a time shift\nbecause it takes a while to conduct down axons from\nhere to here, probably a few milliseconds. But a few milliseconds\nwe are never going to see with functional MRI. So, surely, there\nis a time shift, but this method\ncan't exploit it, OK? Yeah, I'll just\nleave it at that. OK, but does everybody\nget what this map is? We've just chosen a\nseed region, a starting point just for the hell of it. And we've asked, what\nother bits of the brain are correlated with\nthat region at rest? It's a pretty weird thing to do. And you wouldn't do it if you\ndidn't find systematically replicable answers that are\nrepeatable across subjects. And when that\nhappens, you go, OK, I don't know what this means,\nbut it's pretty systematic. Let's keep following the thread. OK?"}, {"content": "Question? AUDIENCE: What do you mean\nby correlated [INAUDIBLE]?? NANCY KANWISHER: OK,\nso let's do this again. You scan people\nmoving their fingers. You find little-finger\nregion here. Now you scan the same\nperson just in the scanner. You say, I'm going to\nscan you for five minutes. Just close your eyes and don't\ndo anything in particular. You lie there. I scan your brain. Now I take that region,\nwhich I found before. And I take the time\ncourse of that region while you were just lying in\nthe scanner doing nothing, and I get some randomish-looking\nthing like this. Now I take that time\ncourse, and I say, let's see if there are any\nother voxels in your brain that were correlated when you\nwere lying there with that time course. And I color them in, and\nthere are lots of them, even regions that are far away. OK? It's really not obvious. You wouldn't have predicted\nthis would happen, yeah? Yeah? AUDIENCE: So if you look\nat the brain just as some underlying resting rhythm\nand like just all regions of the brain just have\nsome resting rhythm, wouldn't it be just\nalways be [INAUDIBLE]?? NANCY KANWISHER: Yeah. OK, so there's been a\nwhole suite of speculations of exactly that kind. Are there endogenous\nrhythms that are characteristic of\nparticular brain regions and so those things go together? Maybe, but so far, that doesn't\nseem to be the main answer. For a long time,\npeople thought, OK, is it just blood-flow supply? Maybe the blood-flow supply\nto the brain branches and feeds those regions,\nand that somehow regulates the bold\nresponse in those regions. There have been many accounts\nlike this, and none of those seem to really capture it. It really seems like, probably,\nthose neurons are firing in sync with each other, right? Yeah, question, Nava? AUDIENCE: Yes, before a\nquestion in direction-- if you have a time\ndelay, I guess the question was because if\nyou would have a time delay, you could see what's\nfurther right. Can you, instead\nof the time delay, see if you measure it in one of\nthe regions that seems to be-- seems to be correlated-- if\nyou measure from one of those, if you could estimate the\ndistance based on how strongly they correlate [INAUDIBLE]? NANCY KANWISHER: Oh,\nwith the thought of maybe there's not a time\ndelay, but maybe you lose some of your\ncorrelation with distance. You could. But just looking at this, these\nguys are pretty far apart. So it's certainly not that\nthere's just things are-- that nearby things\nhave a similar. AUDIENCE: No, but I\nmean, if you would say those are five\ndifferent regions, did you measure from region 1? NANCY KANWISHER:\nYeah, yeah, I got you. Yeah."}, {"content": "Yeah. Yeah, you could. I think that's not going\nto work because there are big, big correlations\nthat people find between very distant regions. I'll show you more. Yeah. I mean, you could try that, and\nI'm sure people have done that. I can't tell you exactly where. Actually, they do it as part of\ntheir-- one of the common ways you normalize your data is\nto take this and normalize it for distance from the seed\nregion, which would be a way to build that factor in. And once you do that, you\nstill get lots of stuff. AUDIENCE: They take the\ndistance and the image space for that, right? NANCY KANWISHER: You can\ndo it different ways. There's an algorithm\nthat somebody at MGH wrote that is distanced by,\nmost likely, a white-matter path or as the crow flies, not\nthat the crow can fly straight through the brain, but\nyou see what I mean. Yeah."}, {"content": "Sorry, go ahead. AUDIENCE: Is the\nresult different in if you measure\nthe correlation when they're doing the finger-tapping\naction versus [INAUDIBLE]?? NANCY KANWISHER: Yeah. OK, so this is a really\nimportant question, and it's a whole\npart of this field that I'm leaving\nout of this lecture because I'm sort of\nsuspicious of it."}, {"content": "But your question is a good one. So you're saying, would\nthey be correlated while you're finger-tapping? Well, certainly, if\nwe did the paradigm while they're\ntapping both fingers, they're going to be\ncorrelated because we built the correlation into the task. We said, while you're\ndoing this, do that. And so they will\nsurely be correlated. And so there's a\nwhole enterprise where people try to factor\nout those things and ask, even after you account for\nthe activation of the task, are there changes in these\npatterns of correlation with the task you're doing? And that's called PPI for\nphysiological interactions. And lots and lots\nof people do it-- hundreds, thousands of papers. It's probably\npretty respectable, but it drives me nuts because\nI don't feel like there's any way you could\nknow that you're fully accounting for the task. And so I think those\ncorrelations may be largely reflecting regions\ncommonly activated by the task, and that's why I didn't\nput that in this lecture. But surely, task will also\nproduce correlations, right? Let me just put it another way. If I flash up a bunch\nof faces versus-- it's like faces versus nothing-- and then we look\nat the correlations during that period, well,\nyou'll find correlations between V1 and the FFA\nbecause when their face is on, both V1 and the FFA turn on. And when there aren't,\nthey both turn off. That's just a task\nresponse, right? So to be able to look at how\nthese endogenous correlations are affected by\ntask, we would have to be certain we could siphon\noff the entire task effect so that we could look\nat just the residual. And I don't think\nany of our analysis are good enough to siphon\noff an entire task effect. And that's why I just\ndon't go there with PPI, even though everyone else does. If you didn't follow\nthat, it doesn't matter. I'm just trying to\ngive you an answer. I'm going to take just\nquestions of clarification now because there's a couple of\nthings I really want to get to and I'm running out of time."}, {"content": "OK. But everybody should\nunderstand this-- an activation map that's made by\nasking, which brain regions are correlated at rest with a given\nregion I choose a seed region I choose? OK. OK, important caveat--\neven though people call this \"resting\nfunctional connectivity,\" we will not be using\nthat phrase in this class because we do not know\nthat it's connectivity in the structural sense. It's just a correlation, OK? And I'll say more\nabout that later. But if you read about resting\nfunctional connectivity, it's the same thing. It's just, I think, people\nare making a mistake using that word. OK, so let me get\nthis idea across here. You may have heard of\nthe default-mode network. There's heaps of papers on this. It's a thing. There's a lot of\ndiscussion of it. And it's bizarre. It has arisen from two\nindependent findings, OK? So let's do these\nfindings one at a time. The first one is people started\nnoticing around 15 years ago that across lots of\ndifferent kinds of tasks, if you looked at not the\nintended direction, like, say, reading sentences\nversus staring at a dot, or doing a demanding\nworking-memory task versus a really passive-viewing\ntask, anything where there's a really engaging task\nversus an easy task, you would find a\nbunch of regions that were activated in the\nreverse contrast, regions that are more activated when you're\ndoing less mental activity, typically, regions that\nare active when you're just lying there at rest compared\nto doing something difficult. And so originally, people were\nlike, what's up with that?"}, {"content": "How can that be? It seemed paradoxical,\nimpossible. But, in fact, it's\nnot impossible, right? Suppose I had you do a bunch\nof mental-arithmetic tasks, and they're pretty demanding. And I compared that to\njust having you lie there in the scanner doing nothing. It's like, OK, do mental\narithmetic for 20 seconds, rest 20 seconds, mental\narithmetic for 20 seconds, rest for 20 seconds. Now imagine we find parts of\nyour brain, systematic ones, that are more engaged at rest. What might that mean? David. AUDIENCE: That part of the\nbrain could be, I think, like daydreaming. NANCY KANWISHER:\nDaydreaming, exactly. Yeah. You can't turn your brain off. You don't turn your\nbrain off at rest. You daydream. Absolutely. What else? What are the things--\nsome of the things you do when you daydream? What are the typical\ncontents of daydreaming? I guess it depends who it is and\nwhat you're daydreaming about, but there are very\nsystematic things people do. They recall episodic memories. It's like, oh, yeah, before\nI got in here-- you replay things that were happening. And what else do you do? You think about people? Why? Because we're social\nprimates, and that's what we care a lot about. You don't think\nonly about people. Some of you guys might be\ntrying to solve a math problem that you couldn't solve before. But most people in the scan\nare asked to do nothing, are recalling events, which\nusually involve people, or thinking about people, OK? So this whole suite of brain\nregions that was called the \"default-mode network\" is\njust the regions that are more engaged when nobody tells you\nwhat to do than for a whole bunch of things when\nthey tell you what to do. And so it's some weird mix of\ndaydreaming and other stuff. And the interesting\nthing about it is they're reasonably\nsystematic. So those are the-- I keep getting confused here. Hang on. Let me get this right. Did I label this backwards? All right, they're\nthe green guys. Yeah, deactivated\nduring demanding tasks. Yeah."}, {"content": "There's too many\nnegatives for me here. The green guys here-- does\nthat look familiar, that patch? What does that look like kind\nof, not exactly but kind of? Sorry? AUDIENCE: Visual,\nthe visual system. NANCY KANWISHER: It's sort of\nnear the visual system, yeah. It is, but it's also\nlike something else we've been talking about recently. Our TPT. It's a little further back, but\nit's right in the same region, OK? And here are these\nmedial regions. There's a medial view\nof the left hemisphere, like, \"take my right hemisphere\nout and look at the inside\" view. That's this-- [INAUDIBLE]\nand sulcus, right? All these medial regions. It looks a whole lot like the\nsocial-cognition network that I talked about last time, that\nyou identify with the contrast of belief task versus-- the false-belief test\nversus a false-photo test. So that's weird\nfinding number one, that there's a\nsystematic set of regions that are engaged at rest. They're called the\ndefault-mode network because they're what you\ndo by default when nobody's controlling you externally. So that's finding number one,\nand there's finding number two."}, {"content": "But first, Jack, did\nyou have a question? AUDIENCE: Yeah. I was just wondering,\ndoes deactivated during demanding\ntasks necessarily imply that it is activated\nduring not-demanding tasks? NANCY KANWISHER: We're not\ndistinguishing between those."}, {"content": "We're just taking\nthose two conditions. You'd have to have\nsome third baseline to figure out whether\nthose two were different. And that's very problematic\nbecause we're are we having a problem saying, what\ncounts as a baseline, right? So we'll just compare\nthose two, OK? So that's weird\nfinding number one. And it's not that weird when\nyou think about it further because, of course,\nyou're doing stuff when you're lying there, right? But the further finding that\nreally put the default mode network on the map\nwas when people started putting seeds in parts\nof that default-mode network up here and finding that\nthey got the whole rest of the network at rest, OK? So all of those things\nare correlated at rest. It's not just that they're\nall activated at rest. Their time courses are\ncorrelated at rest. So, actually, what people mean\nby default mode network now is not, I took the reverse\ncontrast and all the stuff that activated more for rest than\ntask, I call that default mode. Actually, what they mean\nis I stuck a seed in there during my rest scans,\nand I took all the stuff that was correlated\nwith that position because those pick out, more\nor less, the same thing. OK? So that's led to a\nwhole lot of discussion about what the default mode\nnetwork is, and what it means, and what we can learn from it. That's what all this says."}, {"content": "I'm just trying\nto figure out how I'm going to do this because\nI'm going to run out of time. Maybe I won't run out of time. We'll just go for it."}, {"content": "OK. So people started messing\naround with these correlations at rest. And they found\nthat you could find other systematic sets of regions\nif you stuck seeds elsewhere. And so another systematic\nregion, a set of regions, is all the hot-color ones,\nthe yellow and red ones here. And so if you look\nin there, you see various things-- the\ninterparietal sulcus, a bunch of frontal regions,\nVisual-Motion area, MT, or other visual\nregions down there. And they found\nthat set of regions was strongly correlated\nwith each other at rest. You stick a seed in here, and\nyou get all that yellow stuff, OK? And then they looked at it, and\nthey said, yeah, right, we've seen those regions engage. Whenever people do demanding--\npotentially demanding tasks-- they've seen that before\nin other task contrasts. So all those things that\nturn on when you really have to pay a lot of\nattention and you're doing a really hard task-- all those regions do that,\nand they're also correlated with each other at rest. OK? And so there's this convergence\nof these two different lines of work-- task contrasts\nthat just say, what makes a given set of\nregions turn on or off, and correlations-- which\nthings are correlated at rest? OK? And so they're both\nconverging here with these two different networks. OK, so I need to\ndo a little sidebar on this other hot-color network,\nnot the default-mode network but this other one. It was originally\ncalled \"task-positive\" because it turns on more\nwhen you do tasks than rest. I mean, that's a really\nvague statement, OK? But it also has\nlots of other names, and the name that we're\ngoing to refer to here is the multiple-demand\nregions, OK? Multiple demand comes out\nfrom another line of work that just converged with us. They're picking out pretty much\nthe same set of brain regions. But \"multiple demand\" means\nlots of different kinds of cognitive demand\nactivate those same regions. OK? So I can give you a difficult\nspatial working-memory task. I can give you a\ndifficult perceptual orientation-judgment task,\na difficult arithmetic task. In each of those cases,\nI can compare them to an easy version\nof the same task, and I'll get, more or\nless, those regions there, which are-- it's getting a\nlittle vague here, but they're pretty similar to\nthe task-positive ones, OK? So this is both\ninteresting and scandalous. It's scandalous because-- to\nme only, not to anyone else-- because unlike all the regions\nwe've been talking about so far that have these very\nspecific functions-- they just do face recognition\nor just theory of mind-- these ones will do anything,\nalmost, anything difficult, OK? So whenever you engage\nin a difficult task-- I'm skipping over a\nwhole literature-- it's a big literature on this-- but lots and lots of\ntotally different kinds of tasks that have\nnothing in common other than they're very demanding--\nyou engage those regions. And in some ways, that's an\neven more fascinating puzzle. Like, what the hell would\nthose operations be? What is in common between\nspatial working memory and arithmetic and\nline-orientation judgment and all the other\nthings that have been shown to activate these\nregions when they're demanding? Nobody knows. I think it's a big,\nfascinating puzzle. Someday we'll have a\ncomputational story about what's actually\ncomputed in those regions, but we don't yet, OK? There's a lot of stuff on\nthe multiple-demand regions, and they're interesting. But I can't resist\none little thing. All right, I can't."}, {"content": "I have no self-control\nbecause I'm not-- I don't have enough\nmultiple-demand activity right now, so I'm going to have\nto just tell you these things because they're cool. OK, so a guy named John\nDuncan has spent the last 15 years arguing that the\nmultiple-demand regions first are really truly\nmultiple demand. He's tested lots and\nlots of different tasks, and they're very,\nvery domain general. But second, he thinks\nthey're implicated in fluid intelligence. Fluid intelligence differs\nfrom crystallized intelligence. Crystallized intelligence is\nstuff like your vocabulary, just stuff you've\nlearned and cached away, and facts you've stored, and\nabilities you've-- specific abilities you've stored. Fluid intelligence\nyou measure with stuff like Raven's matrices,\nwhere nothing you know is going to help you do it. You just have to be smart\nand see some abstract pattern or something like that. And so Duncan thinks\nthat these regions are related to fluid intelligence. And one of his measures of\nthat is if you find people with brain damage-- he had a big set\nof around 80 people who had brain\ndamage who he'd been studying in all different\nparts of the brain. And what he found is if you have\nbrain damage in those regions, your IQ goes down as a result\nof the damage in proportion to the amount of cortical\nvolume destroyed by the damage. If you have damage\nanywhere else in the brain, your IQ is unaffected. You may become paralyzed, or\naphasic, or prosopagnosic, or akinetopsic. You may have any of these\nvery specific deficits according to where it lands,\nbut it won't affect your IQ. And so the picture here\nis that in addition to all these special-purpose\nprocessors that this course has been focusing on, we\nhave this thing that's kind of like the brain's\nCPU or something like that. And it seems to live in\napproximately those regions, and it seems to under-- it seems to be essential\nfor fluid intelligence, OK? So I'm skipping over\nlots of literature just to heighten that this is\na particularly interesting set of regions here, OK?"}, {"content": "Yeah. AUDIENCE: Do people\nstudy novelty? NANCY KANWISHER: Yeah. AUDIENCE: The regions that\nspecialize in novelty. NANCY KANWISHER: These guys\nwill be interested in novelty. These guys will be interested\nin novelty but not only. You can do the same boring\nbut difficult task on, and on, and on, and they'll keep going."}, {"content": "OK. The reason I went\non that sidebar is that you can identify\nthese regions, not just by scanning people while\nthey're doing difficult tasks but by sticking a seed\nin any of those regions and getting the others, OK? That's the task-positive\nnetwork pretty much, OK? So we're getting\nthis convergence between sets of\nbrain regions that we find with a task contrast\nand sets of brain regions we find by finding what's\ncorrelated with what. And the bigger picture\nof this whole thing is that I've been focusing\non individual regions and what they do, and the\ngist of this whole resting functional-correlation\nliterature is a very relevant\nlevel of organization of the brain is not just an\nindividual cortical region but a set of cortical regions\nthat seem to be in cahoots. And, again, we don't know\nwhat that means exactly, but they're correlated at\nrest, and they have something to do with each other, OK? So we're finding this\nhigher-level organization, and the multiple-demand\nsystem is part of it. OK, so how are we\ngoing to look at this? So there's a bunch of these. I've talked only about the\ndefault mode network and-- it's another name for the same\nthing-- executive control. Don't worry about it. You think of that\nas multiple demand. It doesn't matter."}, {"content": "But there's a bunch of them that\nyou can find by sticking seeds in different places. And so yes, I just\nsaid the big idea here is that networks are\nan interesting level-- an interesting kind\nof unit in thinking about brain\norganization-- bigger than an individual region. It's a set of regions that\nhave something in common, OK? But I've sort of backed into\nin this awkward way of saying, OK, here are things that are\ncorrelated with each other, and here's what we know\nabout the same regions from previous task analysis. Most of the literature on\nresting functional correlation just looks at correlations and\ndoesn't try to put it together with what we know\nabout those regions, and that just seems\ndeeply weird to me. So for years, I ignored\nthis whole thing because it's like,\nI don't know what these resting correlations are. And if I don't\nknow what they are, I'm not going to work on them. And then Idan Blank came along. And when he was a first-year\ngrad student at Fedorenko, said, hey, we have all these\nresting-functional data. Let's have Idan, for his\nrotation, for a month, analyze the\nresting-functional data. I said, resting\nfunctional-- we don't know what the hell it means. Let's not bother. She's like, get over yourself. Let's let him play with it. Well, thank God she's\nnot as stuck in her ways as I am because Idan\nspent just a month playing with some of our data, and\nwhat he found blew me away. So here's what he did. He said, OK, let's start with\nactually identified regions of brain where we know\nsomething about what they do, like the language system and\nthe multiple-demand system. OK? Let's identify those\nregions in each subject individually, and then let's\nscan subjects at rest, OK? First, you scan subjects with\nsentences versus nonwords. You find the language regions. Then you scan them with a\ndifficult-versus-easy spatial working-memory task. You find the\nmultiple-demand regions. Then you scan them at rest, and\nyou get the average timecourse from each of those\nregions at rest. These are fake data, just\nto give you the gist. Makes sense? Are you with me now? Now you can ask, OK,\nwhich of these things are correlated with\neach other at rest? And this is now a\nmore interesting thing to do because we're asking this\nprincipled question of regions we know something about\nrather than random seeds in some random location, right? OK, so now what we do is we\nexamine those correlations. And we just ask, for\nexample, how correlated are those timecourses of two\ndifferent language regions or those two different parts\nof the multiple-demand system? And how strong are\nthe correlations between the systems, some little\npiece of the language system and some little piece of\nthe multiple-demand system? Makes sense?"}, {"content": "So that's a cool question to\nask, and that's what Idan did. And here's what he found."}, {"content": "Let me first orient you. So here are lots and lots\nof regions of interest that were identified\nfunctionally-- a whole bunch of language regions\nup here, a whole bunch of multiple-demand\nregions down here. The details don't matter, OK? But what I'm going to\nshow you is in each cell, we're going to have a\ncorrelation between a given-- so this would be a given part of\nthe cell over here-- given part of the multiple demand system. Sorry, a given part of\nthe multiple-demand system and some other part of the\nmultiple-demand system, or over here, a cell would\nbe some part of the language system and some part of the\nmultiple-demand system, OK? So when you do that,\nhere's what you see. Here are the correlations\nat rest between all of these pairs of conditions. And if you squint a\nlittle-- you don't even have to squint much--\nbut the black ones are the ones that are not\nsignificantly correlated at all. Blue means a\nnegative correlation, and hot colors mean a\npositive correlation. And so what you see is here\nare all the language regions. These are the right-hemisphere\nlanguage regions, which barely even count. They're just there\nfor the hell of it. This is really the\ncore language regions, and you can see\nthey're all correlated with each other, even ones\nthat are really far apart-- Broca's area and\nWernicke's area-- 10, 12 centimeters apart--\nstrongly correlated at rest, OK? And if you look\nat different parts of the multiple-demand\nsystem, they're all strongly correlated\nat rest, even regions that are far\napart-- something way up in the frontal\nlobe, something way back in the parietal lobe--\nstrongly correlated at rest. And so yeah. If you zoom in here-- so what this is really-- does everybody see that this is\nrevealing a lot of structure? Yeah, question? AUDIENCE: So the diagonals would\nbe, like, self correlation, right? NANCY KANWISHER: Yeah,\nthat's why it's black. Actually, what is it? Oh, you know what? It's split in half. It's split in half. It's actually a\nbetter way to do it. You take your data, and you\nhave two different halves of the data. And so it gives you\na baseline for the-- no, that doesn't make\nany sense, does it? Never mind. AUDIENCE: Yeah, [INAUDIBLE]. AUDIENCE: [INAUDIBLE]. AUDIENCE: [INAUDIBLE]. NANCY KANWISHER: It is maroon. AUDIENCE: If you\nlook at the spectrum on the bottom, [INAUDIBLE]. AUDIENCE: Yeah. NANCY KANWISHER:\nAll right, I'm going to have to solve this offline\nbecause I'm now confused, unless Anya can figure it out\nright now and bail us out. AUDIENCE: [INAUDIBLE] NANCY KANWISHER: Yeah, but\nas they're pointing out, it's not black. OK. AUDIENCE: [INAUDIBLE] [INTERPOSING VOICES] AUDIENCE: I'm saying\nit should be high. I was just wondering\n[INAUDIBLE].. NANCY KANWISHER: Oh,\nit's a correlation of 1. Is that what it is? AUDIENCE: Yeah. NANCY KANWISHER: OK, because\nit's correlated with itself. All right."}, {"content": "OK."}, {"content": "Thank you. Anyway, does\neverybody get the gist that all of these\ndifferent pieces of the multiple-demand\nsystem that we identified individually-- they're all\ncorrelated with each other at rest? All these different pieces\nof the language system are correlated with\neach other at rest. And there's no\ncorrelation at all between any part of\nthe language system and any part of the\nmultiple-demand system at rest. All of these-- OK,\nmaybe a couple. These cells are all either\nblack for not significant or inversely correlated. That's the cool colors. So do you see how this gives\nus a totally cool way aside from just the\nfunctional localizers we ran to identify these regions\nto show us that these things are functioning as a system, right? It's not just that Broca's area\nis a cool little thing that does a piece of language and\nsome bit of the temporal lobe is a cool thing that does\nsome piece of language. But those guys are part\nof a broader system, and these resting\nfunctional correlations are revealing this broader\nsystem and the integrity of the parts within it,\nas well as the distinction between those parts and parts\nof another system, or network. Does everybody get that idea? Good. That's a big idea\nfor this lecture."}, {"content": "I think what I'll do-- so you can-- I'll skip that. So this is basically\nthe correlation between all of the cells\nwithin the language system, all of the cells within\nthe multiple-demand system, and any pair of cells\nbetween systems here. So that's just averaging over\nthe matrix I showed you before. And so this is a cool\nway to ask about broader systems in the brain. And I was going to show you some\ndata published just a month ago that asked this question\nnot just about the language and multiple-demand\nsystems but also, about the theory-of-mind\nnetwork, which is basically really similar to the\ndefault mode network. But the theory-of-mind\nnetwork we can identify that we\ntalked about last time. And you can go think offline. Actually, I'll\ntake a suggestion."}, {"content": "What do you think? Should the\ntheory-of-mind network be correlated with\nthe language system, with the multiple-demand\nsystem, both, or neither? AUDIENCE: Neither. NANCY KANWISHER: Neither? Why? AUDIENCE: This is\nsomething different. NANCY KANWISHER: OK, that's\na totally reasonable answer, and that's largely\ntrue but not 100% true. What else might you think? It is a different system,\nand it does function quite independently\nbut not perfectly. Yeah. AUDIENCE: Because it's\n[INAUDIBLE] analyzing [INAUDIBLE] NANCY KANWISHER: All right. That's a lovely speculation\nand an intelligent one, and it's half true."}, {"content": "I'll just skip to the data. So in this very recently\npublished paper, Alex Paunov, and Idan\nBlank, and Ev Fedorenko looked at the language system,\nthe theory-of-mind network, which is not just the TPJ\nbut these other regions that I mentioned\nbriefly that you also get in the contrast of\nthe false-belief test versus the false-photo task and\nthe multiple-demand network. Same deal-- identify each of\nthose regions in each subject individually, then scan\nthe subject at rest and see what's\ncorrelated with what. And here's the answer. You see, again, replicate the\nlanguage system, especially in the left hemisphere. The theory of mind\nsystem is all a system. And the multiple-demand system\nis a system, separate system. But if you look in\nat the cell where you have theory of\nmind and language, it's slightly above\nchance, not theory of mind in multiple demand but theory\nof mind in language, probably for just the reason you said,\nthe whole essence of language, even though it's\na different thing, than thinking about the contents\nof someone else's thoughts. They are so enmeshed\nin each other. The reason we have language\nis to take our thoughts and put them in your head\nand take your thoughts and put them in our head. And so it makes sense that\nthose things are a little bit correlated. AUDIENCE: [INAUDIBLE] language? NANCY KANWISHER: Yeah."}, {"content": "Yeah. But neither of\nthem is correlated with multiple-demand. It's 1:26, so-- or-- wait. Am I reading the wrong-- yeah-- oh, 12:28. Sorry. There's a number here. That's how long\nI've been talking. So 12:28-- so if you\nneed to go, that's fine, but I'm happy to\nanswer questions. So go ahead. AUDIENCE: I was\njust going to say, there was a review paper\nabout [INAUDIBLE] talked about how there's a behavioral\nconnection between theory of mind and, like, when children\nstarted to learn [INAUDIBLE].. NANCY KANWISHER: Lots of links,\nespecially developmentally, yeah. Yeah. Did you have a-- AUDIENCE: By an\nextension of that, [INAUDIBLE] should be\ncorrelated to the theory of mind [INAUDIBLE]? NANCY KANWISHER: Yes,\nwouldn't you think? Not really. AUDIENCE: [INAUDIBLE] NANCY KANWISHER: The\nFFA is irritating. It's not strongly\ncorrelated with the things it ought to be correlated with."}]}